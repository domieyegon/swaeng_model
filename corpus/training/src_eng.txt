It has never been easy to have a rational conversation about the value of gold.
Lately, with gold prices up more than 300% over the last decade, it is harder than ever.
Just last December, fellow economists Martin Feldstein and Nouriel Roubini each penned op-eds bravely questioning bullish market sentiment, sensibly pointing out gold’s risks.
Wouldn’t you know it?
Since their articles appeared, the price of gold has moved up still further. Gold prices even hit a record-high $1,300 recently.
Last December, many gold bugs were arguing that the price was inevitably headed for $2,000.
Now, emboldened by continuing appreciation, some are suggesting that gold could be headed even higher than that.
One successful gold investor recently explained to me that stock prices languished for a more than a decade before the Dow Jones index crossed the 1,000 mark in the early 1980’s.
Since then, the index has climbed above 10,000.
Now that gold has crossed the magic $1,000 barrier, why can’t it increase ten-fold, too?
Admittedly, getting to a much higher price for gold is not quite the leap of imagination that it seems.
After adjusting for inflation, today’s price is nowhere near the all-time high of January 1980.
Back then, gold hit $850, or well over $2,000 in today’s dollars.
But January 1980 was arguably a “freak peak” during a period of heightened geo-political instability.
At $1,300, today’s price is probably more than double very long-term, inflation-adjusted, average gold prices.
So what could justify another huge increase in gold prices from here?
One answer, of course, is a complete collapse of the US dollar.
With soaring deficits, and a rudderless fiscal policy, one does wonder whether a populist administration might recklessly turn to the printing press.
And if you are really worried about that, gold might indeed be the most reliable hedge.
Sure, some might argue that inflation-indexed bonds offer a better and more direct inflation hedge than gold. But gold bugs are right to worry about whether the government will honor its commitments under more extreme circumstances.
In fact, as Carmen Reinhart and I discuss in our recent book on the history of financial crises, This Time is Different, cash-strapped governments will often forcibly convert indexed debt to non-indexed debt, precisely so that its value might be inflated away.
Even the United States abrogated indexation clauses in bond contracts during the Great Depression of the 1930’s.
So it can happen anywhere.
Even so, the fact that very high inflation is possible does not make it probable, so one should be cautious in arguing that higher gold prices are being driven by inflation expectations.
Some have argued instead that gold’s long upward march has been partly driven by the development of new financial instruments that make it easier to trade and speculate in gold.
There is probably some slight truth – and also a certain degree of irony – to this argument.
After all, medieval alchemists engaged in what we now consider an absurd search for ways to transform base metals into gold.
Wouldn’t it be paradoxical, then, if financial alchemy could make an ingot of gold worth dramatically more?
In my view, the most powerful argument to justify today’s high price of gold is the dramatic emergence of Asia, Latin America, and the Middle East into the global economy.
As legions of new consumers gain purchasing power, demand inevitably rises, driving up the price of scarce commodities.
At the same time, emerging-market central banks need to accumulate gold reserves, which they still hold in far lower proportion than do rich-country central banks.
With the euro looking less appetizing as a diversification play away from the dollar, gold’s appeal has naturally grown.
So, yes, there are solid fundamentals that arguably support today’s higher gold price, although it is far more debatable whether and to what extent they will continue to support higher prices in the future.
Indeed, another critical fundamental factor that has been sustaining high gold prices might prove far more ephemeral than globalization.
Gold prices are extremely sensitive to global interest-rate movements.
After all, gold pays no interest and even costs something to store.
Today, with interest rates near or at record lows in many countries, it is relatively cheap to speculate in gold instead of investing in bonds.
But if real interest rates rise significantly, as well they might someday, gold prices could plummet.
Most economic research suggests that gold prices are very difficult to predict over the short to medium term, with the odds of gains and losses being roughly in balance.
It is therefore dangerous to extrapolate from short-term trends.
Yes, gold has had a great run, but so, too, did worldwide housing prices until a couple of years ago.
If you are a high-net-worth investor, a sovereign wealth fund, or a central bank, it makes perfect sense to hold a modest proportion of your portfolio in gold as a hedge against extreme events.
But, despite gold’s heightened allure in the wake of an extraordinary run-up in its price, it remains a very risky bet for most of us.
Of course, such considerations might have little influence on prices.
What was true for the alchemists of yore remains true today: gold and reason are often difficult to reconcile.
Last week Tony Blair, Jacques Chirac, and Gerhard Schroeder met in Berlin.
They departed pledging to revive Europe's growth.
We've heard that empty promise before.
Instead, the European Union needs a new direction.
I say this as leader of the party which has been at the forefront of Britain's engagement with Europe.
It was a Conservative government that first applied for membership in the early 1960's.
A Conservative government took the United Kingdom into the European Economic Community in 1973.
Margaret Thatcher worked with Jacques Delors to forge the Single Market in 1986.
So I have no doubt that Britain must remain influential within the Union.
But British policy towards the EU has often led to worse rather than better relations among member states.
Faced with a new EU initiative, our traditional response has often been to oppose it, vote against it, lose the vote, then sulkily to adopt it while blaming everyone else.
Many Europeans are sick of British vetoes.
So am I.
Of course there are basic requirements that all member states must accept.
Foremost are the four freedoms of the single market; free movement of goods, services, people and capital.
But a single market does not require a single social or industrial policy, far less a common taxation policy.
Allowing countries to pursue their own policies in these areas encourages competitiveness.
Forcing common standards means that Europe will fall further behind as member states shuffle their costs onto their neighbours.
Which areas should be applied to every member state, and which should be optional?
I believe that every member state should administer those policies that do not directly and significantly affect other member states.
In areas which serve their national interest, individual members should decide whether to retain wholly national control or whether to co‑operate with others.
The Union's members should form a series of overlapping circles: different combinations of members should be able to pool their responsibilities in different areas of their own choosing.
Precedents exist for this.
NATO has been flexible since its inception.
France signed up for membership but later refused to submit her armed forces to NATO's central command.
Similar flexibility exists with the Euro, the Schengen Agreement, and the Social Chapter.
These precedents can be extended.
So far, everyone has had to move forward together, with individual countries negotiating specific opt‑outs.
But since 1998, there has been a procedure within the Treaties - called enhanced co‑operation - that could allow some members to go ahead with further integration in a specific area without involving every other member.
Instead of individual member states having fraught negotiations to opt‑out of a new initiative, those that support it can simply opt‑in.
Countries that want to integrate further can do so.
They don't need to drag Britain and others kicking and screaming in their wake because the others are not compelled to join them.
In this way we can break free of the institutionalised tug of war that has characterised EU relations.
I am not talking about a two‑speed Europe.
That implies that we all agree on the destination and differ only about the speed of the journey.
I don't want to reach the destination that some of our partners may aspire to.
But I don't want to block their way.
There are some who say that this would mean a loss of influence on the part of those countries which choose not to integrate more closely.
But influence is not an end in itself - it is a means to an end.
Britain does not need a seat at the table when decisions on the Euro are taken.
Our economy has not been adversely affected by staying out.
Keeping the pound does not mean that we oppose the Euro, or hope for its failure.
The European Union should stop trying to do everything and concentrate on doing fewer things more effectively.
It should give member states the chance to develop an approach to Europe that suits their national traditions, within the EU framework.
It is on this basis that British Conservatives oppose the proposed constitution.
We disagree with many of its contents, of course, but also oppose the idea of having an EU constitution at all.
There is a world of difference between an association of nation states bound together by treaty, and a single entity, whether you call it a state or not, with its own legal personality, deriving its authority from its own constitution.
If this constitution were accepted in anything like the proposed form, the EU would gain many attributes and trappings of statehood: its own president and foreign minister, its own legal system.
The supremacy of EU law would derive not from Acts of national Parliaments but from a supra‑national constitution.
That is a radical change, not the mere tidying‑up exercise some suggest.
I do not believe it is right to make a change of such magnitude without specifically consulting the people on whose behalf we govern.
Elected parliaments do not own our liberties.
They safeguard them, and should not diminish those liberties without an explicit mandate.
Any proposal for a new constitution must be put to the British people and to the people in each EU member state.
BRUSSELS – Austerity alone cannot solve Europe's economic and financial crisis.
Growth and jobs need to be promoted with equal zeal.
European Union leaders now recognize this: kick-starting growth in 2012 was high on the agenda at the European Council’s meeting on January 30.
But the big question remains: How?
The need for immediate action is clear.
The eurozone’s economy contracted in the last three months of 2011; even Germany’s shrank.
The new year is looking grim.
France is flat-lining (as is Britain).
Italy and Spain have sunk into deep recession.
Greece is in its fifth year of a slump.
And eurozone unemployment is at record highs, with nearly one in two young people jobless in Spain and Greece.
The economic headwinds are formidable: fiscal austerity, high interest rates outside AAA-rated countries, credit cutting by banks, deleveraging households, weak private-sector investment, and declining exports as the global slowdown undermines demand.
Until growth resumes, any tentative financial stabilization will be extremely fragile.
Recession will hit banks’ and governments’ already-weak balance sheets, increasing pressure for faster deleveraging.
But, while gradual adjustment is essential, faster and deeper cuts are largely self-defeating: big reductions in private credit and government spending will cause a sharper slowdown – and thus a vicious downward spiral.
A big new push for growth is therefore vital.
So far, the growth agenda has consisted largely of structural reforms, which are essential for boosting future productivity and flexibility.
The crisis does provide a political opportunity for bold moves on this front in many countries; but structural reforms generally will not generate growth and jobs immediately (one exception is permitting shops to open longer).
On the contrary, a shakeout of less productive jobs, for example, would at first raise unemployment, increase government outlays, and reduce private spending.
And, because demand is depressed, credit is in short supply, and barriers to enterprise are often high, it will take longer than usual for businesses to create more productive jobs.
In short, structural reforms alone cannot be relied upon to stimulate growth in 2012.
Instead, the immediate focus needs to be on boosting investment and exports in economies with a current-account deficit – such as France, Italy, and Spain (and the United Kingdom) – and stimulating consumption in surplus countries such as Germany and the Netherlands.
The European Central Bank has acted decisively to prop up European banks; now it needs to support the real economy, too.
While official interest rates are only 1%, solvent sovereigns such as Spain pay more than 5% to borrow for ten years, while creditworthy businesses in Italy can borrow only at punitive rates, if at all.
So the ECB should do more to unblock the transmission mechanism for monetary policy; the European Banking Authority should discourage excessive deleveraging by insisting that banks raise specific capital amounts rather than hit a uniform 9% ratio; and, where necessary, national governments should provide guarantees for bank lending to small and medium-size businesses.
While improving access to finance is vital, governments also need to do more to boost investment.
They should prioritize measures to make it easier to start a business, lift barriers to venture capital, and introduce temporary 100% capital allowances to encourage businesses to bring forward investment.
At the EU level, the (callable) capital of the European Investment Bank should be greatly increased, as European Commission President José Manuel Barroso suggested in his State of the Union speech last September, so that the EIB can finance a big wave of pan-European investment, notably in infrastructure.
Boosting exports is also essential.
Deficit countries need to become more competitive, increasing productivity while cutting costs.
A more competitive currency would be welcome: just as the sterling’s collapse since 2008 has lifted UK exports, a weaker euro would help Mediterranean economies regain competitiveness for price-sensitive exports.
A fiscal devaluation – slashing payroll taxes and replacing the revenues with a higher VAT – would also help.
Surplus countries, too, must do their part, which is in their own interest.
Just as China needs to allow the renminbi to rise, so Germany – whose current-account surplus exceeds China's both as a share of GDP and in absolute terms – needs a higher real exchange rate.
That means that Germans need to earn higher wages, commensurate with their increased productivity, so that they can afford more Greek and Spanish holidays.
If businesses will not oblige, an income-tax cut would do the trick.
That brings us to fiscal policy.
Governments that cannot borrow cheaply (or at all) from markets have no option but to tighten their belts.
But they should pursue smart consolidation rather than unthinking austerity.
So they should maintain investment in skills and infrastructure, while cutting subsidies and transfer payments.
They should also legislate now for future reforms, notably to encourage people to work longer.
Last but not least, governments that can borrow at unprecedentedly low rates – 0% in real terms over 10 years in the case of Germany – must play their role in supporting demand.
Would it be really be so difficult to see VAT coming down ahead of the German election next year?
At the onset of the US-led war in Iraq, two competing views shaped predictions about the outcome.
The first contended that overthrowing Saddam Hussein's regime would usher in a democratic era in Iraq that would serve as a model and catalyst for democratic change regionally.
Derided by detractors as a new "domino theory," this view presented intervention in Iraq as similar to America's role in post-WWII Japan.
Against the optimism of that "Japan scenario," pessimists argued that a "Somalia scenario" was more likely.
They staked their claim on the tribal, sectarian, and multiethnic nature of Iraq, which, in the absence of dictatorship, would supposedly incite Iraq's collapse into a "failed state," with rampant warlordism, ethnic and religious feuds, and harboring of terrorist organizations.
But the main question now is whether Iraq will drift along lines somewhere between these two scenarios, increasingly resembling Afghanistan.
This "Afghan scenario" implies a weak state with nominal power over effectively autonomous fiefdoms that are headed by strongmen who are represented in the central government.
Bad as it sounds, this prospect appears to be a "realistic" compromise between the supposedly utopian vision of a flourishing, unified democracy and the wretchedness of a failed state.
Many of the actions and policies of the Coalition Provisional Authority (CPA), as well as higher-level Bush administration decisions, seem to point to a resigned acceptance that early hopes that Iraq would embrace Western-style democracy were misplaced.
Indeed, such hopes were misplaced.
Iraq's political culture - and that of most of the Middle East - is incompatible with the basic components of a recognizable Western-style democracy: notions of individual rights and responsibilities are lacking, the concept of a patriarchal state is deeply rooted, and individual cultural identity is rarely tied to the national community.
On the other hand, much circular logic figures in analyses that consider the "traditional" nature of Iraqi society an obstacle to liberal democracy.
For these analyses are hardly neutral, but unwittingly enter an ongoing confrontation.
In Iraq, as elsewhere in the Arab and Muslim worlds, a cultural war is being waged between two paradigms: grand narratives that accept and promote a collectivistic understanding (nationalism, socialism, Islamism), versus an implicit paradigm of individualistic modernity that is locally rooted yet informed by the global experience.
The frontlines of this war are notions of the individual, cultural identity, civil society, and the nation-state.
The religious Islamic component in Iraqi social life should not be underestimated.
But it also should not be equated with the political Islamism that strives to capitalize on it.
Nationalist and leftist political discourses did leave an imprint on the Iraqi value system, but they are not its sole components.
Indeed, the nominal acceptance of grand narratives of "democracy" and "human rights" as common bases for political discourse represents a crucial shift in demarcating the cultural battle.
This cultural debate is not limited to the Arab scene.
There are also vigorous discussions in the West about the applicability of democratic institutions to the Arab context.
Advocates of the notion of "Arab exceptionalism," which questions the ability of Arab societies to adapt democratic systems are in fact objectively allied with "grand narrative" ideologues - and also with the beneficiaries of the Arab world's patronage-based political order.
The models used in the West, both in political circles and in academia, for the analysis and interpretation of Arab societies are seriously deficient.
In particular, many analyses nowadays promote an ethnic model, reducing Iraq to an artificial construct that rests atop a fragmented "reality" of separate communities.
Some have even suggested hastening the outcome predicted by this faulty view by dividing Iraq into its "genuine" original components: Sunni, Shi`i, and Kurd.
In fact, Iraqi society is more complex than this.
The reception and adoption of democracy is not a function of sectarian belonging, but a reflection of the multi-dimensional historical, cultural, religious, and political identities of Iraqi individuals.
Given the right circumstances, it is eminently possible to mobilize Iraqi society towards a democratic formulation of its state-to-be.
The fall of Saddam ushers in the right circumstances.
Indeed, the seeming failure of a recognizable democratic core to emerge in Iraq within the first few months of the collapse of Saddam's dictatorship is due more to idiosyncrasies of the process than to any presumed essential nature of Iraqi society.
Upon Saddam's fall, a large "middle ground" existed in Iraq that was positively disposed towards democratic discourse and practice.
Policy mistakes and reversals eroded this middle ground, opening a path for ideological Islamism and a reconstituted neo-Ba`athism.
The key mistake was the failure of occupation forces to equip and empower the small group of Iraqi liberal democratic figures to tap into this middle ground.
As a result, the space for a liberal democratic outcome receded.
But to treat this setback as a failure would be a self-fulfilling prophecy.
Iraqi democrats must re-assess and develop a clear public strategy.
The CPA, and the world community, must not prejudice the outcome of their efforts by accepting a facile and bogus view of Iraqi society.
Even if such efforts succeed, the road to a full-fledged democratic system in Iraq will still be arduous and expensive.
But instead of succumbing to a "Somalia scenario," dreaming of a "Japan scenario," or settling for an "Afghanistan scenario," Iraq may yet become a "scenario" for successful intervention in the 21 st century.
Although the EU's eastward enlargement has not yet happened, the debate is already shifting to ask what will follow: when should the new, predominantly postcommunist, members adopt the euro?
Assuming that they comply with the Maastricht Treaty's provisions concerning the EMU - and are not unfairly held to more stringent criteria - the core issue is whether new members would benefit more by waiting or whether they should seek early entry. 
At the outset, it must be stressed that, in seeking earlier entry into the EMU a country assumes a more ambitious fiscal and structural program than would be needed if EMU membership is delayed.
Early entry, otherwise, would be an empty gesture. 
I believe that early adoption of the euro is not only possible, but preferable to delay.
By early adoption I mean the shortest permissible period of time - two years - following a new member subordinating its monetary policy to the fiscal and monetary constraints of the exchange rate mechanism (ERM II).
Assuming entry into both the EU and ERM II in 2004, new members should aim to enter the eurozone around 2006. 
Is this realistic?
Well, most candidate countries have already achieved a high degree of structural convergence with the EU.
Exports to the Union have soared since 1991, when the collapse of the Soviet-era COMECON trading system forced a radical reorientation of trade - helped by massive foreign investment from the EU - towards Western markets.
Most accession candidates now send more exports to the EU than Greece, Portugal, and Spain did when they entered the EU and EMU. 
Progress on disinflation is similarly impressive.
Annual inflation in most candidate countries has fallen to 4-5% - not much higher than in many EU countries, and lower than in The Netherlands last year.
As with structural convergence, EU candidates already outperform Spain, Portugal, and Greece at a comparable time before their EMU debut.
Nor is there much risk of large, future corrective price swings because all but a few prices are completely liberalized. 
Theoretical studies suggest that inflation in the accession countries will remain stubbornly higher than the Maastricht Treaty allows.
The culprit in this pessimistic view is the so-called "Balassa-Samuelson" effect: rapid productivity growth in the accession candidates' tradable sectors - export manufacturing, for example - is pushing up real wages throughout their economies, including in non-tradable sectors like services.
This overall rise in real wages in the face of lower productivity growth for the service sector boosts relative prices and keeps inflation above the eurozone average. 
The Balassa-Samuelson effect is still evident in Greece, Spain and Portugal.
But as empirical research prepared by the CEC5 National Banks estimates, its contribution to total price growth in the candidate countries is 1-2%.
With the Balassa-Samuelson effect so subdued and limited scope for future corrective inflation, the EMU criterion regarding price stability - of annual inflation within 1.5% of the average rate for the three best-performing economies in the EU - is within reach. 
But is early admission to EMU preferable to postponing membership?
From the standpoint of current member states, would admitting Hungary, Latvia, Poland, or Slovakia, sooner rather than later, drag down the euro as many fear? 
Fears that extending EMU to new states "too soon" would undermine the euro's external exchange rate are irrational.
If all candidate countries join the EU at around the same time, they will together account for a mere 6% of its total GDP.
So any negative impact on the euro from rapid accession to EMU would at worst amount to little more than a rounding error. 
Delaying entry into EMU could make sense if a longer wait produced more information.
But a wait of greater length might produce nothing but added noise.
Equally, the transition period is already turbulent, with convergence-driven capital flows driving up exchange rates and complicating monetary policy in several candidate countries, including Poland, the Czech Republic, and Hungary.
Indeed, capital-flow volatility could make short work of the flexible exchange rate on offer under ERM II - a 15% fluctuation band either side of a central parity. 
Some argue that ERM II membership should be viewed as a longer-term proposition - possibly lasting until 2010 - for the benefit of candidates themselves.
The benefit is simple: ERM II permits some exchange rate flexibility, as opposed to the fixed rates implied by adopting the euro.
This would help keep the candidates' economic output high and thus sustain real convergence with average EU income levels. 
This is an exceptionally weak argument, and a politically suspect one, too.
As European Central Bank data shows, average per capita GDP in the accession candidates is 44% of the eurozone level.
The size of the income gap combines with the small growth differentials to imply that the process of real convergence will extend far beyond even the most cautious dates for EU and EMU entry, probably lasting several decades.
More important, long-lasting economic growth does not depend on the type of exchange rate - whether flexible or fixed (EMU) - while early accession will speed up crucial reforms. 
A few years of limited exchange rate flexibility is a poor substitute for rapid completion of structural reforms.
In almost all candidates, further disinflation and long-term economic growth require fiscal consolidation, more flexible labor markets, and completion of privatization.
Delaying EMU entry risks weakening the incentive to complete these politically costly but necessary reforms. 
Any delay in completing reforms will ultimately slow the process of real convergence that EU officials rightly hold dear.
Early adoption, by contrast, would be more conducive to these reforms, and thus to real convergence.
Success here would allow candidate countries to start reaping the benefits of greater price transparency, reduced transaction costs, and a solid macroeconomic framework.
This strategy, not one of deferred entry, promises the most for both the EU's current and its future members. 
PARIS – As the economic crisis deepens and widens, the world has been searching for historical analogies to help us understand what has been happening.
At the start of the crisis, many people likened it to 1982 or 1973, which was reassuring, because both dates refer to classical cyclical downturns.
Today, the mood is much grimmer, with references to 1929 and 1931 beginning to abound, even if some governments continue to behave as if the crisis was more classical than exceptional.
The tendency is either excessive restraint (Europe) or a diffusion of the effort (the United States).
Europe is being cautious in the name of avoiding debt and defending the euro, whereas the US has moved on many fronts in order not to waste an ideal opportunity to implement badly needed structural reforms.
For geo-strategists, however, the year that naturally comes to mind, in both politics and economics, is 1989.
Of course, the fall of the house of Lehman Brothers has nothing to do with the fall of the Berlin Wall.
Indeed, on the surface it seems to be its perfect antithesis: the collapse of a wall symbolizing oppression and artificial divisions versus the collapse of a seemingly indestructible and reassuring institution of financial capitalism.
Yet 2008-2009, like 1989, may very well correspond to an epochal change, whose unfolding consequences will be felt for decades.
The end of the East-West ideological divide and the end of absolute faith in markets are historical turning points.
And what happens in 2009 may jeopardize some of the positive results of 1989, including the peaceful reunification of Europe and the triumph of democratic principles over nationalist, if not xenophobic, tendencies.
In 1989, liberal democracy triumphed over the socialist ideology incarnated and promoted by the Soviet Bloc.
For many of his supporters, it was President Ronald Reagan who, with his deliberate escalation of the arms race, pushed the Soviet economy to the brink, thereby fully demonstrating the superiority of liberal societies and free markets.
Of course, there are obvious differences between 1989 and now.
First, and perhaps above all, the revolutions of 1989 and the subsequent collapse of the Soviet Union put an end to global bipolarity.
By contrast, 2009 is likely to pave the way to a new form of bipolarity, but with China substituting for the Soviet Union.
Second, whereas democracy and market capitalism appeared as clear – if more fragile than expected – winners in 1989, it is difficult in 2009, with the spread of the global crisis, to distinguish winners from losers.
Everyone seems to be a loser, even if some are more affected than others.
Yet, history is unfair, and the US, despite its greater responsibility for today’s global crisis, may emerge in better shape than most countries from the morass.
In better shape, but not alone.
As a visiting professor at Harvard and MIT, I am getting a good preview of what the world could look like when the crisis finally passes.
One senses something like the making of an American-Asian dominated universe.
From the incredible media lab at MIT to the mathematics and economics departments at Harvard, Asians – Chinese and Indians, in particular – are everywhere, like the Romans in Athens in the first century BC: full of admiration for those from whom they were learning so much, and whom they would overcome in the coming decades.
But before this new order appears, the world may be faced with spreading disorder, if not outright chaos.
What, for example, will happen to a country as central and vulnerable as Egypt when hundred of thousands of Egyptians working in the Gulf are forced to return to their homeland as a result of the crisis in the oil-producing countries?
When the rich get less rich, the poor get poorer.
And what about the foreign workers who have reached for the “European dream” and are now faced with potential explosions of xenophobia in Europe’s supposedly open countries?
The consequences of 1989 ended up being less enduring than many observers, including me, would have assumed.
We can only hope that, in the end, the consequences of 2009 similarly prove to be far less dramatic than we now – intuitively and in our historical reflexes – feel them to be.
MOSCOW – Most people who know of me think of me as an information-technology expert, someone who probably lives in California and invests in edgy Internet start-ups.
In fact, my formal residence is in New York City, but I am about to spend most of the next five months in Russia, training to be a cosmonaut in Star City, just outside Moscow. 
It all came about in a number of ways.
First of all, as a kid, I just assumed that I would go to the moon, without having to do much in particular to make it happen.
I just took it for granted that, by the time I was, say, 40, space travel would be a common thing.
My father was involved with the United States space program, and we had some moon rocks at home, so I thought it was no big deal.
Then I got distracted for about 40 years.
A few years ago, however, I started paying attention to space again.
A lot of people I knew in the IT industry were doing the same: Elon Musk, a co-founder of PayPal, founded Space-X; Jeff Bezos of Amazon started a spacecraft company called Blue Origin; Jeff Greason, a senior manager at Intel, started XCOR Aerospace (in which I’m an investor).
In 2005, the last year I held my PC Forum conference for IT entrepreneurs, I started a conference called Flight School for entrepreneurs in space and private aviation.
Meanwhile, in about 2005, I was in South Africa with a small group advising former President Thabo Mbeki and his government about its IT policy.
One of the group was Mark Shuttleworth, founder of Thawte (sold to VeriSign), who had recently come back from a trip to the space station as the second “space tourist.”
One evening, the group sat around a campfire as the sun set, and around 50 African schoolchildren were bussed in.
Altogether, there were about 100 of us, President Mbeki included, around a roaring fire.
Once it was dark, a screen was set up and Mark showed home videos from space.
He gave a fascinating talk about his adventures, complete with clips of him floating around, catching bubbles in his mouth, and so on.
The kids loved it, and I'm sure some of them decided then and there to study math and science.
Eventually, I invested in Space Adventures, the company that organized Shuttleworth’s trip into space.
Later, I went on a tour that they organized to watch the launch of Charles Simonyi, the fifth (and soon seventh) space tourist, from Baikonur in Kazakhstan.
(Simonyi wrote the Microsoft Word program, and now has another start-up, Intentional Software, and a foundation, as well as a Web site, CharlesinSpace.org.)
Soon after, I started casually discussing the notion of becoming a backup cosmonaut with the Space Adventures team.
Yes, I would love to actually go, but the trip to space costs $35 to $40 million, whereas backup training costs “only” $3 million.
So I had vague thoughts that I might go into space sometime in 2011 - the year that Google co-founder Sergey Brin is (very) tentatively slated to go.
Space Adventures was pushing for 2009, but I was pretty busy.
Then something happened last spring: my sister Emily discovered that she had cancer and had a double mastectomy.
(She is doing well now and, in fact, just won a mini-marathon.)
A couple of weeks later, I was faced with one of those conflicts: a board meeting here, a conference there, another opportunity at the same time somewhere else. “Aaagh,” I thought, “if only I had a double mastectomy: I could cancel all these things and no one would complain!”

Good grief!  I realized my priorities were all out of whack.   So in some odd way, this sabbatical in Russia is my alternative to a double mastectomy – a positive one, to be sure, but the same kind of reset-button experience. 
It is also the answer to another question I hear a lot because of my work on human genetics through 23andMe (www.23andme.com) and the Personal Genome Project (www.personalgenome.org): If you learned you had a high chance of developing Alzheimer’s in a few years, what would you do?
Why, I’d go train to be a cosmonaut, of course! And why wait to find out I may get Alzheimer’s?  Next month, I will write about what training to go into space actually involves.
Five years after the attacks on the Twin Towers in New York and the Pentagon in Washington, “9/11” is no longer a mere date.
It has entered the history books as the beginning of something new, a new era perhaps, but in any case a time of change.
The terrorist bombings in Madrid and London and elsewhere will also be remembered; but it is “9/11” that has become the catchphrase, almost like “August 1914.”
But was it really a war that started on September 11, 2001?
Not all are happy about this American notion.
During the heyday of Irish terrorism in the UK, successive British governments went out of their way not to concede to the IRA the notion that a war was being waged. “War” would have meant acceptance of the terrorists as legitimate enemies, in a sense as equals in a bloody contest for which there are accepted rules of engagement.
This is neither a correct description nor a useful terminology for terrorist acts, which are more correctly described as criminal.
By calling them war – and naming an opponent, usually al-Qaeda and its leader, Osama bin Laden – the United States government has justified domestic changes that, before the 9/11 attacks, would have been unacceptable in any free country.
Most of these changes were embodied in the so-called “USA Patriot Act.”
Though some of the changes simply involved administrative regulations, the Patriot Act’s overall effect was to erode the great pillars of liberty, such as habeas corpus , the right to recourse to an independent court whenever the state deprives an individual of his freedom.
From an early date, the prison camp at Guantánamo Bay in Cuba became the symbol of something unheard of: the arrest without trial of “illegal combatants” who are deprived of all human rights.
The world now wonders how many more of these non-human humans are there in how many places.
For everyone else, a kind of state of emergency was proclaimed that has allowed state interference in essential civil rights. Controls at borders have become an ordeal for many, and police persecution now burdens quite a few.
A climate of fear has made life hard for anyone who looks suspicious or acts suspiciously, notably for Muslims.
Such restrictions on freedom did not meet with much public opposition when they were adopted.
On the contrary, by and large it was the critics, not the supporters, of these measures who found themselves in trouble.
In Britain, where Prime Minister Tony Blair supported the US attitude entirely, the government introduced similar measures and even offered a new theory.
Blair was the first to argue that security is the first freedom.
In other words, liberty is not the right of individuals to define their own lives, but the right of the state to restrict individual freedom in the name of a security that only the state can define.
This is the beginning of a new authoritarianism.
The problem exists in all countries affected by the threat of terrorism, though in many it has not become quite as specific.
In most countries of continental Europe, “9/11” has remained an American date.
There is even a debate – and indeed some evidence – concerning the question of whether involvement in the “war against terrorism” has actually increased the threat of terrorist acts.
Germans certainly use this argument to stay out of the action wherever possible.
This stance, however, has not prevented the spread of something for which a German word is used in other languages, too: Angst .
A diffuse anxiety is gaining ground.
People feel uneasy and worried, especially when traveling.
Any train accident or airplane crash is now at first suspected of being an act of terrorism.
Thus, 9/11 has meant, directly or indirectly, a great shock, both psychologically and to our political systems.
While terrorism is fought in the name of democracy, the fight has in fact led to a distinct weakening of democracy, owing to official legislation and popular angst.
One of the worrying features of the 9/11 attacks is that it is hard to see their purpose beyond the perpetrators’ resentment of the West and its ways.
But the West’s key features, democracy and the rule of law, have taken a far more severe battering at the hands of their defenders than by their attackers.
Two steps, above all, are needed to restore confidence in liberty within the democracies affected by the legacy of 9/11.
First, we must make certain that the relevant legislation to meet the challenge of terrorism is strictly temporary.
Some of today’s restrictions on habeas corpus and civil liberties have sunset clauses restricting their validity; all such rules should be re-examined by parliaments regularly.
Second, and more importantly, our leaders must seek to calm, rather than exploit, public anxiety.
The terrorists with whom we are currently at “war” cannot win, because their dark vision will never gain broad popular legitimacy.
That is all the more reason for democrats to stand tall in defending our values – first and foremost by acting in accordance with them.
NEW YORK – It was a decade ago that 19 terrorists took control of four planes, flew two into the twin towers of the World Trade Center, hit the Pentagon with a third, and crashed the fourth in a field in Pennsylvania after passengers resisted and made it impossible for the terrorists to complete their malevolent mission.
In a matter of hours, more than 3,000 innocent people, mostly Americans, but also people from 115 other countries, had their lives suddenly and violently taken from them.
September 11, 2001, was a terrible tragedy by any measure, but it was not a historical turning point.
It did not herald a new era of international relations in which terrorists with a global agenda prevailed, or in which such spectacular terrorist attacks became commonplace.
On the contrary, 9/11 has not been replicated.
Despite the attention devoted to the “Global War on Terrorism,” the most important developments of the last ten years have been the introduction and spread of innovative information technologies, globalization, the wars in Iraq and Afghanistan, and the political upheavals in the Middle East. 
As for the future, it is much more likely to be defined by the United States’ need to put its economic house in order; China’s trajectory within and beyond its borders; and the ability of the world’s governments to cooperate on restoring economic growth, stemming the spread of nuclear weapons, and meeting energy and environmental challenges.
It is and would be wrong to make opposition to terrorism the centerpiece of what responsible governments do in the world.
Terrorists continue to be outliers with limited appeal at best.
They can destroy but not create.
It is worth noting that the people who went into the streets of Cairo and Damascus calling for change were not shouting the slogans of Al Qaeda or supporting its agenda.
Moreover, measures have been implemented to push back, successfully, against terrorists.
Intelligence assets have been redirected.
Borders have been made more secure and societies more resilient.
International cooperation has increased markedly, in part because governments that cannot agree on many things can agree on the need to cooperate in this area.
Military force has played a role as well.
Al Qaeda lost its base in Afghanistan when the Taliban government that had provided it sanctuary was ousted from power.
Osama bin-Laden was finally found and killed by US Special Forces in the suburbs of Islamabad.
Drones – unmanned aircraft that are remotely steered – have proven to be effective in killing a significant number of terrorists, including many of the most important leaders.
Weak governments can be made stronger; governments that tolerate or support terrorism must be held accountable.
But progress is not to be confused with victory.
Terrorists and terrorism cannot be eliminated any more than we can rid the world of disease.
There will always be those who will resort to force against innocent men, women, and children in pursuit of political goals.
Indeed, terrorists are advancing in some areas.
Pakistan remains a sanctuary for Al Qaeda and some of the world’s other most dangerous terrorists.
A mixture of instability, government weakness, and ideology in countries such as Yemen, Libya, Somalia, and Nigeria are providing fertile territory for terrorists to organize, train, and mount operations – much as they did in Afghanistan did a decade ago.
New groups constantly emerge from the ruins of old ones.
There is also a growing danger of homegrown terrorism.
We have seen it in Great Britain and the US.
The Internet, one of the great inventions of the modern Western world, has shown itself to be a weapon that can be used to incite and train those who wish to cause harm to that world.
The question raised in October 2003 by then US Secretary of Defense Donald Rumsfeld is no less relevant today: “Are we capturing, killing, or deterring and dissuading more terrorists every day than the madrassas and the radical clerics are recruiting, training, and deploying against us?”
All things being equal, we probably are. But even small terrorist successes are costly in terms of lives, money, and making open societies less so.
What is to be done?
Alas, there is no single or silver bullet.
The establishment of a Palestinian state will not be enough for those terrorists who want to see the elimination of the Jewish state, any more than reaching a compromise over Kashmir will satisfy those Pakistan-based terrorists with bigger agendas vis-à-vis India.
Reducing unemployment is desirable, of course, but many terrorists do not come from poverty.
Helping to make societies in the Middle East and elsewhere more democratic might reduce the alienation that can lead to radicalism and worse, but this is easier said than done.
Of course, we want to continue to find ways to make ourselves less vulnerable and terrorists more so.
But what may be most important, particularly in the Arab and Islamic communities, is to end any acceptance of terrorism.
The Nigerian father who warned the US embassy in Lagos that he feared what his own son might do – before that same young man attempted to detonate a bomb aboard a flight to Detroit on Christmas Day 2009 – is an example of just this.
Only when more parents, teachers, and community leaders behave likewise will recruitment of terrorists dry up and law-enforcement authorities receive full cooperation from the populations they police.
Terrorism must lose its legitimacy among those who have historically supported or tolerated it before it will lose its potency.
The world has tried with little success to cut carbon emissions under the Kyoto Protocol.
The enormous effort expended to bring the Protocol into force nonetheless indicates how much work will be required to produce the next treaty, due to be agreed in Copenhagen in December 2009.
Campaigners will push for tough and far-reaching policies, but strong resistance will continue from countries concerned about their economic vitality.
The new negotiations will have one advantage over the earlier efforts, because governments now understand the need for a portfolio of adaptation, mitigation, and research efforts.
New research that my colleagues and I undertook for the Copenhagen Consensus Center in Denmark explores the effectiveness of different responses to this global challenge, but it strongly supports the portfolio approach for several reasons.
First, we now know that adaptation will be essential, because temperatures will rise by another 0.6°C by 2100 even if greenhouse gas emissions are eliminated tomorrow.
We also know that the impact of climate change will not be evenly distributed across the globe.
In some areas, modestly warmer temperatures could produce higher crop yields if associated changes in precipitation patterns are not adverse and/or irrigation remains viable.
Even with 0.6°C warming, however, Africa and South Asia will experience almost immediate reductions in the viability of many crops and, eventually, increased vulnerability to infectious disease.
These impacts will clearly hit the planet’s worst-off inhabitants hardest: the “bottom billion” who already bear the heaviest burden of disease, poverty, conflict and malnutrition.&#160;
Ensuring that adaptive capacity is expanded and exploited where it is most needed is thus a key challenge.
Long-term development may give countries more capacity to soften the impact of climate change on the environment and citizens’ health, but in the meantime the planet’s poorest people will need help from the rich.
Our analysis investigated, for example, the merits of more targeted policies for the near term: purchasing mosquito-resistant bed nets and oral re-hydration malaria therapy for children in the poorest nations affected by climate change.
The goal was to deal aggressively and proactively with some of the marginal health impacts of global warming.
Benefits would appear almost immediately, but would dissipate over time as economies developed.
Even as development improves conditions, however, reducing carbon emissions would become increasingly important over the longer term as the impact of climate change become more severe.
Since the effects of climate change have been observed in many areas around the world, thinking about mitigation makes sense everywhere.
But we found that mitigationalone did not meet a standard cost-benefit test.
We allowed specified annual costs of climate policy to grow in proportion with global GDP through 2100 from an initial annual benchmark of $18 billion.
The discounted cost of the resulting stream of fixed annual costs totaled $800 billion, but damages avoided by this approach amounted to a discounted value of only $685 billion.
The Copenhagen Consensus study also examined a portfolio option of the sort heralded by the United Nations’ Intergovernmental Panel on Climate Change.
We allocated $50 billion to research into greener technology, so that only $750 billion could be absorbed by the economic cost of adaptation and mitigation.
The gap between the cost of carbon-free and carbon-emitting technology fell, and the taxes designed to mitigate emissions became more effective.
As a result, the research and development program essentially paid for itself, and total discounted benefits for the $800 billion investment climbed to more than $2.1 trillion.&#160;
Ensuring that research and development is part of the world’s climate change response portfolio would make mitigation efforts more efficient and significantly enhance their ability to reduce carbon emissions over the next century.
But these favorable net benefits reflect very conservative assumptions regarding the timing of emissions reductions and when the developing world would “come onboard.”
Optimizing investment in the portfolio over time would, for example, increase the discounted benefits by more than a factor of three.
Expected benefits would increase further if we included the chance that potentially higher climate sensitivities would exacerbate damages, even though doing so would require including similarly plausible lower climate sensitivities, which would push in the opposite direction.
Fighting climate change can be a sound investment, even though neither mitigation nor adaptation alone will be enough to “solve” the problem.
To make a real difference, especially in the near term, the world must combine mitigation and adaptation with increased research and development into carbon-saving and sequestering technology, which in turn requires designing and exploiting market-based incentives.
STOCKHOLM – One year after the war in Georgia of last August, pushing the “reset” button on diplomatic relations is a popular endeavor nowadays.
President Barack Obama recently journeyed to Moscow in order to “reset” strained United States-Russian ties.
The European Union, though not in need of a “reset” because of strained ties with its eastern neighbors, is involved in a deep strategic reconstruction of those relations.
When the EU launched its new “Eastern Partnership” in May, the purpose was to promote further integration with the Union’s six immediate eastern neighbors – Armenia, Azerbaijan, Belarus, Georgia, Moldova, and Ukraine.
The global financial crisis had made an updated and strengthened policy for the EU’s eastern neighborhood an urgent need.
Equally important was the fact that all the countries concerned expressed an ambition to move closer to the EU.
The Eastern Partnership – originating from a Polish/Swedish initiative – offers to the six countries a substantial upgrading and deepening of relations with the EU in key areas.
In trade and economic relations, it clearly sets out the objective of establishing deep and comprehensive free-trade areas between the EU and the partner countries.
It confirms full visa liberalization as a long-term goal (with visa facilitation agreements in the meantime), promises enhanced cooperation on energy security, diversification, and efficiency, and comes with dedicated programs and projects to help the neighbors in their integration and reform efforts in all these areas.
Sweden’s assumption of the EU Presidency this month should help these efforts.
However, it comes at a time when the Union’s eastern neighborhood faces severe challenges, with the financial and economic crisis hitting many of the partner countries hard.
Ukraine suffers from the sharp drop in global demand and trade, severely undermining its steel industry.
Georgia’s economic success has been largely dependent on direct foreign investment, for which there is hardly any appetite today.
Partner countries that are less integrated into the global market, such as Moldova, have seen the crisis arrive more slowly, but the real effect might be equally as bad, and they are likely to recover more slowly.
The Eastern Partnership does not offer any quick remedies to the crisis.
But it can provide a political framework and institution-building support to improve the deficiencies that made these countries so vulnerable to the crisis: imperfect market economies, weak state institutions, and continued corruption.
The Eastern Partnership’s offer of deep integration with the EU in the areas such as trade and energy carries with it considerable transformational power.
The other type of crisis that most of the partner countries are enduring is political.
In most of these countries, democratic development has not yet reached a point where a change in government is a routine part of political life and can take place without risking the country’s stability.
The Eastern Partnership is based on the profound values of democracy, human rights, and the rule of law.
Political association with the EU, and the process of integration under this Partnership, will promote reforms in these key areas.
The Swedish EU Presidency will concentrate on starting up the concrete work – the nuts and bolts – of the Partnership.
The establishment of “Comprehensive Institution-Building Programs,” designed to support reform of key institutions in each partner country, should take place before the year’s end.
Some flagship initiatives proposed by the European Commission will finally see the light of day as well, and new projects and initiatives are likely to be developed.
Here, Sweden will attach particular importance to energy efficiency programs, which will serve not only the purposes of enhancing energy security and reducing costs, but will also be an important contribution to the fight against climate change.
The Swedish Presidency, together with the European Commission, intends to organize the first meeting of the Eastern Partnership Civil Society Forum this autumn.
We hope to see the start of parliamentary cooperation, as well as exchanges between local and regional authorities of the thirty-three EU and partner countries.
At the end of the year, a meeting of EU foreign ministers and their colleagues from the six partners will assess the progress made so far and give guidance on the way ahead.
The Eastern Partnership is about EU integration, about the six countries moving closer to the EU’s values, legislation, and ways of working, and about the EU being there to support and help this convergence.
In Russia, there is a perception that is sometimes fostered which suggests that the Partnership is directed against it.
But this, of course, is untrue.
On the contrary, Russia, like Turkey, will be welcome to take part in relevant activities within the Partnership’s multilateral dimensions.
The Eastern Partnership is not an answer to all the problems and difficulties that the six partners are facing.
Nevertheless, it does represent a clear commitment by the EU to lend its political and economic support to their transition and reform – a process that should bring prosperity and stability to the whole region.
PARIS – “Let’s engage Russia if we can, but contain it if we must.” These two alternatives already defined Western strategy toward Russia in the mid-1990’s.
Since then, Russia may have changed dramatically, but not our questions about it.
What do you do when your big neighbor widens the gap that exists between its culture, which is European, and its political system, which is becoming increasingly “Asian,” at least in the bad old sense of “Oriental despotism”?
Should the best answer to the return of Russia’s imperial ambitions be a modern version of a Holy Alliance of stability designed to contain the world’s new maverick?
Or is a latter-day Yalta Conference, aimed at redrawing the political boundaries of Europe, necessary?
Could the answer be a bit of both?
If Russia is becoming what revolutionary France was under Napoleon, or reverting to Soviet form – shorn of a totalitarian ideology but with an appetite for conquest and re-conquest – what is needed is not the “league of democracies” advocated by some conservatives in America.
What is needed, instead, is a “stability league” that includes prominent actors like China, India, and other countries that are more interested in economic growth than in “rocking the boat” of the international system.
Such a strategy implies, first of all, a solid partnership with China, not because it is evolving in the direction of democracy, but because it is a status-quo power.
Such a strategy could lead to the opening of negotiations with Iran, and of course to a further closing of ranks within NATO.
The message to the Kremlin here would be crystal clear. “Do not fool yourself.
Nationalism and imperialism will lead you nowhere; you cannot expand geographically without serious costs to your economic growth and your personal enrichment.
Europe may be weak and divided, America may no longer be what it was, but with your falling population and the sad state of your economy beyond oil and gas, you simply are not equipped to be in the league of great global powers.
China is; you are not.”
But the containment argument fails, because the Kremlin can still make mischief around the world by acting with Syria or Venezuela in an irresponsible manner.
More importantly, rallying the world solely against Russia would mean taking Russia’s great power pretensions too seriously.
For example, many Asians believe that Russia is a problem for Europe, but no longer for the world.
At the Cold War’s end, Japan remained obsessed with Russia as the heir to the Soviet Union.
Today, the Japanese are so concerned with China that they have little time for fears about Russia.
The other alternative to a rebirth of “containment” would consist in accepting the Russian argument, or more precisely, Russian “emotions.”
It would mean saying, in effect, “We have unnecessarily humiliated you over the last ten years.
From NATO enlargement to the grant of independence to Kosovo, we have deliberately ignored your sensitivities and your interests.
Let’s sit down together like Churchill, Roosevelt, and Stalin at Yalta and redesign a twenty-first-century map of Europe.
What do you want back?
What do we keep?”
This approach might recognize Russia’s droit de regard on the future evolution of the Caucasus.
Indeed, while talking tough under the guidance of Nicolas Sarkozy’s France, which currently holds the EU presidency, Europe has de facto resigned itself to Georgia’s dismemberment.
Russian troops are to remain in South Ossetia and Abkhazia.
The West is not about to declare war on Russia for the sake of a Georgia whose credibility has been greatly eroded by its president’s irresponsible behavior.
As for Ukraine, it may one day become part of the European Union, but its future is not in NATO.
Yet, between all-out containment, which is very unlikely and not necessarily desirable or realistic, and accommodation which borders on appeasement, which would be dangerous for Europe’s future, a third way, based on a few firm principles, must be found.
These principles are clear.
First, Ukraine’s territorial integrity is not negotiable.
This has been said many times, but repetition does not diminish its importance.
Russia without Ukraine is a manageable nation-state; Russia with Ukraine is an unmanageable empire.
Second, even if the West condemns Georgia’s irresponsibility and incorporates into its policy Russia’s sensitivities on the complex historical feelings related to its ex-imperial territories, the Kremlin’s shameless brutality is unacceptable.
After all, this is Europe more than six decades after World War II, and nearly 20 years after the collapse of the Soviet Union.
The use of force to settle scores and impose one nation’s will upon another cannot be accepted passively.
In the short term, time may be on Russia’s side.
In the long run – economically, demographically, politically, strategically – time is on “our” side, if we stick to our values and our principles.
The drubbing that many governments suffered in the recent elections to the European Union Parliament places them in a difficult position as they maneuver ahead of this week's EU Summit.
Only an incurable optimist can hope that the summit will bring glory to any of them.
The summit has two purposes: to finalize the text of a new EU Constitution, and to appoint the next President of the Commission.
These negotiations will be much harder in view of the spectacular repudiation of a number of key governments at the ballot box, together with the potent rise of protest and Euroskeptic parties in several member states.
The problem for Europe's leaders is that their own repudiation by voters does not necessarily carry the same message as the rise of the Euroskeptic parties.
The record slump in the vote for Gerhard Schröder's governing Social Democrats in Germany has little to do with his policy towards Europe, but a great deal to do with the perceived failure of his economic policies - and the persistence of low growth and high unemployment - at home.
Despite nationalist parties' success in France, the same is true of the setback for President Jacques Chirac's centre-right party.
In Britain, by contrast, where the economy is strong and unemployment low, the main factor behind the collapse in the vote for the governing Labor Party has been anger with Tony Blair's determination to go to war in Iraq beside George Bush.
Nevertheless, the rise of Euroskeptic parties, in a number of countries including Britain, France, Belgium, Poland, and the Czech Republic, has worrying implications for a summit meeting whose purpose is to take European integration a small but unmistakable step forward.
In Britain, in particular, the spectacular surge of the UK Independence Party (UKIP) can only strengthen the government's long-standing latent Euroskepticism.
The proposed constitution will contain a Charter of Fundamental Rights, which is intended to enhance the political and moral legitimacy of the EU.
But will it really enhance the rights of EU citizens?
Or, as the British government insists, will it merely be a declaratory document that only describes rights already existing under national legislation in the member states.
The draft constitution would enhance the policymaking powers of the Union, with a bit more majority voting in the Council of Ministers, and a stronger role for the European Parliament.
But, despite Tony Blair's one-time declaration that he would take Britain "into the heart of Europe," he remains viscerally opposed to the prospect of further integration, and he will resist any new encroachment on British sovereignty in his "red line" areas of tax, foreign policy, and EU budget finance.
Blair's Euroskepticism is understandable insofar as it chimes with the British mood.
Opinion polls consistently show that British voters are unenthusiastic about the EU, and the picture is confirmed by the latest Eurobarometer poll, conducted throughout the Union for the Commission - but before the recent enlargement from 15 to 25 member states.
One question always asked in this poll is whether voters tend to trust or mistrust different institutions, such as national parliaments, national governments, and the European Union.
Overall, the general level of trust in the European Union is not high: only 41% of voters tend to trust the EU, whereas 42% tend not to trust it.
But in Britain, the figures are dramatically different: only 19% trust the EU, while 55% distrust it.
By contrast, the European Parliament has a better reputation than the EU as a whole: the average EU-wide level of trust in the European Parliament is 54%, whereas in Britain it is 30%.
Across the EU, 48% think EU membership is a good thing; in Britain, this figure falls to 29%.
On virtually every question, British voters are less enthusiastic about the EU than voters in any other country. 
One might think that Britons' aversion to the EU would be reflected in support for, and pride in, their national institutions.
Not so.
British trust in the European Parliament may stand at only 30%; but trust in the Westminster Parliament is much lower, at only 19% - the lowest figure in the EU.
Trust in the national government is a bit higher, but still only 25%, while trust in national political parties is only 10%.
Both figures are, again, the lowest in the EU.
Voters in other states have more confidence in EU institutions, but their opinion of their own institutions is also low.
In France, 57% trust the European Parliament, but only 29% trust the French parliament; while the corresponding figures for Germany are 51% and 23%. 
But the puzzle in the poll is that, even if Europe's voters are unenthusiastic about the EU and its existing institutions as they stand now, 65% of them would support a common foreign policy for Europe, and 72% would support a common defense and security policy; even in Britain, there is 52% support for the idea of a common defense policy.
This may be a reaction to the American-led war in Iraq; but Tony Blair will exclude it precisely for that reason, and a common European defense policy without Britain makes little sense.
The predicament for Europe's leaders at this week's summit is that they stand at the cusp of an unstable process of European integration.
With the accession of 10 new members, the EU must become more integrated if it is to function.
But it is not at all clear that those governments that would normally support more integration can sell it to their disillusioned electorates.
Tony Blair has promised a referendum on the new EU constitution, which he cannot possibly win.
The central question will be whether Europe's "leaders" deliberately play for failure, in the hope that the problem will go away.
WASHINGTON, DC – The painfully negotiated US budget legislation that President Barack Obama signed on August 2 combines an increase in America’s government debt ceiling with reductions in federal spending, thus averting the prospect of the first default in the 224-year history of the United States.
But the agreement has three major flaws.
Two of them offset each other, but the third threatens what America needs most in the coming years: economic growth.
The first flaw is that the spending reductions are badly timed: coming as they do when the US economy is weak, they risk triggering another recession.
The measure’s second shortcoming, however, is that the spending reductions that it mandates are modest.
While the legislation does too little to address America’s problem of chronic and rising budget deficits, the damage that it inflicts on the economy in the short term is likely to be limited.
The third and most damaging flaw, however, is that the spending cuts come in the wrong places.
Because the Democrats in Congress have an almost religious commitment to preserving, intact, America’s principal welfare programs for senior citizens, Social Security and Medicare, the legislation does not touch either of them.
These programs’ costs will rise sharply as the 78-million-strong baby-boom generation – those born between 1946 and 1964 – retires and collects benefits, accounting for the largest increase in government spending and prospective deficits in the years ahead.
And, because the Republicans in Congress have an equally strong allergy to raising any taxes, any time, under any circumstances, the bill does not rely at all on tax increases – not even for the wealthiest Americans – for the deficit reduction that it provides.
All of the spending cuts come from the “discretionary” part of the federal budget, which excludes Social Security, Medicare, the Medicaid program for the poor, and interest on the national debt.
That leaves only about one-third of total federal spending from which to cut, and much of that goes to the defense budget, which Republicans will attempt to protect in the future.
So the structure established by the August 2 law concentrates deficit reduction on the “discretionary non-defense” part of the federal budget, which is only about 10% of it.
This is too small a pool of money from which to achieve deficit reduction on the scale that the US will need in the years ahead.
Worse yet, discretionary non-defense spending includes programs that are indispensable for economic growth – and economic growth is indispensable for America’s future prosperity and global standing.
Growth is, in the first place, the best way to reduce the country’s budget deficits.
The higher the growth rate, the more revenues the government will collect without raising tax rates; and higher revenues enable smaller deficits.
Moreover, economic growth is necessary to keep the promise – enormously important to individual Americans – that each generation will have the opportunity to become more prosperous than the preceding one, the popular term for which is “the American dream.”
Just as important for non-Americans, only robust economic growth can ensure that the US sustains its expansive role in the world, which supports the global economy and contributes to stability in Europe, East Asia, and the Middle East.
As Thomas L. Friedman and I explain in our forthcoming book That Used To Be Us: How America Fell Behind in the World It Invented and How We Can Come Back, a crucial factor in America's economic success has been an ongoing public-private partnership, which dates back to the founding of the country, that is imperiled by the pattern of budget cuts established by the August 2 legislation.
That partnership has five components: wider opportunities for education in order to produce a workforce with cutting-edge skills; investment in infrastructure – roads, power plants, and ports – that supports commerce; funds for research and development to expand the frontiers of knowledge in ways that generate new products; an immigration policy that attracts and retains talented people from beyond America’s borders; and business regulations strong enough to prevent disasters such as the near-meltdown of the financial system in 2008 but not so stringent as to stifle the risk-taking and innovation that produce growth.
The first three elements of the American formula for growth cost money, and that money is included in the “discretionary non-defense” part of the federal budget now targeted by the debt-ceiling legislation.
Cutting these programs will lower American economic growth in the long term, with negative consequences both at home and abroad.
Reducing the deficit by cutting funds for education, infrastructure, and research and development is akin to trying to lose weight by cutting off three fingers.
Most of the weight will remain, and one’s life prospects will have worsened significantly.
Reducing deficits in order to raise the debt ceiling was the right thing to do, but the August 2 law does it in the wrong way.
Unless more deficit reduction, which is inevitable, comes from curbing entitlement benefits and increasing revenues, and less from programs vital for economic growth, the result will be a poorer, weaker US – and a more uncertain, if not unstable, world.
EU Commission President Romano Prodi has proposed a scheme to strengthen the Union's executive.
Britain, France, and Spain are working on an opposing plan that will consolidate EU executive powers among the biggest EU states.
What's the ordinary European to think?
Europe's citizens scarcely grasp the issues at the heart of the European Constitutional Convention in Brussels.
Mountains of detail obscure problems; sterile, misleading national discussions that pit "Euroskeptics" against "Europhiles" muster sound and fury but clarify nothing.
So complicated do many issues seem that some newspapers and broadcasters have abandoned reporting about the Convention.
EU citizens can secure a clearer understanding of what the Convention should achieve by asking this question: how should governmental functions be divided between the EU and its member nations?
To answer this, we need to grasp government's true purpose.
Government should provide citizens with public goods: collective defense, legislation and regulation, enforcement of the rule of law.
These can be provided at different levels: local, regional, national, or supranational government, i.e., the EU.
But what is the right level?
In some areas, decentralization works because it recognizes diverse local or national communities.
However, local decisions often have repercussions on citizens in other communities.
So certain services should be allocated to a broader geographic unit because they have externalities (that is, interdependence of effects).
Europe's allocation of governmental powers should be based on the principle that institutions carry out only those activities with clear economies of scale and where differences of opinion are modest.
The lower a government activity's externalities, the more it should be localized.
Low externalities imply limited benefits to be gained from centralization; deep differences among citizens imply that the costs of harmonization would be too high.
The euro, for example, delivers clear advantages of scale by favoring international commerce and avoiding negative externalities.
No longer can the lira be devalued to favor Italian exports to the detriment of the French, followed by a French reaction, etc.
Although the imperfectly synchronized economic cycles of EU members causes friction over monetary and exchange rate policy, the euro's benefits outweigh the costs of diversity.
In educational policy, however, to impose the same system on all members would not create economies of scale.
Cultural differences are too strong to win voluntary compliance.
It would be absurd to delegate education and culture to a supranational level.
Of the areas of public policy with high economies of scale or externalities, two stand out: the common market and competition; and foreign policy and defense.
The former covers antitrust, trade, and the common currency.
Some think that fiscal policies - from the structure of taxation to welfare, to budget balances - should also be harmonized.
But national preferences are diverse, and if mechanically imposed, fiscal centralization might incite resistance.
Nor do centralized fiscal policies have any real raison d'être from a constitutional point of view.
The US Constitution, for example, does not prescribe balanced budgets for the states.
Only in exceptional circumstances is fiscal harmonization justified: prohibitions, say, on fiscal incentives aimed at limiting competition, impeding commerce, or restricting the movement of capital.
Foreign policy and defense belong, par excellence, at government's apex.
There are clear externalities and economies of scale.
It would be absurd if New York pursued a different foreign policy than Texas.
Much the same is true in Europe.
The addition of new EU members implies that more internal differences will occur, which means that fewer centralized policies are justified.
These considerations suggest a series of principles for the Convention to consider:
The EU Constitution should establish unequivocally which prerogatives belong to Europe and which to member countries.
When in doubt, the principle of subsidiarity suggests that national states remain supreme;
European-level institutions should guarantee the functioning of markets, including competition, commercial, and monetary policies;
Fiscal policy should remain largely decentralized, save for a few exceptions;
Foreign policy and defense are areas of federal competence, to be delegated to Europe at a proper time;
The creation of new areas of federal competence should be accompanied by decision-making mechanisms found in genuinely representative democracies.
So "No centralization without representation."
Today's EU diverges enormously from these principles (see table), as is demonstrated by the fact that agriculture, which represents 2% of European GDP, accounts for 40% of EU expenditures.
Activities of EU Institutions (percent of total)
Source of Table: "What Does the European Union do?"
A. Alesina, I. Angeloni &amp; L.Schuknecht, CEPR Discussion Paper no.
3115.
Europe faces an historic opportunity.
America's founding fathers wrote a Constitution that has lasted over 200 years.
Members of the European Convention obviously face a far more complex and diverse society-and thus a more daunting constitutional challenge.
But they can succeed by displaying comparable wisdom and foresight.
BEIJING – Before July 2007, most economists agreed that global imbalances were the most important threat to global growth.
It was argued that the United States’ rising net foreign debt-to-GDP ratio – the result of chronic current-account deficits – would put a sharp brake on capital inflows, in turn weakening the dollar, driving up interest rates, and plunging the US economy into crisis.
But this scenario failed to materialize.
Instead, the crisis stemmed from the US sub-prime debacle, which quickly dragged the global economy into its deepest recession since the 1930’s.
Most economists failed to foresee the economic dynamics that actually led to the crisis, because they failed to pay enough attention to the rapid increase in US total debt.
Instead, they focused exclusively on US foreign debt, ignoring household debt (mortgage and consumer debt), public debt, business debt, and financial debt.
In particular, they should have paid greater attention to the sustainability of US mortgage and consumer debt.
In 2007, the mortgage and consumer debt-to-GDP ratio was more than 90%, compared to 24% for net foreign debt.
Of course, the various components of debt differ considerably in their character and sources of financing – and thus in their sustainability.
But all parts of a country’s total debt and how it is financed are interconnected.
This means two things.
First, funds from different sources of finance are interchangeable to a certain degree: deficiency of funds for one component of total debt can be supplemented by surplus funds originally aimed at financing other components.
Second, troubles in any single component of total debt will have an impact on all the other components.
After the subprime crisis erupted, mortgage and consumer debt was paid down by households either with their savings or by default.
The fall in US total debt, and the narrowing of the financing gap between total debt and domestic funds, led to a significant improvement in the US current-account deficit in 2008-2009, disproving US Federal Reserve Board Chairman Ben Bernanke’s claim that the deficit was caused by a global “saving glut.”
Indeed, America’s current-account position strengthened despite the dollar’s appreciation in the face of safe-haven demand.
Unfortunately, as a result of the private-sector deleveraging and an increase in household savings, the US economy, driven by debt and consumption, slid into recession.
To offset the negative impact of private-sector deleveraging on growth, the US government has maintained expansionary fiscal and monetary policies.
Now, with household debt sustained on a knife-edge after feverish government intervention, the fiscal position has deteriorated dramatically and the current-account balance has worsened again.
Sustainability of public debt has replaced sustainability of private debt as the biggest threat to financial stability, and the focus of debate about the US current account has shifted from the sustainability of foreign debt to the impact of reducing the external deficit on growth and employment.
The dilemma facing US policymakers is how to stimulate growth while lowering the level of total debt.
The most important way to achieve both objectives is to increase exports by strengthening US competitiveness.
But where will increased competitiveness come from?
Devaluation of the dollar could improve US competitiveness in the short run, but it is not a solution.
Because rapid fiscal deterioration now has investors worrying about capital losses on US government securities, devaluation would make foreigners more hesitant to finance America’s budget deficit.
If foreign financing is not forthcoming, yields on US government debt will rise and the US economy will fall back into recession.
In the long run, America’s growth pattern must undergo a structural shift from reliance on debt and consumption one based on Americans vaunted capacity for creativity and innovation.
Only then will America improve its competitiveness enough to allow the government to reduce both private and public debt to sustainable levels while maintaining a respectable growth rate.
But neither improved competitiveness, nor reduction of total debt, can be achieved overnight.
In the short run, the US current-account deficit will remain, regardless of which country runs bilateral surpluses.
Thus, China’s continued reinvestment of its current-account surplus in US government securities is of utmost important for US growth and financial stability.
Given that America benefits mightily from China’s purchases of US government securities, it is difficult to understand why the US government and Congress have been complaining so much about the bilateral current-account deficit.
It is also difficult to grasp why China is so reluctant to reduce its bilateral surplus, given meager returns on its massive holdings of US government securities and a sustained risk of large capital losses in the future.
The good news is that, following President Hu Jintao’s recent visit to Washington, both America and China have been taking positive steps to resolve their differences over the bilateral current-account balance.
That augurs well for a more rational and constructive Sino-American dialogue on global imbalances, which would certainly benefit the global economy.
HONG KONG – A recent trip to Berlin brought back memories of an earlier visit in the summer of 1967, when I was a poor student who marveled at the Wall that would divide and devastate an entire society for another two decades.
Berlin today is vibrant and rejuvenated, rebuilt by the German peoples' hard work and sacrifice to unify the country, and an apt setting for the conference of the Institute for New Economic Thinking (INET), which I was there to attend.
The conference’s theme was “Paradigm Lost,” with more than 300 economists, political scientists, systems analysts, and ecologists gathering to rethink economic and political theory for the challenges and uncertainty posed by growing inequality, rising unemployment, global financial disarray, and climate change.
Almost everyone agreed that the old paradigm of neoclassical economics was broken, but there was no agreement on what can replace it.
Nobel laureate Amartya Sen attributed the European crisis to four failures – political, economic, social, and intellectual.
The global financial crisis, which began in 2007 as a crisis of US subprime lending and has broadened into a European sovereign-debt (and banking) crisis, has raised questions that we cannot answer, owing to over-specialization and fragmentation of knowledge.
And yet there is no denying that the world has become too intricate for any simple, overarching theory to explain complex economic, technological, demographic, and environmental shifts.
In particular, the rise of emerging markets has challenged traditional Western deductive and inductive logic.
Deductive inference enables us to predict effects if we know the principles (the rule) and the cause.
By inductive reasoning, if we know the cause and effects, we can infer the principles.
Eastern thinking, by contrast, has been abductive, moving from pragmatism to guessing the next steps.
Abductive inference is pragmatic, looking only at outcomes, guessing at the rule, and identifying the cause.
Like history, social-scientific theory is written by the victors and shaped by the context and challenges of its time.
Free-market thinking evolved from Anglo-Saxon theorists (many from Scotland), who migrated and colonized territories, allowing fortunate individuals to assume that there were no limits to consumption.
European continental thinking, responding to urbanization and the need for social order, emphasized institutional analysis of political economy.
Thus, the emergence of neoclassical economics in the nineteenth century was very much influenced by Newtonian and Cartesian physics, moving from qualitative analysis to quantifying human behavior by assuming rational behavior and excluding uncertainty.
This “predetermined equilibrium” thinking – reflected in the view that markets always self-correct – led to policy paralysis until the Great Depression, when John Maynard Keynes’s argument for government intervention to address unemployment and output gaps gained traction.
By the 1970’s, the neoclassical general-equilibrium school captured Keynesian economics through real-sector models that assumed that “finance is a veil,” thereby becoming blind to financial markets’ destabilizing effects.
Economists like Hyman Minsky, who tried to correct this, were largely ignored as Milton Friedman and others led the profession’s push for free markets and minimal government intervention.
But then technology, demographics, and globalization brought dramatic new challenges that the neoclassical approach could not foresee.
Even as the world’s advanced countries over-consumed through leveraging from derivative finance, four billion of the world’s seven billion people began moving to middle-income status, making huge demands on global resources and raising the issue of ecological sustainability.
New thinking is required to manage these massive and systemic changes, as well as the integration of giants like China and India into the modern world.
A change of mindset is needed not just in the West, but also in the East.
In 1987, the historian Ray Huang explained it for China:
“As the world enters the modern era, most countries under internal and external pressure need to reconstruct themselves by substituting the mode of governance rooted in agrarian experience with a new set of rules based on commerce.…This is easier said than done.
The renewal process could affect the top and bottom layers, and inevitably it is necessary to recondition the institutional links between them.
Comprehensive destruction is often the order; and it may take decades to bring the work to completion.”
Using this macro-historical framework, we can see Japanese deflation, European debt, and even the Arab Spring as phases of systemic changes within complex structures that are interacting with one another in a new, multipolar global system.
We are witnessing simultaneous global convergence (the narrowing of income, wealth, and knowledge gaps between countries) and local divergence (widening income, wealth, and knowledge gaps within countries).
Adaptive systems struggle with order and creativity as they evolve.
As the philosopher Bertrand Russell presciently put it: “Security and justice require centralized governmental control, which must extend to the creation of a world government if it is to be effective.
Progress, on the contrary, requires the utmost scope for personal initiative that is compatible with social order.”
A new wave of what the economist Joseph Schumpeter famously called “creative destruction” is under way: even as central banks struggle to maintain stability by flooding markets with liquidity, credit to business and households is shrinking.
We live in an age of simultaneous fear of inflation and deflation; of unprecedented prosperity amid growing inequality; and of technological advancement and resource depletion.
Meanwhile, existing political systems promise good jobs, sound governance, a sustainable environment, and social harmony without sacrifice – a paradise of self-interested free riders that can be sustained only by sacrificing the natural environment and the welfare of future generations.
We cannot postpone the pain of adjustment forever by printing money.
Sustainability can be achieved only when the haves become willing to sacrifice for the have-nots.
The Washington Consensus of free-market reforms for developing countries ended more than two decades ago.
The INET conference in Berlin showed the need for a new one – a consensus that supports sacrifice in the interest of unity.
Europe could use it.
To many, myself included, NATO's enlargement to take in, among others, the Baltic states of Estonia, Latvia, and Lithuania -- which were once Soviet republics -- is an impossible dream come true.
When the idea was first floated some 10 years ago, expansion into the Baltics was taken seriously by few people.
Until recently, Russia's robust opposition to the idea posed a serious obstacle, because it sharpened the impression that Russia regarded its so-called "near abroad" as a zone of special interest and influence.
NATO's enlargement makes it crystal clear that no country in the new Europe can be regarded as part of another country's "zone."
It assures the three small Baltic countries that the nightmare of occupation by big neighbors (Hitler's Reich and Stalin's USSR), which they endured for half-a-century -- will not be repeated.
By putting paid to any revanchist tendencies in Russia concerning the Baltics, Europe is made a safer place, and Russia is helped in its effort to redefine itself as a national state and not an empire.
Expansion will also create a better Europe because enlargement widens the territory in which countries are committed to NATO's political values, including individual rights as well as the rights of minorities.
Fortunately Russia now seems to grasp the value of this political aspect of NATO-enlargement.
Rightly so: enlargement of NATO is not an "expansion" that threatens Russia or other countries which strive for democratic political reforms.
On the contrary, expansion takes away the worries - be they real or imagined - that surround the situation of the large Russian-speaking populations that now live outside of Russia but within the borders of the former Soviet Union.
The civil rights of the Russian minorities in the Baltics and elsewhere are now enshrined in law, due in no small part to NATO demands.
Those civil rights initiatives on the part of NATO reflect the increasingly workmanlike way that Russia, Europe, and America now work out their disagreements.
Indeed, enlargement of NATO comes only a few days after a deal was struck between Russia and the EU on the tricky question of access to the Russian enclave of Kaliningrad.
This small piece of Russia, with 1 million inhabitants and bordering on the Baltic Sea, is squeezed between Poland and Lithuania, two future members of the EU.
This could have incited a complicated situation where Russians were faced with tough visa requirements when travelling between Kaliningrad and Russia proper.
A deal was struck between President Putin and the EU that makes access much easier without compromising the status of Lithuania and Poland within the EU-regime.
This, in turn, created once again the kind of win-win situation that is so important for future relations between the EU and Russia.
When the enlargement of the EU into Central and Eastern Europe is finally decided by the European Council in Copenhagen next month, the conclusion is clear: Europe has become a much better and safer place to live in, thanks to the decisions taken by NATO and the EU during the crucial autumn of 2002.
But this is no cause for complacency.
For the really hard work is only now beginning: dealing with all the internal practical and political problems that these enlargements will bring, as well as reckoning with countries in the membership waiting rooms, in particular Russia.
Relations with Russia are of vital importance if Europe is to continue to improve the quality of life of its citizens and address concerns of safety.
The common threat of international terrorism must be faced jointly.
We need to convince each other that the fight against this common enemy has to be fought with a keen eye to balancing the needs of security with those of human and minority rights.
Kaliningrad could be a litmus test of these relations.
The first hurdle has been overcome with the agreement on access to the enclave.
The next hurdle is to support Kalingrad's fight against disease and crime as well as strengthening its economic and social structures.
This calls for generosity from the EU and flexibility from Moscow.
In a wider context this could lead to a strengthening of the so-called Northern Dimension of the EU, where the goal is a free trade area to include all the countries around the Baltic Sea.
Such a grand project can be achieved if the political will exists and asserts itself.
Only a few years ago EU and NATO enlargement were regarded as wild dreams.
But determination and political will has now made the dreams come true.
Now is the time to set new ambitious goals for Europe.
In 1977, when I served in President Jimmy Carter's State Department, I was sent to India to dissuade that country's leaders from developing a nuclear bomb.
My hosts replied that they needed to keep up with China.
I said that Pakistan would inevitably follow suit and the world would become less safe.
India promised that it would not export its weapons technology.
So far as we know, its leaders have kept their word.
But revelations about the nuclear weapons smuggling network organized by A. Q. Khan, the father of Pakistan's bomb, confirm the danger I predicted back then.
Some call Khan's network an effort to spread an "Islamic bomb," but given that North Korea was on the list of recipients along with Libya and Iran, it might better be termed a corrupt bomb.
As events in Pakistan illustrate, the spread of nuclear technology does not extend the stability that comes with mutual deterrence.
Rather, it increases the prospects of corrupt leakage that may allow terrorist groups access to nuclear weapons.
That makes everyone less safe.
Any pathological group of extremists could destroy New Delhi, Tokyo, Paris, or any city they chose.
Now the world's attention is focussed on Iran, one recipient of Pakistani technology, as the country seemingly keenest to create its own nuclear arsenal.
According to the International Atomic Energy Agency (IAEA), Iran began enriching uranium at a pilot centrifuge plant last August, and is constructing larger underground enrichment facilities.
Iran proclaims that its programs are for peaceful generation of nuclear energy, but inspectors have already found traces of highly enriched weapons-grade uranium.
Last October, Mohamed El Baradei, the head of the IAEA, announced that Iran had accepted enhanced inspection procedures.
In addition, after visits by the French, British, and German foreign ministers, Iran announced a temporary suspension of its enrichment program.
Now it hints that it may resume enrichment, and recent press reports about the imports from Pakistan suggest Iran failed to disclose everything to the IAEA.
Iran claims that as a party to the Non-Proliferation Treaty, it has the right to enrich uranium for peaceful purposes.
Correct, because the NPT was born with a loophole.
Even if a country agrees to broad ranging IAEA inspections, it can legally accumulate enriched uranium (or reprocessed plutonium) under the guise of a peaceful energy program, and then suddenly declare that circumstances have changed and withdraw from the treaty - with the ability to produce nuclear weapons on short notice.
If Iran did this, it would not only add to the dangers in an unstable region, but would likely begin a process of unravelling the non-proliferation regime worldwide.
Iran may ask what right others have to demand that it forego nuclear weapons.
The answer lies both in the fact that it promised not to do so when it signed the NPT and in the consequences that it would impose on others.
For these reasons, President Bush declared an Iranian nuclear weapon unacceptable.
However, America's unilateral options are limited.
Not only is the US military busy trying in Iraq, but the way the US went into Iraq - which proved to have fewer nuclear capabilities than Iran - undermined American credibility, making it difficult to recruit allies to contain Iran's nuclear ambitions.
Fortunately, there is a multilateral option and an existing precedent.
In the mid-1970's, many parties to the NPT planned to import and develop enrichment and reprocessing facilities.
Realizing the threat to the non-proliferation regime, countries as diverse as the Soviet Union, France, Germany, and Japan formed a "Nuclear Suppliers Group" that restrained the export of enrichment and reprocessing facilities.
That plugged part of the loophole in the treaty without amending it.
Today, such countries should join together to offer Iran (and others) a deal.
Countries that wish to develop nuclear energy but not nuclear bombs should be given international guarantees of fuel supply and disposal of spent fuel.
For example, Russia, which is helping Iran construct a nuclear reactor at Bushehr, should offer Iran a guarantee of low enriched uranium fuel and reprocessing of the reactor's spent fuel by sending it back to Russia if Iran agrees to forego enrichment and reprocessing.
This deal could then be given teeth by the UN Security Council.
The Council would declare that further proliferation of nuclear weapons is a threat to peace, and that any country moving in that direction is subject to sanctions.
Such a resolution would also include a carrot by guaranteeing Iran access to the non-dangerous parts of the nuclear energy fuel cycle.
The pot could be further sweetened by offers to relax existing sanctions and provide a security guarantee if Iran remains non-nuclear.
European foreign ministers have already expressed their concerns about Iran's nuclear program.
Russia indicates that it is willing to provide such fuel services.
It is time for the Security Council to try to internationalize the most dangerous parts of the nuclear fuel cycle.
It is not too late to learn the lessons of the misadventures of A. Q. Khan.

NEW YORK – The G-8’s $20 billion initiative on smallholder agriculture, launched at the group’s recent summit in L’Aquila, Italy, is a potentially historic breakthrough in the fight against hunger and extreme poverty.
With serious management of the new funds, food production in Africa will soar.
Indeed, the new initiative, combined with others in health, education, and infrastructure, could be the greatest step so far toward achieving the Millennium Development Goals, the internationally agreed effort to reduce extreme poverty, disease, and hunger by half by 2015 .
During 2002-2006, I led the United Nations Millennium Project, which aimed to achieve the Millennium Development Goals, for then-UN Secretary General Kofi Annan.
One cornerstone of the project was “smallholder farmers,” meaning peasant farm families in Africa, Latin America, and Asia – working farms of around one hectare (2.5 acres) or less.
These are some of the poorest households in the world, and, ironically, some of the hungriest as well, despite being food producers.
They are hungry because they lack the ability to buy high-yield seeds, fertilizer, irrigation equipment, and other tools needed to increase productivity.
As a result, their output is meager and insufficient for their subsistence.
Their poverty causes low farm productivity, and low farm productivity reinforces their poverty.
It’s a vicious circle, technically known as a poverty trap.

The UN Millennium Project’s Hunger Task Force, led by two world-leading scientists, M. S. Swaminathan and Pedro Sanchez, examined how to break this vicious circle.
The Hunger Task Force determined that Africa could substantially increase its food production if help was given to smallholder farmers, in the form of agricultural inputs.  The Millennium Project recommended a big increase in global funding for this purpose.  Drawing on that work and related scientific findings, Annan launched a call in 2004 for an African Green Revolution, based on an expanded partnership between Africa and donor countries.
Many of us, notably current UN Secretary General Ban Ki-moon, have worked hard to make this possible, with Ban repeatedly emphasizing the special emergency arising from the global food, financial, and energy crises of the past two years.
The G-8 announcement reflects these years of effort, and of course the boost from the leadership of US President Barack Obama, Spanish Prime Minister Jose Luis Zapatero, Australian Prime Minister Kevin Rudd, World Bank President Robert Zoellick, European Commissioner Louis Michel, European Parliamentarian Thijs Berman, and others.
Now the key is to make this effort work.
The lessons of history are clear.
Getting seed and fertilizer to smallholder farmers at highly subsidized prices (or even free in some cases) will make a lasting difference.
Not only will food yields rise in the short term, but farm households will use their higher incomes and better health to accumulate all sorts of assets: cash balances, soil nutrients, farm animals, and their children’s health and education.
That boost in assets will, in turn, enable local credit markets, such as micro-finance, to begin operating.
Farmers will be able to buy inputs, either out of their own cash, or by borrowing against their improved creditworthiness.
A consensus has now been reached on the need to assist smallholders, but obstacles remain.
Perhaps the main risk is that the “aid bureaucracies” now trip over each other to try to get their hands on the $20 billion, so that much of it gets taken up by meetings, expert consultations, overhead, reports, and further meetings. “Partnerships” of donors can become an expensive end in themselves, merely delaying real action.
If donor governments really want results, they should take the money out of the hands of thirty or more separate aid bureaucracies and pool it in one or two places, the most logical being the World Bank in Washington and the International Fund for Agricultural Development (IFAD) in Rome.
One or both of these agencies would then have an account with several billion dollars.
Governments in hunger-stricken regions, especially Africa, would then submit national action plans that would provide details on how they would use the donor funds to get high-yield seeds, fertilizer, irrigation, farm tools, storage silos, and local advice to impoverished farmers.
An independent expert panel would review the national plans to verify their scientific and managerial coherence.
Assuming that a plan passes muster, the money to support it would quickly be disbursed.
Afterward, each national program would be monitored, audited, and evaluated.
This approach is straightforward, efficient, accountable, and scientifically sound.
Two major recent success stories in aid have used this approach: the Global Alliance on Vaccines and Immunizations, which successfully gets immunizations to young children, and the Global Fund to Fight AIDS, TB, and Malaria, which supports national action plans to battle these killer diseases.
Both have saved millions of lives during the past decade, and have paved the way to a new more efficient and scientifically sound method of development assistance.
Not surprisingly, many UN agencies and aid agencies in rich countries fight this approach.
All too often, the fight is about turf, rather than about the most effective way to speed help to the poor.
Obama, Rudd, Zapatero, and other forward-thinking leaders can therefore make a huge difference by following up on their pledges at the G-8 and insisting that the aid really works.
The bureaucracies must be bypassed to get help to where it is needed: in the soil tilled by the world’s poorest farm families.
NEW YORK – In the afternoon of July 16 two men appeared to be breaking into a fine house in an expensive area of Cambridge, Massachusetts.
Alerted by a telephone call, a policeman arrived smartly on the scene.
He saw one black male standing inside the house and asked him to come out.
The man refused.
He was then told to identify himself.
The man, still refusing to step out, said he was a Harvard professor, showed his ID, and warned the cop not to mess with him.
He said something about black men in America being singled out, and asked the cop, who was white, for his name and identification.
The cop, joined by several colleagues, arrested the professor for disorderly conduct.
We now know that the professor had broken into his own home, with the help of his chauffeur, because the door was jammed. 
What was unusual here was not the cop’s heavy-handedness.
Most people in the US know that if you talk back to the police, they will get nasty very fast.
The fact that the man was black might or might not have made the cop go for his handcuffs even sooner than he might normally have done.
That, too, would not have been unusual.
What made this case special was that Henry Louis “Skip” Gates is one of the most celebrated professors in the country, famous for his books, his articles, and numerous television appearances.
He is a grandee, a mover and shaker in the academic and media world, a friend of President Barack Obama.
That is why he warned the cop, Sgt. James Crowley, a veteran of the Cambridge police force, not to mess with him.
Class and race overlap in the US.
In this instance, it is impossible to pry them apart.
Gates, deeply conscious, indeed a specialist of the terrible history of race relations in his country, instinctively assumed that he was a victim of prejudice.
From his words it appears that he was equally conscious of not getting the proper respect due to a distinguished Harvard professor and media celebrity.
As he put it to his daughter in an interview published online: “[Crowley] should have gotten out of there and said, ‘I’m sorry, sir, good luck.
Loved your [television] series—check with you later!’”
Alas, Sgt.Crowley had never heard of Professor Gates.
A local man whose brothers all serve in the police force, a sports fan, and an amateur basketball coach, Crowley does not move in the same social circles as Gates.
As it happens, the charges were duly dropped, and there the case might have rested if President Obama, tired and frustrated after weeks of fighting for his healthcare bill, had not weighed in on behalf of his “friend” Gates, and called the police “stupid.”
Both he and Gates then spoke of “learning” from the incident.
Gates might even be planning a television documentary on racial profiling.
One thing to be learned, if we didn’t know this already, is how close racial sensitivities are to the surface of US life, despite the election of a black president.
The complexities of black anger, white guilt, and of black, and white fear, are so vexed that most Americans prefer not to talk about race at all.
The field is too full of mines.
One of Obama’s great achievements is that he made it into a serious topic through the brilliance and subtlety of his rhetoric.
And there remains plenty to talk about: the grotesquely disproportionate number of black men in US prisons; the lack of educational opportunities in poor, mostly black areas; the appalling healthcare system; and the very real brutality used by police officers against blacks, who don’t have the privilege of a Harvard ID.
It is probably true that many white policemen, even if they are trained to avoid racial profiling, as Sgt. Crowley was, need to be convinced that a black man can be at home in one of the finer houses of Cambridge, or any other American city.
But is the Gates affair the right way to enter into this discussion?
One might argue that itwas.
If not Professor Gates, then who?
Precisely because he is a grandee, he is in the position to draw national attention to a serious issue.
If the same thing had happened to an unknown man in Harlem, or some other poor, or predominantly black district, no one would ever have heard about it.
The fact that it happened to a professor in Cambridge makes everyone sit up and take notice.
There is, however, a danger that it will have an adverse affect on the necessary national discussion about race.
By having made such a big issue out of what was in fact a relatively minor event Gates could be accused of trivializing much worse instances of abuse.
Indeed, we don’t even know for certain whether this was such an instance.
Crowley never mentioned the color of Gates’ skin.
There was no question of violence.
There were just very raw nerves and hypersensitivity to hints of disrespect, on the part of the professor, and of the cop.
Outrage about a professor who is not to be messed with is not the best way to discuss the plight of countless, poor, anonymous people, whom most of us find it too easy to ignore.
BERLIN – Twenty-five years after the nuclear disaster at Chernobyl, the ongoing catastrophe at the Fukushima nuclear reactor in Japan has – it must be hoped – made clear once and for all that the purported blessings of the nuclear age are mere illusions: nuclear power is neither clean nor safe nor cheap.
Indeed, the opposite is true.
Nuclear power is saddled with three major unresolved risks: plant safety, nuclear waste, and, most menacing of all, the risk of military proliferation.
Moreover, the alternatives to nuclear energy – and to fossil fuels – are well known and technically much more advanced and sustainable.
Taking on nuclear risk is not a necessity; it is a deliberate political choice.
Fossil-fuel and nuclear energy belong to the technological utopias of the nineteenth and twentieth centuries, which were based on a belief in the innocence of the technologically feasible and on the fact that, at the time, only a minority of people worldwide, largely in the West, benefited from technological progress.
By contrast, the twenty-first century will be informed by the realization that the global ecosystem and its resources, which are indispensable for human survival, are finite, and that this implies an enduring responsibility to preserve what we have.
Meeting this imperative entails both an enormous technological challenge and an opportunity to redefine the meaning of modernity.
The energy future of nine billion people, which is what the world population will be in the middle of the century, lies neither in fossil fuels nor in nuclear energy, but in renewable energy sources and dramatic improvements in energy efficiency.
We already know this.
Why, then, do the most advanced countries, in particular, take on the risk of a mega-catastrophe by seeking to create energy from radioactive fission?
The answer, ultimately, doesn’t lie with any civilian use of nuclear energy, but first and foremost with its military applications.
The energy derived from splitting uranium and plutonium atoms was originally used for the ultimate weapon, the atomic bomb.
Being a nuclear power provides sovereign states with protection and prestige.
Even today, the Bomb divides the world into two classes: the few states have it, and the many that do not.
The old Cold War world order was based on the nuclear arms race between the two superpowers, the United States and Soviet Union.
To stop others from trying to become nuclear powers, which would have multiplied and spread the risk of nuclear confrontation, the Non-Proliferation Treaty (NPT) was framed in the 1960’s.
To this day, it governs the relationships between the nuclear powers and the rest of the world, imposing renunciation on the have-nots and nuclear-disarmament obligations on the haves.
Of course, the NPT has repeatedly been violated or circumvented by states that never subscribed to it.
To this day, therefore, the risk remains that the number of nuclear powers will increase, particularly given small and medium powers’ hope to enhance their prestige and position in regional conflicts.
Iran is the most current example of this.
The nuclearization of these not-always-stable states threatens to make the regional conflicts of the twenty-first century much more dangerous, and will also substantially increase the risk that nuclear weapons eventually end up in the hands of terrorists.
Despite the NPT, a clear separation between civilian and military use of nuclear energy hasn’t always worked, or worked completely, because the NPT’s rules permit all signatory states to develop and use – under international supervision – all of the components of the nuclear fuel cycle for civilian purposes.
From here, then, all that is required to become a nuclear power are a few small technical steps and political leaders’ decision to take them.
This political power, not the requirements of energy policy, is what makes giving up nuclear energy so difficult.
As a rule, the path to nuclear-power status always begins with so-called “civilian” nuclear programs.
The supposed “civilian” nuclear ambitions of Iran have thus, for instance, led to a large number of such “civilian” programs in neighboring states.
Honni soit qui mal y pense!
And, of course, the reactions of the nuclear powers to the disaster at Fukushima will be watched and analyzed closely by the so-called “clandestine threshold countries.”
So how will the world – first and foremost, the main nuclear powers – react to the Fukushima disaster?
Will the tide truly turn, propelling the world towards nuclear disarmament and a future free of nuclear weapons?
Or will we witness attempts to downplay the calamity and return to business as usual as soon as possible?
Fukushima has presented the world with a far-reaching, fundamental choice.
It was Japan, the high-tech country par excellence (not the latter-day Soviet Union) that proved unable to take adequate precautions to avert disaster in four reactor blocks.
What, then, will a future risk assessment look like if significantly less organized and developed countries begin – with the active assistance of the nuclear powers – to acquire civilian nuclear-energy capabilities?
Any decision to continue as before would send an unambiguous message to the clandestine threshold countries that are secretly pursuing nuclear weapons: despite lofty rhetoric and wordy documents, the nuclear powers lack the political will to change course.
Were they to abandon nuclear energy, however, their epochal change of heart would constitute a seminal contribution to global nuclear security – and thus to the fight against nuclear proliferation.
WAGENINGEN, NETHERLANDS – Born in 1957, the Common Agricultural Policy (CAP) is now more than 50 years old, and the European Commission is proposing what it calls a health check for its middle-aged child.
But superficial repairs will not meet the European Union’s future needs.
The CAP must be born again.
Work on its renewal is due to start now, with the completed project ready in 2013.
But a much more profound re-think is needed.
The CAP’s original aim was to provide a secure source of food for the six original member states of the Union, which were importers of food and sought a degree of self-sufficiency.
Good, healthy, and cheap food had to be accessible for all citizens.
Improved agricultural productivity would benefit rural areas and give farmers a comparative share in the Union’s growing wealth.
Instruments to achieve those objectives were developed, and food security was achieved.
The CAP quickly came to be seen as the jewel in the crown of the European project.
As the EU has evolved and expanded, food systems have become more complex, involving production, processing, supply-chain organization, and wholesale and retail distribution, with all of these involving new issues like health and the environment.
The use of land is also receiving more serious scrutiny.
A 1991 study by the Netherlands Scientific Council for Governmental Policy, entitledGround for Choices, demonstrated that the EU’s food supply could be met with 50% less cultivated land, 80% less pesticides, and at 50% less cost.
Pollution would be reduced by 70% as a result of fewer nitrates in the surface water, and greenhouse gases would be cut.
Those figures were for an EU of 15 countries, so with today’s 27 members the possibilities are even greater.
A Dutch analysis of land use has shown that by employing the best technical and ecological means on the best available land, substantial gains could be made in food production.
So it is not surprising that the number of farmers needed has fallen substantially.
Viewed from the standpoint of food security and the wealth of rural areas, there is now an urgent need to revisit the CAP’s main instruments so that a new policy formula can be introduced.
Perverse subsidies must be removed and recent new ones favoring products such as bio-fuels reconsidered.
Thestatus quo clearly has to be changed.
Rural policy in the EU is too often reduced to income guarantees for the farming community.
But that attitude is undermining change.
Competition must be encouraged, as more rural entrepreneurship will strengthen the farming community, with fewer farmers but better farms.
A simplified CAP would encourage cleaner, more productive, and efficient agriculture.
A side benefit for the EU’s standing in the world could be that the World Trade Organization’s stalled Doha negotiations could be restarted once farmers in developing countries are assured of getting a fair deal from Europe.
Moreover, the CAP’s role as a motor of political and social integration in Europe could be restored once renewed policies are in place.
But renewal of this sort cannot be left to global market forces, as the results might not necessarily benefit European agriculture and society.
If the market “misbehaves,” farmers could be reduced to poverty, leading to the neglect of large areas of Europe.
That is a real enough danger to which policymakers must give serious thought as they reform the CAP on the basis of the following five pillars.
1.&#160;&#160;&#160;&#160;&#160; The EU needs a knowledge and innovation policy that strengthens European agriculture’s competitiveness.
Such a policy has been successful in the Netherlands, substantially contributing to the development and power of the country’s agribusiness.
Ten of 21 branches of Dutch agribusiness, including horticultural seeds, ornamentals, seed potatoes, and veal, are among the top contributors to the national economy and the country’s trade balance.
In the EU as a whole, a policy directed toward research programs stimulating scientific excellence and greater coherence in the European knowledge system would greatly strengthen agriculture’s competitiveness and contribute to food security and sustainable development.
2.&#160;&#160;&#160;&#160;&#160; Europe also needs a restructuring policy for land use.
Many structural improvement programs have been financed at the European level, but agricultural production and land use are not among them.
The development of an Agricultural Main Structure would compliment the European Ecological Main Structure.
Reforestation and the repair of natural ecosystems should also be part of a land use policy.
3.&#160;&#160;&#160;&#160;&#160; A policy for European food systems would treat production, processing, distribution, logistics, and retailing in combination.
Consumption patterns and preferences are an integral part of such systems.
Preliminary studies by the European Science Foundation’s “Forward Look on European Food Systems” could prove useful in devising an EU-wide policy.
4.&#160;&#160;&#160;&#160;&#160; Metropolitan agriculture in a rapidly urbanizing world can provide high-quality produce on small amounts of land.
It offers an answer to rising demand for healthy food with minimal environmental side effects.
5.&#160;&#160;&#160;&#160;&#160; A new CAP should include a policy to safeguard Europe’s landscapes.
But a cultural heritage should not be maintained everywhere, nor should it ignore cost.
And it should not be a defensive policy of the sort that tends to concentrate on poor-quality land.
These five pillars involve drastic choices, but they will probably require less money from Europe’s taxpayers, not more.
They could make a real contribution to cleaner, more productive, and efficient farming and land use, while addressing social needs.
NEW YORK – Today’s world hunger crisis is unprecedentedly severe and requires urgent measures.
Nearly one billion people are trapped in chronic hunger – perhaps 100 million more than two years ago.
Spain is taking global leadership in combating hunger by inviting world leaders to Madrid in late January to move beyond words to action.
With Spain’s leadership and United Nations Secretary General Ban Ki-moon’s partnership, several donor governments are proposing to pool their financial resources so that the world’s poorest farmers can grow more food and escape the poverty trap.
The benefits of some donor help can be remarkable.
Peasant farmers in Africa, Haiti, and other impoverished regions currently plant their crops without the benefit of high-yield seed varieties and fertilizers.
The result is a grain yield (for example, maize) that is roughly one-third less than what could be achieved with better farm inputs.
African farmers produce roughly one ton of grain per hectare, compared with more than four tons per hectare in China, where farmers use fertilizers heavily.
African farmers know that they need fertilizer; they just can’t afford it.
With donor help, they can.
Not only do these farmers then feed their families, but they also can begin to earn market income and to save for the future.
By building up savings over a few years, the farmers eventually become creditworthy, or have enough cash to purchase vitally necessary inputs on their own.
There is now widespread agreement on the need for increased donor financing for small farmers (those with two hectares or less of land, or impoverished pastoralists), which is especially urgent in Africa.
The UN Secretary General led a steering group last year that determined that African agriculture needs around $8 billion per year in donor financing – roughly four times the current total – with a heavy emphasis on improved seeds, fertilizer, irrigation systems, and extension training.
In addition to direct help for small farms, donors should provide more help for the research and development needed to identify new high-yielding seed varieties, especially to breed plants that can withstand temporary flooding, excess nitrogen, salty soils, crop pests, and other challenges to sustainable food production.
Helping the poor with today’s technologies, while investing in future improved technologies, is the optimum division of labor.
This investment pays off wonderfully, with research centers such as the International Rice Research Institute and the International Maize and Wheat Improvement Centre providing the high-yield seeds and innovative farming strategies that together triggered the Asian Green Revolution.
These centers are not household names, but they deserve to be.
Their scientific breakthroughs have helped to feed the world, and we’ll need more of them.
Dozens of low-income, food-deficit countries, perhaps as many as 40-50, have elaborated urgent programs for increased food production by small farms, but are currently held back by the lack of donor funding.
These countries have appealed to the World Bank for financing, and the Bank made a valiant effort in 2008 to help through its new Global Food Crisis Response Program (GFCRP).
But the Bank does not yet have sufficient funds to meet these countries’ urgent needs, and has had to ration assistance to a small fraction of the flows that could be effectively and reliably used.
Hundreds of millions of people, in the meantime, remain trapped in hunger.
Many individual donor countries have declared that they are now prepared to increase their financial support for smallholder agriculture, but are searching for the appropriate mechanisms to do so.
The current aid structures are inadequate.
The more than 20 bilateral and multilateral donor agencies for agriculture are highly fragmented and of insufficient scale individually and collectively.
Despite the dedicated efforts of many professionals, the response to the hunger crisis remains utterly inadequate.
The 2008 planting seasons came and went with much too little additional help for impoverished small farmers.
African countries search endlessly, and mostly fruitlessly, for the small amounts of funding needed for their purchases of fertilizer and improved seeds.
My colleagues and I, serving on an advisory committee for the Spanish initiative, have recommended that donors pool their funds into a single international account, which we call the Financial Coordination Mechanism (FCM).
These pooled funds would enable farmers in poor countries to obtain the fertilizer, improved seed varieties, and small-scale irrigation equipment that they urgently need.
Poor countries would receive prompt and predictable financing for agricultural inputs from a single account, rather than from dozens of distinct and fragmented donors.
By pooling financial resources into a single-donor FCM, aid programs’ administrative costs could be kept low, the availability of aid flows could be assured, and poor countries would not have to negotiate 25 times in order to receive help. 
The time for business as usual is over.
The donors promised to double aid to Africa by 2010, but are still far off track.
Indeed, during the past 20 years, they actually cut aid for agriculture programs, and only now are reversing course.
Meanwhile, a billion people go hungry each day.
We need a breakthrough that is demonstrable, public, clear, and convincing, that can mobilize the public’s hearts and minds, and that can demonstrate success.
History can be made in Madrid at the end of January, when the world’s richest and poorest countries converge to seek solutions to the global hunger crisis.
The lives of the billion poorest people depend on it.
CAMBRIDGE – With youth unemployment touching 50% in eurozone countries such as Spain and Greece, is a generation being sacrificed for the sake of a single currency that encompasses too diverse a group of countries to be sustainable?
If so, does enlarging the euro’s membership really serve Europe’s apparent goal of maximizing economic integration without necessarily achieving full political union?
The good news is that economic research does have a few things to say about whether Europe should have a single currency.
The bad news is that it has become increasingly clear that, at least for large countries, currency areas will be highly unstable unless they follow national borders.
At a minimum, currency unions require a confederation with far more centralized power over taxation and other policies than European leaders envision for the eurozone.
What of Nobel Prize winner Robert Mundell’s famous 1961 conjecture that national and currency borders need not significantly overlap?
In his provocative American Economic Review paper “A Theory of Optimum Currency Areas,” Mundell argued that as long as workers could move within a currency region to where the jobs were, the region could afford to forgo the equilibrating mechanism of exchange-rate adjustment.
He credited another (future) Nobel Prize winner, James Meade, for having recognized the importance of labor mobility in earlier work, but criticized Meade for interpreting the idea too stringently, especially in the context of Europe’s nascent integration.
Mundell did not emphasize financial crises, but presumably labor mobility is more important today than ever.
Not surprisingly, workers are leaving the eurozone’s crisis countries, but not necessarily for its stronger northern region.
Instead, Portuguese workers are fleeing to booming former colonies such as Brazil and Macau.
Irish workers are leaving in droves to Canada, Australia, and the United States.
Spanish workers are streaming into Romania, which until recently had been a major source of agricultural labor in Spain.
Still, if intra-eurozone mobility were anything like Mundell’s ideal, today we would not be seeing 25% unemployment in Spain while Germany’s unemployment rate is below 7%.
Later writers came to recognize that there are other essential criteria for a successful currency union, which are difficult to achieve without deep political integration.
Peter Kenen argued in the late 1960’s that without exchange-rate movements as a shock absorber, a currency union requires fiscal transfers as a way to share risk.
For a normal country, the national income-tax system constitutes a huge automatic stabilizer across regions.
In the US, when oil prices go up, incomes in Texas and Montana rise, which means that these states then contribute more tax revenue to the federal budget, thereby helping out the rest of the country.
Europe, of course, has no significant centralized tax authority, so this key automatic stabilizer is essentially absent.
Some European academics tried to argue that there was no need for US-like fiscal transfers, because any desired degree of risk sharing can, in theory, be achieved through financial markets.
This claim was hugely misguided.
Financial markets can be fragile, and they provide little capacity for sharing risk related to labor income, which constitutes the largest part of income in any advanced economy.
Kenen was mainly concerned with short-term transfers to smooth out cyclical bumpiness.
But, in a currency union with huge differences in income and development levels, the short term can stretch out for a very long time.
Many Germans today rightly feel that any system of fiscal transfers will morph into a permanent feeding tube, much the way that northern Italy has been propping up southern Italy for the last century.
Indeed, more than 20 years on, Western Germans still see no end in sight for the bills from German unification.
Later, Maurice Obstfeld pointed out that, in addition to fiscal transfers, a currency union needs clearly defined rules for the lender of last resort.
Otherwise, bank runs and debt panics will be rampant.
Obstfeld had in mind a bailout mechanism for banks, but it is now abundantly clear that one also needs a lender of last resort and a bankruptcy mechanism for states and municipalities.
A logical corollary of the criteria set forth by Kenen and Obstfeld, and even of Mundell’s labor-mobility criterion, is that currency unions cannot survive without political legitimacy, most likely involving region-wide popular elections.
Europe’s leaders cannot carry out large transfers across countries indefinitely without a coherent European political framework.
European policymakers today often complain that, were it not for the US financial crisis, the eurozone would be doing just fine.
Perhaps they are right.
But any financial system must be able to withstand shocks, including big ones.
Europe may never be an “optimum” currency area by any standard.
But, without further profound political and economic integration – which may not end up including all current eurozone members – the euro may not make it even to the end of this decade.
OXFORD – In Anthony Burgess’s novella (and Stanley Kubrick’s film) A Clockwork Orange, Alex, an unrepentant psychopath, has his eyes pried wide open and is forced to watch violent images.
Like Pavlov’s dog, Alex is being programmed to respond with nausea to violence and sex.
This scene remains shocking, but, like most science fiction, it has aged.
The behaviorist psychology it drew upon has long expired, and the fear that science will be used to make, or even force, people to be morally better now sounds old-fashioned.
Science fiction ages fast, but it has a long afterlife.
Over the past decade, an army of psychologists, neuroscientists, and evolutionary biologists has been busy trying to uncover the neural “clockwork” that underlies human morality.
They have started to trace the evolutionary origins of pro-social sentiments such as empathy, and have begun to uncover the genes that dispose some individuals to senseless violence and others to acts of altruism, and the pathways in our brain that shape our ethical decisions.
And to understand how something works is also to begin to see ways to modify and even control it.
Indeed, scientists have not only identified some of the brain pathways that shape our ethical decisions, but also chemical substances that modulate this neural activity.
A recent study has shown that the anti-depressant Citalopram can change the responses of individuals to hypothetical moral dilemma scenarios.
Individuals given the drug were less willing to sacrifice an individual to save the lives of several others.
Another series of studies has shown that when the hormone oxytocin is administered via nasal spray, it increases trusting and cooperative behavior within social groups, but also decreases cooperation with those perceived as outsiders.
Neuroscientists have even magnetically “zapped” carefully targeted areas of people’s brains to influence their moral judgments in surprising ways – for example, making it easier for them to lie.
Of course, no one is developing a “moral pill” that will transform us into saints.
But the research is advancing fast, and it is almost certain to suggest new ways to reshape our moral intuitions, sentiments, and motivations.
Should we use our growing scientific understanding of the basis of human morality to try to make people morally better?
A Clockwork Orange was accused of glorifying violence, and some of its scenes are still hard to watch.
But as Burgess himself argued, the novella has an almost Christian message: what makes us human is our freedom to choose both good and evil, and for society to crush individuals into servile conformity is as wicked as, and perhaps even worse than, the sadism of psychopaths like Alex.
I suspect that many will agree with this view.
They will agree that our ability to distinguish right from wrong is something precious that we should safeguard, not a broken clock that scientists should fix.
Of course, most of us don’t need to be conditioned to feel repulsed by rape or torture.
But this does not mean that we are morally good, or good enough.
As you read this, perfectly ordinary people somewhere in the world are doing unspeakable things to others.
Even in the most advanced and affluent societies, a vast concentrated effort is needed to preserve even minimal decency: think of locks, security alarms, police, courts, and prisons.
And it is doubtful that we really care enough about others, or give enough to the less fortunate.
Humans are born with the capacity to be moral, but it is a limited capacity which is ill equipped to deal with the ethical complexities of the modern world.
For thousands of years, humans have relied on education, persuasion, social institutions, and the threat of real (or supernatural) punishment to make people behave decently.
We could all be morally better, but it is clear that this traditional approach cannot take us much further.
It is not as if people would suddenly begin to behave better if we just gave them more facts and statistics, or better arguments.
So we shouldn’t be too quick to dismiss the suggestion that science might help – in the first instance, by helping us design more effective institutions, more inspiring moral education, or more persuasive ethical arguments.
But science might also offer more direct ways of influencing our brains.
Science fiction sometimes limits rather than expands our sense of what is possible.
It would be self-defeating, or worse, to try to promote morality through brutal coercion.
Governments must not be given the power to control its citizens’ moral code – we know that if they had such power, they would misuse it.
It would be ideal if individuals could freely explore different ways to improve themselves, whether by practicing mindfulness, reading moral philosophy, or, yes, by taking a ’morality’ pill.
But it is also true that although some people are eager to take pills that make them feel better or think faster, it is not so obvious that people would really want to take pills that would make them morally better.
It is not clear that people really want to be morally better.
And those who, like the psychopathic Alex, need the most help are probably those who would want it least.
These are, of course, hypothetical questions.
We don’t yet know what is possible.
But it is better to begin the ethical discussion too early than too late.
And even if “moral pills” are just science fiction, they raise deep questions.
Will we want to take them if they ever become available?
And what does it say about us if we won’t?
PRINCETON – When airports across Europe reopened after the closure caused by the eruption of Iceland’s Eyjafjallajökull volcano, it was not because the amount of ash in the atmosphere had dropped, but because the risk that the ash posed to airplane safety had been reassessed.
Was it new scientific information that led to the lifting of the flight ban, or was it a reflection of the hardship, both personal and economic, that the ban was causing?
Over six days, about 95,000 flights were canceled, at a cost to airlines of more than $1 billion.
An estimated five million people were stranded or delayed.
The British economy lost £1.5 billion, and others were similarly affected.
Flower growers in Kenya, who depend on air transport to take their short-lived product to Europe, suddenly had no income.
Sixteen cancer patients in critical need of bone marrow for transplants were put at risk because the matching marrow could not be flown in from the United States or Canada.
In the past, jets flying into ash from volcanoes in the US, Indonesia, the Philippines, and Mexico have temporarily lost engine power, and in one case, dropped thousands of feet, although all managed to land safely.
But there was no evidence that the more widely dispersed ash blowing over Europe from Iceland would cause similar problems.
The decision to ground flights was based on the view that any level of ash in the atmosphere posed some risk to aircraft, and that no matter how slight that risk might be, the government’s job was, as British Prime Minister Gordon Brown put it, “to make sure that safety was paramount.”
Indeed, in closing their skies, European governments seem to have given safety absolute priority over everything else.
Yet none of them act on that principle in other areas.
Some 3,000 people die on the world’s roads every day.
Cutting speed limits to, say, 10 kilometers per hour would prevent most accidents and save many lives.
We don’t do it, because we give safety a lower priority than our desire to spend less time driving.
The price we are willing to pay for safety cannot be infinite.
It is distasteful to put a price on human life, but the more we spend on safety, the less we will have for our other goals.
The British government uses a figure of a little more than £1 million as a general limit to the amount it is prepared to pay to save a statistical life – for example, by improving road safety.
In the US, the Department of Transportation is prepared to go up to $5.8 million – nearly four times as much, at current exchange rates – for the same purpose.
Does that mean that safety is paramount in the US, but not in Britain?
Giovanni Bisignani, the head of the International Air Transport Association, an industry group, criticized the shutdown, saying that no risk assessment had been undertaken.
On the whole, though, the public seemed to support the decision.
Stranded travelers, interviewed at airports, typically said that they would rather be stuck at an airport than in a plane falling out of the sky.
But what if some travelers have a higher tolerance of risk, or just a more urgent need to travel, than others?
John Stuart Mill, in his classic book On Liberty, considered a situation in which a man sets out to cross a bridge that we know is unsafe.
In Mill’s view, we are justified in stopping him only to make sure that he is aware of the danger.
Once he knows of it, the decision is his to make, because only he can judge the importance of his journey, and balance that against the risk he is running.
Air safety is slightly different, because a crashing plane can kill people on the ground, but the greatest risks by far are borne by the passengers and crew.
If they are fully informed of the risks, and are still willing to fly – perhaps the crew has been offered more money, as workers in dangerous occupations often are – should we prevent them from making the decision to fly?
In the end, after test flights with no passengers aboard had shown no engine damage, and aircraft engine manufacturers told aviation authorities that their engines could operate safely with a low level of ash in the atmosphere, Europe’s skies were reopened.
The International Civil Aviation Authority has announced that it will convene a group of experts to help it provide guidance for the industry to decide what level of ash in the atmosphere makes it unsafe to fly.
Now that we have seen the costs of giving absolute priority to safety, we know that this is not only a technical question.
I trust that among the experts will be some who have pondered the underlying ethical question: how safe should we aim to be?
PRINCETON – Russian President Vladimir Putin’s anointment of Alexander Medvedev to succeed him in what is supposed to be a democratic presidential election next March shows that Russia’s leaders have not changed a whit.
It looks increasingly likely that, as under Leonid Brezhnev, we will see the same names in the news for decades to come.
According to Gleb Pavlovsky, the Putin regime’s leading ideologist, the current Russian system is perfect in all respects but one: it doesn’t know its enemies.
Indeed, it seems as if everyone in the Kremlin is reading Carl Schmitt, the Nazi legal theorist who taught that naming your enemy is the central mission of politics.
In the spirit of Schmitt, Putin’s men designated a liberal party, the Union of Right Forces, as their ur-enemy.
Its public meetings were broken up by armed police; its leaders arrested and beaten; Putin called its supporters “coyotes.”
What is surprising is that this aggressive behavior occurred in response to no visible danger.
Oil prices are soaring, as are Putin’s approval ratings.
His appointees control everything that matters, from Gazprom to the Central Electoral Committee.
Since the pacification of Chechnya with violence and subsidies, the incarceration or emigration of a few financially viable opponents, and the massive “social investments” of recent years, which, under Medvedev’s personal supervision, have bribed the population, no credible force can seriously challenge Putin’s men.
Yet their regime is in crisis, and they know it.
Russia’s economy is more dependent on gas and oil than ever before.
Military reform has been reversed.
Despite increasing incomes, Russians are less educated and less healthy than they were when Putin came to power; they still die at a shockingly young age.
Russian involvement in world affairs is tainted by poison and corruption.
State monopolies undo what private businesses created.
With more money, ill-educated bureaucrats hire more ill-educated bureaucrats; as a result, the regime fails to rule the country.
The country is unruly, and its rulers know it.
So they panic.
Putin’s aim was to subject all power to the control of Russia’s security forces.
His generation of KGB officers watched the collapse of the Communist Party and all the governmental bodies that it “directed and controlled,” including the KGB.
Under Putin, the security service has had its revenge.
Its people have become powerful, arrogant, and enormously rich.
They have also become disobedient.
In 2004, General Viktor Cherkesov, then Putin’s representative in northwest Russia, published an essay that glorified the KGB as the only unspoiled authority in a corrupted country.
This essay, more than anything else, defined Putin’s second term.
In October 2007, Cherkesov (now chief of one of the most obscure and powerful services, the Federal Anti-Drug Administration) published another essay in which he lamented his colleagues’ degradation: warriors had turned into traders, he complained.
Earlier, generals from a competing service, the FSB, had arrested Cherkesov’s deputy for “illegal bugging.”
In a public gesture of despair, Cherkesov admitted the failure of Putin’s project to reanimate Russian governance by subordinating it to the security services.
Cherkesov’s deputy remains in prison. Most believe that Putin is unable to intervene in his defense.
In the absence of Communist Party control, these security officers betrayed their corporate ethic and engaged in horse-trading, applying force when a trade did not go well.
That this happens to ordinary Russians is clear; what Cherkesov revealed was that Putin’s circle also confronts this situation.
What is to be done when ex-KGB warriors turn their swords and bugs against one another?
Cherkesov’s case exemplifies Putin’s nightmare.
But if your instincts betray you, you go back to even deeper ones.
Now that Putin’s people have left their predecessors’ neo-liberal ideas behind and feel disenchanted with the ex-KGB clique, the task is to recreate an omnipresent political party that controls the security services, the administration, business, and much else.
This party will be centralized under personal leadership and will reduce the state to a legal fiction.
Preaching nationalism, its managers will believe in their universal competence, as opposed to KGB-style professionalism and corporatism.
Boris Yeltsin forbade party cells in state-controlled institutions by decree.
Putin’s lawyers will reverse that decision; the party will have cells or committees in every factory, corporation, military unit, university department, etc. Integrated by the leader’s charisma and party discipline, party members will direct and unify the desolated country.
This is Putin’s plan.
Like former Soviet leader Yuri Andropov, the only other KGB man to rule Russia, Putin will become the party’s general secretary.
As in the Soviet era, state and governmental officials will be reduced to party ciphers – the role that President Medvedev will play under General Secretary Putin.
And, of course, being General Secretary carries no constitutional term limit.
In the end, Putin has what history left him: not ideas, just a faction yearning to consolidate its grip on power.
Lenin and Trotsky needed a party to make their ideology a reality; Putin and Medvedev are devising an ideology to solidify their party.
It is a bizarre ideology.
Accusing warriors of being traders and traders of being thieves, it shuns its Marxist origins.
It will subordinate all who really do work – traders, warriors, journalists, and others – to party ideologues whose sole job is to search for enemies.
LONDON – Last month, while in New York City, I happened to be staying in the same hotel as Israeli Prime Minister Binyamin Netanyahu.
To accommodate his security needs, the hotel had been converted into a fortress, much like Israel itself.
Netanyahu was in the United States for yet another round of Middle East peace talks.
The US offered various sweeteners to induce Israel to freeze its West Bank settlement construction for another 90 days.
The Israelis refused; another impasse was reached.
What, then, might be the prospects of a negotiated peace between two peoples with claims to the same land?
The answer is: very poor.
All peace efforts since the Oslo accords of 1993 have been based on the “two-state solution,” according to which Israel is supposed to turn over the occupied territories to a Palestinian state, the Palestinians are supposed to renounce any claims on the Jewish state, and everyone is supposed to live happily ever after.
A negotiated “land for peace” solution still remains official Western doctrine.
As US Secretary of State Hillary Clinton put it in a recent speech, “a just, lasting, and comprehensive peace” has to be based on “two states for two peoples.”
Meanwhile, the two main parties to the dispute, Palestine and Israel, are searching for unilateral alternatives to the stymied “peace process.”
The Palestinians are pushing for international recognition of their statehood, while the Israelis are using their settlement policy to preempt a Palestinian state.
Palestinian President Mahmoud Abbas has said that, if the latest peace talks collapse, he will press for UN recognition of a Palestinian state based on the 1967 borders.
This month, Brazil and Argentina recognized “Palestine,” and a cascade of Latin American countries is expected to follow.
Abbas is now setting his sights on Europe, and would ask Turkey to serve as a go-between.
The game is to use international recognition of an independent Palestinian state to pressure the US to retreat from its almost unconditional support for Israeli policy.
Israel’s main concern continues to be security.
The official Western doctrine is that Israel’s long-term security depends on the success of the “peace process.”
In practice, Israel has been taking other measures to secure its future.
Media attention has been focused on the “security wall,” which has certainly succeeded in reducing the level of violence.
But, to the hawks who now control Israeli politics, the key to Israel’s security depends on depth of defense, for which expansion of the settlements is indispensable.
The hawks’ recipe for survival is threefold: continued military and economic support from the US, defensible frontiers through a strategic settlement program, and the carve-up of the Palestinian West Bank into disconnected bantustans, or subordinate authorities, incapable of concerted opposition to Israeli policy.
Thus, while Abbas seeks to create a new “fact on the ground” by drumming up international support for a Palestinian state, Israel aims to trump him by making such a state unviable.
The ideal alternative to both strategies is a peace process that aims not to create two states, but rather to establish the political and economic basis for a single confederal state.
Indeed, the two-state solution was always an illusion.
There was never enough land to satisfy the passionate possessiveness of all those with claims to it.
And, over time, Israeli settler disengagement from the West Bank and East Jerusalem has become just as impossible as any attempt by Israel to expel its remaining Arabs.
Israeli Jews are bound to stay in the West Bank and East Jerusalem, and Israeli Arabs are bound to stay in Israel proper.
These are the “facts on the ground” that doom Palestinian hopes for a sovereign Palestinian state no less than Israeli hopes for a wholly Jewish state.
Moreover, land for peace never made sense from an economic point of view.
If compensation for wrongs to the Palestinians was to be the guiding principle, there were always better ways of going about it than to found a rickety, poverty-ridden new country dependent on foreign aid.
Most people have forgotten that the Paris Protocols of April 1994 established a customs union between Israel and the occupied territories, with a joint Economic Council to adjudicate trade disputes.
The free movement of goods, labor, and capital between the two parts could have given a tremendous economic boost to Palestinian GDP.
It could also have been the basis of a confederal state, whose Palestinian part would have benefited from the West Bank settlers’ productivity and taxes.
But this benign prospect was undermined by the violence needed to maintain the Jewish state and enable the emergence of a Palestinian one.
The official view remains that only an internationally guaranteed two-state settlement will bring about the security needed for the economic revival of the Palestinian territories.
But it is just possible that unilateral Israeli policy, implicitly backed by the US, will create interim conditions of peace that are sufficient for economic growth to cool Palestinian nationalism.
The Palestinian cause is not the overriding preoccupation of even the Arab states, so Netanyahu’s strategy of defense in depth stands a better chance of success than Abbas’s pursuit of statehood through international recognition.
Netanyahu’s project is not moral.
But that doesn’t mean that it won’t work, at least for a time.
Time is running out in Kosovo. If a United Nations-backed settlement is not reached by early December, the province’s majority Albanian population is likely to declare independence unilaterally – a move that the United States has announced it may support.
That would be a disastrous step.
Russia would be furious, because it fears that Kosovo’s secession – whether or not it is internationally recognized – might fuel separatist movements in the former Soviet empire.
Serbia is even more strongly opposed.
Dusan Prorokovic, Serbia’s state secretary for Kosovo, has said that his country might use force to maintain its sovereignty.
Even if the government hesitates, ultranationalist groups might push Prime Minister Vojislav Kostunica to send in troops: the current UN presence in Kosovo is very thin (only 40 “military observers” and 2,116 policemen) but the stationing of 15,000 NATO troops could make any armed clash very dangerous.
After eight years of international administration, Kosovo’s Albanian majority has tasted freedom and is eager for full independence.
But Serbia claims that the province remains an essential part of its historical and cultural tradition.
Moreover, independence would not be accepted by the Serbian public, which has already watched in dismay as “Great Serbia” has been gradually whittled away, most recently with the secession of Montenegro.
Serbia is prepared to concede only “enhanced autonomy” to Kosovo, and some capacity to enter into international agreements.
Yet, while the two parties now seem irreconcilable, it is not too late for compromise.
But this is possible only by resuscitating – and updating – an old institution of the international community: a confederation of states.
By means of a binding UN Security Council resolution, Kosovo could be granted full and exclusive authority over its citizens and territory, as well as limited capacity for action on the international scene.
It could be authorized to enter into trade agreements as well as agreements concerning individuals (for example, admission and circulation of foreigners, or extradition), plus the right to seek admission to the UN (which does not require full sovereignty and independence).
Kosovo would thus gain some essential trappings of statehood.
However, a decision-making body consisting of delegates from Kosovo, Serbia, and the European Union would be given full authority over major foreign policy issues (for example, alliances and relations with international economic institutions), defence, borders (in case Kosovo wished to join with Albania), and the treatment of Kosovo’s Serbian minority.
As a result, Kosovo and Serbia would constitute two distinct international subjects, bound by a confederation hinging on a common decision-making body.
Of course, this confederation would be asymmetrical, because the Serbian government’s sovereignty over the rest of Serbia would remain intact and unlimited, whereas the Kosovar government’s “sovereignty” over Kosovo would be restrained.
To avoid one of the two parties getting the upper hand and imposing arbitrary decisions, the common decision-making body should consist of four Serbian delegates, two Kosovar delegates, and three representatives of the EU, thus requiring both sides to gain the support of the European delegates.
In addition, the EU should create a small but effective military force (say, 5,000 troops) to back up the common body’s decisions.
As with any compromise, the contending parties would both gain and lose from this arrangement.
Serbia would save face, and would continue to have a say on crucial matters concerning Kosovo, including the treatment of the Serbian minority.
Kosovo would acquire limited independence, with its status rising from a province of a sovereign state to an international subject capable of entering into certain agreements with other states and even joining the UN.
The EU would benefit as well, by contributing to the stabilization of a highly volatile area.
Subsequently, the EU would monitor Kosovo and prevent any dispute that might turn violent.
A final advantage of this solution is that it would be temporary.
Historically, confederations sooner or later either become federations (as occurred in the US, Germany, and Switzerland) or, pushed by centrifugal forces, split up (as with the United Arab Republic, established in 1958, which split three years later into Egypt and Syria).
The confederation I advocate would thus constitute an intermediate stage (lasting five or ten years), at the end of which Kosovo is likely to become fully independent.
Delaying a final solution in this way would provide time to verify Kosovo’s prospects of joining the EU and thus eventually sharing “sovereign authority” with other independent states, which could deflate Kosovars’ dangerously robust nationalistic demands.
NEW YORK – Is this the Age of the Conspiracy Theory?
Plenty of evidence suggests that we are in something of a golden age for citizen speculation, documentation, and inference that takes shape – usually on the Internet – and spreads virally around the globe.
In the process, conspiracy theories are pulled from the margins of public discourse, where they were generally consigned in the past, and sometimes into the very heart of politics.
I learned this by accident.
Having written a book about the hijacking of executive power in the United States in the Bush years, I found myself, in researching new developments, stumbling upon conversations online that embrace narratives of behind-the-scenes manipulation.
There are some major themes.
A frequent one in the US is that global elites are plotting – via the Bilderberg Group and the Council on Foreign Relations, among others – to establish a “One World Government” dominated by themselves rather than national governments.
Sometimes, more folkloric details come into play, broadening the members of this cabal to include the Illuminati, the Freemasons, Rhodes Scholars, or, as always, the Jews.
The hallmarks of this narrative are familiar to anyone who has studied the transmission of certain story categories in times of crisis.
In literary terms, this conspiracy theory closely resembles The Protocols of the Elders of Zion , featuring secretive global elite with great power and wicked aims.
Historically, there tends to be the same set of themes: fearsome, uncontrolled transformative change led by educated, urbanized cosmopolitans.
Students of Weimar Germany know that sudden dislocations and shocks – rapid urbanization, disruption of traditional family and social ties, loosening of sexual restrictions, and economic collapse – primed many Germans to become receptive to simplistic theories that seemed to address their confusion and offer a larger meaning to their suffering.
Similarly, the “9/11 Truth Movement” asserts that al-Qaeda’s attack on the Twin Towers was an “inside job.”
In the Muslim world, there is a widespread conspiracy theory that the Israelis were behind those attacks, and that all Jews who worked in the buildings stayed home that day.
Usually, conspiracy theories surface where people are poorly educated and a rigorous independent press is lacking.
So why are such theories gaining adherents in the US and other affluent democracies nowadays?
Today’s explosion of conspiracy theories has been stoked by the same conditions that drove their acceptance in the past: rapid social change and profound economic uncertainty.
A clearly designated “enemy” with an unmistakable “plan” is psychologically more comforting than the chaotic evolution of social norms and the workings – or failures – of unfettered capitalism.
And, while conspiracy theories are often patently irrational, the questions they address are often healthy, even if the answers are frequently unsourced or just plain wrong.
In seeking answers, these citizens are reacting rationally to irrational realities.
Many citizens believe, rightly, that their mass media are failing to investigate and document abuses.
Newspapers in most advanced countries are struggling or folding, and investigative reporting is often the first thing they cut.
Concentration of media ownership and control further fuels popular mistrust, setting the stage for citizen investigation to enter the vacuum.
Likewise, in an age when corporate lobbyists have a free hand in shaping – if not drafting – public policies, many people believe, again rightly, that their elected officials no longer represent them.
Hence their impulse to believe in unseen forces.
Finally, even rational people have become more receptive to certain conspiracy theories because, in the last eight years, we actually have seen some sophisticated conspiracies.
The Bush administration conspired to lead Americans and others into an illegal war, using fabricated evidence to do so.
Is it any wonder, then, that so many rational people are trying to make sense of a political reality that really has become unusually opaque?
When even the 9/11 commissioners renounce their own conclusions (because they were based on evidence derived from torture), is it surprising that many want a second investigation?
Frequently enough, it is citizens digging at the margins of the discourse – pursuing such theories – who report on news that the mainstream media ignores.
For example, it took a “conspiracy theorist,” Alex Jones, to turn up documentation of microwave technologies to be used by police forces on US citizens. The New Yorker confirmed the story much later – without crediting the original source.
The mainstream media’s tendency to avoid checking out or reporting what is actually newsworthy in Internet conspiracy theories partly reflects class bias.
Conspiracy theories are seen as vulgar and lowbrow.
So even good, critical questions or well-sourced data unearthed by citizen investigators tend to be regarded as radioactive to highly educated formal journalists.
The real problem with this frantic conspiracy theorizing is that it leaves citizens emotionally agitated but without a solid ground of evidence upon which to base their worldview, and without constructive directions in which to turn their emotions.
This is why so many threads of discussion turn from potentially interesting citizen speculation to hate speech and paranoia.
In a fevered environment, without good editorial validation or tools for sourcing, citizens can be preyed upon and whipped up by demagogues, as we saw in recent weeks at Sarah Palin’s rallies after Internet theories painted Barack Obama as a terrorist or in league with terrorists.
We need to change the flow of information in the Internet age.
Citizens should be able more easily to leak information, pitch stories, and send leads to mainstream investigative reporters.
They should organize new online entities in which they pay a fee for direct investigative reporting, unmediated by corporate pressures.
And citizen investigators should be trained in basic journalism: finding good data, confirming stories with two independent sources, using quotes responsibly, and eschewing anonymity – that is, standing by their own bylines, as conventional reporters do.
This is how citizens can be taken – and take themselves – seriously as documenters and investigators of our common situation.
In a time of official lies, healthy investigative energy should shed light, not just generate heat.
Changing constitutions is always a risky business.
But it is a downright dangerous one when undertaken to benefit one man alone.
Indeed, when a president volunteers to reduce the powers of his own office, you can be certain that he is up to no good.
That is exactly what is going on in Ukraine, where President Leonid Kuchma proposes to junk our presidential system and replace it with a strange type of parliamentary system he has concocted.
Kuchma has not suddenly converted to the view that parliamentary democracies are better than presidential ones.
No, Kuchma wants to change Ukraine's constitution for no other reason than to maintain his grip on power.
Today, Kuchma rules as an all-powerful president.
But his term ends next year and he cannot run again.
So, instead of retiring gracefully, as presidents from Bill Clinton to Boris Yeltsin routinely do, Kuchma wants to change the constitution in order to become an all-powerful prime minister who will never face a limit on the length of his term.
Of course, constitutions are not meant to protect the status quo if the status quo is rotten.
Constitutions can, and should, accommodate reform when necessary.
A powerful president, however, is not necessarily wrong for Ukraine.
In our wrenching postcommunist transition, it is essential that a government can act decisively.
To change a system that seems best suited to Ukraine's circumstances, you need a good reason.
The Ukraine president is authorized to appoint and sack the prime minister, dissolve parliament if he wishes, and rule by decree if he judges that the country's institutions are in danger.
He maintains day-to-day control over every aspect of government.
Sopuissant a Caesar must be above reproach.
Kuchma is not.
On the contrary, what is rotten in Ukraine is not its constitution, but its president, who is mired in charges of corruption and orchestrating the murder of journalists, and who is shunned by other world leaders.
As president, Kuchma is grotesquely unpopular.
Even Slobodan Milosevic had more support in Yugoslavia before his fall.
So Kuchma knows that he cannot rely on handpicking his successor, as Yeltsin did in Russia.
Unable to assure himself of a tame presidential successor, Kuchma wants what he calls a "parliamentary republic" with a weak president and powerful prime minister.
But the parliament he has in mind is a mutant, one where the authoritarian rule of the criminal clans Kuchma controls will continue, unabated, behind the facade of parliamentary procedure.
People too easily forget Ukraine, this big country on the border of the soon-to-be enlarged European Union.
But any attempt to prolong Kuchma's rule will create such a political mess that it is not absurd to fear that Ukraine could follow Belarus and the Balkans of the early 1990's into outright dictatorship and chaos.
Indeed, this scenario could worsen, because Russia is unlikely to sit around idly and watch Ukraine unravel.
Intervention of some type seems more likely in such circumstances.
Only an imperial Russia, however, would dare reabsorb Ukraine.
But an imperial Russia cannot be a democratic Russia.
So Kuchma endangers freedom and human rights not only in Ukraine, but ultimately threatens Russia's democracy as well.
Luckily, there has never been a better time for the West--particularly the EU--to nudge Ukraine back from the brink.
With EU expansion coming next spring, all Ukrainians fear that a new wall will cut their country off from the Union's easternmost border in Poland.
Although the job of maintaining Ukraine's democracy is primarily one for Ukrainians, the EU can help if it takes practical steps to reassure Ukrainians that they won't be cut off from the rest of Europe.
A generous visa regime and the use of regional development funds in Ukraine that will benefit impoverished eastern Poland, are two possible inducements.
But these should be made conditional on Kuchma leaving the country's constitution and democracy alone.
The EU should not fret about interfering in Ukraine's domestic affairs.
After all, it hesitated little a few years ago to put a current member state, Austria, on notice that it was watching out for the welfare of that country's democracy.
The wayward Kuchma is far more deserving of Europe imposing safeguards to ensure his good behavior.
Similarly, the US should cast a wary eye at Kuchma's decision to send troops to Iraq.
It cannot be the case that America's fidelity to democracy in Ukraine can be so cynically purchased.
Within Ukraine, a government capable of truly governing should seek to adopt EU laws and norms in exactly the manner that the countries poised to join the Union have done, thus helping to clean up the murky system in which Kuchma's criminal cronies flourish.
The constitution must be reformed, but not to shift power from one unaccountable leader to another.
What is needed are clear checks on arbitrary rule, and transparency in decision-making.
No one should doubt that Kuchma intends to stay in power, no matter what.
Less certain is whether he will feel secure enough to hold a presidential election (or any other kind of election) if he cannot change the constitution in a way that guarantees his continued misrule.
It is, after all, President Kuchma who is discredited, not Ukraine's constitutional arrangements.
NEW YORK – The Great Recession of 2008 has morphed into the North Atlantic Recession: it is mainly Europe and the United States, not the major emerging markets, that have become mired in slow growth and high unemployment.
And it is Europe and America that are marching, alone and together, to the denouement of a grand debacle.
A busted bubble led to a massive Keynesian stimulus that averted a much deeper recession, but that also fueled substantial budget deficits.
The response – massive spending cuts – ensures that unacceptably high levels of unemployment (a vast waste of resources and an oversupply of suffering) will continue, possibly for years.
The European Union has finally committed itself to helping its financially distressed members.
It had no choice: with financial turmoil threatening to spread from small countries like Greece and Ireland to large ones like Italy and Spain, the euro’s very survival was in growing jeopardy.
Europe’s leaders recognized that distressed countries’ debts would become unmanageable unless their economies could grow, and that growth could not be achieved without assistance.
But, even as Europe’s leaders promised that help was on the way, they doubled down on the belief that non-crisis countries must cut spending.
The resulting austerity will hinder Europe’s growth, and thus that of its most distressed economies: after all, nothing would help Greece more than robust growth in its trading partners.
And low growth will hurt tax revenues, undermining the proclaimed goal of fiscal consolidation.
The discussions before the crisis illustrated how little had been done to repair economic fundamentals.
The European Central Bank’s vehement opposition to what is essential to all capitalist economies – the restructuring of failed or insolvent entities’ debt – is evidence of the continuing fragility of the Western banking system.
The ECB argued that taxpayers should pick up the entire tab for Greece’s bad sovereign debt, for fear that any private-sector involvement (PSI) would trigger a “credit event,” which would force large payouts on credit-default swaps (CDSs), possibly fueling further financial turmoil.
But, if that is a real fear for the ECB – if it is not merely acting on behalf of private lenders – surely it should have demanded that the banks have more capital.
Likewise, the ECB should have barred banks from the risky CDS market, where they are held hostage to ratings agencies’ decisions about what constitutes a “credit event.”
Indeed, one positive achievement by European leaders at the recent Brussels summit was to begin the process of reining in both the ECB and the power of the American ratings agencies.
Indeed, the most curious aspect of the ECB’s position was its threat not to accept restructured government bonds as collateral if the ratings agencies decided that the restructuring should be classified as a credit event.
The whole point of restructuring was to discharge debt and make the remainder more manageable.
If the bonds were acceptable as collateral before the restructuring, surely they were safer after the restructuring, and thus equally acceptable.
This episode serves as a reminder that central banks are political institutions, with a political agenda, and that independent central banks tend to be captured (at least “cognitively”) by the banks that they are supposed to regulate.
And matters are little better on the other side of the Atlantic.
There, the extreme right threatened to shut down the US government, confirming what game theory suggests: when those who are irrationally committed to destruction if they don’t get their way confront rational individuals, the former prevail.
As a result, President Barack Obama acquiesced in an unbalanced debt-reduction strategy, with no tax increases – not even for the millionaires who have done so well during the past two decades, and not even by eliminating tax giveaways to oil companies, which undermine economic efficiency and contribute to environmental degradation.
Optimists argue that the short run macroeconomic impact of the deal to raise America’s debt ceiling and prevent sovereign default will be limited – roughly $25 billion in expenditure cuts in the coming year.
But the payroll-tax cut (which put more than $100 billion into the pockets of ordinary Americans) was not renewed, and surely business, anticipating the contractionary effects down the line, will be even more reluctant to lend.
The end of the stimulus itself is contractionary.
And, with housing prices continuing to fall, GDP growth faltering, and unemployment remaining stubbornly high (one of six Americans who would like a full-time job still cannot get one), more stimulus, not austerity, is needed – for the sake of balancing the budget as well.
The single most important driver of deficit growth is weak tax revenues, owing to poor economic performance; the single best remedy would be to put America back to work.
The recent debt deal is a move in the wrong direction.
There has been much concern about financial contagion between Europe and America.
After all, America’s financial mismanagement played an important role in triggering Europe’s problems, and financial turmoil in Europe would not be good for the US – especially given the fragility of the US banking system and the continuing role it plays in non-transparent CDSs.
But the real problem stems from another form of contagion: bad ideas move easily across borders, and misguided economic notions on both sides of the Atlantic have been reinforcing each other.
The same will be true of the stagnation that those policies bring.
The British government recently issued the most comprehensive study to date of the economic costs and risks of global warming, and of measures that might reduce greenhouse gas emissions, in the hope of averting some of the direst consequences.
Written under the leadership of Sir Nicholas Stern of the London School of Economics, who succeeded me as Chief Economist of the World Bank, the report makes clear that the question is no longer whether we can afford to do anything about global warming, but whether we can afford not to.
The report proposes an agenda whose cost would be equivalent to just 1% of annual consumption, but would save the world risk equivalent costs that are five times greater.
The reported costs of global warming are higher than in earlier studies because it takes into account the mounting evidence that the process of global warming is highly complex and non-linear, with a non-negligible chance that it may proceed much faster than had previously been thought and that the extent of warming may be much greater than had previously been thought.
Indeed, the study may actually significantly underestimate the costs: for instance, climate change may lead to more weather variability, a possible disappearance or major shift of the Gulf Stream – of particular concern to Europe – and a flourishing of disease.
When I served in 1995 on the Intergovernmental Panel on Climate Change, the scientific group that periodically assesses the science of global warming, there was overwhelming evidence that the concentration of greenhouse gases in the atmosphere had increased markedly since the beginning of the industrial revolution, that human activity had contributed significantly to those increases, and that they would have profound effects on climate and sea levels.
But few saw, for instance, the Artic ice cap melting as rapidly as now seems to be the case.
Still, some suggest that because we are not certain about how bad global warming will be, we should do little or nothing.
To me, uncertainty should make us act more resolutely today, not less.
As one scientist friend puts it: if you are driving on a mountain road, approaching a cliff, in a car whose brakes may fail, and a fog bank rolls in, should you drive more or less cautiously?
Global warming is one of those rare instances where the scientific community is more fearful of what may be happening than the population at large.
Scientists have glimpsed what the future may portend.
As the Stern report points out, as usual, the poor are the most vulnerable.
A third of Bangladesh will be underwater by the end of this century.
The Maldives and a host of Pacific Island states will disappear: our twenty-first-century Atlantis.
To an economist, the problem is obvious: polluters are not paying the full costs of the damage they cause.
Pollution is a global externality of enormous proportions.
The advanced countries might mean Bangladesh and the disappearing island states no harm, but no war could be more devastating.
A global externality can best be dealt with by a globally agreed tax rate.
This does not mean an increase in overall taxation, but simply a substitution in each country of a pollution (carbon) tax for some current taxes.
It makes much more sense to tax things that are bad, like pollution, than things that are good, like savings and work.
Although President George W. Bush says he believes in markets, in this case he has called for voluntary action.
But it makes far more sense to use the force of markets – the power of incentives – than to rely on goodwill, especially when it comes to oil companies that regard their sole objective as maximizing profits, regardless of the cost to others.
Exxon has reportedly been funding so-called think tanks to undermine confidence in the science of global warming, just as the tobacco industry funded “research” to question the validity of statistical findings showing the link between smoking and cancer.
Some companies even seem to celebrate the melting of the polar ice cap, because it will reduce the cost of extracting the oil that lies beneath the Arctic Ocean.
The good news is that there are many ways by which improved incentives could reduce emissions – partly by eliminating the myriad of subsidies for inefficient usages.
The US subsidizes corn-based ethanol, and imposes tariffs on sugar-based ethanol; hidden in the tax code are billions of dollars of subsidies to the oil and gas industries.
Most importantly, price signals that show the true social costs of energy derived from fossil fuels will encourage innovation and conservation.
Small changes in practices, when replicated by hundreds of millions of people, can make an enormous difference.
For example, simply changing the color of roofs in warm climates to reflect sunlight or planting trees around houses can lead to great savings on energy used for air conditioning.
We have but one planet, and should treasure it.
Global warming is a risk that we simply cannot afford to ignore anymore.
LONDON – Reading Barack Obama’sDreams from My Father, the US president’s beautifully written reflections on his early life and identity, most people are struck by his cool and intellectual approach.
This is not to say that he is unemotional.
Obama can rage and weep.
But he rarely seems to act on the basis of raw sentiment or instinctive prejudice.
Pragmatic and highly intelligent, sooner or later every issue receives the full attention of his forensic curiosity.
Recalling Hillary Clinton’s famous Democratic primary television advertisement, Obama, it turns out, is exactly the sort of president that most of us would want to have in the post for that 3 a.m. phone call about an international crisis.
He would not be afraid to act, but he would be prepared to think first.
I do not think, therefore, that Obama will be too vexed by some of the criticism he faces at the end of his first year in office, though he will undoubtedly grimace at the defeat of the Democratic candidate in the special election in Massachusetts to fill Ted Kennedy’s old seat.
Obama was praised extravagantly a year ago; 12 months on, the criticism is over the top, too.
Obama inherited a terrible legacy – recession, financial meltdown, Iraq, Afghanistan.
He has not solved all of these problems.
But it is difficult to see any really bad mistakes, except perhaps allowing himself to be pushed around by Israeli Prime Minister Netanyahu and giving China the impression that he was prepared for a bilateral relationship entirely on China’s terms.
That seems to be changing now.
Obama may have come to understand that when you are the leader of the world’s only superpower, you need to be feared just a little if you are to be respected.
The left in America criticizes Obama for not turning the economy around already.
The right angrily denounces him as a crypto-communist because he wants every American to have health care.
With a dispassionate eye on the long game, what will the president himself be thinking?
One issue that Obama is certain to have in his sights is a problem that shadowed the world for years.
When I was growing up in the 1950’s and 1960’s, world peace was based on the nuclear standoff between the US and the Soviet Union.
The main strategic assessment on both sides of the Berlin Wall was that if either side made a wrong move, all of us might end up consumed in the flames of a nuclear holocaust.
This was called, in the geostrategic jargon of the day, “mutually assured destruction,” or MAD.
The acronym was entirely appropriate.
We have forgotten those days.
Yet there are still 23,000 nuclear warheads on our planet, with the explosive power of 150,000 Hiroshima bombs.
Terrorist groups would undoubtedly like to get their hands on one.
In all, there are eight nuclear-weapon states – the US, Russia, Britain, France, China, Israel, India, and Pakistan.
North Korea may also have a few bombs.
Iran is believed by many to be trying to develop one.
Other states, which have their own civil nuclear capacity, have the potential to develop a weapon.
The number of countries in this category is bound to increase as the number of nuclear power reactors doubles over the next 20 years.
The Nuclear Non-Proliferation Treaty (NPT) has contained the number of nuclear states.
A conference is to be held in May to renew and review it.
Obama clearly recognizes that the NPT needs to be strengthened in order to prevent countries from turning their civil nuclear-power capacity into weapons.
But Obama also knows that if the existing nuclear states want others to accept tougher restrictions, they will have to cut back their nuclear arsenals.
This is principally an issue for the US and Russia, which possess 95% of the world’s nuclear weapons.
In addition, it would help if the US could take a strong lead by ratifying the Comprehensive Nuclear-Test-Ban Treaty.
The nuclear issue is one of the biggest items on the Obama agenda.
How it is handled will help to define his presidency.
Even before the talking gets serious in May, there will be the question of Iran to sort out.
Iran says that it seeks no more than its own ability to produce nuclear power.
Disbelief grows with every revelation of secret Iranian facilities and plans, and with every refusal by Iran to negotiate safeguards that would allow for civil use while preventing weaponization.
The US, the European Union, and Russia have tried to engage Iran on this issue, so far without success.
China seems likely to block effective sanctions on Iran because of its close energy relationship with the country.
How China eventually handles this will profoundly affect its standing in the US and Europe.
These are going to be some of the major questions for Obama over the next year and more.
If he gets them right, he can forget about his short-term critics.
Fortunately, he is smart enough to know this.
MUNICH – For a while, it looked as if the European Central Bank’s €1 trillion credit program to pump liquidity into Europe’s banking system had calmed global financial markets.
But now interest rates for Italian and Spanish government bonds are on the rise again, closing in on about 6%.
Of course, this may not be the breaking point beyond which the debt burden becomes unsustainable.
After all, interest rates in Southern Europe were well above 10% in the decade before the euro was introduced.
Even Germany at that time had to pay bondholders more than 6%.
Nevertheless, the markets are clearly signaling growing doubt about whether Spain and Italy will be willing to bear their debt burden.
The main problem is Spain, where private and public-sector foreign debt is larger than that of Greece, Portugal, Ireland, and Italy combined, and, as in Greece, is in the neighborhood of 100% of GDP (93% to be precise).
A quarter of the labor force and half of Spain’s youth are unemployed, reflecting the country’s loss of competitiveness in the wake of the real-estate bubble inflated by cheap euro credit in the pre-crisis period.
The current-account deficit remains at 3.5% of GDP, despite the recession-induced decline in imports, while economic contraction will cause Spain to miss its budget-deficit target again.
Moreover, Spain’s debt with the ECB’s TARGET settlement system rose by €55 billion ($72 billion) between February and March, because capital outflows of that amount had to be compensated.
Since July 2011, Spain’s TARGET debt has grown by €199 billion.
Capital is in full flight, more than offsetting the inflows from 2008-2010.
The cumulative total since the beginning of the first crisis year (2008) means that Spain has financed its entire current-account deficit via the printing press.
The picture is little better in Italy, where the current-account balance has swung from a surplus of around 2% of GDP to a 3%-of-GDP deficit over the last ten years.
The country’s TARGET debt grew by €76 billion from February to March, with the total since July 2011 reaching €276 billion.
Italy, too, is being drained of capital; in fact, the flight of investors accelerated after the ECB’s liquidity injection.
It is now clear that the ECB itself has caused a large part of the capital flight from countries like Spain and Italy, because the cheap credit that it offered drove away private capital.
The purpose of the ECB’s measures was to re-establish confidence and bring about a recovery of the inter-bank market.
In this, too, it has not really been successful, despite the huge amount of money that it put on the table.
Indeed, now the French are looking wobbly.
As capital fled the country between July 2011 and January 2012, France’s TARGET debt increased by €95 billion.
France, too, has become uncompetitive, owing to the cheap credit brought by the euro in its initial years.
According to a recent study by Goldman Sachs, the country’s price level must drop by an estimated 20% vis-à-vis the euro average – that is, depreciate in real terms – if the economy is to regain competitiveness within the eurozone.
Italy will have to depreciate by 10-15%, and Spain by roughly 20%.
While Greece and Portugal face the need for deflation totaling 30% and 35%, respectively, the figures for Spain and Italy are high enough to justify fears about the future development of the eurozone.
These imbalances can be redressed only with great effort, if at all, and only if one accepts a decade of stagnation.
For Greece and Portugal, staying in the eurozone will be a tight squeeze.
There are many who would solve the problem by routing more and more cheap credit through public channels – bailout funds, eurobonds, or the ECB – from the eurozone’s healthy core to the troubled South.
But this would unfairly force savers and taxpayers in the core countries to provide capital to the South on terms to which they would never voluntarily agree.
Already German, Dutch, and Finish savings amounting to €15,000, €17,000, and €21,000, respectively, per working person have been converted from marketable investments into mere equalization claims against the ECB.
No one knows what these claims will be worth in the event of a eurozone breakup.
Above all, however, the permanent public provision of cheap credit would ultimately lead to a lingering infirmity, if not to Europe’s economic collapse, because the eurozone would become a central management system with state control over investment.
Such systems cannot work, because they eliminate the capital market as the economic system’s main steering mechanism.
One cannot help but wonder how thoughtlessly Europe’s politicians have started down this slippery slope.
LONDON – Public trust in financial institutions, and in the authorities that are supposed to regulate them, was an early casualty of the financial crisis.
That is hardly surprising, as previously revered firms revealed that they did not fully understand the very instruments they dealt in or the risks they assumed.
It is difficult not to take some private pleasure in this comeuppance for the Masters of the Universe.
But, unfortunately, if this loss of trust persists, it could be costly for us all.
As Ralph Waldo Emerson remarked, “Our distrust is very expensive.” The Nobel laureate Kenneth Arrow made the point in economic terms almost 40 years ago: “It can be plausibly argued that much of the economic backwardness in the world can be explained by the lack of mutual confidence.”
Indeed, much economic research has demonstrated a powerful relationship between the level of trust in a community and its aggregate economic performance.
Without mutual trust, economic activity is severely constrained.
Even within Europe, there is powerful evidence that countries where mutual trust is higher achieve higher levels of investment, particularly through venture capital investment, and are prepared to use more flexible contracts, which are also beneficial for growth and investment.
So if it is true that trust in financial institutions – and in the governments that oversee them – has been damaged by the crisis, we should care a lot, and we should be devising responses which seek to rebuild that trust.
In fact, the evidence for a crisis of trust is rather difficult to interpret.
In the United Kingdom, recent survey results are ambiguous.
Surveys promoted by financial firms tend to show that trust in them has not diminished much, and that people continue to trust them even more than they do the National Health Service or the BBC.
Surveys promoted by the BBC tend to show the reverse.
Banks quote statistics to show that they are more trusted than supermarkets, whereas supermarkets cite evidence that the opposite is true, and are expanding into financial services in the belief that the public will trust them more than they trust the banks, which have had to be expensively bailed out by the government.
The market will prove one side right before too long.
In the United States, there is now a more systematic, independent survey promoted by economists at the University of Chicago Booth School of Business.
Their financial trust index, based on a large-scale survey of financial decision-makers in American households, did show a sharp fall in trust in late 2008 and early 2009, following the collapse of Lehman Brothers.
That fall in confidence affected banks, the stock market, and the government and its regulators.
Furthermore, the survey showed that declining trust was strongly correlated with financial behavior.
In other words, if your trust in the market and in the way it is regulated fell sharply, you were less likely to deposit money in banks or invest in stocks.
So falling trust had real economic consequences.
Fortunately, the latest survey, published in July this year, shows that trust in banks and bankers has begun to recover, and quite sharply.
This has been positive for the stock market.
There is also a little more confidence in the government’s response and in financial regulation than there was at the end of last year.
The latter point, which no doubt reflects the Obama administration’s attempts to reform the dysfunctional system it inherited, is particularly important, as the sharpest declines in investment intentions were among those who had lost confidence in the government’s ability to regulate.
It would seem that rebuilding confidence in the Federal Reserve and the Securities and Exchange Commission is economically more important than rebuilding trust in Citibank or AIG.
Continuing disputes in Congress about the precise details of reform could, therefore, have an economic cost if a perception that the system will not be overhauled gains ground.
All these data are at an aggregate level and reflect average views among voters and investors.
Yet we also know that individual views are remarkably heterogeneous.
Some people are very trusting of others, and of the firms and institutions with which they do business.
Others are congenitally distrustful.
Researchers at the European University Institute in Florence and UCLA recently demonstrated that there is a relationship between trust and individuals’ income.
A pan-European opinion survey, which has been carried out for many years, allows us to relate the two.
It asks simple but powerful questions about how far individuals are inclined to trust those with whom they deal.
The data show, intriguingly, that those who show levels of trust well below the average for the country they live in are likely to have lower incomes.
Is that just because low-income people feel that life is unfair and therefore distrust those around them?
It would seem not, as it is also true that very trusting people also have lower incomes than the average.
In other words, if you diverge markedly from society’s average level of trust, you are likely to lose out, either because you are so distrustful of others that you miss out on opportunities for investment and mutually beneficial exchange, or because you are so trusting that you leave yourself open to being cheated and abused.
When anyone I don’t know says “trust me” – an irritating conversational tic – I usually close my wallet.
Perhaps most academics, who are at the lower end of the skill and qualification-adjusted income scale, do the same.
Maybe we should trust each other more – but not too much.
NEW HAVEN – Few economists predicted the current economic crisis, and there is little agreement among them about its ultimate causes.
So, not surprisingly, economists are not in a good position to forecast how quickly it will end, either.
Of course, we all know the proximate causes of an economic crisis: people are not spending, because their incomes have fallen, their jobs are insecure, or both.
But we can take it a step further back: people’s income is lower and their jobs are insecure because they were not spending a short time ago – and so on, backwards in time, in a repeating feedback loop.
It is a vicious circle, but where and why did it start?
Why did it worsen?
What will reverse it?
It is to these questions that economists have been unable to offer clear answers.
The state of economic knowledge was just as bad in the Great Depression that followed the 1929 stock market crash.
Economists did not predict that event, either.
In the 1920’s, some warned about an overpriced stock market, but they did not predict a decade-long depression affecting the entire economy.
Late in the Great Depression, in August 1938, an article by Ralph M. Blagden inThe Christian Science Monitor reported an informal set of interviews with US “professors, banking experts, union leaders, and representatives of business associations and political factions,” all of whom were given the same question: “What causes recessions?” The multiplicity of answers seemed bewildering, and did not inspire confidence that anyone knew what was causing the deepest crisis of capitalism.
The causes given were “distributed widely among government, labor, industry, international politics and policies.” They included misguided government interference with markets, high income and capital gains taxes, mistaken monetary policy, pressures towards high wages, monopoly, overstocked inventories, uncertainty caused by the reorganization plan for the Supreme Court, rearmament in Europe and fear of war, government encouragement of labor disputes, a savings glut because of population shrinkage, the passing of the frontier, and easy credit before the depression.
Although economic theory today is much improved, if we ask people about the cause of the current crisis, we will mostly get the same answers.
We would certainly hear some new ones, too: unprecedented real-estate bubbles, a global savings glut, international trade imbalances, exotic financial contracts, sub-prime mortgages, unregulated over-the-counter markets, rating agencies’ errors, compromised real-estate appraisals, and complacency about counterparty risk.
More likely than not, many or most of these people would be mostly or partly right, for the economic crisis was caused by a confluence of many factors, the chance co-occurrence of a lot of bad things, which pushed the financial system beyond its breaking point.
At that point, the trouble grabbed widespread attention, destroyed public confidence, and set in motion a negative feedback loop.
Our attention, after all, is naturally drawn to the worst events.&nbsp;Precisely because the worst events are statistical outliers, their causes are probably multiple.
Consider the question of predicting events like the January 2010 earthquake in Haiti, which killed more than 200,000 people.
It captured our attention because it was so bad in terms of lives and property damage.
But if one went beyond trying to predict the occurrence of earthquakes to predicting the extent of the damage, one could surely devise a long list of contributing factors – including even political, financial, and insurance factors – that resembles the list of factors that caused the global economic crisis.
Indeed, the crisis knows no end to the list of its causes.
For, in a complicated economic system that feeds back on itself in many ways, events that start a vicious cycle might be as seemingly trivial as the proverbial butterfly in the Amazon, which, by flapping its wings, sets off a chain of events that eventually results in a far-away hurricane.
Chaos theory in mathematics explains such dependency on remote and seemingly trivial initial conditions, and explains why even the extrapolation of apparently precise planetary motion becomes impossible when taken far enough into the future.
Weather forecasters cannot forecast far into the future, either, but at least they have precise mathematical models.
Massive parallel computers are programmed to yield numerical solutions of differential equations derived from the theory of fluid dynamics and thermodynamics.&nbsp;Scientists appear to know the mechanism that generates weather, even if it is inherently difficult to extrapolate very far.
The problem for macroeconomics is that the types of causes mentioned for the current crisis are difficult to systematize.
The mathematical models that macroeconomists have may resemble weather models in some respects, but their structural integrity is not guaranteed by anything like a solid, immutable theory.
The most important new book about the origins of the economic crisis, Carmen Reinhart’s and Kenneth Rogoff’sThis Time Is Different, is essentially a summary of lessons learned from virtually every financial crisis in every country in recorded history.
But the book is almost entirely non-theoretical.
It merely documents recurrent patterns.
Unfortunately, in 800 years of financial history, there is only one example of a really massive worldwide contraction, namely the Great Depression of the 1930’s.
So it is hard to know exactly what to expect in the current contraction based on the Reinhart-Rogoff analysis.
This leaves us trying to use patterns from past, dissimilar crises to try to infer the likely prognosis for the current crisis.
As a result, we simply do not know if the recovery will be solid or disappointing.
CAMBRIDGE – Should more countries create independent fiscal advisory councils to infuse greater objectivity into national budget debates?
Jailed swindler Bernie Madoff recently summed up a lot of people’s feelings about fiscal policy, declaring that “the whole government is a Ponzi scheme.”
Perhaps this was just wishful thinking from a man who will die in prison after his own record-breaking $50 billion pyramid scheme collapsed in 2008.
Personally, I suspect Madoff’s unenviable place in the record books will be secure for quite a while.
Still, with many of the world’s largest governments facing a lethal combination of unsustainable conventional debt, unprecedented old-age pension obligations, and a downshift in growth, one has to wonder what the fiscal plan is.
In a new paper, “A Decade of Debt,” Carmen M. Reinhart and I show that general government debt in the United States, including federal, state, and local debt, has now surpassed the record 120% of GDP reached at the end of World War II.
Japan, of course, is in even worse shape, with government debt totaling more than 200% of GDP.
Though this is partially offset by foreign-exchange reserves, Japan now faces massive disaster-relief costs – and this on top of its depressing demographic trends.
Many other rich countries’ debt levels are also uncomfortably close to 150-year highs, despite relative peace in much of the world.
There is a no easy way out.
For now, low world interest rates are restraining debt-service costs, but debt levels can be reduced only very gradually over long periods, whereas real (inflation-adjusted) interest rates can rise far more quickly, even for rich countries.
Debt crises tend to come out of the blue, hitting countries whose debt trajectories simply have no room for error or unplanned adversity.
The single most immediate and direct impact of having an independent fiscal policy would be to reign in spending by producing a counterpoint to Panglossian government growth and revenue forecasts.
In principle, an independent and respected advisory council could also force governments to acknowledge the hidden costs of government guarantees and off-balance sheet debts.
It is high time to consider novel approaches.
Of course, no one simple change will eliminate the huge bias towards deficit spending in most modern political systems.
And no one simple change will preclude the risk of future debt and inflation crises.
Many countries require sweeping reforms to make their tax systems more efficient and their entitlement programs – including their pension schemes – more realistic.
The recent advent of fiscal advisory councils is a promising institutional start.
A number of countries, including Denmark, the Netherlands, the US, and Belgium, have long-standing fiscal watchdog agencies, such as the US Congressional Budget Office (CBO).
But, while these older institutions have proven enormously useful, they are typically quite constrained.
The CBO, for example, is free to issue long-term fiscal projections based on its own best estimates of growth, but is largely forced to accept politically implausible future “fixes” at face value, somewhat neutralizing the potential effectiveness of any critique of deficit policies.
To enhance credibility, a number of governments are gingerly moving towards creating fiscal councils with greater independence, often with central banks as a role model.
The new vanguard includes councils in Sweden, the United Kingdom, Slovenia, and Canada.
The remit of Sweden’s fiscal council is particularly broad, giving it a mandate not only to forecast, but also to look more deeply at the motivations and consequences of government policy.
In principle, an independent fiscal council could have provided invaluable help during the financial crisis.
In the US, such an agency could have weighed in on the costs and benefits of bailout plans, perhaps helping to end congressional paralysis and steeling nerves to give taxpayers more upside risk.
It is too much to expect that these new fiscal institutions will become as important or powerful as central banks, at least anytime soon.
There is far more consensus over monetary policy than over fiscal policy.
And fiscal policy is far more complex and multi-dimensional.
Still, the general principle seems like an important step towards fiscal sanity.
Of course, fiscal councils by themselves are not enough, no matter how well designed they are.
It will remain very tempting for each generation to say, “My grandchildren will be two or three times richer than I, so who cares if they have to pay some debt?” Moreover, the political cycle creates a very strong deficit bias, as leaders seek to embellish feelings of economic health and prosperity by raising visible expenditures at the cost of hidden debts and lower long-term investment.
To resist these powerful pressures, fiscal councils will need to have their work audited periodically by international agencies such as the International Monetary Fund, both to protect their independence and to promote accountability.
To be sure, Bernie Madoff may yet be proved right, and his will not turn out to be the biggest Ponzi scheme ever.
But greater transparency and a more systematic independent evaluation of government policies could be a very helpful step towards solving the perpetual conundrum of outsized deficits.
It is certainly one of the more innovative and promising ideas to emerge from a rather barren policy landscape.
The fall of Milosevic does not cure the political woes of the Balkans; indeed, it raises their urgency.
Yugoslavia has disintegrated, but the disintegration is incomplete.
It was in Yugoslavia that Vojislav Kostunica was elected president, but his mandate comes solely from support in Serbia.
Montenegro, Serbia’s junior partner in the Yugoslav federation, mostly boycotted the election while Albanians in Kosovo ignored them.
Yet it was Yugoslavia, whose foundations are unstable, that was recently admitted to the UN.
A host of problems remain unresolved: relations between Serbia and Montenegro and the status of Kosovo (not to mention Serbia’s northern province of Vojvodina).
Any resolution – any suggestion of change – will engender new conflicts because of conflicting claims of sovereignty.
However tempting it may be to solve the puzzle by drawing new borders or establishing new entities, this conundrum cannot be resolved in terms of sovereignty.
That traditional solution would only perpetuate the problems of the Balkans.
A new approach is needed: the European Union should use the prospect of European integration as the way to promote regional integration.
The EU could act as a magnet to bring the region closer together by bringing the region as a whole closer to Europe.
This idea has great appeal to people in the region, but only the EU can make it happen.
After NATO intervention in Kosovo, European leaders made this approach the cornerstone of their vision for the Balkans. It was enshrined in the Stability Pact signed at the Sarajevo Summit of July, 1999.
But the Stability Pact is merely a shell – it needs to be filled with content.
The time to do so is at the Zagreb Conference on November 24 called by France as the current EU president.
The European Union should now propose a three-point plan for the Balkans:
$ a customs union with preferential access to EU markets within one year.
The existing EU-Turkey customs union should be used as a model.
Once all these countries reach agreement with the EU there would automatically be free trade throughout the Balkans.
This will take some time to implement.
But from the start, the EU should give a signal by unilaterally opening its border to imports from the region.
This cannot endanger any EU interests as the countries at issue now have far less than 1% of the EU market.
$ a regional VAT to replace the lost customs revenues should be established within two years.
Differences in indirect taxes such as VAT pose another way in which borders become obstacles to trade.
They should be unified throughout the region.
Regional VAT rates might be increased slightly if expenditure restraint is not sufficient to offset the loss of tariff revenues due to the customs union.
$ Temporary budgetary support on a declining scale for three years, subject to EU supervision over budgetary expenditures.
Because it will take time to collect revenues from the regional VAT, the EU should provide financial help during the transition.
The area covered by this plan would include Bulgaria, Croatia and Albania as well as Serbia, Bosnia, Macedonia, Montenegro and Kosovo.
Participation by Romania and Moldova is optional.
Bulgaria and Croatia could be persuaded to participate provided it would not interfere with their candidacy for EU membership.
Depending on the country, there could be more or less budgetary support.
(Bulgaria, for example, might not need compensation since to a great extent it has already eliminated tariffs).
In comparison to the cost of military intervention and peacekeeping, the financial costs here are ridiculously low.
I estimate that Euro 750 million in the first year, Euro 500 million in the second year and Euro 250 million in the third year would do the trick.
(If Romania and Moldova were included the figures would be slightly higher).
These figures are well within range of pledges already made by the EU for the Stability Pact and they could be easily accommodated within the confines of the Berlin Accord on the EU budget for 2000-2005 if EU member states agree to a reallocation of unspent funds.
Budgetary support in the context of a Customs Union would be a more effective way to disburse EU funds than conventional methods.
This three-point program would lay the ground for economic resurgence.
It would remove two major sources of corruption and inefficiency: the customs service and the misuse of public funds in general.
It would create a trade area large enough to generate both local and foreign investment.
The Deutsche Mark, already widely used in the region, now functions as the de facto common currency.
Any ban on its use should be lifted to make borders irrelevant for trade and investment.
Improved economic prospects and the strengthening of institutions, in turn, would have a positive impact on the political climate throughout the Balkans.
Serbia has climbed part of the way out of the abyss.
Success in peacefully removing a tyrant has set in motion a process of national renewal.
But that process has a long way to go.
The opposition inherited a bankrupt country whose institutions are in ruins.
The population, frustrated by ever deepening impoverishment and isolation, is beginning to question what happened over the past decade in Serbia.
People are asking about crimes committed by the Milosevic regime against Serbs.
They must begin to come to terms with the crimes committed against others - in Croatia, Bosnia and Kosovo.
Once that process is underway, many problems that now seem intractable will be resolved more easily.
Kostunica’s election as President of Yugoslavia amounts to an incomplete revolution: many of the old guard are still in place.
The momentum created by Milosevic’s overthrow needs to be maintained.
Milosevic was overthrown in the hope of ending Serbia’s isolation.
Europe must now fulfill its promise.
If the French Presidency fails to seize the moment in Zagreb, an historic opportunity will be lost.
PRAGUE – As I listened to what some Europeans were saying as my country prepared to take over the presidency of the European Union, I heard dim echoes of Neville Chamberlain’s infamous description of Czechoslovakia as “a faraway country of which we know little.”
I suppose that Donald Rumsfeld’s misguided bid a few years ago to incite a divide between “new and old” Europe contributed to the re-emergence of that disdainful attitude. 
The reality is that there is no such thing as “old and new” Europe, and there never was.
The break with communism and reunification of Europe is now almost two decades old.
We Czechs are 100% European, and were even when the Iron Curtain cut us off from democratic Europe.
Indeed, our pro-EU sentiments may be all the stronger because our membership in the Union, like our freedom, is so comparatively new.
So no one in Europe needs to fear that the Czech Republic has some nostalgic or idiosyncratic agenda that it wants to impose on the Union.
On the contrary, events have imposed an agenda on Europe that we cannot escape and for which solidarity – true union – will be needed.
The primary, and most pressing, of the problems we face is the financial and economic crisis that is enveloping the EU.
Unfortunately, conditions across the Union will likely worsen before they begin to improve.
The type of social unrest recently witnessed in Greece may spread, because the downturn is likely to take a disproportionate toll on Europe’s young people, who are seeking jobs at a time when hard-pressed European businesses will be able to offer them very few.
It will fall to the Union, once again, to help transform despair into hope.
We Czechs know something about this, as the wrenching economic transition that we underwent in the 1990’s taught us much about how the right policies can break the grip of hopelessness.
To contain today’s financial and economic crisis, Europe will also need to continue the cooperation that it has shown up to this point.
The very existence of our Union, and particularly of the euro, has already helped to prevent the competitive devaluations and beggar-thy-neighbor policies that ravaged Europe during the 1930’s – the last time the continent faced so brutal an economic downturn. 
But we cannot be complacent that the forces of national egoism will remain in check.
For now, EU governments’ coordinated fiscal stimulus has deprived populists of their usual charge that the EU is indifferent to the fate of individuals.
Even more policy coordination will be needed both to confront the crisis and to re-establish EU norms once the storm clouds begin to dissipate.
Although it is right that the Stability and Growth Pact has become more flexible in these extraordinary times, its rules did secure a successful first decade for the euro.
These rules must eventually be restored intact if Europe is to return to the path of sustainable growth, and a consensus will need to be forged now to make that happen.
The second key challenge that we will face during our European presidency is that of Russia.
A new Partnership and Cooperation Agreement (PCA) between the EU and the Russian Federation must be negotiated.
Those negotiations should have begun seriously last year, but the war in Georgia intervened to put them on hold.
Now those talks have resumed, but the background to the negotiations has changed dramatically.
Russia’s economy is now in far worse shape than that of EU members.
The collapse of world oil and gas prices has wounded Russia’s budget, and lack of investment in the country’s energy sector over the years is now causing the declining production that economists have long predicted.
Until now, Russia has cared less about a new PCA than the EU, because two-thirds of Russia’s exports to the Union comprise natural resources, which bring in cash even without the strong rules that a PCA provides.
Given the stark changes in economic conditions, however, it is now in Russia’s national interest to reassure international markets that it is a reliable place to do business, for which a new PCA would serve as an ideal signal.
Moreover, without a new PCA, individual European countries may feel it necessary to seek even more bilateral agreements with Russia.
Indeed, many EU members have been in a race with each other to see who will be Russia’s closest friend in the Union.
But the bilateral deals that have emerged from this race sometimes come at the expense of other Union members, and may unbalance relations within the Union as a whole.  Only a rules-based EU framework can provide a firm foundation for both bilateral and Union-wide relations with Russia. 
Europe’s main strength in foreign policy is not its commitment to a rules-based multilateralism, important as that undoubtedly is, but its unity.
When the Georgia crisis erupted, Europe united around a single position on Russia’s withdrawal.
It is the Czech Republic’s task, and that of the Swedish EU presidency that will follow our own, to maintain this unity as the PCA negotiations move forward.
During the 1990’s, the US and Europe erred in treating Russia with benign neglect.  It would be a mistake for Russia to respond in kind today by seeking to prolong the PCA negotiations in the hope that a possibly more amenable EU president may one day offer softer terms.
We, like all EU presidencies, will be representing the wider Union interests when we negotiate.
PRINCETON – What we are doing to our planet, to our children and grandchildren, and to the poor, by our heedless production of greenhouse gases, is one of the great moral wrongs of our age.
On October 24, you can stand up against this injustice.
October 24 is 350 Day.
The name comes from the number of parts per million of carbon dioxide in the atmosphere that, according to Jim Hansen, perhaps the world’s leading climate scientist, we should not exceed if we are to avoid potentially catastrophic climate change.
It is a measure of the seriousness of our problem that CO2 is already at 386 ppm, and is rising by two ppm each year.
The need to cut greenhouse gases has become increasingly clear as predictions of global warming – denounced as “alarmist” when they were first made just a few years ago – have repeatedly turned out to have been too conservative.
We are approaching a point of no return, at which feedback loops will kick in and continue to warm the planet, no matter what we do.
The melting of arctic ice is one example.
Four hundred years ago, explorers sought the legendary “Northeast Passage” across the north of Europe and Russia to China.
They found the arctic ice impenetrable, and soon gave up their quest.
This year, commercial vessels successfully navigated the Northeast Passage.
That is one of many recent dramatic signs that our climate is changing and that our planet is warmer than it has been for a very long time.
But ice-free arctic waters are more than a symptom of global warming.
They are themselves a cause of further warming: ice and snow reflect the sun’s rays.
An ice-free surface absorbs more warmth from the sun than one covered in snow or ice.  In other words, our greenhouse gas emissions have, by causing enough warming to melt the arctic ice, created a feedback loop that will generate more warming, and melt more ice, even if we were to stop emitting all greenhouse gases tomorrow.
Other feedback loops pose a similar danger.
In Siberia, vast quantities of methane, an extremely potent greenhouse gas, are locked up in what used to be called “permafrost” – regions in which it was assumed that the ground was permanently frozen.
But areas that used to be frozen are now thawing, releasing methane and thus contributing to further warming – and to further thawing, which releases more methane.
Developing nations are grasping just how outrageous the current distribution of greenhouse-gas emissions really is.
At the United Nations Summit on Climate Change in September, President Paul Kagame of Rwanda pointed out that, while developed nations outside Africa are almost entirely responsible for the problem, its greatest impact will probably be on Africa, which has few resources to cope with the challenge.
Kagame then suggested giving every country an annual per capita quota for CO2 emissions, and allowing developing countries that are below the quota to trade their excess quota with countries that are above theirs.
The money that developing countries would receive for this would not be aid, but rather a recognition that the rich nations must pay for something that in the past they simply appropriated: far more than their fair share of our atmosphere’s capacity to absorb our waste gases.
Sri Lanka took a similar stance, using studies from the UN Intergovernmental Panel on Climate Change to calculate that in 2008, environmentally permissible carbon emissions totaled no more than 2,172 kilograms per person.
In fact, the world’s per capita emissions were 4,700 kilograms, or more than double the permissible limit.
But, while emissions in the rich nations were far above the permissible limit, Sri Lankan emissions were, at 660 kilograms, well below it.
As Sri Lanka’s government pointed out, “That means low-emitting countries like us could not emit more because our space has already been exploited by developed or global heavy polluting countries without our consent.”
This situation is an injustice of vast proportions, reminiscent of – and arguably much worse than – the now-repudiated colonialism of the Western powers in the nineteenth century.
The task of remedying it must begin at the meeting on climate change that will be held in Copenhagen in December.
Many political leaders have expressed support for strong action on climate change, but what most of them regard as “strong action” will not be enough to get us back below 350 ppm.
In some countries, including the United States, there are major political obstacles to taking even modest steps.
On October 24, people in nearly every country will be taking action to raise awareness of the need for an international treaty to bring our atmosphere back to 350 ppm of CO2.
There will be climbers hanging banners high in the Himalayas, where the glaciers are melting, and scuba divers at Australia’s Great Barrier Reef, which is threatened by climate change.
Churches will ring bells 350 times, 350 cyclists will circle towns, and, in many places, 350 trees will be planted.
Atwww.350.org you can find out what is happening near you and join in, or put your own idea online.
But don’t just sit back and hope that others will do enough to make an impact.
One day your grandchildren will ask you: what did you do to meet the greatest moral challenge of your time?
When I was seven years old, in 1960, my grandmother Angelica opened my eyes to the meaning of 8 May 1945, the day when Nazi Germany surrendered and World War II ended in Europe.
We were spending our summer holidays in Normandy where the liberation of Europe from Nazism had started on D-Day, 6 June 1944.
One evening, I listened to my parents and my grandmother talking about the past.
I have forgotten the details of their conversation, but I can still hear my grandmother’s sigh of relief when she said “Thank God we lost that war!”
From a child’s perspective, it wasn’t self-evident that losing was a good thing.
But of course, my grandmother was right to equate defeat with liberation.
The more I have thought about the lesson she taught me 45 years ago, the clearer I have seen another, less obvious dimension in what she said: It is “we” who lost the war.
Collectively, the Germans had not been the innocent victims of a small gang of criminal outsiders called “Nazis” – Nazism had been an inside ideology supported by millions of Germans, and every German was liable for its atrocities whether or not he or she had adhered to it individually.
In today’s Germany, an overwhelming majority subscribes to the proposition that 8 May 1945 was a day of liberation – not only for Europe, but also for Germany itself.
Compared to public opinion in 1960, that’s certainly an enormous progress.
But paradoxically, it may also contain an element of forgetfulness, because it tends to conceal the fact that liberation required a military defeat.
To use my grandmother’s parlance, it is not “us” who were the liberators, but “them”.
The way people see the past tells us more about their present attitudes than about the past itself.
This is what the term “politics of memory” is meant to indicate.
And this is why it doesn’t matter whether the relevant events happened 60 years ago (as World War II), 90 years (as in the case of the Armenian genocide) or even 600 years (such as the battle of Kosovo in 1389).
A violent conflict in the past may survive as a war of memories in the present, as can be observed in the current dispute between China and South Korea on one side, and Japan on the other.
A war of memories, in turn, may sometimes lead to a violent conflict in the future.
Former perpetrators often try to de-legitimize their former victims’ moral superiority by claiming they were victims themselves.
Therefore, the 60th anniversary of the firebombing of Dresden by Allied forces on 13 February 1945 has probably been a more crucial moment in terms of the German “politics of memory” than the 60th anniversary of 8 May 1945 is going to be.
Far-right groups infamously dubbed the attack by which at least 30,000 people were killed “Dresden’s Holocaust of bombs.”
Fortunately, their propaganda campaign has been a failure.
Although it is true that thousands of the civilians killed in Dresden and other German cities were innocent at an individual level, there can be no doubt it was morally imperative that Germany be defeated collectively.
On the left side of the German political spectrum, the proposition that 8 May 1945 was a day of liberation remains unchallenged.
However, it is sometimes repressed that the massive use of force had been necessary to achieve that result.
Left-wing pacifism tends to overlook this simple fact.
Its slogan “Never again war!” is only half the truth – the other half is “Never again appeasement!” 8 May 1945 was not “zero hour,” as a popular saying in Germany goes.
It had an antecedent, that is, a lack of pre-emptive resistance at home and abroad to the threat that built up in Nazi Germany during the 1930’s.
There is yet another lesson to be learned.
Yes, 8 May 1945 was a day of liberation to which the Soviet army contributed decisively.
But for millions of Central and East Europeans, liberation was followed by Stalin’s oppressive regime.
The current war of memories between the Baltic republics and Russia, with regard to the international celebration in Moscow on 9 May this year, reminds Germany of a special historic responsibility.
The German-Soviet non-aggression treaty, the so-called Hitler-Stalin pact, concluded in August 1939, had been supplemented by a secret appendix dividing the border states Finland, Estonia, Latvia, Lithuania, Poland and Romania into spheres of interest for the two parties.
But excusing Nazi atrocities by pointing to Stalinist crimes is an intellectually and morally unacceptable stratagem.
When Chancellor Schröder travels to Moscow for the Red Square celebrations, he should bear in mind Nazi Germany’s contribution to the Baltic tragedy.
On 8 May this year, public speakers will remind us how important it is not to forget.
They will stress that if the lessons of history are not learned, history is bound to repeat itself.
All this is perfectly true.
But personally, I will also remember my grandmother’s sentence “Thank God we lost that war!” Thank God – and thanks to all those brave Allied soldiers who sacrificed their lives for the sake of Europe’s liberty.
Cambridge – It may take a few months or a couple of years, but one way or another the United States and other advanced economies will eventually recover from today’s crisis.
The world economy, however, is unlikely to look the same.
Even with the worst of the crisis over, we are likely to find ourselves in a somewhat de-globalized world, one in which international trade grows at a slower pace, there is less external finance, and rich countries’ appetite for running large current-account deficits is significantly diminished.
Will this spell doom for developing countries?
Not necesarily.
Growth in the developing world tends to come in three distinct variants.
First comes growth driven by foreign borrowing.
Second is growth as a by-product of commodity booms.
Third is growth led by economic restructuring and diversification into new products. 
The first two models are at greater risk than the third.
But we should not lose sleep over them, because they are flawed and ultimately unsustainable.
What should be of greater concern is the potential plight of countries in the last group.
These countries will need to undertake major changes in their policies to adjust to today’s new realities.
The first two growth models invariably come to a bad end.
Foreign borrowing can enable consumers and governments to live beyond their means for a while, but reliance on foreign capital is an unwise strategy.
The problem is not only that foreign capital flows can easily reverse direction, but also that they produce the wrong kind of growth, based on overvalued currencies and investments in non-traded goods and services, such as housing and construction.
Growth driven by high commodity prices is also susceptible to busts, for similar reasons.  Commodity prices tend to move in cycles.
When they are high, they are apt to crowd out investments in manufactures and other, non-traditional tradables.
Moreover, commodity booms frequently produce ugly politics in countries with weak institutions, leading to costly struggles for resource rents, which are rarely invested wisely.
So it is no surprise that the countries that have produced steady, long-term growth during the last six decades are those that relied on a different strategy: promoting diversification into manufactured and other “modern” goods.
By capturing a growing share of world markets for manufactures and other non-primary products, these countries increased their domestic employment opportunities in high-productivity activities.
Their governments pursued not just good “fundamentals” (e.g., macroeconomic stability and an outward orientation), but also what might be called “productivist” policies: undervalued currencies, industrial policies, and financial controls.
China exemplified this approach.
Its growth was fueled by an extraordinarily rapid structural transformation towards an increasingly sophisticated set of industrial goods.
In recent years, China also got hooked on a large trade surplus vis-à-vis the US – the counterpart of its undervalued currency.
But it wasn’t just China.
Countries that had been growing rapidly in the run-up to the great crash of 2008 typically had trade surpluses (or very small deficits).
These countries did not want to be recipients of capital inflows, because they realized that this would wreak havoc with their need to maintain competitive currencies.
It is now part of conventional wisdom that large external balances – typified by the bilateral US-China trade relationship – played a major contributing role in the great crash.
Global macroeconomic stability requires that we avoid such large current-account imbalances in the future.
But a return to high growth in developing countries requires that they resume their push into tradable goods and services.
In the past, this push was accommodated by the willingness of the US and a few other developed nations to run large trade deficits.
This is no longer a feasible strategy for large or middle-income developing countries.
So, are the requirements of global macroeconomic stability and of growth for developing countries at odds with each other?
Will developing countries’ need to generate large increases in the supply of industrial products inevitably clash with the world’s intolerance of trade imbalances?
There is in fact no inherent conflict, once we understand that what matters for growth in developing countries is not the size of their trade surpluses, nor even the volume of their exports.
What matters is their output of modern industrial goods (and services), which can expand without limit as long as domestic demand expands simultaneously.
Maintaining an undervalued currency has the upside that it subsidizes the production of such goods; but it also has the downside that it taxes domestic consumption – which is why it generates a trade surplus.
By encouraging industrial production directly, it is possible to have the upside without the downside.
There are many ways that this can be done, including reducing the cost of domestic inputs and services through targeted investments in infrastructure.
Explicit industrial policies can be an even more potent instrument.
The key point is that developing countries that are concerned about the competitiveness of their modern sectors can afford to allow their currencies to appreciate (in real terms) as long as they have access to alternative policies that promote industrial activities more directly.
So the good news is that developing countries can continue to grow rapidly even if world trade slows in and there is reduced appetite for capital flows and trade imbalances.
Their growth potential need not be severely affected as long as the implications of this new world for domestic and international policies are understood.
One such implication is that developing countries will have to substitute real industrial policies for those that operate through the exchange rate.
Another is that external policy actors (for example, the World Trade Organization) will have to be more tolerant of these policies as long as the effects on trade balances are neutralized through appropriate adjustments in the real exchange rate.
Greater use of industrial policies is the price to be paid for a reduction of macroeconomic imbalances.
George W. Bush is obsessed with the war on terrorism, especially with the military response to terrorism.
American foreign policy reflects that obsession.
This year, the US will spend around $450 billion for the military, including the costs of the Iraq War, while it will spend no more than $15 billion to overcome global poverty, global environmental degradation, and global diseases.
In other words, US foreign policy spending is thirty times more focused on the military than on building global prosperity, global public health, and a sustainable environment.
Throughout 2003, the world lived with Bush's obsession.
Debate over Iraq dominated international diplomacy, and took up almost the entire UN agenda.
The war in Iraq cost countless innocent lives, such as when the UN headquarters in Baghdad was bombed.
At the same time, Bush's emphasis on a one-dimensional, militarized approach to global problems has fueled unrest and instability throughout the Islamic world, leading to increased terrorism in Turkey, North Africa, Saudi Arabia, and Southeast Asia.
The nature of suffering around the world hardly justifies this narrow strategy.
Focusing on terrorism to the exclusion of other issues, and emphasizing the military response to it, will not bring prosperity and peace, or even a significant reduction in the number of attacks.
While 3,000 innocent people died in the US on September 11, 2001, in Africa 8,000 innocent children die every day from malaria.
Yet malaria is preventable and treatable.
The problem is that most of Africa is too poor to mobilize the methods of prevention (bed nets) and treatments (anti-malarial medicines) that could save millions of children every year.
The US spends more on Iraq each day than it does on Africa's malaria in a year.
As 2003 draws to a close, it is time for world leaders to help guide the world away from the obsessive, failing approach of America's government.
President Bush should be made to understand that the US will find no true international support if America speaks incessantly about terrorism while doing almost nothing about the problems that really affect most of the world: poverty, lack of access to safe water and sanitation, vulnerability to disease, and climate change.
Ironically, President Bush claims that the UN does not follow through on its word.
He declared in London recently that "the credibility of the UN depends on a willingness to keep its word and to act when action is required."
Yet the US repeatedly violates its own UN pledges.
For example, at the International Conference on Financing for Development, in Monterrey, Mexico in March 2002, America signed the Monterrey Consensus, which includes a promise by rich countries to raise their development assistance towards 0.7% of national income.
That would bring an additional $60 billion per year in foreign assistance from the US--approximately what it spent on Iraq this year.
Yet President Bush has simply ignored this promise.
There are many other similar commitments that the US has made in recent years to the UN that remain utterly unfulfilled.
The US promised action to fight man-made climate change as a signatory to the UN Framework Convention on Climate Change (UNFCC) in 1992.
It has so far failed to act.
America also promised--in the Doha Declaration in 2001--to open its markets to the world's poorest countries.
Yet at Cancun, Mexico earlier this summer, it refused to open its markets even to exports from struggling African economies.
The list goes on and on.
At the Millennium Assembly in 2000, the US promised to pursue reduction of global poverty, yet it has taken few steps in that direction.
At the World Summit on Sustainable Development in Johannesburg in 2002, America committed itself to protect global ecosystems, yet little has been seen or heard from US policy makers on this issue since then.
America is certainly not alone in failing to promote the international goals adopted in the UN.
But because the US is the richest, most powerful country in the world, its neglect is devastating.
If the US really wants to undercut terrorism, it must recognize the interconnectedness of extremism, poverty, and environmental degradation, and it will need to understand the struggles for survival that are underway among the poor everywhere.
But the world should not wait for the America to come to its senses.
The US represents just 5% of the world's population, and just one vote of 191 countries in the UN General Assembly.
Poor countries, especially the democracies of the developing world--Brazil, South Africa, India, Mexico, Ghana, the Philippines--should say, "We need to act on the issues that concern us, not just on the issues that concern the US."
What the world needs most in 2004 is a declaration of independence from American willfulness.
Turkey's seeming fall from grace with the US may turn out to be a blessing in disguise.
The Iraq war and the tortured diplomacy that led up to it may help resolve Turkey's conflict between its "strategic alliance" with America and its drive to join the EU.
The elections last November that brought the Justice and Development Party (AKP) to power were preceded by a dispute between the members of the then-ruling coalition over enacting the reforms demanded by the EU.
Some liberal elements of that "secular" coalition resigned from the government and joined with the Islamists to push the reforms through parliament.
After coming to power, the AKP's leaders, former Islamists who had reinvented themselves as "conservative democrats," energetically engaged with the US, the EU, and the UN on issues ranging from Cyprus to Iraq, from Kurdish language rights to other human rights issues within Turkey.
Having suffered the oppressive practices of Turkey's "secular" state and recognizing that human rights must be protected across-the-board, the AKP emerged as a credible interlocutor with the West.
The US, preoccupied with the supposed specter of a "clash of civilizations" between Islam and the West, saw the AKP's modern, westernized face as an opportunity and urged the EU to admit Turkey.
Today, both "conservative democrats" and liberals advocate passing all the reforms needed to gain accession to the EU, while opponents include extreme nationalists, of both left and right, as well as some elements of the "secular" establishment.
The Europeans could have tipped the balance decisively in favor of the reformers by finally rewarding the efforts of the pro-EU Turks at last December's summit of EU leaders.
Instead, the EU kept Turkey waiting yet again, putting off formal negotiations that, in any case, may take years to complete.
Europe's persistent reluctance puts the Turks in a quandary.
The Americans want full EU membership for Turkey--a longstanding NATO member and close American ally--while Europeans complain about the Turkish military's domestic political role.
The paradox is that, by maintaining a political distance and thus limiting Turkey's options, Europe may end up reinforcing Turkey's status as a military outpost of the US.
At least, that was how things were shaping up prior to the war in Iraq.
Then, despite massive US pressure, Turkey's parliament unexpectedly rejected the government's proposal to allow US troops in Turkey to launch an invasion from Turkish territory.
Turkey's refusal to grant the Americans access to military bases on its territory effectively ruled out a northern front in the war.
The Turkish government even attempted a regional initiative for a peaceful solution to the crisis, an effort no current EU member could have contemplated.
Parliament's rejection of US troops powerfully refutes suggestions that Turkey was primarily concerned about the size of the American aid package on offer as an inducement to cooperate.
Suggestions that characterized the vote as revealing the government's true "Islamic" character ignore the fact that the only opposition party in parliament, the Republican People's Party--founded by Atatürk and still fully "secularist"--voted against the plan.
Likewise, other elements of Turkey's secular establishment, including the President and the military leadership, either opposed or were lukewarm, at best, to the idea of war in Iraq.
Turkey's military initially remained silent on the issue, uncharacteristically watching the civilian political process unfold.
By contrast, the military had earlier publicly criticized AKP initiatives on Cyprus.
Their silence on Iraq reflected their apprehension about unwanted alternatives: either support the US plan and risk encouraging Kurdish moves toward an independent state, or oppose the Americans and jeopardize a critical strategic relationship.
They chose to defer to the civilian leadership and to parliament, which, in voting down the US plan, reflected overwhelming public sentiment against the war.
Only after the vote did the Chief of Staff publicly endorse the original proposal to bring in American troops.
In fact, the allegedly Islamic party had skilfully managed to negotiate with an unrelenting US, consult with the Turkish military and President, and share all information with the public and parliament.
Walking a fine line in what was essentially a lose-lose situation, the party leadership laid out the stakes clearly and judiciously left the final decision to parliament.
The outcome was a victory for Turkish democracy and recognized as such internationally.
After the US military action in Iraq, the tables may be turning in surprising ways.
As America establishes itself in Iraq, Turkey's geopolitical military significance may decline.
Yet the declared American aim of building a Muslim democracy in Iraq will only enhance Turkey's symbolic importance as a role model.
This shift in Turkey's strategic role may also be reflected in a new domestic balance between the military and the forces pushing for reform.
With careful management, Turkey may find itself drawing closer to Europe, while rebuilding its relationship with America.
CAMBRIDGE – This year is likely to mark a make-or-break ordeal for the euro.
The eurozone’s survival demands a credible solution to its long-running sovereign-debt crisis, which in turn requires addressing the two macroeconomic imbalances –&nbsp;external and fiscal –&nbsp;which are at the heart of that crisis.
The crisis has exposed the deep disparities in competitiveness that have developed within the eurozone.
From 1996 to 2010, unit labor costs in Germany increased by just 8%, and by 13% in France.
Compare that to 24% in Portugal, 35% in Spain, 37% in Italy, and a whopping 59% in Greece.
The result has been large trade imbalances between eurozone countries, a problem compounded by large fiscal deficits and high levels of public debt in southern Europe (and France) – much of it owed to foreign creditors.
Does addressing these imbalances require breaking up the eurozone?
Suppose, for example, that Portugal were to leave and re-introduce the escudo.
The ensuing exchange-rate devaluation would immediately lower the price of Portugal’s exports, raise its import prices, stimulate the economy, and bring about much-needed growth.
But a euro exit would be a messy affair.
The resulting turmoil could very well trump any short-term gains in competitiveness from devaluation.
There is a remarkably simple alternative that does not require southern Europe’s troubled economies to abandon the euro and devalue their exchange rates.
It involves increasing the value-added tax while cutting payroll taxes.
Our recent research demonstrates that such a “fiscal devaluation” has very similar effects on the economy in terms of its impact on GDP, consumption, employment, and inflation.
A currency devaluation works by making imports more costly and exports cheaper.
A VAT/payroll-tax swap would do exactly the same thing.
An increase in VAT raises the price of imported goods, as foreign firms face a higher tax.
To ensure that domestic firms do not have an incentive to raise prices, an increase in VAT needs to be accompanied by a cut in payroll taxes.
Moreover, since exports are exempt from VAT, the price of domestic exports will fall.
The desired competitiveness effects of exchange-rate devaluation can thus be had while staying in the euro.
This policy can also help on the fiscal front.
As is true of an exchange-rate devaluation, the positive impact on growth of an increase in competitiveness can strengthen the fiscal position by raising tax revenues.
Moreover, an important advantage of fiscal devaluations is that they generate additional revenues in proportion to the country’s trade deficit.
For countries that are suffering from weak competitiveness and, as a consequence, running trade deficits, this typically means more revenues, especially in the short run.
Like exchange-rate devaluations, fiscal devaluations create winners and losers.
Both act as a wealth levy: inflation means that bondholders suffer a real loss in proportion to their wealth and the size of the devaluation.
If taxes on capital are not adjusted, holders of domestic stocks suffer a comparable loss.
By contrast, many transfers, such as unemployment benefits, health benefits, and public pensions, are indexed to inflation, and thus maintain their real value.
The same is true of minimum wages.
These distributive effects play an important role in the politics of exchange-rate devaluations, and most of these effects appear in fiscal devaluations as well.
Fiscal devaluations already have some advocates.
Indeed, French President Nicolas Sarkozy’s government just announced one.
And concerns that a fiscal devaluation will conflict with euro rules can be met by simply pointing out that Germany’s government carried one out in 2007, though by another name, when it raised VAT from 16% to 19% and cut employers’ contribution to social insurance, from 6.5% to 4.2%.
In short, there are simple fiscal alternatives to exchange-rate devaluation that can address southern Europe’s short-term competitiveness problems.
To be sure, feasible fiscal devaluations would be limited in size.
But, together with debt restructuring, accommodative monetary policy, liquidity support from the European Central Bank, and much-required structural reforms, they can help to put these troubled economies on a sound footing without a euro breakup or a major austerity-induced recession.
COPENHAGEN – Amid a growing wave of concern about climate change, many countries – including Brazil, Australia, the United States, and the members of the European Union – passed laws in the 2000’s outlawing or severely restricting access to incandescent light bulbs.
The intention was understandable: if everyone in the world exchanged most light bulbs for energy-efficient compact fluorescent light bulbs (CFLs), we could save 3.5% of all electricity, or 1% of our CO2 emissions.
The current attempt by Republicans in the US Congress to roll back America’s effort to ban incandescent bulbs has revived this discussion.
Many contend that the agenda is being driven by knuckle-dragging climate-change deniers.
But it’s worth taking a closer look at the premise that banning things is the smartest way to tackle global warming.
Let’s be clear: we do need to tackle climate change.
But this does not mean that we should just cut all emissions.
Burning fossil fuels also has significant benefits, and we should weigh those benefits against the costs.
A tax on carbon should be equivalent to its damage.
The best estimate of this is about $7/ton of CO2 or $0.06/gallon of gasoline (€0.015/liter).
Most developed countries already have a tax of this size (and often much larger) on electricity and fossil fuels, although this also incorporates the costs of air pollution and supply insecurity.
While CFLs are more expensive to buy, they are much cheaper over their lifespan, because they use much less energy (even more so with the cost of CO2 factored into taxes on electricity).
Thus, on a straightforward cost-benefit basis, it seems to make sense for most people to switch from incandescent bulbs to the new, greener technology.
This is what is great about technological solutions to climate change: if an alternative option is cheaper, people will start using it.
My household uses CFLs, and I enjoy knowing that I am causing fewer CO2 emissions and spending less money.
Why, then, is it even necessary to outlaw the old bulbs?
The reason is that monetary cost is only one factor.
Many people find it annoying that CFLs take time to “warm up.”
Or they believe that their light is “funny.”
Or they worry that the bulbs can spread poisonous mercury if they break.
For some people, energy-efficient bulbs can trigger epileptic seizures and migraines.
The up-front cost is a factor, too, especially for those on low budgets.
And in places where lights are not used very often, a lower-price incandescent bulb can cost less overall than the energy-efficient alternative.
You might imagine that people could choose the right light bulbs for themselves.
But proponents of phasing out access to incandescent bulbs argue that they know better.
As US Energy Secretary Steven Chu put it recently, “We are taking away a choice that continues to let people waste their own money.”
Setting aside other possible objections to this view, there is the problem that it presumes that all incandescent bulbs are worth less than $7/ton of CO2.
This is clearly not true for those who suffer from migraines or epileptic seizures because of the new bulbs, or for those who are seriously worried about mercury, or for those who have other reasons for preferring incandescent bulbs.
The solution should be to focus on improving the technology – making the lights safer, brighter, warm up faster, and save more energy, so that more people will replace more of their lights.
But it is not just light bulbs that policymakers have tried to ban.
EU parliamentarians voted overwhelmingly to outlaw patio heaters, which one MEP declared to be “a luxury the planet cannot afford.”
Who decides when something is luxurious?
And where does this end?
Should we outlaw air conditioning or television satellite boxes because some people find them luxurious?
Should we ban private cars wherever public transport is available to move us from A to B with fewer CO2 emissions?
It makes sense to reflect the cost of CO2 (among many other factors) in the price paid to drive our cars or heat our patios; but when the phase-out proceeds more slowly than some lawmakers wish, a ban is not the right solution.
Real reductions in carbon emissions will occur only when better technology makes it worthwhile for individuals and businesses to change their behavior.
CFLs and other advances can take us part of the way, but there are massive technological hurdles to overcome before fossil fuels generally become less attractive than greener alternatives.
This is where a lot of policymakers get it wrong.
Governments talk far too much about setting a relatively high carbon tax on emissions, while focusing far too little on ensuring a meaningful increase in research and development to bring about necessary breakthroughs.
Limiting access to the ‘wrong’ light bulbs or patio heaters, ultimately, is not the right path.
We will only solve global warming by ensuring that alternative technologies are better than our current options.
Then, people the world over will choose to use them.
TOKYO – 2009 was a good year for China.
The Chinese economy still roared ahead in the midst of a worldwide recession.
American President Barack Obama visited China, more in the spirit of a supplicant to an imperial court than the leader of the world’s greatest superpower.
Even the Copenhagen summit on climate change ended just the way China wanted: failure in its attempt to commit China, or any other industrial nation, to making significant cuts in carbon emissions, with the United States getting the blame.
The Chinese government, under the Communist Party, has every reason to feel confident.
So why did a gentle former literature professor named Liu Xiaobo have to be sentenced to 11 years in prison, just because he publicly advocated freedom of expression and an end to one-party rule?
Liu was co-author in 2008 of a petition, Charter 08, signed by thousands of Chinese, calling for basic rights to be respected. Liu is not a violent rebel.
His opinions, in articles published on the Internet, are entirely peaceful.
Yet he was jailed for “inciting subversion of state power.”
The notion that Liu might be capable of subverting the immense power of the Communist Party of China is patently absurd.
And yet the authorities clearly believe that they had to make an example of him, to prevent others from expressing similar views.
Why does a regime that appears to be so secure consider mere opinions, or even peaceful petitions, so dangerous?
Perhaps because the regime does not feel as secure as it looks.
Without legitimacy, no government can rule with any sense of confidence.
There are many ways to legitimize political arrangements.
Liberal democracy is only a recent invention.
Hereditary monarchy, often backed by divine authority, has worked in the past.
And some modern autocrats, such as Robert Mugabe, have been bolstered by their credentials as national freedom fighters.
China has changed a great deal in the last century, but it has remained the same in one respect: it is still ruled by a religious concept of politics.
Legitimacy is not based on the give and take, the necessary compromises, and the wheeling and dealing that form the basis of an economic concept of politics such as that which underpins liberal democracy.
Instead, the foundation of religious politics is a shared belief, imposed from above, in ideological orthodoxy.
In imperial China, this meant Confucian orthodoxy.
The ideal of the Confucian state is “harmony.”
If all people conform to a particular set of beliefs, including moral codes of behavior, conflicts will disappear.
The ruled, in this ideal system, will naturally obey their rulers, just as sons obey their fathers.
After the various revolutions in the early decades of the twentieth century, Confucianism was replaced by a Chinese version of Communism.
Marxism appealed to Chinese intellectuals, because it was bookish, introduced a modern moral orthodoxy, and was based, like Confucianism, on a promise of perfect harmony.
Ultimately, in the Communist utopia, conflicts of interests would melt away.
Chairman Mao’s rule combined elements of the Chinese imperial system with Communist totalitarianism.
This orthodoxy, however, was also destined to fade away.
Few Chinese, even in the top ranks of the Communist Party, are convinced Marxists anymore.
This left an ideological vacuum, swiftly filled in the 1980’s by greed, cynicism, and corruption.
Out of this crisis came the demonstrations all over China, collectively known as “Tiananmen.”
Liu Xiaobo was an active spokesman in 1989 for the student protests against official corruption and in favor of greater freedom.
Soon after the bloody crackdown on Tiananmen, a new orthodoxy replaced Chinese Marxism: Chinese nationalism.
Only one-party rule would guarantee the continuing rise of China and put an end to centuries of national humiliation.
The Communist Party represented China’s destiny as a great power.
To doubt this was not just mistaken, but unpatriotic, even “anti-Chinese.”
From this perspective, Liu Xiaobo’s critical views were indeed subversive.
They cast doubt on the official orthodoxy, and thus on the legitimacy of the state.
To wonder, as many have, why the Chinese regime refused to negotiate with the students in 1989 – or to find some accommodation with its critics today – is to misunderstand the nature of religious politics.
Negotiation, compromise, and accommodation are the marks of economic politics, where every deal has its price.
By contrast, those who rule according to a shared belief cannot afford to negotiate, for that would undermine the belief itself.
This is not to say that the economic concept of politics is utterly strange to the Chinese – or, for that matter, that the religious notion of politics is unknown in the democratic West.
But the insistence on orthodoxy is still sufficiently strong in China to remain the default defense against political critics.
These things can change.
Other Confucian societies, such as South Korea, Taiwan, and Japan, now have thriving liberal democracies, and there is no reason to believe that such a transition is impossible in China.
But external pressure is unlikely to bring it about.
Many non-Chinese, including me, have signed a letter of protest against the jailing of Liu Xiaobo.
One hopes that this will lend comfort to him, and give a moral boost to Chinese who share his views.
But it is unlikely to impress those who believe in the current orthodoxy of Chinese nationalism.
Until China is released from the grip of religious politics, Liu’s ideals are unlikely to take root.
This does not bode well for China, or, indeed, for the rest of the world.
As America debates whether or not to invade Iraq, fears that the country's economic recovery will stall are beginning to creep into the discussion; with that, worries about the health of the global economy are growing, too.
A consensus is emerging that the gap between the US economy's growth potential and its actual performance will remain large for some time to come.
Can the situation get worse?
Yes, it can: much worse.
A number of worrying factors about the US economy have been around for a long time:
huge trade deficits have persisted since Ronald Reagan's misguided tax cuts of 1981 converted America from the world's largest creditor into the world's largest debtor.
Today, these deficits set new records by the month;
America's appallingly low savings rate.
When American wealth seemed to be growing year after year as the stock market boomed, this was understandable; individual Americans were becoming richer without savings, so why bother?
Today's savings rate, while it has increased slightly, still finds America at the bottom of the world's savings league tables;
lax accounting standards.
The Arthur Anderson, Enron, and WorldCom scandals didn't emerge out of thin air, but had their origins in the mid-1990s, when the US Treasury actually intervened to stop attempts by the supposedly independent accounting standards board to improve matters.
Bad accounting contributed to the recent stock market bubble; bad information led to stock prices that did not reflect underlying realities; and these in turn provided incentives for the excess investment in telecoms that caused today's excess capacity.
To this old brew, new ingredients have been added, notably the most rapid change in a nation's fiscal posture the world has probably ever seen.
In a "now you see it, now you don't" move only a magician should love, the $3 trillion, ten year (non social security) US budget surplus was - in a matter of months - converted into a gapingdeficit of $2 trillion dollars.
Of course, excuses are at hand: the magnitude of the economic downturn was not anticipated and the increased expenditures to fight terrorism could not be foretold.
Excuses, excuses.
As the old saying goes: Don't count your chickens before they hatch.
The Bush Administration not only counted its chickens, it sold them forward!
To anyone with decent eyesight, it was clear that the rosy budget projections of two years ago were nonsense.
Clear, too, was the fact that, in promoting its tax cuts, the Bush Administration was engaging (on a multi-billion dollar scale) in dishonest, Enron-like accounting.
So if things are so bad now, how can they get worse?
Here's a plausible scenario.
To finance its trade deficit, America must borrow from abroad over a billion dollars a day.
When America was the only safe haven for global investors, this was easy.
But America today appears less safe.
The combination of lack of confidence in US corporate accounts, lack of confidence in America's economic policy management (compounded by the mounting deficits), and America's soft underlying economic fundamentals, has dented the US economy's global reputation.
As foreigners start pulling their money out of a country they suspect, the dollar will weaken.
As the dollar weakens, America looks even less safe.
So a rush to the door begins.
While a weak dollar may be good for exports, a falling dollar will be accompanied by stock market losses and greater declines in confidence.
Eventually, even the almighty American consumer will be shaken and realize that he is poorer today than three years ago and that he better start putting money away for his retirement, especially given Bush's proposed risky experiments with the social security system.
At that point, Americans will join the stampede out of their economy.
Why shouldn't they?
They're free to choose where to put their money.
Europe's stock markets will begin to look like an attractive alternative.
But this scenario offers no happy ending for Europe.
A weakening US economy and the strengthening Euro will dampen European exports.
The European Central Bank, fixated on inflation, will be slow to lower interest rates, and the European Stability Pact will make it impossible for fiscal policy to offset these weaknesses.
Europe will join America in a downturn, reinforcing America's decline and setting in motion a global downward spiral.
I am not predicting that this will happen.
I hope that the Bush Administration will enact policies to strengthen the US economy: a tax cut that might made minimal sense when itseemedthat the US had a multi-trillion dollar surplus no longer makes any sense at all.
The Bush Administration should admit this, and redesign a tax program to strengthen the economy by making the country live within its means.
President Bush could even stabilize the economy, offering better unemployment benefits to provide needed stimulus if the downturn continues.
America is strong, and the global economy is strong.
Should the disastrous events contemplated here occur, a new global economy will eventually emerge from the ashes.
Downturns, of course, can never be fully prevented.
We can, however, decrease their frequency; we can make them shallower; we can ensure that fewer people are hurt and that those that get hurt are better protected.
Sadly, we are doing less than is possible to prevent things from getting worse and doing less than necessary to protect ourselves from the consequences.
Last winter, America's central bank - the Federal Reserve - was busy patting itself on the back.
The Fed's cut in its basic interest rate to 1.75% per year seemed to have worked: the recession was ending.
Despite sobered expectations about the high-tech revolution's impact on productivity and profits, as well as the jitters inspired by the terror attack on the World Trade Center, American businesses, it was believed, would soon start investing again big-time because borrowing money at 1.75% was too good a deal to pass up.
By late spring, those expectations had disintegrated alongside the collapse of Enron, WorldCom, and Arthur Andersen.
Suddenly, everyone doubted the integrity of the financial accounts of American companies.
Suddenly, everyone saw just how much America's system of corporate surveillance and control had deteriorated during the bubble of the 1990s.
The American stock market fell 15-20% below its winter levels.
Spreads between the interest rate at which America's government could borrow and the interest rates at which America's corporations could borrow widened.
Suddenly, the Fed stopped congratulating itself: a 1.75% interest rate might be the right interest rate to fuel a recovery when the Dow-Jones stock market index stands at 10,000, but not when the Dow-Jones index stands at 8,500.
Throughout the summer, corporate investment news remained disappointing.
More and more analysts began to speak about the possibility of a "double dip" recession.
Yet throughout all this, the Federal Reserve remained passive.
The short-term interest rates it controlled didn't budge.
Only in mid-August did the Fed hint that interest rates might be cut.
The informal and unofficial rationale leaking out of the Fed for its inaction had two parts.
Today, however, the real threats to the majority of the world's population stems from dangers almost unknown back then: poverty, hunger, population growth, migration, the environment, and the like.
For the UN to meet these challenges, its very structure must change.
Two new councils, each with comparable power to the Security Council, are needed: a Social Council and an Economic Council.
The IMF, World Bank, and WTO should not only report to, but be dependent upon this new UN reformed structure.
Why are these new bodies needed?
The world cannot do without rules; it cannot move forward against our age's most pressing problems without defined legal rules and the institutions that regulate international law.
Because these institutions do not exist, the UN must now invent them.
Of course some rules, such as rules governing the promulgation of trade sanctions, now exist within, say, the WTO.
These rules, however, are but steps in the right direction: steps toward socially and ecologically sustainable free trade and against protectionism, especially that often practiced by rich countries.
Across the board, more global rules are needed so that global efforts to confront poverty, disease, and mass migration can be made consistent, predictable and most of all effective.
We have the Rome Statute of International Criminal Code; we are heading for an innovative guide to best practice on how civil society organizations can best contribute to the work of the UN; and we now have a large coalition, far beyond NATO, combatting terrorism.
I am grateful that one of the reactions to September 11th was, if I am not mistaken, a somewhat changed attitude within the USA vis-à-vis the UN.
But it is of a paramount importance that these kinds of change, namely, to incorporate real power into the structure of the UN, make more progress.
In dangerous times such as these, the world's peoples need to prove their solidarity.
The large coalition now fighting terrorism is one way to demonstrate this.
But solidarity also must be recognized within the real power structures of the UN.
The Secretary General convocation of a ``Dialogue of Civilizations'' is but a start here.
Far more needs to be done.
The institution of Social and Economic Councils at the UN would mark an enormous step in the right direction.
I have tried to present the ideas outlined here not only to the General Assembly but also to the permanent members of the Security Council.
I have also been invited to present them to the US Senate.
So far, none of those discussions have proved to be very fruitful.
But just as the time is coming when the US will to come see the UN as indispensable, the Security Council and its members will come to see the creation of new bodies within the UN not as rivals, but as the only means for the world's people, in solidarity, to confront the myriad social and economic problems that they face.
NEW YORK – The solution to manmade climate change depends on the transition to electricity production that, unlike burning oil, natural gas, and coal, emits little or no carbon dioxide – the main greenhouse gas responsible for global warming.
Low-carbon electricity can be produced by solar, nuclear, and wind energy, or by coal-burning power plants that capture and store their CO2 emissions.  
The policy problem is simple.
Coal is a cheaper and more easily used energy source than the alternatives.
It is cheap because it is plentiful.
It is easier to use than wind or solar power because it can produce electricity around the clock, without reliance on weather conditions. 
To save the planet, we need to induce power suppliers to adopt low-carbon energy sources despite coal’s lower price and greater ease of use.
The obvious way is to tax coal, or to require power plants to have permits to use coal, and to set the tax or permit price high enough to induce a shift towards the low-carbon alternatives.
Suppose coal produces electricity at a cost of $0.06 per kilowatt-hour, while solar power costs $0.16/kilowatt-hour.
The tax on coal-based electricity would have to be $0.10/kilowatt-hour.
In that case, consumers would pay $0.16/kilowatt-hour for either coal or solar.
The utilities would then shift to low-carbon solar power.
The switchover, however, would more than double the electricity bill in this example.    
Politicians are loath to impose such a tax, fearing a political backlash.
For years , this has stymied progress in the United States towards a low-carbon economy.
Yet several European countries have successfully introduced the idea of a “feed-in tariff,” which provides the core of a politically acceptable long-term solution.
A feed-in tariff subsidizes the low-carbon energy source rather than taxing the high-carbon energy source.
In our example, the government would pay a subsidy of $0.10/kilowatt-hour to the solar-power plant to make up the difference between the consumer price of $0.06 and the production cost of $0.16.
The consumer price remains unchanged, but the government must somehow pay for the subsidy.
Here is another way.
Suppose that we levy a small tax on existing coal power plants in order to pay for the solar subsidy, and then gradually raise consumers’ electricity bills as more and more solar plants are phased in.
The price charged to consumers would rise gradually from $0.06/kilowatt-hour to the full cost of $0.16/kilowatt-hour, but over a phase-in period of, say, 40 years (the lifespan of the newest of today’s coal plants).
Assume that as of 2010, the entire electricity system is coal-based, and that the electricity price paid by the consumers is $0.06/kilowatt-hour.
By 2014, suppose that 10% of the 40-year transition to solar power has been achieved.
The consumer price is raised 10% of the way from $0.06 to $0.16, thus reaching $0.07/kilowatt-hour. 
The coal tax for 2014 is then set at $0.01/kilowatt-hour, which is just enough to pay the needed solar subsidy of $0.09/kilowatt-hour.
Solar producers fully cover their costs of $0.16/kilowatt-hour, since they sell power to the consumers at $0.07/kilowatt-hour and receive a subsidy of $0.09/kilowatt-hour.
A small coal tax can support a large solar subsidy.
Suppose, further, that by 2030 the transition to a low-carbon economy is halfway completed.
The consumer price for electricity is now set at $0.11, exactly halfway between $0.06 and $0.16.
The coal tax is now raised to $0.05/kilowatt-hour, just enough to cover the solar subsidy of $0.05/kilowatt-hour.
Once again, the solar producers cover their costs exactly, since the subsidy of $0.05/kilowatt-hour closes the gap between the consumer price ($0.11/kilowatt-hour) and the producer cost ($0.16/kilowatt-hour).
Let us presume, finally, that by 2050, all electricity production has made the transition to low-carbon energy sources.
The consumer price finally reaches $0.16/kilowatt-hour, enough to cover the full cost of solar power without a further subsidy.
This approach allows higher consumer electricity prices to be phased in gradually, yet establishes strong, immediate incentives for adopting solar power.
Moreover, the government budget is balanced every year, since the coal tax pays for the solar subsidy.
The actual transformation in the coming years will have one major advantage compared to this illustration.
Today’s solar power plants might cost an extra $0.10/kilowatt-hour compared to coal, but such plants will be much less costly in the future because of improved technology.
Thus, the magnitude of subsidies needed in a decade or two will be lower than they are today.
Energy debates in the US, Australia, and other countries have centered so far on introducing a cumbersome cap-and-trade permit system.
Every major user of fossil fuel would need to buy permits to emit CO2, and those permits would trade in a special marketplace.
The market price of the permits would be equivalent to paying a tax on CO2 emissions. 
Unfortunately, cap-and-trade systems are difficult to manage and don’t give clear signals about the future price of permits.
Europe has adopted such a system, but other parts of the world have repeatedly rejected it.
In fact, Europe’s biggest successes in promoting low-carbon energy have come from its feed-in tariffs, and carbon taxes in some countries, rather than its cap-and-trade system.  
The time has come for the US, China, India, and other major economies to declare how they will foster their own transition to a low-carbon economy.
A small and gradually rising carbon tax that funds a feed-in tariff system could win political support in the US.
It could also help to foster consensus among the major coal-based economies, including China and India.  
There really are effective long-term solutions to manmade climate change that are politically acceptable and feasible to implement.
It is time to embrace them.
An unusual meeting of scientists took place in Paris this summer, when scientists gathered to brainstorm about the need for a new science, one that could be as revolutionary as Einstein’s insights were a century ago.
Most scientists assume that the basics of science are known.
In terms of big challenges, the conventional wisdom is that few things are left to discover.
The remaining options are said to fall into three groups: “grand scientific quandaries” (such as uniting gravity and electricity into one theory) which require a huge investment and first world infrastructure; “data collection,” which is the field work associated with archeological digs and biological/genetic surveys; and “science-informed problems,” such as combating AIDS or addressing global warming.
Beyond that, many believe the only hard work will be to use existing laws to benefit humankind in new technological ways.
Who can argue?
After all, today’s models work.
But an emerging group of scientists points to phenomena that current theories do not address well.
These problems are exceedingly common and artfully avoided because the science that would account for them just doesn’t exist.
This missing science would describe processes, and how entire systems evolve.
Individual scientific disciplines are understood fairly well.
Physics, at least the physics we encounter as ordinary humans, is well mapped.
Chemistry and biochemistry are similarly solid -- there are some things we don’t understand about the body, but it is believed that the basic machinery of how cells and molecules interact is known.
Slightly apart from these are the new social sciences, which deal with humans and societies.
In each of these areas -- physics, biochemistry and social science -- the theories are mature and largely uncontroversial.
Each discipline has its own language and its own separate machinery.
Rarely is a scientist an expert in more than one area, because the worlds and languages are so different.
This means that we can’t answer complex questions that depend on more than one field.
Consider the brain, for example.
This complex organ is composed of molecules that interact using the principles of physics.
That information moves according to the laws of electricity.
There is also a system of specialized cells, and these interact, exchanging chemicals that also convey information.
The interaction between two brains adds another level: here, information is exchanged by means of languages, signs and ideas.
Information is at work on each level and comfortable theories explain how the separate ones operate.
But information is being exchanged between the levels as well. There is no science that explains this, even at the most rudimentary level.
To cope with this deficiency, some scientists have tried to reinvent the tools of one level in order to apply them to another.
This leads to such things as a “language” at the level of cells and “energy” behind organized societies.
Sometimes the transplant works well enough, but it does not address the central problem: What is the nature of the information conveyed between each level, and how is it conveyed?
As it happens, nearly every system in the world is composed of such layers.
A similarly embarrassing lack of understanding about how the whole system works exists in every case.
The group of interdisciplinary scientists that met in Paris is loosely affiliated under the banner “Foundations of Information Science.”
They have been working in a distributed collaboration for eight years and come from a range of countries and specialties.
As well as scientists from the relevant disciplines, art theorists, psychiatrists, language experts and philosophers are beginning to participate in the discussion.
Most of the group is banking on the “transplant” strategy, in which the basic science of one layer is placed in another, tweaked and supplemented in order to be functional.
Others think that a whole new approach is required.
They assume that many scientific conventions are accidents of history and new abstractions can be devised.
If the FIS group is lucky, there will also be some radical input from thinkers that do not presently have access to first world infrastructure.
Independent thinking is an underestimated factor.
Nearly all the activities collected under the banner of “science” have developed institutional tendencies that are similar to their economic counterparts.
It is usually assumed that developing economies need to build resources that emulate those in the developed world, but this could actually stifle the most creative thinking.
Many scientific disciples are going through a revolution, and a lot of those ideas -- sometimes revolutionary ideas -- are bubbling up from labs and research centers that are unaffiliated with large institutions.
Twenty years of the most advanced thinking for mathematical algorithms came from a Soviet empire starved of computing power.
The cleverest, most literally earth-shattering notions of physics for two generations came not from the expected powerhouses of the day, but from Budapest.
Iran has a tradition of architectural design that has revealed key insights to cognitive scientists.
Today, some of the most radical new ideas in second generation artificial intelligence (so-called “autonomous agents”) are incubating in Prague.
The most creative breakthroughs became famous events.
When Einstein added new abstractions to the language of physics, the identity of space and time changed.
The FIS meeting in July was the unheralded beginning of an attempt to remodel the universe in such a way.
The group identified the gaps that need explanation.
They will expand their pool of thinkers to include scientists from necessarily innovative regions.
Following this, they will identify which problems might be solved if this new science is developed.
Or if you wish, discovered.
VIENNA – US President Barack Obama has injected fresh momentum into efforts – stalled for a decade – to bring about nuclear disarmament.
He has committed himself to the vision of a world free of nuclear weapons and acknowledges the link between nuclear non-proliferation and disarmament by the nuclear-weapon states.
Obama has pledged to revitalize the 1970 Nuclear Non-Proliferation Treaty (NPT), which aims to prevent the spread of nuclear weapons.
The non-proliferation regime, of which the NPT is the cornerstone, is in disarray.
The main problems are easily identified.
First, the five main nuclear-weapon states have not taken seriously their NPT obligation to work for nuclear disarmament.
Instead, they have insisted that nuclear weapons are essential for their security and continued to modernize their nuclear arsenals.
This naturally robs them of the moral authority to persuade others not to acquire nuclear weapons, which continue to be perceived as a source of power and influence, and an insurance policy against attack.
Second, as we have seen in the case of North Korea, there is nothing to stop countries that sign the Treaty from simply walking out after declaring that “extraordinary events” have jeopardized their supreme interests.
Third, the International Atomic Energy Agency, which is supposed to police the non-proliferation system, is shamefully underfunded.
When it comes to determining whether or not a country is conducting a covert nuclear weapons program, IAEA inspectors often have their hands tied, either because they lack the legal authority to gain access to all the locations they consider necessary, or because the IAEA’s analytical laboratories are outdated, or because the Agency does not have adequate access to satellite imagery.
Fourth, export controls have failed to prevent the spread of sensitive nuclear technology, not least due to the sophisticated efforts of clandestine networks like the one run by Pakistani nuclear scientist A.Q. Khan.
Nine countries already have nuclear weapons, and it would be naive to presume that others, particularly in regions of conflict, will not try to get hold of them.
In addition, a number of countries with nuclear energy programs have the capability, if they choose, to manufacture nuclear weapons within a matter of months if their security perceptions change, because they have mastered the critical technology – uranium enrichment and plutonium reprocessing.
If more countries take this path, it could prove to be the Achilles’ heel of non-proliferation.
Fifth, the international community, spearheaded by the United Nations Security Council, has more often than not been paralyzed in the face of challenges to international security and ineffectual in responding to suspected cases of nuclear proliferation.
These issues will not be resolved overnight.
But there is much that can be done relatively quickly.
The United States and Russia have started negotiations on deep cuts in their nuclear arsenals, which together account for 95% of the world’s 27,000 warheads.
Other key steps include bringing into force the Comprehensive Nuclear Test Ban Treaty; negotiating a verifiable treaty to end production of fissile material for use in weapons; radically improving the physical security of nuclear and radioactive materials, which is vital to prevent them from falling into the hands of terrorists; and strengthening the IAEA.
Last month, I proposed a key measure to strengthen non-proliferation to the IAEA’s Board of Governors – establishing an IAEA bank of low-enriched uranium (LEU) to guarantee supplies to countries that need nuclear fuel for their power reactors.
LEU cannot be used to make weapons.
Some such mechanism will be essential in the coming decades as more and more countries introduce nuclear energy.
My proposal is to create a physical stockpile of LEU at the disposal of the IAEA as a last-resort reserve for countries with nuclear power programs that face a supply disruption for non-commercial reasons.
This would give countries confidence that they can count on reliable supplies of fuel to run their nuclear power plants, and therefore do not need to develop their own uranium-enrichment or plutonium-reprocessing capability.
This could help to avoid a repeat of Iran’s experiences after its 1979 revolution, when contracts for fuel and technology for its planned nuclear power program were not honored.
Thirty years later, some of the consequences are still being felt.
The LEU would be available to countries in need on the basis of non-political and non-discriminatory criteria.
It would be accessible at market prices to all states in compliance with their nuclear safeguards obligations.
No state would be required to give up the right to develop its own fuel cycle.
The money needed to launch an LEU bank is in place, thanks primarily to a non-governmental organization – the Nuclear Threat Initiative – and initial funding from Warren Buffett.
But this can only be a first step.
It should be followed by an agreement that all new enrichment and reprocessing activities will be placed exclusively under multinational control, and that all existing such facilities will be converted from national to multinational control.
This is a bold idea, but bold ideas are needed now more than ever.
The opportunity to put the nuclear fuel cycle under multinational control was missed 60 years ago because of the Cold War.
The spread of nuclear technology and the growing risk of nuclear terrorism make it imperative that we get it right this time.
On August 8, 2008, the world watched with awe the amazing spectacle of the Olympics opening ceremony in Beijing.
We saw the electronic unrolling of Chinese scrolls replete with great historic symbols and were mesmerized by dancers creating “harmony,” using their bodies as ink brushes.
2008 martial arts students performed millennia-old moves with mechanical precision, while the flying celestials and the galloping torchbearer created a sense of heavenly abode on earth.
There was another time when China dazzled the world at its doorstep: the Tang dynasty (618-907), often thought of as China’s golden age, when it was truly the “middle kingdom” at the center of the universe.
Its capital, Chang Àn (modern day Xìan) was a world-class city; visitors came from all over the world and were dazzled by its wealth, beauty, and power.
Its emperors used silver from Persia, glass from Europe, precious stones from Central Asia, and gold implements from India.
Open, confident, and cosmopolitan, China connected with the world with ease, adopting new ideas, and projecting its own indigenous creations.
It’s no wonder that Chinese scholars sometimes refer to today’s China era as the new Tang Dynasty.
Indeed, when China was awarded the Olympic Games in 2001, the country’s official news agency, Xinhua called it a “milestone in China’s rising international status and a historical event in the great renaissance of the Chinese nation.”
For seven years, Chinese officials and artists worked tirelessly to make this dream of a “renaissance” a glittering reality, and they exceeded all expectations.
But how should we understand the broader implications of the opening ceremony, both for China and the outside world?
First, the good news.
In keeping with China’s recent efforts to project its “soft” side, the opening ceremony produced the idea of a historic, but dynamic culture at its best. Other than the presence of a few People’s Liberation Army soldiers, you would have been hard pressed to find any visible evidence of the reigning communist regime or its founder, Mao Zedong.
Equally significant was the projection of China as a nascent leader of the new international cultural order.
The “Bird’s Nest” stadium was the creation of the multinational design team of Herzog &amp; de Meuron, with suggestions from the visual artist Ai Weiwei.
Many artists involved in the creation of the spectacle, including the fireworks specialist Cai Guo Qiang, the dance star Shen Wei, and the composer Tan Dun, earned their fame primarily in the West.
Even Zhang Yimou, the lead impresario for the event, gained fame in the West through his early films chronicling the hard life of a young modern China.
Chinese officials had clearly decided that these diaspora darlings of the international art scene should be now claimed as China’s own.
These artists’ ability to the bridge traditions of East and West and to create a new space for creativity that can transcend the cultural specificities of the past in favor of a new blended future could be squarely associated with China’s own global aspirations.
Like the artists and their art, the country could elevate itself from the dichotomies of old-new, past-present, and traditional-modern to project an image appropriate to our globalizing age.
Not surprisingly, Chinese leadership was keen to avoid any reference to the last two centuries of struggle and humiliation, or to its problematic political agendas and thorny trade issues.
At the same time, it could be argued that the spectacle of the opening ceremony was intended to overcome China’s historic humiliation by the West and signal a new chapter. The “sleeping dragon,” as Napoleon described China in the early nineteenth century, was now fully awake, ready to charge into the new world.
As in the Tang Dynasty, arts and culture were at center stage, reflecting the country’s economic prowess and political might.
But the extravaganza also left lingering doubts.
Why such a drive to prove to the world that these had to be the very best Olympics ever?
(Chinese authorities even pressed the International Olympic Committee to make such a declaration at the conclusion of the games.)
Some have suggested that the effort suggests a hint of insecurity.
It should also be noted that while Mao was conspicuously absent in the Olympics, his communist legacy was present in subtle ways.
The relentless emphasis on the “harmonious” presence of large groups of performers left no room for individual voices (even the young singer Lin Miaoke, as we now know, didn’t have her own voice).
Ironically, while younger Chinese (products of China’s one-child policy) are obsessed with personal stylistic statements, the drama of the opening ceremony consisted in collective expression at the service of the state.
Chinese intellectuals have always been cognizant of this tension between individual creativity and collective will.
How will the new China balance these two conflicting needs?
As we contemplate the potential arrival of the new Tang Dynasty in China, we should remember the message of the old Tang Dynasty poet, Po Chü-i (772-846 AD):
Sent as a present from Annam,
A red cockatoo.
Colored like the peach-tree blossom,
Speaking with the speech of men.
And they did to it what is always done
To the learned and eloquent.
They took a cage with stout bars
And shut it up inside.
MEXICO CITY – For the next American president, fixing the international mess inherited from the Bush administration will be no simple task.
While Latin America will not be a priority for either an Obama or McCain administration, continuing the United States’ neglect of the last seven years is no longer viable.
Two distinct political/diplomatic challenges stand out: Cuba’s imminent transition or succession crisis, and the continuing ascent of the region’s “two lefts,” one represented by Venezuela’s President Hugo Chávez and the other by Brazil’s increasingly influential President Luiz Inácio Lula da Silva.
The next US administration will only prove successful if it grasps that Latin America is living through a moment that combines the best and worst aspects of its history: the fastest economic growth since the 1970’s, with poverty and inequality diminishing, and more democratic and respectful of human rights than ever before, but becoming more politically polarized.
In Cuba, Fidel Castro’s eventual passing from the scene represents an immense challenge.
The US cannot continue with the failed policies of the past half-century.
Demanding a full-fledged democratic transition as a pre-condition for normalizing US-Cuban relations is both unrealistic and unpalatable to Latin America.
Yet the US cannot set aside the question of democracy and human rights in Cuba while it awaits the departure of Fidel’s brother, Raúl.
Realpolitik and fear of another exodus of Cuban refugees across the Florida Straits may tempt the US to pursue a “Chinese” or “Vietnamese” solution to Cuba: normalizing diplomatic relations in exchange for economic reform, while leaving the question of internal political change until later.
But the US should not succumb to this temptation.
The US, Canada, Europe, and Latin America have constructed a regional legal framework, which must not be abandoned, to defend democratic rule and human rights in the hemisphere.
Cuba needs to return to the regional concert of powers, but it must accept this concert’s rules.
Holding free and fair elections may not be the primary issue, but nor are they issues that should be shelved in the interests of stability and expediency.
Elections must instead be part of a comprehensive process of normalization: they should neither be a deal-breaker nor a non-issue.
While the US should lift its trade embargo as soon as Cuba’s transition begins, everything else should be conditional on Cuba initiating a process of resolving all outstanding issues.
But Cuba is just part of what might be called Latin America’s “left” problem.
Indeed, much has been written recently about the ascent of the left in Latin America over the past decade.
In fact, there are two lefts in the region: a modern, democratic, globalized and market-friendly left, found in Chile, Brazil, Uruguay, parts of Central America, and, up to a point, in Peru; and a retrograde, populist, authoritarian, statist, and anti-American left, found in Mexico, El Salvador, Nicaragua, Cuba, Ecuador, Bolivia, Venezuela, and, to a lesser extent, in Argentina, Colombia, and Paraguay.
Some of these “lefts” are in power; some, as in Mexico in its last, disputed presidential election, barely missed conquering it, but may still do so.
Over the past two years, it has become increasingly evident that the “modern” or “soft” left is, all in all, governing well.
The other left has proved to be more extreme and erratic than many anticipated.
The former feels no urge to “export” its “model,” whereas the latter has a strategy and the means to do so.
The retrograde left today can realize Che Guevara’s old dream: not “one, two, many Vietnams,” but “one, two, many Venezuelas,” winning power by the ballot and then conserving and concentrating it through constitutional changes and the creation of armed militias and monolithic parties.
It can finance all of this with the support of Venezuela’s state oil company, implementing social policies that are misguided over the long term but seductive in the short run, especially when carried out by Cuban doctors, teachers, and instructors.
Herein lies a dilemma for the next US president: how to address the clear rift between the two lefts in a way that improves US-Latin American relations, fortifies the modern left, and weakens the retrograde left without resorting to the failed interventionist policies of the past.
The best, strictly Latin America-focused steps, are self-evident, if not easily achievable.
They require strengthening those governments of the modern left, or those of the center or center-right threatened by the old-fashioned left, and simultaneously making it clear to the latter that there is a price to be paid for violating the basic tenets of democracy, respect for human rights, and the rule of law.
Turning its back in the face of such challenges is no longer a viable American option.
Aside from areas of particular concern (oil, arms, guerrillas, drugs), the US needs Latin America dearly nowadays because resistance to it is springing up everywhere, and with greater virulence than at any time since World War II’s end.
The next US president must reinvigorate a relationship that is ready to be substantially transformed for the first time since Franklin Roosevelt’s Good Neighbor Policy of seven decades ago.
PRAGUE: Rebellion by Czech TV journalists against a new director of the publicly-owned Czech TV marks the climax of a ten year battle between two concepts of democracy.
The first concept is represented by former prime Minister Vaclav Klaus, the second by President Vaclav Havel.
Klaus sees political parties as the backbone of any democratic system and sees little place for civil society in politics.
He deems the proponents of civil society “elitists” who refuse to be tested at the ballot box and who try to influence politics through informal mechanisms.
President Havel argues that a democracy based only on political parties and basic democratic mechanisms is deformed.
In his view, political parties, although necessary, must be checked by a robust civil society.
If civil society is too weak, parties will seek to dominate institutions that should remain independent.
Over the past ten years President Havel has repeatedly asked the Czechs to be more active and to not let politicians control their lives.
Klaus’s vision of democracy had the upper hand for most of the past decade.
Easily understood, it conformed to patterns of behavior most Czechs acquired during the communist era, when public and private spheres of life were rigidly separated.
True, communism’s fall was brought about by a strong civic movement called “Civic Forum”, but that movement disintegrated once it achieved its goal.
With its passing, people became passive once more.
Klaus and his followers spearheaded the creation of well-functioning, standard political parties.
But in the absence of a strong civil society, those parties monopolized public space, pushing civic activists to the sidelines.
Havel was the first important Czech politician to criticize this trend, warning against excessive partisanship and arguing that political parties would become internally weak but outwardly authoritarian if they did not draw inspiration from a vibrant civil society.
Unfortunately, Havel’s vision of democracy appears complicated when compared to that of Klaus.
In the past, calls for active civic engagement and Havel’s moralistic views left average Czechs cold and alienated political opponents, who accused him of promoting a nonpolitical form of politics.
Prompted by civic passivity, political parties not only came to dominate every aspect of Czech life but engaged in dubious practices that increased cynicism and public passivity.
At the end of 1997, the second Klaus government collapsed under the weight of financial scandals.
Rather than learn from this fiasco, Klaus went on the offensive, claiming that he was a victim of a conspiracy hatched by Havel.
But his party, the Civic Democrats (ODS), lost the June 1998 elections to the Social Democrats (CSSD), whom Klaus vilified before the elections as a threat to democracy.
Soon afterwards, however, the Civic Democrats and the Social Democrats signed the so-called “opposition agreement”, under which Klaus’s party gained important posts and other advantages in exchange for allowing the Social Democrats of Prime Minister Zeman to form a minority government.
Klaus, Zeman and their parties also agreed to work together to limit presidential power and the independence of the Central Bank by changing the Constitution, as well as to change the electoral law in their favor.
Four smaller parties, who allied themselves in a four-party coalition called “4K” objected.
Protests against these political arrangements were criticized by the ODS and CSSD as attempts to undermine their efforts to ensure political stability.
Despite the fact that the opposition agreement boosted the popularity of the unreformed Czech Communists, the determination of the Civic Democrats and Social Democrats to continue dividing the spoils of power remained undiminished.
In the fall of 2000, Czech voters rebuked both parties during regional and Senate elections, with the Social Democrats losing their joint majority in the Senate.
Because the Czech Parliament’s upper house has an absolute veto over constitutional amendments, the opportunity to amend the Constitution was lost.
Loss of control of the Senate also meant that Klaus’s hope to replace Havel as president diminished.
Defeat prompted Klaus and Zeman to try to and gain control over Czech TV by packing its council of overseers with their sympathizers.
Shortly before Christmas, Czech TV’s director, who was resisting political pressure, was replaced by Jiri Hodac, a man with close ties to ODS.
TV journalists rebelled, occupying the station's newsroom.
The protests by artists, intellectuals and opposition politicians that followed were the biggest political upheavals since 1989.
Realizing that the game was lost, the Social Democrats joined with Klaus’s opponents in parliament on January 5th to demand Hodac’s resignation.
Parliament is also working on a new TV law to prevent political parties from politicizing the TV Council.
But political realignment is not the most important news arising from this turmoil.
Of far greater importance is the reawakening of civil society which has, for the first time since 1989, stood up to the political parties to reclaim the public space it relinquished ten years ago.
Equally important is the fact that for the first time since 1989, civil society has found a voice independent of President Havel.
Unrecognized by almost everyone, Czech society has moved beyond Havel and Klaus.
It rejects Klaus’s truncated democracy, and, although it supports (to some extent) Havel’s vision, Havel himself is no longer the motor of civil society in action.
NEW YORK – Twenty years after the fall of the Berlin Wall and the collapse of communism, the world is facing another stark choice between two fundamentally different forms of organization: international capitalism and state capitalism.
The former, represented by the United States, has broken down, and the latter, represented by China, is on the rise.
Following the path of least resistance will lead to the gradual disintegration of the international financial system.
A new multilateral system based on sounder principles must be invented.
While international cooperation on regulatory reform is difficult to achieve on a piecemeal basis, it may be attainable in a grand bargain that rearranges the entire financial order.
A new Bretton Woods conference, like the one that established the post-WWII international financial architecture, is needed to establish new international rules, including treatment of financial institutions that are too big to fail and the role of capital controls.
It would also have to reconstitute the International Monetary Fund to reflect better the prevailing pecking order among states and to revise its methods of operation. 
In addition, a new Bretton Woods would have to reform the currency system.
The post-war order, which made the US more equal than others, produced dangerous imbalances.
The dollar no longer enjoys the trust and confidence that it once did, yet no other currency can take its place.
The US ought not to shy away from wider use of IMF Special Drawing Rights.
Because SDRs are denominated in several national currencies, no single currency would enjoy an unfair advantage.
The range of currencies included in the SDRs would have to be widened, and some of the newly added currencies, including the renminbi, may not be fully convertible.  This would, however, allow the international community to press China to abandon its exchange-rate peg to the dollar and would be the best way to reduce international imbalances.
And the dollar could still remain the preferred reserve currency, provided it is prudently managed.
One great advantage of SDRs is that they permit the international creation of money, which is particularly useful at times like the present.
The money could be directed to where it is most needed, unlike what is happening currently.
A mechanism that allows rich countries that don’t need additional reserves to transfer their allocations to those that do is readily available, using the IMF’s gold reserves.
Reorganizing the world order will need to extend beyond the financial system and involve the United Nations, especially membership of the Security Council.
That process needs to be initiated by the US, but China and other developing countries ought to participate as equals.
They are reluctant members of the Bretton Woods institutions, which are dominated by countries that are no longer dominant.
The rising powers must be present at the creation of this new system in order to ensure that they will be active supporters.
The system cannot survive in its present form, and the US has more to lose by not being in the forefront of reforming it.
The US is still in a position to lead the world, but, without far-sighted leadership, its relative position is likely to continue to erode.
It can no longer impose its will on others, as George W. Bush’s administration sought to do, but it could lead a cooperative effort to involve both the developed and the developing world, thereby reestablishing American leadership in an acceptable form.
The alternative is frightening, because a declining superpower losing both political and economic dominance but still preserving military supremacy is a dangerous mix.
We used to be reassured by the generalization that democratic countries seek peace.
After the Bush presidency, that rule no longer holds, if it ever did.
In fact, democracy is in deep trouble in America.
The financial crisis has inflicted hardship on a population that does not like to face harsh reality.
President Barack Obama has deployed the “confidence multiplier” and claims to have contained the recession.
But if there is a “double dip” recession, Americans will become susceptible to all kinds of fear mongering and populist demagogy.
If Obama fails, the next administration will be sorely tempted to create some diversion from troubles at home – at great peril to the world.
Obama has the right vision.
He believes in international cooperation, rather than the might-is-right philosophy of the Bush-Cheney era.
The emergence of the G-20 as the primary forum of international cooperation and the peer-review process agreed in Pittsburghare steps in the right direction.
What is lacking, however, is a general recognition that the system is broken and needs to be reinvented.
After all, the financial system did not collapse altogether, and the Obama administration made a conscious decision to revive banks with hidden subsidies rather than to recapitalize them on a compulsory basis.
Those institutions that survived will hold a stronger market position than ever, and they will resist a systematic overhaul.
Obama is preoccupied by many pressing problems, and reinventing the international financial system is unlikely to receive his full attention.
China’s leadership needs to be even more far-sighted than Obama is.
China is replacing the American consumer as the motor of the world economy.  Since it is a smaller motor, the world economy will grow slower, but China’s influence will rise very fast.
For the time being, the Chinese public is willing to subordinate its individual freedom to political stability and economic advancement.
But that may not continue indefinitely – and the rest of the world will never subordinate its freedom to the prosperity of the Chinese state.
As China becomes a world leader, it must transform itself into a more open society that the rest of the world is willing to accept as a world leader.  Military power relations being what they are, China has no alternative to peaceful, harmonious development.  Indeed, the future of the world depends on it.

It is time for New Year's resolutions, and this year's are obvious.
When the millennium opened, world leaders pledged to seek peace, the end of poverty, and a cleaner environment.
Since then, the world has seen countless acts of violence, terrorism, famine, and environmental degradation.
In 2005, we can begin to change direction.
Knowledge, scientific advance, travel, and global communications give us many opportunities to find solutions for the world's great problems.
When a new disease called SARS hit China last year, the World Health Organization coordinated the actions of dozens of governments, and the crisis was quickly brought under control, at least for now.
When Bill Gates donated $1 billion to bring vaccines to poor children, he made it possible to protect tens of millions of young people from preventable diseases.
When an agricultural research unit called the World Agroforestry Center discovered that a certain tree could help African farmers grow more food, they introduced a new and valuable approach to overcoming Africa's chronic food crisis.
Unfortunately, such examples of international cooperation are as rare as they are impressive.
With our knowledge, science, and technology, the horrendous living conditions of the world's poorest people could be dramatically improved.
Millions of people could be spared malaria, HIV/AIDS, hunger, and life in slums.
The problem is not that we lack good solutions.
The problem is that we fail to cooperate globally to put those solutions into practice.
United Nations Secretary-General Kofi Annan has honored me by making me his Special Adviser on the Millennium Development Goals and asking me to lead a group of scholars and development experts in identifying practical steps to reach the goals by the target date in 2015.
This effort, known as the UN Millennium Project, will issue its report to Secretary-General Annan on January 17, 2005.
Our study, Investing in Development: A Practical Plan to Achieve the Millennium Development Goals , will be available for free around the world at www.unmillenniumproject.org .
What we learned is easily summarized.
For every major problem - hunger, illiteracy, malnutrition, malaria, AIDS, drought, and so forth - there are practical solutions that are proven and affordable.
These investments, in turn, would strengthen the private sector and economic growth.
Yet they require global partnership between the rich and poor countries of the world.
Most importantly, the world's richest countries need to do much more to help the poorest countries make use of modern science and technology to solve these great problems.
The US, for example, currently spends around $450 billion each year on its military, but less than $15 billion to help the world's poorest countries fight disease, educate their children, and protect the environment.
This is a mistake, because military approaches alone cannot make America safe.
Only shared prosperity can truly make the planet secure.
The US should be investing much more in peaceful economic development.
Germany, Japan, and several other rich countries are also doing much less than they should - and much less than they promised the poor countries that they would do.
In 2002, all donor countries committed to "make concrete efforts" to reach 0.7% of national income in development aid to poor countries.
Germany, Japan, and the US, among others, remain far below this commitment.
The year 2005 will offer many opportunities for citizens around the world to insist that their leaders keep their Millennium promises.
After our report is issued in January, Secretary-General Kofi Annan will issue a report to the world in the spring, identifying the practical steps that should be taken this year.
Around the same time, an important commission on Africa will issue a report to United Kingdom Prime Minister Tony Blair.
Then, in July, the UK will host the annual G-8 Summit of the rich countries.
Blair has promised that he will make the fight against poverty and long-term climate change the two priorities of the summit.
In September, the world's leaders will reconvene at the UN to decide on their actions during the coming decade.
The rich and powerful nations often declare their leadership in the world.
The US claims that it helps the world fight poverty, but instead spends its money on weapons.
Germany and Japan say that they want a permanent seat on the UN Security Council, but neither has yet followed through on its own pledges to help the world's poorest people.
The world's poorest countries will ask themselves why they should vote for Germany and Japan to have permanent seats on the Security Council if they can't keep their promises.
Nothing would be wiser for the world's rich countries than to fulfill their pledges to the world's poor, hungry and disease-ridden peoples.
Therein lies the path to sustained peace.
2005 is the year that words can become reality, and that the world can begin to fulfill its hopes for our new millennium.
Let us make our leaders aware that we aspire to shared peace and prosperity.
Let us pledge that the rich and powerful should take real actions to help the poor, the weak, and the suffering.
LONDON: A hundred years ago, the humorous English magazine Punch carried a cartoon which depicted a young and nervous curate eating breakfast with his bishop.
He was eating a boiled egg, and clearly not enjoying it.
The bishop enquired: “I say - is your egg all right?” And the curate replies: “My Lord, it is excellent in parts.”
The cartoon caught the English fancy, and created a catch-phrase still in use today, although it is usually misunderstood and misused.
Someone may say: “It’s a bit of a curate’s egg”, when he means that something is a mixture of good and bad.
But of course the point of the original joke was that the curate was just being polite: an egg is either good or bad, and his was bad.
This week’s European Summit at Nice (December 7-9) looks like being a curate’s egg.
The question is, will it be bad all through and a failure?
Or will it be “excellent in parts”?
The probable answer is: both.
It will almost certainly fail to achieve its immediate objectives; but it may open the door to serious progress afterwards.
The ostensible purpose of the summit is to make those changes in the European Union’s decision-making machinery that would enable it to cope with the admission of at least 12 new members, mainly from Central and Eastern Europe.
Everyone knows that these changes ought to be radical, even semi-federal.
At the very least, the coming enlargement will call for much more majority voting in the Council of Ministers, if the Union is not be paralyzed by 27 member states and 27 national vetoes.
But most member states are unwilling to contemplate anything that far-reaching.
The host French, who currently hold the EU Presidency, have listed 50 policy areas where majority voting might be possible.
Every country, however, has special sensitivities: the Germans are unwilling to be outvoted on immigration; the French are unwilling to be outvoted on trade in services; the British are unwilling to be outvoted on taxation.
The cumulative result of all these national objections, is that the Nice summit is likely to see only a modest increase in the potential for majority voting, much smaller than enlargement requires.
A similar reluctance will dominate the rest of the immediate institutional agenda.
In principle, the Commission ought to be slimmed down after enlargement, with fewer Commissioners than member states.
Equally, big member states ought to have more votes in the Council of Ministers, to reflect their greater populations.
Small member states do not like either proposition, because they would lose Commissioners and votes.
On both issues, expect a serious tug-of-war, and any decisions are likely to be half-hearted, or in practice postponed.
Yet, the 15 member states may compensate for their collective failure of nerve by opening up easier options for flexible or multi-speed integration.
This might be a way round the majority voting dilemma, since it would allow groups of member states to cooperate together in particular areas, without waiting for the unanimous agreement of all partners.
Whether this would really be a desirable procedure is hotly debated; but the fact is that multi-speed integration already exists in the sense that Britain and Denmark are not now, and may never be, members of the euro.
If these scraps were to be the sum total of the Nice summit, it will prove unsatisfactory, even a failure.
But the real significance of the meeting may turn out to be, not the limited decisions which the heads of government are able and willing to take this time round, but the opening up, virtually for the first time, of serious discussion about the future direction of the European Union.
One thing that will happen at Nice will be the formal adoption of a Charter of Fundamental Rights.
In its present form, this document recapitulates all kinds of rights which EU citizens already enjoy under existing laws; it is not intended to confer any new rights, and it cannot be enforced in the European Court of Justice.
In other words, it is a public relations conjuring trick, designed to make the EU seem more attractive, without actually conferring any real benefits.
Even as a conjuring trick, the Charter could be influential.
For example, Article 2 reads: “Everyone has the right to life.
No one shall be condemned to the death penalty, or executed.” It seems evident that this principle will be effectively binding on all member states, and all candidates for membership.
The question at Nice will be whether the Charter should be incorporated into the EU Treaties, and thus given the force of law.
Another similar question at Nice will be whether the time has come to simplify the EU Treaties, which are now a confusing jumble of general principles and difficult detail.
Simplification might be intended, at the start, as another conjuring trick: to make the Treaties more comprehensible to voters without changing anything in law.
But it could also become the first, essential step on the road to the drafting of a European constitution.
WASHINGTON, DC – Leaders around the world are vigorously debating the advisability of establishing a no-fly zone to stop the violence unfolding in Libya.
Some cite Bosnia, where NATO took too long to protect civilian populations in the mid-1990’s, as a reason to act.
Others remember Rwanda, where President Bill Clinton later expressed regret for not acting to save innocent lives.
But the stakes in Libya today are more appropriately underscored by the tragedy in southern Iraq in the waning days of the Persian Gulf War 20 years ago.
As coalition forces were routing the Iraqi army in February 1991, President George H.W. Bush encouraged the Iraqi people to “take matters into their hands to force Saddam Hussein the dictator to step aside.”
When Iraqi Shiites, Kurds, and Marsh Arabs rebelled against Hussein, they believed that American forces would protect them against their brutal dictator’s superior firepower.
Instead, when Iraqi attack helicopters and elite troops began butchering their own people, coalition forces were ordered to stand down.
The world watched as thousands of Iraqis were slaughtered.
The situation in Libya today is not identical.
Inspired by events in Tunisia and Egypt, the Libyan people rose up spontaneously against four decades of repression by Col. Muammar el-Qaddafi.
Still, the specter that haunts me is the same – ordinary people facing off against an autocrat’s airpower and well-armed soldiers, counting on the free world to protect them against massacre after we have applauded and bolstered their bravery with our words.
So far, Qaddafi’s forces have relied on airpower selectively.
But Qaddafi is shrewd.
My fear is that he is either choosing to bleed the opposition to death, rather than invite global action with a broad massacre, or waiting for the world to prove itself unwilling to act – at which point he might well begin killing civilians in large numbers.
We cannot wait for that to happen.
We need to take concrete steps now so that we are prepared to implement a no-fly zone immediately if Qaddafi starts using his airpower to kill large numbers of civilians.
Diplomacy is urgently needed to build broad support for a no-fly zone.
The most important imprimatur should come from the United Nations, where debate should begin immediately over a resolution authorizing a no-fly zone.
China and Russia have expressed reservations.
If the Security Council fails to authorize action, those of us determined to protect Libyan civilians will face a more difficult choice should the violence escalate.
So our diplomatic efforts must extend beyond the UN.
The support of NATO and the African Union are important.
To avoid the perception of NATO or the US attacking another Muslim country, the backing of the Arab world is also needed.
On that front, there are promising signs.
The six Arab countries of the Gulf Cooperation Council have called for a UN-imposed no-fly zone.
The Arab League has endorsed a similar proposal.
Muslim countries in particular should support preparations for intervention if the violence spirals out of control.
Qaddafi cannot be allowed to think that he can massacre his people with impunity. And he cannot be free to make those attacks more lethal by using his airpower.
If the UN cannot approve a resolution for implementing a no-fly zone, then the US and its allies in NATO and the Arab world must be prepared to prevent a massacre like the one that occurred in Srebrenica in 1995, when more than 8,000 Bosnian men and boys were slaughtered.
Of course, imposing a no-fly zone would not be a panacea.
It probably would not tip the balance if the situation in Libya deteriorates into a full-scale civil war.
But a no-fly zone would eliminate airstrikes and save civilian lives.
It is a tool that we should be ready to use if the situation warrants it, and it would signal to the opposition that it is not alone.
Before that decision is reached, the international community needs to provide humanitarian assistance and medical supplies to the rebels in eastern Libya.
We must not allow them to be starved into submission.
The one option that should not be on the table is US ground troops; no one wants to see US forces bogged down in another war, especially in another Muslim country.
And, as President Barack Obama has said, the Libyan people must not be deprived of full ownership of their struggle for freedom, and Qaddafi must not be given a useful foil and scapegoat.
Perhaps the mere threat of a no-fly zone will keep Qaddafi’s pilots from using their helicopters and fighter jets to kill their own people.
If it does not, we should make clear that we will lead the free world to avoid the senseless slaughter of any more Libyan citizens by a madman bent on maintaining power.
The US and the world community should also make clear – as we did in Bosnia and Kosovo – that we are taking a united stand against a thug who is killing Muslims.
LONDON – Earlier this week, a group of almost 100 prominent Europeans delivered an open letter to the leaders of all 17 eurozone countries.
The letter said, in so many words, what the leaders of Europe now appear to have understood: they cannot go on “kicking the can down the road.”
And, just as importantly, they now understand that it is not enough to ensure that governments can finance their debt at reasonable interest rates; they must also address the weakness of Europe’s banking system.
Indeed, Europe’s banking and sovereign-debt problems are mutually self-reinforcing.
The decline in government bond prices has exposed the banks’ undercapitalization, while the prospect that governments will have to finance banks’ recapitalization has driven up risk premiums on government bonds.
Facing the prospect of having to raise additional capital at a time when their shares are selling at a fraction of book value, banks have a powerful incentive to reduce their balance sheets by withdrawing credit lines and shrinking their loan portfolios.
Europe’s leaders are now contemplating what to do, and their next move will have fateful consequences, either calming the markets or driving them to new extremes.
All agree that Greece needs an orderly restructuring, because a disorderly default could cause a eurozone meltdown.
But, when it comes to the banks, I am afraid that the eurozone’s leaders are contemplating some inappropriate steps.
Specifically, they are talking about recapitalizing the banking system, rather than guaranteeing it.
And they want to do it on a country-by-country basis, rather than on the basis of the eurozone as a whole.
There is a good reason for this: Germany does not want to pay for recapitalizing French banks.
But, while Chancellor Angela Merkel is justified in insisting on this, it is driving her in the wrong direction.
Let me stake out more precisely the narrow path that would allow Europe to pass through this minefield.
The banking system needs to be guaranteed first, and recapitalized later.
Governments cannot afford to recapitalize the banks now; it would leave them with insufficient funds to deal with the sovereign-debt problem.
It will cost much less to recapitalize the banks after the crisis has abated and both government bonds and bank shares have returned to more normal levels.
Governments can, however, provide a credible guarantee, given their power to tax.
A new, legally binding agreement – not a change to the Lisbon Treaty (which would encounter too many hurdles), but a new agreement – will be needed for the eurozone to mobilize that power, and such an accord will take time to negotiate and ratify. But, in the meantime, governments can call upon the European Central Bank, which the eurozone member states already fully guarantee on a pro rata basis.
In exchange for a guarantee, the eurozone’s major banks would have to agree to abide by the ECB’s instructions.
This is a radical step, but a necessary one under the circumstances.
Acting at the behest of the member states, the ECB has sufficient powers of persuasion: it could close its discount window to the banks, and the governments could seize institutions that refuse to cooperate.
The ECB would then instruct the banks to maintain their credit lines and loan portfolios while strictly monitoring the risks they take for their own account.
This would remove one of the two main driving forces of the current market turmoil.
The ECB could deal with the other driving force, the lack of financing for sovereign debt, by lowering its discount rate, encouraging distressed governments to issue treasury bills, and encouraging the banks to subscribe (an idea I owe to Tommaso Padoa-Schioppa).
The T-bills could be sold to the ECB at any time, making them tantamount to cash; but, as long as they yield more than deposits with the ECB, the banks would find it advantageous to hold them.
Governments could meet their financing needs within agreed limits at very low cost during this emergency period, and the ECB would not violate Article 123 of the Lisbon Treaty.
These measures would be sufficient to calm markets and bring the acute phase of the crisis to an end.
Recapitalization of the banks should wait until then; only the holes created by restructuring the Greek debt would have to be filled immediately.
In conformity with Germany’s demand, the additional capital would come first from the market and then from individual governments – and from the European Financial Stability Facility only as a last resort, thereby preserving the EFSF’s firepower.
A new agreement for the eurozone, negotiated in a calmer atmosphere, should not only codify the practices established during the emergency, but also lay the groundwork for an economic-growth strategy.
During the emergency period, fiscal retrenchment and austerity are unavoidable; but, in the longer term, the debt burden will become unsustainable without growth – and so will the European Union itself.
PRAGUE – The global financial crisis may be grabbing all the headlines, but resolving it should not be allowed to crowd out other vital issues.
In the Middle East, for example, Israelis and Palestinians – as well as many others around the world – are beginning to believe that the permanent status negotiations to determine the future of Palestine are going nowhere.
The situation may be more promising than it appears, but one cannot deny that hope for real changes on the ground has faded since talks were re-launched two years ago.
This loss of faith is, sadly, establishing a dynamic that will itself inhibit the concessions that are needed if a permanent agreement is to be found.
Because an impasse beckons, it is vitally important to work on those areas where intensive negotiations have the potential to produce quick results.
Fresh water is one such area.
Across the Middle East, water is a security issue.
Indeed, people are now recognizing two important facts.
First, nations faced with conflicting claims to water have historically found ways to collaborate rather than to fight.
Even during the 60 years of conflict in the Jordan Valley, water has more often been a source of cooperation than of conflict.
Second, water scarcity is seldom absolute, and even less often an explanation of poverty.
To quote the United Nations Human Development Report for 2006: “There is more than enough water in the world for domestic purposes, for agriculture and for industry….Scarcity is manufactured through political processes and institutions that disadvantage the poor.”
But almost every nation in the Middle East is using more water than arrives on a renewable basis.
There simply is not enough water for everything these nations want to use it for, and the situation will only worsen.
Yet, even in Palestine, the key water issue is not thirst, but arrested economic development.
In the short term, Palestine needs more water to provide employment and income from farming; in the longer term, educational, cultural, and political changes are needed in order to develop a capacity to adapt.
The region’s climate and geography mean that water resources are unavoidably shared.
But only if water is shared in a rational manner that respects the region’s fragile ecology will human life be sustainable.
Clearly, no final agreement on water will be possible until there are agreed-upon borders between the State of Israel and the State of Palestine, and some resolution of the Israeli settlements in the West Bank.
But interim resolution of water issues does not need to wait for final resolution of the major issues.
Finding rational ways to share and co-manage water may be easier than solving the “big” issues.
In fact, water could help to create a climate of success that aids progress in other areas.
The good news is that the quantity of water that is needed for drinking, cooking, other household chores and sanitation is small.
Most water is used to grow food, so, if a nation’s economy is healthy, there is scope for saving water by importing a greater share of food, although every nation will want to maintain some assured food supply for security reasons.
The bad news is that water, unlike land, cannot simply be divided.
Water flows on the surface and underground.
As it moves, it changes in quantity and quality, and it supports different ecosystems.
Moreover, demand for water changes over time.
Only a few percentage points of the Israeli GNP come from agriculture today; as a result, its economy requires less water than it once did.
Exactly the same transition is likely to occur in Palestine, but it has not happened yet.
Few Israelis deny that Palestinians need more water.
Similarly, there is wide agreement that some water currently used by Israelis will have to be allocated to Palestinian use.
The current negotiations will inevitably deal with rights to water, which do not seem to be very contentious anymore, and the talks can suggest various mechanisms for transfer of management in some cases and for shared management in others.
These are eminently negotiable issues.
A flexible and sustainable formula can certainly be found, almost surely including a transitional period that allows both sides to adjust to and account for their different water management systems, as well as for changing conditions and institutions in the future.
The principle of a just division of water resources to meet the Palestinians’ urgent needs for additional water should be taken as a starting point.
Everything else can be worked out.
Shared water calls for flexible, continuous, cooperative water management, based on agreed-upon rights and responsibilities, as well as ongoing monitoring and dispute resolution mechanisms.
One important point should be added: extensive public participation and transparency, in terms of both process and outcomes, will be key to successful management.
We believe that progress in the peace process and in finding solutions for water issues between Israel and Palestine would also help to unblock progress in the broader region, between the parties on the Jordan, the Orontes, the Tigris, and the Euphrates rivers.
Water can be a catalyst for regional cooperation, opening the way to a future comprehensive “Community of Water and Energy” to enhance the human environment.
In such a forum, water and solar energy in tandem could help to move the Middle East from conflict to collaboration.
The cost of inaction or merely pretending to act is likely to be high for everyone in the Middle East.
Future water policy should no longer be seen as an extension of current policy, but rather as a new opportunity.
Water is the essence of life.
People in Palestine and in Israel need it; people in the region need it.
Cooperating to secure it is the only way forward.
NEW HAVEN – We are in the midst of a boom in popular economics: books, articles, blogs, public lectures, all followed closely by the general public.
I recently participated in a panel discussion of this phenomenon at the American Economic Association annual meeting in Denver.
An apparent paradox emerged from the discussion: the boom in popular economics comes at a time when the general public seems to have lost faith in professional economists, because almost all of us failed to predict, or even warn of, the current economic crisis, the biggest since the Great Depression.
So, why is the public buying more books by professional economists?
The most interesting explanation I heard was that economics has become more interesting, because it no longer seems to be a finished and closed discipline.
It is no fun to read a book or article that says that economic forecasting is best left to computer models that you, the general reader, would need a Ph.D. to understand.
And, in truth, the public is right: while there is a somewhat scientific basis for these models, they can go spectacularly wrong.
Sometimes we need to turn off autopilot and think for ourselves, and when a crisis occurs, use our best human intellect.
The panelists all said, in one way or another, that popular economics facilitates an exchange between specialized economists and the broader public – a dialogue that has never been more important.
After all, most economists did not see this crisis coming in part because they had removed themselves from what real-world people were doing and thinking.
Successful popular economics involves the reader or listener, in some sense, as a collaborator.
That, of course, means that economists must be willing to include new and original theories that are not yet received doctrine among professional specialists.
Until recently, many professional economists would be reluctant to write a popular book.
Certainly, it would not be viewed favorably in considering a candidate for tenure or a promotion.
Since it does not include equations or statistical tables, they would argue, it is not serious work that is worthy of scholarly attention.
Worse than that, at least until recently, a committee evaluating an economist would likely think that writing a popular economics book that does not repeat the received wisdom of the discipline might even be professionally unethical.
Imagine how the medical profession would view one of its members who recommended to the general public some therapy that had not yet passed scrutiny from the appropriate authorities.
Medical professionals know how often seemingly promising new therapies turn out, after careful study, not to work, or even to be harmful.
There is a rigorous process of scholarly review of proposed new therapies, associated with professional journals that uphold high research standards.
Circumventing that process and promoting new, untested ideas to the general public is unprofessional.
In the decades prior to the current financial crisis, economists gradually came to view themselves and their profession in the same way, encouraged by research trends.
For example, after 1960, when the University of Chicago started creating a Univac computer tape that contained systematic information about millions of stock prices, a great deal of scientific research on the properties of stock prices was taken as confirming the “efficient markets hypothesis.”
The competitive forces that underlie stock exchanges were seen to force all securities prices to their true fundamental values.
All trading schemes not based on this hypothesis were labeled as either misguided or outright frauds.
Science had triumphed over stock-market punditry – or so it seemed.
The financial crisis delivered a fatal blow to that overconfidence in scientific economics.
It is not just that the profession didn’t forecast the crisis.
Their models, taken literally, sometimes suggested that a crisis of this magnitude couldn’t happen.
One way to interpret this is that the economics profession was not fully accounting for the economy’s human element, an element that can’t be reduced to mathematical analysis.
The relatively few professional economists who warned of the current crisis were people, it seems, who not only read the scholarly economics literature, but also brought into play more personal judgment: intuitive comparisons with past historical episodes; conclusions about speculative trading, price bubbles, and the stability of confidence; evaluations of the moral purposes of economic actors; and impressions that complacency had set in, lulling watchdogs to sleep.
These were judgments made by economists who were familiar with our business leadership – their inspirations, beliefs, subterfuges, and rationalizations.
Their views could never be submitted to a scholarly journal and evaluated the way a new medical procedure is.
There is no established scientific procedure that could prove their validity.
Of course, economics is in many ways a science, and the work of our scholars and their computer models really does matter.
But, as the economist Edwin R. A. Seligman put it in 1889, “Economics is a social science, i.e., it is an ethical and therefore an historical science….It is not a natural science, and therefore not an exact or purely abstract science.”
To me, and no doubt to the other panelists, part of the process of pursuing the inexact aspects of economics is speaking honestly to the broader public, looking them in the eye, learning from them, reading the emails they send, and then searching one’s soul to decide whether one’s favored theory is really close to the truth.
NEW YORK – Where is the American and global economy headed?
Last year, there were two sides to the debate.
One camp argued that the recession in the United States would be V-shaped – short and shallow.
It would last only eight months, like the two previous recessions of 1990-1991 and 2001, and the world would decouple from the US contraction.
Others, including me, argued that, given the excesses of private-sector leverage (in households, financial institutions, and corporate firms), this would be a U-shaped recession – long and deep.
It would last about 24 months, and the world would not decouple from the US contraction.
Today, 20 months into the US recession – a recession that became global in the summer of 2008 with a massive re-coupling – the V-shaped decoupling view is out the window.
This is the worst US and global recession in 60 years.
If the US recession were – as most likely - to be over at the end of the year, as is likely, it will have been three times as long and about fives times as deep – in term of the cumulative decline in output – as the previous two.
Today’s consensus among economists is that the recession is already over, that the US and global economy will rapidly return to growth, and that there is no risk of a relapse.
Unfortunately, this new consensus could be as wrong now as the defenders of the V-shaped scenario were for the past three years.
Data from the US – rising unemployment, falling household consumption, still declining industrial production, and a weak housing market – suggest that America’s recession is not over yet.
A similar analysis of many other advanced economies suggests that, as in the US, the bottom is quite close but it has not yet been reached.
Most emerging economies may be returning to growth, but they are performing well below their potential.
Moreover, for a number of reasons, growth in the advanced economies is likely to remain anemic and well below trend for at least a couple of years.
The first reason is likely to create a long-term drag on growth: households need to deleverage and save more, which will constrain consumption for years.
Second, the financial system – both banks and non-bank institutions – is severely damaged.
Lack of robust credit growth will hamper private consumption and investment spending.
Third, the corporate sector faces a glut of capacity, and a weak recovery of profitability is likely if growth is anemic and deflationary pressures still persist.
As a result, businesses are not likely to increase capital spending.
Fourth, the re-leveraging of the public sector through large fiscal deficits and debt accumulation risks crowding out a recovery in private-sector spending.
The effects of the policy stimulus, moreover, will fizzle out by early next year, requiring greater private demand to support continued growth.
Domestic private demand, especially consumption, is now weak or falling in over-spending countries (the US, the United Kingdom, Spain, Ireland, Australia, New Zealand, etc.), while not increasing fast enough in over-saving countries (China, Asia, Germany, Japan, etc.) to compensate for the reduction in these countries’ net exports.
Thus, there is a global slackening of aggregate demand relative to the glut of supply capacity, which will impede a robust global economic recovery.
There are also now two reasons to fear a double-dip recession.
First, the exit strategy from monetary and fiscal easing could be botched, because policymakers are damned if they do and damned if they don’t.
If they take their fiscal deficits (and a potential monetization of these deficits) seriously and raise taxes, reduce spending, and mop up excess liquidity, they could undermine the already weak recovery.
But if they maintain large budget deficits and continue to monetize them, at some point – after the current deflationary forces become more subdued – bond markets will revolt.
At this point, inflationary expectations will increase, long-term government bond yields will rise, and the recovery will be crowded out.
A second reason to fear a double-dip recession concerns the fact that oil, energy, and food prices may be rising faster than economic fundamentals warrant, and could be driven higher by the wall of liquidity chasing assets, as well as by speculative demand.
Last year, oil at $145 a barrel was a tipping point for the global economy, as it created a major income shock for the US, Europe, Japan, China, India, and other oil-importing economies.
The global economy, barely rising from its knees, could not withstand the contractionary shock if similar speculative forces were to drive oil rapidly towards $100 a barrel.
So the end of this severe global recession will be closer at the end of this year than it is now, the recovery will be anemic rather than robust in advanced economies, and there is a rising risk of a double-dip recession.
The recent market rallies in stocks, commodities, and credit may have gotten ahead of the improvement in the real economy.
If so, a correction cannot be too far behind.
LONDON – The Greek debt problem has been poorly handled by Europe’s decision-makers.
European Union heads of government, and the European Central Bank, initially rejected the idea of involving the International Monetary Fund, but without a fall-back plan. It is hard to avoid the conclusion that part of the motivation for this was French President Nicolas Sarkozy’s reluctance to see Dominique Strauss-Kahn, the IMF’s managing director, ride in from Washington to the rescue of the eurozone.
Strauss-Kahn is, of course, likely to be Sarkozy’s Socialist rival in the next French presidential election.
Is Greece the “canary in the coalmine” – the warning that tells us that Europe’s monetary union is on the verge of dissolution, with the other three of the famous PIGS (Portugal, Italy, and Spain) lining up like dominoes to fall? George Soros fears this might be the case, and gives the eurozone only a 50% chance of survival in its present form.
Certainly, the episode highlighted flaws in the way the euro’s governance – flaws that are no surprise to some of those involved in creating the common currency.
Helmut Kohl, one of the euro’s principal parents, said in 1991 that “the idea of sustaining an economic and monetary union over time without political union is a fallacy.” Margaret Thatcher, from the opposite camp, said in her memoirs: “I believe the European single currency is bound to fail, economically, politically and indeed socially, although the timing, occasion and consequences are all still unclear.”
There may now be a market for a Greek translation of her book.
Although they might not agree with either of these two apocalyptic predictions, many of Europe’s leaders are coming round to the view that there is a need for change, and that the Greek case has revealed a flaw at the center of the project. Sarkozy, for example, has revived a long-standing French argument for some form of economic government in Europe as a counterweight to the ECB.
The French usually advance this proposal to get some purchase on the ECB’s monetary decisions, which they sometimes consider hostile to growth and employment, or in order to prevent other countries from maintaining unfair tax policies (“unfair” usually being defined as a tax rate lower than the relevant French one).
In the past, the Germans brushed these arguments aside, but now they are a little more receptive. German Finance Minister Wolfgang Schäuble, however, focuses on the issue of distressed members, and has advanced a proposal for a European Monetary Fund to provide assistance to countries in Greek-style difficulties, roughly on the IMF model.
This idea has logic behind it. The drawback is that it would require a change in the European treaties, which in turn requires a unanimous decision by 27 countries, and positive votes in referendums in some of them, including the United Kingdom if David Cameron’s Conservatives win the upcoming general election there.
In the aftermath of the negative referendum votes in France, the Netherlands, and Ireland on European constitutional reform, it is close to inconceivable that EU heads of government would agree to set off down that path again. Certainly nothing could be achieved on a timetable that would offer any comfort to the other PIGS.
They would all be bacon and sausages before any agreement was reached.
So, in the short run, the IMF will have to be used, if that kind of support is needed, and Sarkozy will have to swallow his pride.
But is an EMF really what is required in the long run?
I think not.
Nor do I think that a European economic government is strictly necessary. What is needed, though, is a collective agreement on fiscal discipline, and a revival of the Stability and Growth Pact, which was unwisely abandoned – ironically when the French and Germans found its rules too constraining.
Europe’s leaders should refer to a paper by Otmar Issing, “The Euro – A Currency Without a State,” published in December 2008, before the debt crisis erupted. Issing, the ECB’s chief economist in its formative years, knows more about how a monetary union operates in practice than any man alive.
He maintains that “the Stability and Growth Pact contains all the rules that are necessary for Monetary Union to function.
There is no need for coordination of macroeconomic policies to go any further than this.”
Europe does not need the French plan for coordination of tax policies, or another IMF, but there does need to be fiscal discipline to prevent other countries from free riding, as the Greeks seem to have done. They apparently assumed that the rest of Europe would overlook continuing high deficits, and that, as eurozone members, the market would consider their debt to be just like German bunds, though issued by friendly and welcoming people in an agreeable climate, and with a glass of ouzo on the side.
The original Pact envisaged a 3%-of-GDP cap on fiscal deficits, save in exceptional circumstances.
Investors well understand that we are in such circumstances now, so it will take some time to get back to that level. But that should be the clear aim, with IMF assistance along the way to provide interim funding where necessary and political cover for governments obliged to take tough decisions on public spending and taxation.
Fiscal discipline does not sound as visionary as “economic government.”
But the EU has suffered from a surfeit of “vision” and a deficit of practical budgetary measures. It is time to redress that balance, or Soros’s gloomy prognosis may become reality.
PRINCETON – On February 1, the United Nations Security Council met to consider the Arab League’s proposal to end the violence in Syria.
Secretary of State Hillary Clinton represented the United States.
Midway through her remarks, she began speaking not to the Syrian ambassador, who was in the room, or even the Syrian government, but directly to the Syrian people.
She said that change in Syria would require Syrians of every faith and ethnicity to work together, protecting and respecting the rights of minorities.
Addressing those minorities, she continued: “We do hear your fears, and we do honor your aspirations. Do not let the current regime exploit them to extend this crisis.”
She told Syria’s business, military, and other leaders that they must recognize that their futures lie with the state, not with the regime. “Syria belongs to its 23 million citizens, not to one man or his family.”
Speaking directly to citizens – seeing a country’s people, as well as its government – is not just a rhetorical device.
While many foreign-policy pundits have focused on the US “pivot to Asia,” Clinton has also executed a less-publicized, but no less important, pivot to the people.
She has introduced policies, programs, and institutional reforms designed to support government-to-society and society-to-society diplomacy, alongside traditional government-to-government relations.
These initiatives do not get headlines, but they will gradually transform much of American foreign policy.
In January, the State Department unveiled a new “super-office” of Civilian Security, Democracy, and Human Rights, under the leadership of Under-Secretary Maria Otero.
The office brings together agencies that focus on international law enforcement, counter-terrorism, and reconstruction and stabilization with those charged with advancing democracy, human rights, and humanitarian assistance to refugees and migrants.
Otero explains the logic behind the initiative in terms of “protecting individuals.”
That, in turn, requires “not just engaging state to state,” but also working “with players and actors outside of the traditional [channels] we’ve engaged in.”
Viewed from this perspective, countering terrorism includes rebutting terrorist propaganda with a strategic communications campaign.
Countering narco-gang violence includes working with Mexican telecommunications mogul Carlos Slim to develop tools that allow ordinary citizens to report violence anonymously by text message and enable police to map the results.
Strengthening democracy means working with the Kenyan developers of a crisis-mapping platform that allows anyone with a cell phone to text information about election fraud or violence to a central monitoring station.
On a country-by-country basis, pivoting to the people means engaging with Egypt’s bloggers as well as with the ruling Supreme Council of the Armed Forces; convening young entrepreneurs in Tunisia, Algeria, and Morocco and connecting them to funding and mentoring; and using social media in Russia to rebut government efforts to smear the US ambassador.
And, working at an official level, it means co-sponsoring with Brazil the Open Government Partnership, which brings together governments committed to increasing transparency, accountability, and citizen participation, and uses mutual peer pressure and open reporting to hold them to their commitments.
Thinking about countries in these comprehensive terms also provides a different strategic perspective.
Clinton has created a raft of new positions at the State Department to spur outreach to different social segments.
The strategies and programs developed by the Ambassador for Global Women’s Issues, the Special Adviser for Global Youth Issues, the Senior Adviser for Civil Society and Emerging Democracies, the Special Representative for Outreach to Muslim Communities, the Special Representative for Global Partnerships, and the Special Representative for Commercial and Business Affairs often present a very different face of the US.
As a result, Clinton has launched an actual strategic dialogue with civil society.
For example, Ambassador Melanne Verveer has attended more than 1,000 events around the world focused on empowering women in areas ranging from peace negotiations to farming.
Similarly, she has launched programs such as mWomen, designed to expand and support mobile technology that increases women’s independence, security, and access to health care and vital knowledge.
The Office of Global Youth Affairs is building a local youth council at every US embassy around the world, to advise and help to implement embassy programming aimed at local youth.
Much of the programming aimed at youth, women, entrepreneurs, diasporas, technologists, and other social groups is partly funded and conducted by the private sector.
Indeed, the Obama administration’s National Security Strategy mentions “public-private partnerships” more than 30 times.
Clinton created the Global Partnership Initiative to build as many coalitions, networks, and partnerships as possible with corporations, foundations, NGOs, universities, and other civic organizations.
Here, the pivot to the people includes the American people: the dynamism, creativity, and resources of American business and non-profit organizations already engaged around the world.
One privately-funded initiative spearheaded by the State Department will send 300 dogwood trees to Japan this spring, to be planted in the tsunami-affected region and in Tokyo to express the American people’s support for the Japanese people; another will send English teachers throughout Southeast Asia.
After participating in the Friends of Syria conference in Tunis, Clinton convened a town hall meeting with Tunisian youth.
In her opening remarks, she told her audience that “young people are at the heart of today’s great strategic opportunities and challenges.”
Speaking about her lifetime efforts to put “women’s empowerment on the international agenda,” she added, “It’s time to put youth empowerment there as well.”
The implications of all of this activity, which Clinton calls “twenty-first-century statecraft,” are profound.
From now on, US diplomatic relations with other countries will engage directly with their people and connect them to the American people as much as possible.
From the perspective of US diplomats, the people of every country stand on the same footing as their government.
That assumption is the heart of democracy; it is a revolution for diplomacy.
MELBOURNE – Two new movies released this month – one a science-fiction blockbuster, the other a revealing documentary – raise the issue of our relations with our closest non-human relatives, the great apes.
Both dramatize insights and lessons that should not be ignored.
Rupert Wyatt’s Rise of the Planet of the Apes is the seventh film in a series based on Pierre Boule’s 1963 novel, Planet of the Apes, about a world populated by highly intelligent simians.
Publicity for the new film claims that it is “the first live-action film in the history of movies to star, and be told from the point of view of, a sentient animal.”
Yet no live apes were used.
Instead, “performance capture technology,” originally invented for the movie Avatar, enables a human actor, Andy Serkis, to play the role of the chimpanzee Caesar, not by dressing in a chimp suit, but by having every gesture and facial movement, even the twitch of an eyebrow, transformed into the movement of an ape.
When I spoke with Wyatt last month, he acknowledged that there were practical reasons for not using real apes in his movie. But he also understood the ethical issue.
“There are things I didn’t want to be involved in,” he told me. “To get apes to do anything you want them to do, you have to dominate them; you have to manipulate them into performing.
That’s exploitative.”
Wyatt’s reluctance to join in the exploitation of great apes is understandable, given that the film itself tells the story of apes rising up in response to oppression from dominant humans.
The central human character, Will Rodman (played by James Franco), is a scientist seeking a cure for Alzheimer’s disease who experiments on apes.
Many films would have glorified a scientist seeking such a goal, and treated the use of animals for that purpose as obviously justified.
Rise of the Planet of the Apes, however, portrays Rodman as, in Franco’s words, “a cold, isolated person.”
Only when Rodman’s superiors cancel his experiments and he takes home Caesar, an infant chimpanzee, does the scientist begin to care about others.
The plot then takes another turn when Caesar becomes too big and aggressive to live in a human home, and is taken to what is supposed to be a primate sanctuary, but is in fact a dumping ground for unwanted apes, run by humans who display cruelty to the captive animals.
As far as the treatment of apes is concerned, much of the film is firmly grounded in reality, as a viewing of Project Nim, a documentary based on Elizabeth Hess’s book Nim Chimpsky: The Chimp Who Would be Human, clearly demonstrates.
Nim was born in 1973, in a primate research facility in Oklahoma, and was taken from his mother when he was only ten days old, to be used in a sign-language experiment.
Reared as part of a human family, he learned to use more than 100 signs from American Sign Language, the language used by Deaf Americans.
But he was taken from his first human family and handed over to other teachers with whom he did not have the same kind of bond.
He grew stronger and more aggressive and began biting his teachers.
Herbert Terrace, the Columbia University psychologist who was directing the project, decided to end it and sent Nim back to the primate facility in Oklahoma.
There, the pampered chimpanzee – who, when asked to sort photos of humans and apes, put his own photo among the humans – was locked in a cage with other chimps.
He demonstrated his view of that situation by signing “out” to passing humans.
Nim suffered various other vicissitudes – and narrowly escaped being infected with hepatitis as part of a medical experiment – until he was eventually released to an animal sanctuary, where he died in 2000.
In 1993, Paola Cavalieri and I founded The Great Ape Project, an organization dedicated to the idea of recognizing that great apes have a moral status befitting their nature as self-aware beings who are capable of thought and have rich and deep emotional lives.
At a minimum, they should have the rights to life, liberty, and protection from torture that we grant to all members of our own species, regardless of their intellectual abilities.
In the intervening years, that idea has made steady progress.
Since 2010, the European Union has essentially banned the use of great apes in experiments.
Experiments on great apes are now either banned or severely restricted in New Zealand, Australia, and Japan.
In the United States, a bipartisan group of members of Congress is supporting legislation to end the use of chimpanzees in invasive research.
In Spain in 2008, a parliamentary resolution urged the government to grant some basic legal rights to great apes, but the Spanish government has yet to implement it.
Perhaps the release of these two very different films will lead to a further push to bring great apes within the circle of beings with moral and legal rights.
In that way, our closest relatives could serve to bridge the moral gulf that we have dug between ourselves and other animals.
NEW YORK – In a way, the stir aroused by the decision by the International Criminal Court (ICC) to indict Sudan’s President Omar al-Bashir for war crimes and crimes against humanity in Darfur is a surprise.
After all, the Court has no means of its own to arrest anyone in Sudan, much less a head of state who commands the country’s armed forces.
Nor is there any prospect that someone else will intervene in Sudan to make an arrest.
While the ICC’s chief prosecutor, Luis Moreno-Ocampo, expresses confidence that Bashir will be brought to justice, it is unclear how this will happen.
But it could.
Despite the ICC’s seeming powerlessness, many governments’ leaders are engaged in strenuous efforts to block the indictment.
They do not seem concerned that the charges are unfair; rather, they appear to be demonstrating solidarity with a fellow head of state. 
Those denouncing the attempt to put Bashir on trial include the large blocs of countries that are members of the Organization of the Islamic Conference and the African Union, together with such powerful states as China and Russia.
One can only guess whether some of those joining this effort are motivated by concern that they themselves may some day face charges like those leveled at Bashir by the ICC judges.
Though Bashir may be able to avoid arrest simply by limiting his international travel, the commotion provoked by the indictment is not irrational.
The charges against him have a powerful stigmatizing effect.
The fact that a panel of judges representing the 108 governments that are parties to the ICC has accused Bashir of principal responsibility for the crimes committed in Darfur during the past six years undermines the legitimacy of his continued rule.
Those crimes have caused more than 300,000 deaths, and have forcibly displaced at least another 2.7 million people.
Even if Bashir’s fellow heads of state succeed in their effort to persuade the United Nations Security Council to defer prosecution – which is highly unlikely – the charges will continue to hang over Bashir’s head unless and until he stands trial.
In 1999, an international criminal tribunal indicted another sitting head of state, Slobodan Milosevic of the Federal Republic of Yugoslavia.
Though he seemed secure at the time, a year and a half later he was sent to The Hague to stand trial.
Similarly, in 2003, an international criminal tribunal indicted Liberia’s then president, Charles Taylor.
He had to flee Liberia a few months later and initially received asylum in Nigeria, but is now on trial in The Hague.
When those indictments were issued, no one could have predicted how events would unfold; in retrospect, it is evident that the indictments’ delegitimizing effects had important consequences.
Of course, the ICC’s prosecutor and judges are themselves taking a substantial risk in the indictment of Bashir.
The Court is still in its infancy, and antagonizing the many government leaders expressing solidarity with him could jeopardize its future. 
Yet it should be recognized that the Court’s personnel are carrying out their duties.
The treaty establishing the ICC explicitly states that heads of state do not enjoy immunity.
And the Security Council referred the Darfur case to the Court in 2005.
This was an investigation that had to be conducted, and those found to have the highest level of responsibility for the crimes had to be indicted.
Many of those now objecting to the prosecution of Bashir participated in the decisions leading to the indictment.
If the ICC’s indictment now causes them discomfort, that is only because they did not anticipate that the Court would carry out the responsibilities that they themselves assigned to it.
A few times each year, the world is reminded that a pandemic threat is immanent.
In 2003, it was SARS.
Today, it is a potential avian virus similar to the one that killed 30 million people after 1914.
“Bird flu” has already shown that it can jump from fowl to humans, and now even to cats, which indicates that it might be the next global killer.
But there are many other potential pandemics, and many are not even viruses.
Bacteria, prions, parasites, and even environmental factors could suddenly change in a way that slays us.
It is widely predicted that when this happens, the economic and human losses will exceed that of any previous war.
Indeed, it is humbling to remember that some of history’s most deadly invasions were carried out by single-cell organisms, such as cholera, bubonic plague, and tuberculosis.
Countries with the resources to do so are making resistance plans against pandemics – limited strategies that would protect their own citizens.
Most governments are hoping that early detection will make containment possible.
Containment depends heavily on vaccines, but vaccines are only part of the answer.
While they are a good defense against many viruses, each vaccine is highly specific to the threat.
Viruses are parasites to cells, and each virus attacks a particular type of cell.
The virus is shaped so that it can drill into a particular feature of that cell and inject parts of itself inside, confusing the cell into making more viruses and destroying itself in the process.
With their very specific forms, the most effective anti-viral vaccines must be designed for a narrow range of factors.
Sometimes the tailored nature of viruses works in our favor.
For example, they usually find it difficult to jump between species, because they would have to change their structure.
But if large numbers of a host – say, birds – encounter a great number of people, eventually the virus will find a way to prosper in a new type of cell.
Birds are the greatest concern today only because the spread is easy to see.
But AIDS jumped from monkeys and several types of flu jumped from swine.
Deadly mutations of any kind need to be identified urgently, so that an effective vaccine can be designed before the strain becomes comfortable in the human body.
Unfortunately our present methods of detection are not sensitive enough.
This is even more worrying when you realize that scientists should also be monitoring bacteria, prions, and parasites.
There are more bacteria than any other life form.
Many live harmlessly in our bodies and perform useful functions.
They evolve and adapt easily, which means that they learn to sidestep our drugs over time.
Bacteria should be checked for two types of mutation: adaptation by a hostile form that enables it to become super-immune to drugs, or a deadly mutant strain that appears in one of the multitude of “safe” bacteria.
Prions are a relatively new discovery.
They are made from proteins similar to those that the body uses during healthy operations, which means that they are able to fool the body’s tools into making more prions.
They have only recently been recognized as the cause of several infectious diseases, including mad cow disease and Creutzfeldt-Jakob Disease, which kill by crowding out healthy brain cells.
Many nerve, respiratory and muscle diseases might also be caused by prions.
Finally, parasites, simple animals that infect us, are already classified as pandemics.
Malaria afflicts 300 million people and is the world’s biggest killer of children.
Many parasites are worms: hookworm (800 million people infected), roundworm (1.5 billion), schistosomes (200 million), and the worm that causes Elephantiasis (150 million).
There are also antagonists that are currently ignored.
Environmental chemicals and particulates might warrant their own categories.
Or consider combinations of problems, such as these chemical infectors mixing with airborne pollens, and apparently pushing up incidences of asthma.
New fungal infections are even scarier and might be harder to treat.
The bottom line is that we can’t predict where the threat will emerge, so we need a distributed, intelligent detection system.
In practical terms, how should it be built?
“Detectors” would have to be expert enough to know when an ordinary-looking symptom is actually an emergency.
They would be located everywhere, with an emphasis on vulnerable regions.
Initial warning signs of a pandemic are most likely to appear in the developing world, but detection nodes should be positioned in every country, with the least possible expense.
This is not as difficult as it sounds.
The key is to harness existing infrastructure.
Medical infrastructure exists everywhere, in some form.
It also tends to be the least corrupt of institutions in regions where that is a problem.
Medical centers and clinics would be expected to investigate the cause of ailments in a large number of their patients, even in cases where the symptoms seem common.
A small amount of additional scientific expertise and lab equipment would need to be added to a public health system that serves ordinary needs.
Enhancing existing resources would be effective for two reasons.
First, illness is more likely to be reported in a city hospital than at a specialist institute.
Second, the investment would boost latent public health in that region.
For poor regions, investment in equipment and training would have to come from wealthier counterparts.
Rich countries could justify the expense in terms of the savings that would result from early detection of a major threat.
Tropical climates and urban slums are humanity’s front line against pandemics, and they should be equipped properly.
Public health is an important asset for any nation.
With so much at stake, it makes sense to place sentinels near every swamp, city, public market, and farmyard on earth.
Can a public figure have a private life?
Recent events in three countries have highlighted the importance of this question.
In the French presidential election, both candidates tried to keep their domestic life separate from their campaign.
Ségolène Royal is not married to François Hollande, the father of her four children.
When asked whether they were a couple, Royal replied, “Our lives belong to us.” Similarly, in response to rumors that President-elect Nicholas Sarkozy’s wife had left him, a spokesman for Sarkozy said, “That’s a private matter.”
The French have a long tradition of respecting the privacy of their politicians’ personal lives, and French public opinion is more broad-minded than in the United States, where an unwed mother of four would have no chance of being nominated for the presidency by a major party.
Indeed, last month, Randall Tobias, the top foreign aid adviser in the US State Department, resigned after acknowledging that he had used an escort service described as providing “high-end erotic fantasy” – although Tobias said he only had a massage.
In Britain, Lord John Browne, the chief executive who transformed BP from a second-tier European oil company into a global giant, resigned after admitting he had lied in court about the circumstances in which he had met a gay companion (apparently, he met him through a male escort agency).
In resigning, he said that he had always regarded his sexuality as a personal matter, and he was disappointed that a newspaper – The Mail on Sunday – had made it public.
Candidates for public office, and those holding high administrative or corporate positions, should be judged on their policies and performance, not on private acts that are irrelevant to how well they carry out, or will carry out, their public duties.
Sometimes, of course, the two overlap. The Mail on Sunday and its sister paper, The Daily Mail, justified their publication of revelations by Browne’s former companion on the grounds that they include allegations that Browne had allowed him to use corporate resources for the benefit of his own private business.
The company denied that there was any substance to these allegations.
As the administrator of the US Agency for International Development, Tobias implemented the Bush administration’s policy that requires organizations working against HIV/AIDS to condemn prostitution if they are to be eligible for US assistance.
That policy has been criticized for making it more difficult to assist sex workers who are at high risk of contracting and spreading HIV/AIDS.
Arguably, the public has an interest in knowing if those who implement such policies are themselves paying for sexual services.
Where there is no suggestion that a matter of personal morality has had an impact on the performance of a business executive or government official, we should respect that person’s privacy.
But what about candidates for political leadership?
Since politicians ask us to entrust them with sweeping powers, it can be argued that we should know as much as possible about their morality.
For example, we might reasonably ask whether they pay their fair share of taxes, or inquire about their charitable donations.
Such things tell us something about their concern for the public good.
Similarly, the revelation three years ago that the then-Australian opposition leader and aspiring prime minister, Mark Latham, had assaulted a taxi driver and broken his arm in a dispute about a fare was relevant for those who believe that a nation’s leader should be slow to anger.
But does the legitimate interest in knowing more about a politician extend to details about personal relations?
It is hard to draw a line of principle around any area and determine if knowledge of it will provide relevant information about a politician’s moral character.
The problem is that the media have an interest in publishing information that increases their audience, and personal information, especially of a sexual nature, will often do just that.
Even so, whether people choose to marry or not, whether they are heterosexual or homosexual, even whether they pay to fulfill their erotic fantasies or have fantasies they can fulfill at no cost, tells us little about whether they are good people who can be trusted with high office – unless, of course, they say one thing while doing another.
If we can cultivate a wider tolerance of human diversity, politicians, business leaders, and administrators would be less fearful of “exposure,” because they would realize that they have done nothing that they must hide.
Prostitution is illegal in most of the US, including Washington DC, and this could be one reason why Tobias had to resign.
But when New Jersey Governor John Corzine was involved in a serious road accident last month, it became known that he violated his own state’s law by not wearing his seat belt.
By any sensible measure, Corzine’s violation of the law was more serious than that of Tobias.
Laws requiring the wearing of seatbelts save many lives.
Laws prohibiting prostitution do no evident good at all, and may well do harm.
Yet no one suggested that Corzine should resign because of his foolish and illegal act.
In the US, at least, breaching sexual norms still brings with it a moral opprobrium that is unrelated to any real harm it may do.
WARSAW: The thirteen days that Pope John Paul II spent in Poland this summer will probably be the last that he ever spends in his homeland.
What the Pope wanted to say to the Polish people, and what was understood by them appear, as the nostalgic haze of that journey fades, to have been two very different things.
Pope John Paul II began his pilgrimage in Gdansk, birthplace of Solidarity, with a remembrance mass for St. Adalbert, who introduced Poland to Catholicism some thousand years ago.
St. Adalbert's evangelism is often called the "baptism of Poland".
What the Pope sought, indeed, was nothing less than a re-baptism of our country.
In a way, he treated Poland – up to a point – as a pagan country.
His numerous sermons and speeches revealed his intention to restore Adalbert's spirit in Poland.
John Paul spoke constantly of the need for love, about the love of God, but also about love between people.
In an unprecedented visit to Poland's parliament -- indeed, his address to the Sejm was the first address to a democratic assembly John Paul II has given in the two decades of his papacy -- he even spoke about love between politicians, although he is clever enough to know that such a thing is practically impossible.
Our politicians were happy to hear that they should love each other, though when Pope left they started to quarrel about the meaning of love.
On the last day of his stay, the Pope invited the Polish President, a man with a long communist past, into the "papamobile", which also was totally unprecedented.
So, what was the meaning of the Pope's sermons and this behavior?
First, we can quote the sociologist Ralf Dahrendorf, who often says that democracy and free markets are cold things.
The Pope wanted to show that democracy can be warmed by love, or at least by the fact that real human beings participate in the making of democracy and in the free market.
What was very surprising, particularly given his finger-wagging visits to America and other rich democracies, was that the Pope did not criticize the Polish people for their robust materialism.
In a sense, John Paul II accepted Poland as it is with the hope that people will find more pleasure in democracy and in the free market when they love each other.
Secondly, the Pope recognized the most important problem of Poland and many other young democracies -- the collapse, in the face of material prosperity, of the sense of community.
Even the strongest and most important community in Poland, namely the national community, appears imperilled.
Individualism is of course a part of liberalism and Polish society is now a very liberal one, but some community feelings are necessary for free individuals to exist.
Without a sense of civic and political community, democracy becomes a hollow shell of itself, and can become dangerous as it is no longer controlled by rooted values.
But community cannot be created merely because of common interests.
As Alexis de Tocqueville taught us, community must be a community of values and of patterns of behaviour.
A community based on love need not be a society where people behave like angels.
What the Pope envisioned was a society which is not based on total lack of interest in "thy neighbor", a society of lonely grasping, but containing a certain amount of loyal, reliable friendship.
During the Pope's visit, Poles really loved each other and loved the fact that they belonged to a community, but a very short lived community of those who go to papal masses.
In the weeks since John Paul's plane left Krakow, it is clear that Poles have forgotten everything and things go on as before.
Which means they go as in a cold democracy and a brutally cold free market.
Why is this so?
Evangelical values mean little to people whose only purpose is money.
Even freedom, which in theory is important for the members of a liberal society, is not much valued in Poland.
Democracy in Poland, and probably in all postcommunist countries, was, is, and shall be the freedom to gain money.
One can argue that such is state of affairs elsewhere, but I do not think so.
In some countries, democracy is connected with values which support the welfare state or a society that takes care of its members most of the time.
This is often called "inclusion".
Inclusion in Poland is of no interest to politicians and to businessman, and love, in the Pope's words, was a form of inclusion.
Some months ago Poland faced a wave of peasant strikes.
Farmers sought more money, of course, but what they really wanted was inclusion.
Since 1989 none of the many Polish governments, which nearly always included the Peasant party (PSL), has shown any interest in a group that constitutes 38% of society.
I do not intend to praise communism, but before the Second World War 20% of university students were the offspring of peasants; now we have barely 1%.
No one tries to help young people from the provinces go to high schools and afterward to universities.
Peasants simply cannot manage in the cold free market.
So they feel utterly disconnected from the process of transformation.
Perhaps democracy must be cold as a technique of government but it cannot be cold towards its citizens.
Adam Smith, indeed, was not a theorist of the cold free market, but one of the greatest moralists of the Enlightenment.
The Pope was, therefore, right when he called for more love and was wrong when he hoped that people would listen.
Perhaps, after the first brutal generation of democratic rule, a slightly more moral society will arise and the Pope's words will be recalled from a distance.
Now they are ignored as we, solitarily, grub for the rewards of our material freedom.
MOSCOW: Vladimir Putin has more to celebrate than his election as Russia’s president in his own right.
After a decade of horrific turmoil, Russia’s economy is at last turning around.
Recently, the Moscow brokers Brunswick Warburg predicted that Russia’s GDP will surge 5% this year.
That growth should give President Putin - if he is patient and persistent - leeway to tackle the longer term reforms his country needs if it is to become the powerful state he seeks it to be.
Until now, a broad consensus forecast 1-2% growth in Russia this year.
The reason behind that uninspiring consensus is simple: people - economists and investors alike - have become so pessimistic about Russia that they no longer can see positive facts.
The conventional wisdom is that Russian industrial growth is only an effect of high oil prices and import substitution, facilitated by a great devaluation of the ruble.
Considering that Russia’s growth was 3.2% last year, a staggering 8.8% in the last quarter, this makes little sense.
Growth, indeed, is accelerating.
Dynamism like this does not stop without a major shock.
Industrial growth was 8.1% last year, and has accelerated since, to 14% in February.
Oil and gas have not led the recovery; indeed, they stagnated last year.
Major industries with 16-22% growth were chemicals, light manufacturing, pulp and paper, and machine building; that is, intermediary goods and simple manufacturing, exactly the kind of industries economists like to see expanding at this stage of a recovery.
Within each industry, the best enterprises dash ahead, as should be the case when real restructuring is taking place.
Another tired argument is that Russia’s growth is superficial and not generated by investment.
However, recovery in transition economies from Estonia to Poland to Hungary is usually export led.
Investments tend to follow recovery, as there is so much underutilized capital around.
Even so, investment actually increased by 6% in 1999 and is rising further.
But the most over-hyped argument concerns Russia’s feeble tax collection.
But this obscures the real issue, which is excessive government expenditures.
Last year the government put its finances in order by cutting wasteful and corrupt expenditures, such as enterprise subsidies.
The total government budget deficit stopped at 1.7% of GDP.
This year it will be nearly eliminated.
Barter and arrears (ie, debts between factories and firms), long major concerns, are also diminishing.
Since the financial crash of August 1998 all kinds of arrears have fallen by two/thirds in real terms and barter by half.
One reason was that in 1999 almost 10,000 loss-making Russian enterprises were put into bankruptcy.
The financial crash introduced hard budget constraints on Russian enterprises; they realized they had to make money, prompting rapid monetization.
Today, we are seeing the structural changes that we had hoped to see years ago.
Russia is getting some return from the substantial structural reforms it has actually undertaken.
The last real worry was the foreign balance.
Russia has a substantial foreign debt service, but the recent London Club deal reduced Soviet-era debt to commercial banks by half, easing the pressure mightily.
A similar deal is likely in the Paris Club for the regulation of debts to governments.
During the last few months Russia’s international reserves have grown sharply, as one would expect of a country with a staggering trade surplus of $33 billion this year and which is likely to surge to over $40 billion this year.
Of course, Russia is still hemorrhaging money.
But the cause of Russia’s so-called capital flight is a poor bank system and its dysfunctional tax system.
Fortunately, Russia now has such liberal currency regulations that Russians can keep their money in good international banks instead.
All of these changes mark the beginning of the end of the era of the oligarchs, ushered in with the presidential elections of 1996.
Mr. Putin has no need for the oligarchs to provide him with media support to avert a communist threat or offer a conduit for covert state financing.
To him, Boris Berezovsky and his cronies are a nuisance; most are already been broken to Putin’s will.
Instead, a new group of Russian businessmen, mainly manufacturers, are rising.
Their increasing strength is a reflection of robust economic growth, which promotes production for the market rather than sheer redistribution of resources, implying a new sort of politics.
Last October, McKinsey Global Institute published a major empirical report of Russian industry.
Its conclusion was that Russia had real and human capital suitable to sustain a growth rate of 8% a year, and that its problem was primarily the distortions imposed by a poorly functioning tax system and the absence of a land market.
However, neither the bank system nor the legal system were actually impediments at this stage of development.
They will become important as Russia moves to the next stage of growth, and so these new businessmen are demanding these reforms.
Mr. Putin is no great thinker or reformer, but he is astute and genuinely popular.
He is likely to surf on the current wave of economic growth, using broad consensus about the need for reform to clean up the state administration, and liberalize a tax regime which, though grossly inefficient, is heavy-handed when it goes after a company.
Land reform remains so controversial he may shrink from addressing the issue.
My greatest worry is not Putin but that Russia will face an excessive inflow of foreign portfolio investment again, as in 1997.
Fortunately, the bond markets are dead, and it might take a year to revive them.
Their absence makes it difficult to invest too large amounts of money in Russian securities.
Something fundamental has changed in the Russian economy.
A time comes when all disasters have occurred and all stupidities are recognized.
For Russia, August 1998 marked that dividing line.
It was a horrendous shock, imposing great social costs, but it changed Russia’s mentality, not only the exchange rate.
SYDNEY – Spectators at February’s Daytona 500 in Florida were handed green flags to wave in celebration of the news that the race’s stock cars now use gasoline with 15% corn-based ethanol.
It was the start of a season-long television marketing campaign to sell the merits of biofuel to Americans.
On the surface, the self-proclaimed “greening of NASCAR” (National Association for Stock Car Auto Racing) is merely a transparent (and, one suspects, ill-fated) exercise in an environmental form of whitewashing for the sport – call it “greenwashing.”
But the partnership between a beloved American pastime and the biofuel lobby also marks the latest attempt to sway public opinion in favor of a truly irresponsible policy.
The United States spends about $6 billion a year on federal support for ethanol production through tax credits, tariffs, and other programs.
Thanks to this financial assistance, one-sixth of the world’s corn supply is burned in American cars.
That is enough corn to feed 350 million people for an entire year.
Government support of rapid growth in biofuel production has contributed to disarray in food production.
Indeed, as a result of official policy in the US and Europe, including aggressive production targets, biofuel consumed more than 6.5% of global grain output and 8% of the world’s vegetable oil in 2010, up from 2% of grain supplies and virtually no vegetable oil in 2004.
This year, after a particularly bad growing season, we see the results.
Global food prices are the highest they have been since the United Nations started tracking them in 1990, pushed up largely by increases in the cost of corn.
Despite the strides made recently against malnutrition, millions more people will be undernourished than would have been the case in the absence of official support for biofuels.
We have been here before.
In 2007 and 2008, the swift increase in biofuel production caused a food crisis that incited political instability and fueled malnutrition.
Developed countries did not learn.
Since 2008, ethanol production has increased by 33%.
Biofuels were initially championed by environmental campaigners as a silver bullet against global warming.
They started to change their minds as a stream of research showed that biofuels from most food crops did not significantly reduce greenhouse gas emissions – and in many cases, caused forests to be destroyed to grow more food, creating more net carbon-dioxide emissions than fossil fuels.
Some green activists supported mandates for biofuel, hoping they would pave the way for next-generation ethanol, which would use non-food plants.
That has not happened.
Today, it is difficult to find a single environmentalist who still backs the policy.
Even former US Vice President and Nobel laureate Al Gore – who once boasted of casting the deciding vote for ethanol support – calls the policy “a mistake.”
He now admits that he supported it because he “had a certain fondness for the [corn] farmers in the state of Iowa” – who, not coincidentally, were crucial to his 2000 presidential bid.
It is refreshing that Gore has now changed his view in line with the evidence.
But there is a wider lesson.
A chorus of voices from the left and right argue against continued government support for biofuel.
The problem, as Gore has put it, is that “it’s hard once such a program is put in place to deal with the lobbies that keep it going.”
Politicians can’t stop such rent-seeking behavior.
What they can do is craft well-considered policies that maximize social welfare.
Unfortunately, when it comes to policies marketed as reining in global warming, protecting the environment, or creating “green jobs,” we have a tendency to make hasty decisions that don’t pass the test.
Government support for biofuel is only one example of a knee-jerk “green” policy that creates lucrative opportunities for a self-interested group of businesses but does very little to help the planet.
Consider the financial support afforded early-generation renewable-energy companies.
Germany led the world in putting up solar panels, funded by $75 billion in subsidies.
The result?
Inefficient, uncompetitive solar technology sitting on rooftops in a fairly cloudy country, delivering a trivial 0.1% of Germany’s total energy supply, and postponing the effects of global warming by seven hours in 2100.
Given the financial stakes, it is little wonder that alternative-energy companies, “green” investment firms, and biofuel producers are lobbying hard for more government largesse, and marketing their cause directly to the public by highlighting its supposed benefits for the environment, energy security, and even employment – none of which withstand scrutiny. “The NASCAR deal will push American ethanol into the stratosphere,” declared Tom Buis, CEO of the ethanol trade association Growth Energy.
At least one group is already sold: presidential contenders.
In Iowa last month, possible Republican candidate Newt Gingrich derided “big-city attacks” on ethanol subsidies.
And, in what must be music to the industry’s ears, an Obama administration official declared that even amidst the highest food prices the world has seen, there is “no reason to take the foot off the gas” on biofuel.
In fact, there are millions of reasons – all of them suffering needlessly – to apply the brakes.
Argentina's president, Eduardo Duhalde, has been making impassioned pleas for international support to rebuild his country.
Argentina needs and deserves such help, and the foundations for economic success-skills (a literate and well-educated population) and institutions (a federal constitutional democracy)-have been in place for a long time.
But Mr Duhalde has yet to specify what must be done to take advantage of Argentina' favorable endowments.
He does at least recognize that only Argentina is responsible for the bad policy choices that led to today's morass.
No one forced Argentina to adopt the currency board devised by Domingo Cavallo, the former economy minister, which pegged the peso to the dollar at a fixed exchange rate of one to one.
(The IMF, however, clearly should not have helped finance the currency board's operation without demanding fiscal adjustment when the country liberalized its foreign trade.)
As a result of the currency peg, Argentina's interest rates were largely determined in the US.
Lacking access to basic economic tools such as exchange rate and monetary policies, Argentina could not surmount the profound external shocks of the second half of the 1990s, when export prices fell, the US dollar appreciated, and Brazil, the country's main trading partner, devalued its currency.
The only alternative was severe fiscal austerity, for which the government never mustered the political will.
Argentina is now in a deep recession, with unemployment above 30%, and a shattered banking and financial system.
Fiscal austerity and balanced budgets should be priorities in the longer term, but they are inappropriate now.
The first priority should be boosting employment to enable citizens to put food on the table and recover a basic sense of confidence in the future.
Otherwise, the country's impoverishment will continue to deplete its middle class and lead many young and capable professionals to emigrate.
It will also sustain unprecedented levels of violence and criminality-another crucial dimension of today's insecurity.
To jump-start the economy, the government must promote exports, particularly in the manufacturing and agro-industrial sectors, as well as tourism and infrastructure construction projects.
After all, there can be no reliance on domestic consumption or private investment to turn the tide.
Higher exports will also generate the foreign exchange needed to resume external debt payments, now in default.
But Argentina's exporters will need help in returning to foreign markets, such as removal of tariff and non-tariff trade barriers by rich countries.
The country has already shown that under favorable conditions its exports can compete and grow rapidly.
According to World Bank data, 32% of Argentina's exports are manufactured goods, with roughly one-quarter classified as high-technology products.
From 1991 to 2001, total exports grew from about $12 billion to $27 billion (an average annual growth rate of about 8.5%), despite the overvalued currency.
President Duhalde has specifically requested the help of the IMF, the World Bank, and the Inter-American Development Bank.
Such assistance should be forthcoming, and in order to avoid bureaucratic overlap and turf conflicts, the responsibilities and priorities in dispensing it should be spelled out and agreed upon in advance by the government and these organizations.
Specifically, the IMF should be responsible for advice related to overall macroeconomic policy, as well as for assembling the financial package required to support the government while it implements its program of economic reactivation and reform of the financial sector.
The IMF should also provide technical and financial assistance to support a long-term program aimed at redefining the fiscal responsibility of the central and provincial governments.
True fiscal decentralization must take hold if the central government is ever to regain full control of public finances.
The World Bank should provide technical and financial assistance to support a reorganized judiciary.
This must include making the appointment of federal and Supreme Court judges free from nepotism and political influence.
A shameful legacy of President Menem's government in the 1990s was that it prevented the investigation and prosecution of serious improprieties, corruption, illegal arms sales, and major terrorist acts.
Finally, the Inter-American Development Bank should assist with programs designed to promote and finance industrial exports, as well as underwriting tourism projects.
These are areas in which the Bank has substantial experience in Latin America.
Argentina deserves the international support it is requesting.
At a time of deep recession, such support should not be made contingent on reaching unattainable fiscal objectives.
Fiscal consolidation should be a condition for the longer-term aid that international organizations will have to provide.
But the first priority must be putting people back to work.
Addressing the glaring shortcomings in the country's judicial system should also be made a condition for support, both as an immediate and a long-term objective.
Under any economic circumstances, denial of justice, and poor implementation of the country's laws, must be remedied as quickly as possible.
For, at the most fundamental level, what is at stake in Argentina is not merely the health of the economy, but the quality of its civil society.
The assassination of the President of Iraq's Governing Council makes it crystal clear that the US is failing to create the minimal law-and-order needed for any sort of orderly transfer of power to take place by June 30th.
Barely two months ago, the signing of a constitutional document by a US-appointed group of un-elected Iraqi officials was heralded as if it were the re-enactment of America's constitutional convention in Philadelphia in 1787.
But by now it is clear that this is a worthless piece of paper.
No imposed constitution, however elegant it may be, will be very helpful to Coalition forces when confronted with the type of mayhem seen in towns like Fallujah or Najjaf.
In the Kurdish region of northern Iraq, however, the situation is completely different: in the last ten years, under the protection of the Allies' no-fly zone, and even more so since the toppling of Saddam, the Kurdish regional government has been able to establish and sustain a relatively orderly administration.
It has overcome tribal and party differences and created ade facto functioning government, with an impressive record on development issues such as education, irrigation, and construction - and, above all, with no violence.
Confronted with the debacle in the rest of (Arab) Iraq, the question has to be asked why the US-led coalition should not hold a referendum in the Kurdish region, asking the population how they would like to be ruled.
After all, the Kurds have, by any internationally accepted standards, a right to self-determination.
Historically, the Kurds - who are distinct in language, culture, and historical consciousness from Arabs - never had their day in court.
After World War I and the fall of the Ottoman Empire, the victorious Allies promised them a state of their own - a promise that was cynically betrayed when British and French imperial interests took precedence.
Since then, the Kurds have suffered under the despotic rule of rival ethnic groups.
There are obvious obstacles to holding such a referendum, primarily because the US does not have a mandate to dispose of Iraq as it pleases.
But the same goes for the rest of Iraq: the US is now lamely asking for a UN resolution mandating a transfer of power to a legitimate Iraqi government - but such an authorization is highly unlikely, nor is there anyone in Iraq to whom authority can conceivably be transferred.
Why should the one region - and people - who run an orderly government, are not involved in murder, attacks on mosques, and suicide bombing of schoolchildren, be penalized?
Another objection is the opposition of Turkey - and, to a lesser degree, Iran and Syria - to granting the Iraqi Kurds self-determination.
But if one thinks in terms of universal norms of human rights, what right has Turkey to dictate internal development in another country?
After all, nobody accepts Israel's claim to oppose as a matter of principle the establishment of a Palestinian state in the West Bank and Gaza.
The same should apply to Turkey.
If Turkey grants its own Kurdish minority more cultural and language rights and allows legitimate Kurdish political representation in the Turkish parliament, the willingness of Turkish Kurds to oppose Ankara will be diminished.
In the nineteenth century, the joint interests of the authoritarian Russian, German, and Austrian Empires prevented the establishment of a free Poland: such unholy alliances have no place in the twenty-first century.
Recently, under the aegis of the UN, a referendum on the future of Cyprus was held within the island's Greek and Turkish communities.
The outcome was paradoxical, and not to the liking of those who initiated it: but the right of the communities to determine their future was accepted.
Why not in Iraqi Kurdistan?
Perhaps to assuage political fears - and considerations of international law - any plebiscite in the Kurdish region should, initially, have only a consultative status.
But it will give legitimate expression to the will of a people long oppressed and entitled to their place in the sun.
Such a referendum may also concentrate minds among the Arab Sunnis and Shia in Iraq, when they come to realize that it is their violence that is dismantling Iraq.
Perhaps they may decide that violence is counter-productive and carries its own penalties, and may then follow the Kurdish example of curbing violence, which would help put Iraq together again without recourse to permanent repression.
If not, at the very least, the injustice suffered by the Kurdish people for generations would, at long last, be rectified.
STANFORD – Successful political candidates try to implement the proposals on which they ran.
In the United States, President Barack Obama and the Democrats, controlling the House of Representatives and (a filibuster-proof) Senate, had the power to do virtually anything they wanted in 2009 – and so they did.
Obama and his congressional allies enacted an $800 billion “stimulus” bill that was loaded with programs geared to key Democratic constituencies, such as environmentalists and public employees; adopted a sweeping and highly unpopular health-care reform (whose constitutionality will be determined by the Supreme Court this year); imposed vast new regulations on wide swaths of the economy; embraced an industrial policy that selects certain companies for special treatment; engaged in borrowing and spending at levels exceeded only in World War II; and centralized power in Washington, DC (and, within the federal government, in the executive branch and regulatory agencies).
The last election that was followed by such a sweeping change in policy direction occurred in 1980, when President Ronald Reagan overhauled taxes, spending, and regulation, and supported the Federal Reserve’s course of disinflation.
While the 1988, 1992, and 2000 elections were also quite consequential, the policy shifts were not nearly as large as in 1980 and 2008.
The country rebelled against Obama and the Democrats’ lurch to the left with historic Congressional election victories for Republicans in 2010.
Since then, many Republicans have been deeply disappointed that the House of Representatives has been unable to roll back much of Obama’s agenda.
But the US political system is set up to make it much harder to accomplish something than to block it.
It is not easy to do a lot while controlling only one-half of one-third of the federal government.
The 2012 election is shaping up as a referendum on Obama’s policies and performance.
The economy is improving slowly, but it remains in bad shape, with high unemployment and millions having left the labor force.
Republicans are expected to retain control of the House and regain a majority in the Senate.
Former Massachusetts Governor Mitt Romney, the Republican frontrunner to challenge Obama in November, and the party’s other leading candidates, including former House Speaker Newt Gingrich, want less spending, major reforms of government programs, lower taxes, trade expansion, and less and more-targeted regulation than does Obama.
Romney, for example, has a detailed 59-point economic program, including a cap on federal spending at 20% of GDP, which would require reductions similar to those in the 1980’s and 1990’s.
Gingrich and the other Republicans have an even more aggressive agenda of cutting taxes and reducing the size and scope of government.
The eventual nominee would be wise to incorporate his opponents’ best ideas and top people into his campaign.
A Republican presidential victory, together with Republican control of the House and Senate, would likely lead to substantial reduction, repeal, and replacement of many Obama initiatives, attempts to reform taxes and entitlements, and measures to impose greater fiscal discipline.
High on Romney’s agenda is a reduction of the corporate-tax rate, from 35% to 25%, the OECD average level (the other Republican candidates would lower it still more), which would redress a major competitive disadvantage for American multinational companies’ global business.
A Republican victory would also most likely lead to a major push to open up many more energy-exploration opportunities within America, which Obama has stymied.
Romney has promised tougher negotiations on trade and currency with China, but is generally far more likely to push new trade agreements than the labor-supported Obama administration.
If, however, Democrats retain control of the Senate, this will be far more difficult to accomplish.
A Republican president also would make appointments to many key policymaking positions, from the Federal Reserve and the Treasury to regulatory agencies.
If Obama is re-elected, and Republicans control the House and Senate, his legislative agenda will essentially be a dead letter, and he will spend the next two years, at least, negotiating its reform and rollback.
In this scenario, the policy center of gravity in the Republican party would shift to House Speaker John Boehner, the chairman of the House Budget Committee, Paul Ryan, House Majority Leader Eric Cantor, and other key Representatives, including David Camp, Kevin Brady, and Kevin McCarthy, along with several Senators.
In that case, Obama would be wise to move to the center (as Bill Clinton did after the Democrats lost control of Congress in 1994) and work with congressional Republicans to shape sensible tax and entitlement reforms.
But that seems unlikely: since the Democrats’ massive defeat in 2010, Obama has moved even further to the left, embracing a more populist agenda.
Regardless of the outcome of this year’s presidential and congressional elections, various Republican state governors are likely to gain a higher national profile.
All of them –&nbsp;including Mitch Daniels of Indiana, Chris Christie of New Jersey, Bob McDonnell of Virginia, and former Governor Jeb Bush of Florida – declined to seek the Republican presidential nomination, but will be on the short list for 2016 should Obama win in November.
Supreme Court Justice Louis Brandeis famously described the states as “laboratories”: they should be allowed to experiment and learn from each other which policies work.
For example, Clinton and the Republican Congress based landmark 1996 welfare reform on policies originated by Wisconsin Governor Tommy Thompson and successfully emulated by New York City Mayor Rudy Giuliani, both reformist Republicans.
The current cohort of Republican governors offers similarly innovative state-level solutions – for example, on spending, debt, and unfunded pension and health liabilities – as models for the country.
Until November, divided government and contentious campaigning will most likely prevent significant policy moves.
But, following the election, taxes and spending, trade policy, federalism, regulation, and defense will take a different course – how different depends on who wins – with important implications for America’s fiscal position, external balance, and much else, including its relations with the rest of the world.
COPENHAGEN – Common sense was an early loser in the scorching battle over the reality of man-made global warming.
For nearly 20 years, one group of activists argued – in the face of ever-mounting evidence – that global warming was a fabrication.
Their opponents, meanwhile, exaggerated the phenomenon’s likely impact – and, as a consequence, dogmatically fixated on drastic, short-term carbon cuts as the only solution, despite overwhelming evidence that such cuts would be cripplingly expensive and woefully ineffective.
This scientific pie fight, characterized by juvenile name-calling, ignoble tactics, and intellectual intransigence on both sides, not only left the public confused and scared; it undermined the efforts of the most important organizations working on advancing the science of climate change.
Almost inevitably, at international summits from Kyoto to Copenhagen, governments failed to take any meaningful action on global warming.
Fortunately, there finally seems to be a growing number of influential scientists, economists, and politicians who represent a more sensible approach to the issue.
As I argued in my 2007 book Cool It, the most rational response to global warming is to make alternative energy technologies so cheap that the whole world can afford them.
In broad strokes, this requires a deliberate and significant boost to research and development spending.
Based on recent work by Isabel Galiana and Chris Green of McGill University, I advocate expenditure totaling around 0.2% of global GDP – roughly $100 billion a year.
Of course, no fix to global warming will work overnight.
So we need to focus more on adapting to the effects of global warming – for example, by stepping up efforts to cope with inland flooding and the urban “heat island” effect.
At the same time, we should explore the practicality of climate engineering, which we may need to buy more time for a smooth transition away from fossil fuels.
Acknowledging that man-made climate change is real, but arguing that carbon cuts are not the answer, amounts to staking out a middle ground in the global warming debate – which means being attacked from both sides.
For so-called “alarmists,” pointing out what’s wrong with drastic carbon cuts is somehow tantamount to denying the reality of climate change, while so-called “deniers” lambast anyone who accepts the scientific evidence supporting this “mythical” problem.
Nevertheless, there are encouraging signs that the minority of sensible voices in this debate are beginning to get the attention they deserve.
In mid-2009, as part of a project by the Copenhagen Consensus Center to assess different responses to global warming, Green and Galiana performed a cost-benefit analysis of R&amp;D spending on green technologies.
Green, a long-time proponent of a technology-led response to global warming, demonstrated the effectiveness of a policy of government investment in R&amp;D aimed at developing new low-carbon technologies, making current technologies cheaper and more effective, and expanding energy-related infrastructure such as smart grids.
As Green and Galiana bluntly noted, “No approach to climate stabilization will work without an energy technology revolution.”
Another academic who has advocated a smarter response to global warming is Roger Pielke, Jr. of the University of Colorado, the author of this year’s must-read global-warming book The Climate Fix.
Along with Green, Pielke was one of 14 noted academics who co-wrote February’s “Hartwell Paper,” commissioned by the London School of Economics and the University of Oxford.
The paper made the case for developing alternatives to fossil fuels, ensuring that economic development doesn’t wreak environmental havoc, and recognizing the importance of adaptation to climate change.
In the US, we witnessed an equally promising development in the climate debate just last month, when the conservative American Enterprise Institute, the liberal Brookings Institution, and the centrist Breakthrough Institute teamed up to publish a report that called for revamping America’s energy system with the aim of making clean energy cheap.
Entitled “Post-Partisan Power,” the report comprehensively and convincingly argues that the US government should invest roughly $25 billion per year (about 0.2% of America’s GDP) in low-carbon military procurement, R&amp;D, and a new network of university-private sector innovation hubs to create an “energy revolution.”
This sensible proposal predictably drew fire from committed “alarmists” and “deniers.”
But, promisingly – and surprisingly, given the somewhat toxic state of US politics – it attracted broad support and intelligent commentary from many mainstream pundits.
Adding to the swell of voices, November will see the documentary film based on my book ‘Cool It’ released in the US.
It is too early to suggest that politicians might make real progress toward implementing genuinely effective policies on climate change.
But, given the dearth of common sense in recent years, the mere fact that a growing chorus of reasonable voices can now be heard is nothing short of miraculous.
In the days after the so-called "Roadmap for Peace between Israel and Palestine" was unveiled, a new cycle of violence exploded between the warring parties.
Palestinian suicide bombings and Israeli attacks against Palestinian leaders came with such speed and ferocity that determining who was striking first and who was counterattacking became impossible.
Of course, recriminations also began immediately, with Israelis and Palestinians each accusing the other of deliberately destroying the peace process.
The truth, as usual, is more complicated, and understanding it helps us to comprehend what will be needed if real peace is to be achieved.
There are at least four sides to this conflict: moderate and extremist Israelis and moderate and extremist Palestinians.
Complicated strategic interactions exist not only between Israelis and Palestinians, but also within the two sides.
The extremist positions are clear.
Extremist Palestinians vow to fight until Israel--viewed as a colonial imposition on the Islamic world--is destroyed.
Extremist Israelis vow to fight to hold the entire West Bank, pushing out the Palestinians if necessary.
For them, Israel's pre-1967 borders, the entire city of Jerusalem, and the West Bank of the Jordan River is land given to the Jewish people by God.
No land-for-peace deal will satisfy either side.
Large majorities on both sides--perhaps two-thirds or even three-fourths of each population--would accept a return by Israel to something like its pre-1967 borders in exchange for real peace.
Of course, moderates on both sides would prefer as much land and room to maneuver as possible, but they prefer a negotiated compromise aimed at ending the violence.
The moderates are understandably wary.
Compromise on their side if met by extremism on the other would incite disaster.
If Israel returns to its pre-1967 borders, only to find continuing hostility and terrorism among the Palestinians, Israel will have gravely weakened its security for nothing.
If Palestinians disarm but still confront Israeli demands to keep West Bank settlements, then Palestine will never have a viable state.
Compromise is therefore difficult even among moderates: it requires a belief that moderation on one side will be met by moderation on the other.
The Oslo Peace Process was built on the premise that moderates on both sides would gradually gain each other's trust and move steadily towards compromise.
But this largely ignored the role of extremists.
Israeli extremists assassinated Prime Minister Yitzhak Rabin, lest he mobilize broad public support to make peace.
Arab extremists launched attacks against Israelis civilians, in part to show moderates on both sides that compromise would not stick.
That dynamic is still at work.
Palestinian Prime Minister Abu Mazen has called on Palestinian extremists to disarm, or at least to accept a prolonged cease-fire, but they have responded with more terrorist attacks.
Israel's government, meanwhile, has gone out of its way to attack Palestinian hard-line groups, causing more death, damage, and bitter feelings.
Extremists on both sides "win" their battle to undermine the peace process.
But all factions lose, because violence continues and none of them achieves its goals.
Israelis and Palestinians cannot find the way out alone, because neither side would dare to forcibly disarm its own extremists without absolute proof that the other side will do the same.
So it is fatuous for Israel's government to insist that the Palestinians disarm completely before the peace process can continue, when Palestinian moderates have no proof that Israel will withdraw to the pre-1967 boundaries.
In these circumstances, gradual confidence building will not work.
Extremists simply have enough power to undermine a process based on trust alone.
Nor will one side's extremists defeat the other side's extremists.
Israel's military has failed to destroy Palestinian terrorism through hard-line reprisals; Palestinian extremists have not scared Israeli hard-liners into concessions.
A solution is possible only if the outside world is prepared to police an agreement reached between the moderate majorities.
A strong international peacekeeping force, agreed by the UN, and perhaps led by the US or NATO, must be placed between the warring sides, and must be prepared to suffer losses to terrorists in the service of peace.
The roadmap is--so far--silent on this issue.
When UN Secretary General Kofi Annan made such a proposal, extremists on both sides denounced the plan.
But moderates raised red flags, too.
Would a peacekeeping force truly serve the interests of the agreement, rather than one side or the other?
Would it have the firepower to hold back extremists?
Would it stick to its long-term mission in the face of inevitable attacks?
Would peacekeepers withdraw at one side's insistence (as UN peacekeepers have retreated in other circumstances, including just before the 1967 Six Day War), putting the other side in jeopardy?
The Roadmap to Peace can work only if both sides are pressed to a real compromise, whose outline is clear: Israel's return to something like its pre-1967 borders; financial compensation of Palestinians for losses of land in Israel, rather than a right to return; and Jerusalem as a shared capital.
But enforcement of this compromise against extremists will require putting credible and well-armed international peacekeepers in place to hold the parties to the deal.
Designing such an international peacekeeping effort, one with the credibility and staying power, should now be a priority.
WASHINGTON, DC – Just over a hundred years ago, the United States led the world in terms of rethinking how big business worked – and when the power of such firms should be constrained.
In retrospect, the breakthrough legislation – not just for the US, but also internationally – was the Sherman Antitrust Act of 1890.
The Dodd-Frank Financial Reform Bill, which is about to pass the US Senate, does something similar – and long overdue – for banking.
Prior to 1890, big business was widely regarded as more efficient and generally more modern than small business.
Most people saw the consolidation of smaller firms into fewer, large firms as a stabilizing development that rewarded success and allowed for further productive investment.
The creation of America as a major economic power, after all, was made possible by giant steel mills, integrated railway systems, and the mobilization of enormous energy reserves through such ventures as Standard Oil.
But ever-bigger business also had a profound social impact, and here the ledger entries were not all in the positive column.
The people who ran big business were often unscrupulous, and in some cases used their dominant market position to drive out their competitors – enabling the surviving firms subsequently to restrict supply and raise prices.
There was dominance, to be sure, in the local and regional markets of mid-nineteenth-century America, but nothing like what developed in the 50 years that followed.
Big business brought major productivity improvements, but it also increased the power of private companies to act in ways that were injurious to the broader marketplace – and to society.
The Sherman Act itself did not change this situation overnight, but, once President Theodore Roosevelt decided to take up the cause, it became a powerful tool that could be used to break up industrial and transportation monopolies.
By doing so, Roosevelt and those who followed in his footsteps shifted the consensus.
Roosevelt’s first case, against Northern Securities in 1902, was immensely controversial.
But the break-up, a decade later, of Standard Oil – perhaps the most powerful company in the history of the world to that date – was seen by mainstream opinion as completely reasonable.
And the break-up of Standard Oil took place in great American style: the company was split into more than 30 pieces, the shareholders did very well, and the Rockefeller family went on to rehabilitate itself in the eyes of the American public.
Why are these antitrust tools not used against today’s megabanks, which have become so powerful that they can sway legislation and regulation massively in their favor, while also receiving generous taxpayer-financed bailouts as needed?
The answer is that the kind of power that big banks wield today is very different from what was imagined by the Sherman Act’s drafters – or by the people who shaped its application in the early years of the twentieth century.
The banks do not have monopoly pricing power in the traditional sense, and their market share – at the national level – is lower than what would trigger an antitrust investigation in the non-financial sectors.
Effective size caps on banks were imposed by the banking reforms of the 1930’s, and there was an effort to maintain such restrictions in the Riegle-Neal Act of 1994.
But all of these limitations fell by the wayside during the wholesale deregulation of the past 15 years.
Now, however, a new form of antitrust arrives – in the form of the Kanjorski Amendment, whose language was embedded in the Dodd-Frank bill.
Once the bill becomes law, federal regulators will have the right and the responsibility to limit the scope of big banks and, as necessary, break them up when they pose a “grave risk” to financial stability.
This is not a theoretical possibility – such risks manifested themselves quite clearly in late 2008 and into early 2009.
It remains uncertain, of course, whether the regulators would actually take such steps.
But, as Representative Paul Kanjorski, the main force behind the provision, recently put it, “The key lesson of the last decade is that financial regulators must use their powers, rather than coddle industry interests.”
And Kanjorski probably is right that not much would be required. “If just one regulator uses these extraordinary powers [to break up too-big-to-fail banks] just once,” he says, “it will send a powerful message,” one that would “significantly reform how all financial services firms behave forever more.”
Regulators can do a great deal, but they need political direction from the highest level in order to make genuine progress.
Teddy Roosevelt, of course, preferred to “Speak softly and carry a big stick.” The Kanjorski Amendment is a very big stick.
Who will pick it up?
No secret file is being used to secure a guilty verdict.
The proceedings are held in open court, notin camera.
Yet the trial of Colonel Yuri Budanov in the city of Rostov-on-Don on charges of kidnapping, raping and murdering an 18 year old Chechen girl named Elsa Kungaeva contains echoes of the notorious Dreyfus affair that divided France a century ago.
At that time, the French army was licking its wounds from the defeat at Sedan and the creation of Bismarck's imperial Germany.
In the words of one of the French novelist Anatole France's characters in a novel written at the time, esteem for the army "is all that is left of our glorious past.
It consoles us for the present and gives us hope of the future."
An exaggerated sense of lost glory helped incite the French Army to fake the evidence that convicted Captain Alfred Dreyfus of spying for the Kaiser.
Today's Russian army is not the bastion of reactionary monarchism and anti-Semitism that shaped French officers' behavior in the Dreyfus affair.
But the army's bitterresentiment at the demise of Russia's superpower status, reinforced by the military's own humiliating loss of resources and prestige, is no less evident.
The army's exalted, tormented, and wounded pride appears to be shaping both its response to Budanov's trial as well as that of President Vladimir Putin's Kremlin.
To Russia's officer corps, all opponents areipso facto the army's enemies and, by extension, enemies of Russia.
Unlike their turn-of-the-19th-century French counterparts, however, Russia's officer corps is essentially apolitical, despite decades of dictatorship.
Military officers are not overwhelmingly communist in their political leanings, not exclusively ethnic Russians, and not necessarily nationalists.
Some officers are all of these, and most are some of them.
But the army as a whole is not anti-democratic.
It appears to have mostly learned its lesson about keeping out of politics, having been drawn into the coup against Mikhail Gorbachev in August, 1991, only to switch sides when young officers and conscripts balked at carrying out orders.
Nevertheless, although President Putin is working to make it a more professional body than the Soviet-era mass army, the officer corps retains a Bolshevik mind-set barricaded against the intrusions of civilian criticism.
Poorly paid, slowly promoted, and often drearily garrisoned in Siberian towns, the army's sole recompense nowadays is prestige: the honors, immunities and cachet of a caste; in short, the esteem in which it is held because of the victories over Napoleon and Hitler.
Colonel Budanov's trial challenges this ingrained sense of honor.
When the proceedings began a year ago, democratic Russia seemed to be catching up at long last with the civilized world in holding military officers accountable to the rule of law.
Russian liberals initially welcomed the Budanov case as a sign that the country might address accusations that war crimes were committed in Chechnya.
Last month, however, the military prosecutor accepted Colonel Budanov's argument that he was temporarily insane when he killed the girl, and so acquitted Budanov on the charge of murder.
(The rape charge, for some unclear reason, had already been dropped.)
The prosecution then began to speak of the young girl as a Chechen sniper, from a family of snipers.
Outraged, Defense Minister Sergei Ivanov dismissed the prosecutor, who seemed ready to acquit the patriotic "hero" on all remaining charges.
A new prosecutor revived the investigation, reinstated the charges, and balked at accepting a plea of not guilty due to insanity.
Ivanov, however, apparently intervened not because he feared a miscarriage of justice, but because the Kremlin hierarchy recognized that a verdict exonerating Budanov would leave the army itself vulnerable.
Critics would suggest that it had failed to control its men and might even have encouraged and abetted the savagery in Chechnya-of which the charges against Colonel Budanov are but a small part.
So only a guilty verdict would suffice, but it still had to be qualified with a finding of insanity.
After all, no army can be held accountable for the murderous actions of an insane man.
No ordinary psychiatrist, however, attested to Budanov's alleged insanity.
Instead, he was evaluated by experts from Moscow's Serbsky Institute of Psychiatry, which became infamous in the Brezhnev era for treating dissent as a form of schizophrenia and subjecting "patients" like Vladimir Bukovsky to psychotropic drugs to help them recognize the glories of Soviet life.
The Serbsky team claimed that Colonel Budanov was temporarily insane at the time of the murder due to "patriotic fervor."
As in the Dreyfus affair, Russia's army is increasingly a prisoner of its friends-die hard communists, Great Russian chauvinists, ranting nationalists, and all the other anti-reform and anti-democratic groups who make defense of military honor a rallying cry for their own dark causes.
Indeed, the army's honor is now so firmly tied to finding Budanov both guiltyand insane that Russia finds itself on the brink of issuing a nakedly political verdict.
Like the Dreyfus affair, so pathetic a distortion of law into propaganda will ultimately leave an even more profound sense of shame, one lasting generations after Budanov's supporters have lost all credibility.
A journalist visiting the Kingdom of Saudi Arabia recently asked me why five out of six students he interviewed at King Saud University still believe that Al Qaida was not responsible for the attacks on the World Trade Center and the Pentagon in America last year?
Dealing with this question is increasingly frustrating for me, because I have run out of plausible explanations.
I used to believe that denial of Saudi complicity in the attacks reflected our distress with what happened on that dark day.
I hoped that we would have the courage to overcome our perceived humiliation and start looking deep into our national psyche, asking the big question, "Why did 15 of our young men attack America in so brutal a way?"
So far, we are no closer than we were after the attack to answering to this question, because we cannot even find the nerve to ask it.
Had we been more confident and less full of bluster, we would have organized seminar after seminar to analyze what happened, to understand the reasons behind it, and to plan for a future without a similar tragedy.
After all, Osama bin Laden's hijacked planes not only attacked New York and Washington, they also attacked Islam as a faith and the values of tolerance and coexistence that it preaches.
But despite the enormity of what happened, we remain in denial.
We still cling to conspiracy theories even after bin Laden and his fellow conspirators bragged about their great "achievement."
We continue to close our eyes to the fact that 19 young Muslim men decided to leave home, head for what they described as jihad, and became criminals.
It is past time to move forward.
We must admit that 15 Saudis helped perpetrate the attacks on America of last September 11th, and that hundreds of other Saudis were needlessly killed far away from home, in the mountains and villages of Afghanistan.
We must uncover why Taliban-ruled Afghanistan seemed such an attractive destination for a significant portion of Saudi youth in the years before September 11th.
Afghanistan was a country where Muslims were killing each other.
Any Muslim knew that his duty in this case was to try to reconcile the combatants, not join the violence.
When Arabs, including Saudis, first fought in Afghanistan in the mid-1980s, their campaign was politically and religiously just.
Afghan Muslims were confronting foreign aggressors who sought to impose Soviet-style communism upon them.
The Mujahideen were overseen by responsible clerics, who gave a shining example to Saudi youth.
Some of those young men remained in Afghanistan as Mujahideen entered Kabul to take part in the bitter infighting that led to the Taliban's rise.
Others returned home and were welcomed as heroes.
Were those young men who returned home then wiser than today's Saudi youth?
What happened in the last ten years that allowed extremists to find so many eager followers?
Since September 11th we have busied ourselves counseling the Americans, pointing out where they went wrong, but no one is listening.
Instead, we should be remedying our own deficiencies.
We should be trying to answer the question that the Americans have been asking us incessantly: why did young Saudi men take part in the attacks?
We must answer this question not for the Americans' sake, but for our own.
It is not enough to say that the hijackers--and, indeed, the many Saudis being held at Guantanamo Bay--represent a subset of duped youngsters and that the rest of Saudi youth are different.
That is true, of course, but the damage that this relatively small group inflicted was monumental.
It is far better to try and understand their motives.
In our attempts to defend and justify ourselves over the past year, we Saudis learned about the consequences of extremism at Waco, Texas and Oklahoma City.
We wrote about the Michigan Militia and other American radical extremists.
Of course there is extremism in America--extremism as ugly as any that we have at home.
But the Americans studied and analyzed minutely the Waco and Oklahoma City incidents on their own.
The motives behind those attacks were examined in an effort to guarantee that such events would not recur.
We Saudis have failed to do the same.
The most pressing issue now is to ensure that our children are never influenced by extremist ideas like those that misled 15 of our countrymen into hijacking four planes that fine September day, piloting them, and us, straight into the jaws of hell.
Did the bombings that rocked Riyadh shock the al-Saud royal family from its complacency at long last?
This rude interruption to their majesties' indolence by their subjects incited rage and fury and something else--fear.
Of course, alarm bells have rung before in Saudi Arabia, but the ruling family remained in denial--deniability and repression being the political arts at which the al-Saud excel.
If the regime is to forge a survival strategy, it must now re-examine its foundations.
As ruling families go, the al-Saud are spectacularly numerous--there are perhaps as many 22,000 of them.
But vast bloodlines have not prevented hardening of the arteries.
Indeed, the men now struggling to hold things together are the incapacitated King Fahd (84 years old), his half-brother Crown Prince Abdullah (79 years old), and his full brothers, Defence Minister Sultan (78 years old), and Interior Minister Naif (75 years old).
Old men, unsurprisingly, find it hard to cope with the breakdown of the assumptions that have governed their entire lives.
Perhaps the most shattering lost illusion is the fact that the bombings occurred in the heart of the al-Saud's home-base in the Najdi region, which indicates that the enemy within resides nearer to the throne than anyone suspected.
This recognition is particularly unsettling because the al-Saud have alienated every group except their own.
If some Najdi may now be mistrusted, where can the al-Saud turn?
Saudi Arabia's population is divided into distinctive regional, tribal, and sectarian groups.
To the east, in the oil-rich province, are the Shia.
Politically emboldened since the fall of Saddam's regime and the resurgence of their brethren in Iraq, the Shia wasted no time in petitioning Crown Prince Abdullah to end both their exclusion from Saudi politics and their demonization as heretics by the Wahhabi religious establishment.
Their message to the rulers is that it will no longer suffice to identify being Saudi exclusively with being Wahhabi Najdi.
Meanwhile, the Hijazis, who originate in Mecca and Medina, hold long-repressed resentments due to their humiliating partial inclusion in Saudi politics.
Although the Hijazis, who are Sunnis but not Wahhabis, are not viewed as heretics, they are marginalized because the Islam they practice has Sufi leanings--and tolerant Sufiism is anathema to the austerely dogmatic Wahhabis.
Educated Hijazis ask only for modest reforms.
Yet even moderation is dismissed by the al-Saud.
The tribes of the Asir region, which have a mixed sense of identity due to their close ties to Yemeni tribes, feel alienated from both the political and the economic center.
The population of al-Jawf in the north has a similar sense of political and economic alienation.
Despite long simmering feelings of resentment and dispossession, these `minorities' remain moderate in their demands for reform.
Their leaders want to rescue the state, not raze it.
They form the vast majority of people in Saudi Arabia, and have not yet embraced the uncompromising rage of Osama bin Laden's clones.
The challenge facing the al-Saud is to include at the heart of the political system the peoples they have shunned for decades.
Unless they begin to do so, these peoples will drift into the camp of the fanatics--if not as active terrorists than as passive supporters, much as the Catholic community in Northern Ireland passively embraced IRA terrorism as a way to end their exclusion from political life in the province.
The danger in Saudi Arabia is that the IRA are no match for Muslim fundamentalists in their fanaticism.
For the regime to embrace peoples it has excluded, it must agree on inclusiveness--and the tolerance of non-Wahhabi forms of Islam--as a survival strategy and stick to it.
This is difficult because the ruling al-Saud are themselves divided.
Crown Prince Abdullah is far more disposed to reform than Prince Naif, the powerful Interior Minister, who clings to the old narrow system of repression.
The al-Saud will undoubtedly be ruthless in seeking out the individuals directly implicated in the terrorist bombings.
Those captured face beheading in the traditional way.
The problem for the regime is that the springs that nourish fanaticism will not be dammed by such exemplary punishment.
Some royals recognize this and know that a more thorough housecleaning is needed.
They realize that the al-Saud must choose: continue on the narrow path of repression and ethnic and religious intolerance, or adopt a more open and inclusive policy.
Both choices are fraught with danger: open up, and they include people in Saudi public life hitherto considered unworthy for being either heretics (the Shia) or of impure blood (the Hejazis) or too primitive (the border tribes).
Remain closed, and they will find themselves hostage to the forces of intolerance that threaten the regime.
The al-Saud religious alliance with the Wahhabis and the latter's control of a rigid religious educational system must change. "Moderate" elements among the population will support this change (and the manhunt for terrorist fanatics) if they secure inclusion in Saudi life.
Alexis de Tocqueville warned that the most dangerous time for any authoritarian regime is when it reforms.
The al-Saud have procrastinated so long that every choice they now face is risky.
Inclusion is the less dangerous path.
It puts at risk only the ethnically narrow and religiously intolerant structure of the regime.
By contrast, the regime itself will be imperiled if it clings to its narrow base.
MADRID – “Time and again in our Nation’s history, Americans have risen to meet –and to shape – moments of transition.
This must be one of those moments.” So begins the National Security Strategy of the United States of America, presented before Congress on May 27.
As with the politics pursued in the Obama administration’s 16 months of office – dialogue, international commitment, nuclear non-proliferation and disarmament – the document’s strength lies in the position that it takes.
The Security Strategy is a clear departure from that of its predecessor and offers a wider conception of what national security represents for US President Barack Obama.
In the face of the major challenges of our times, Obama has taken a stand with a comprehensive doctrine.
Indeed, the Security Strategy is almost a “National” Strategy.
Its thinking goes beyond the dominant, unilateral paradigm of its predecessor and includes a defense of international law.
This is particularly noteworthy, given that none of the great treaties to create an international criminal court and a permanent war-crimes tribunal was signed by the US during George W. Bush’s presidency.  
Obama’s approach to security is broader as well, proposing the “three Ds” – defense, diplomacy, and development – as indivisible parts of a whole.
The military dimension of intervention abroad loses its privileged role, making way for the prevention of conflict and for peace-keeping and stabilization missions.
In the fight against terrorism, the Strategy abandons the predominantly military viewpoint underlying the war against terror, and embraces a more significant role for the intelligence services.
For the first time, precise reference is made to people liable to be a threat to US security.
The US is not waging a war against terrorism; it is at “war against a specific network, al Qaida, and its affiliates.” In this war, information resources are particularly necessary.
In order to guarantee national security, the Strategy is categorical – without giving in to the temptation of isolationism – in admitting the strategic value of the example and the importance of doing one’s homework first.
Obama steers clear both of interventions for humanitarian purposes and of attempting to export democracy by force.
There is no better way of exporting the values of democracy than by strengthening the US internally.
Thus, an economic policy that tackles America’s debt and deficit makes up the main portion of the Strategy.
Backing competitive education, innovation, technology, energy, and a more efficient and accessible health-care system complements and reinforces Obama’s leadership approach of setting an example with one’s own policies.
An important example is removing the US prison at Guantánamo Bay from international limbo – one of his first initiatives as president.
This approach does not have unanimous support among international experts.
The two main criticisms – lack of strategic clarity and less emphasis on the classical concepts of power – point to America’s loss of influence, power, and leadership.
But these criticisms reflect an inability to contemplate the current nature of armed conflict, which no longer follows the classical logic of military victory or defeat.
The war in Afghanistan and the complex situation in Iraq have highlighted the importance of a comprehensive approach.
Military action cannot be considered the only variable of success.
A successful strategy should use civilian means – incidentally a model advocated by the European Union.
We are faced with forging a new long-term policy that affects both states and societies.
That task requires patience and strategic perseverance.
Change will not occur from one day to the next, but the results obtained in the end will be better and more enduring.
Obama maintains the idea of service to a historical mission for the US: the important job of guaranteeing global security.
But, unlike his White House predecessors, Obama’s National Security Strategy recognizes the value of partnerships; attaches greater importance to the civilian dimension as opposed to the military; and stresses the value of dialogue and the need to reinforce international institutions.
This is a good sign for a world with different power centers and interests, with resources and legitimacy remaining tied to the nation-state, but in which challenges (climate change, armed conflicts, pandemics, and transnational crime) are global and, therefore, require cooperation among states.
We are in a transition period: international interconnection is increasing, as the global economic crisis has shown, but the management tools and mechanisms to guarantee the smooth operation of governments are still not being shared.
Obama’s new National Security Strategy shows a political willingness to back an international order able to tackle these challenges.
The road ahead is not free of difficulties, but the Strategy represents a decisive step towards solving the challenges of the twenty-first century and preparing us for the world of tomorrow.
PALO ALTO – A group of multi-national European scientists has used gene-splicing techniques to create an extraordinary tomato.
It boasts a deep purple skin and flesh, and contains levels of antioxidants 200% higher than unmodified tomatoes.
When fed to highly cancer-susceptible mice, the tomatoes significantly extended the mice’s lifespan.
These studies have received wide attention, but an equally momentous achievement of genetic modification has been largely ignored for almost a decade.
That innovation is “Golden Rice,” a collection of new rice varieties that is bio-fortified, or enriched, by genes that express beta-carotene, the precursor of vitamin A, which is converted in the body, as needed, to the active form.
Most physicians in North America and Europe never see a single case of vitamin A deficiency in their professional lifetimes.
But the situation is very different in poor countries, where vitamin A deficiency is epidemic among the poor, whose diet is heavily dominated by rice (which contains neither beta-carotene nor vitamin A) or other carbohydrate-rich, vitamin-poor sources of calories.
In developing countries, 200-300 million children of preschool age are at risk of vitamin A deficiency, which can be devastating and even fatal.
It increases susceptibility to common childhood infections such as measles and diarrheal diseases, and is the single most important cause of childhood blindness in developing countries.
Every year, about 500,000 children become blind as a result of vitamin A deficiency, and 70% die within a year of losing their sight.
In theory, we could simply supplement children’s diets with vitamin A in capsules, or add it to some staple foodstuff, the way that we add iodine to table salt to prevent hypothyroidism and goiter.
Unfortunately, neither the resources – hundreds of millions of dollars annually – nor the infrastructure for distribution are available.
Biotechnology offers a better, cheaper, and more feasible solution: Golden Rice, which incorporates beta-carotene into the genetically altered rice grains.
The concept is simple.
Although rice plants do not normally synthesize beta-carotene in the endosperm (seeds), they do make it in the green portions of the plant.
By using gene-splicing techniques to introduce the two genes that express these enzymes, the pathway is restored and the rice grains accumulate therapeutic amounts of beta-carotene. 
Golden Rice offers the potential to make contributions to human health and welfare as monumental as the discovery and distribution of the Salk polio vaccine.
With wide use, it could save hundreds of thousands of lives every year and enhance the quality of life for millions more.
But one aspect of this shining story is tarnished.
Intransigent opposition by anti-science, anti-technology activists – Greenpeace, Friends of the Earth, and a few other groups – has spurred already risk-averse regulators to adopt an overly cautious approach that has stalled approvals.
There is absolutely nothing about Golden Rice that should require endless case-by-case reviews and bureaucratic dithering.
As the British journal Nature argued in 1992, a broad scientific consensus holds that “the same physical and biological laws govern the response of organisms modified by modern molecular and cellular methods and those produced by classical methods.... [Therefore] no conceptual distinction exists between genetic modification of plants and microorganisms by classical methods or by molecular techniques that modify DNA and transfer genes.”
Put another way, government regulation of field research with plants should focus on the traits that may be related to risk – invasiveness, weediness, toxicity, and so forth – rather than on whether one or another technique of genetic manipulation was used.
Nine years after its creation, despite its vast potential to benefit humanity – and a negligible probability of harm to human health or the environment – Golden Rice remains hung up in regulatory red tape, with no end in sight.
(Cancer-preventing tomatoes, take notice.) 
By contrast, plants constructed with less precise techniques such as hybridization or mutagenesis generally are subject to no government scrutiny or requirements (or opposition from activists) at all.
That applies even to the numerous new plant varieties that have resulted from “wide crosses,” hybridizations that move genes from one species or genus to another – across what used to be considered natural breeding boundaries.
Judith Rodin, the president of the Rockefeller Foundation, announced last October that her organization will provide funding to the International Rice Research Institute to shepherd Golden Rice through national regulatory approval processes in Bangladesh, India, Indonesia, and the Philippines.
This is good news, but what is really needed is a multi-faceted, aggressive reform of the regulatory process so that all new genetic constructions will have a chance to succeed.
In an April editorial in the journal Science , Nina Fedoroff, an eminent plant geneticist who serves as senior scientific advisor to US Secretary of State Condoleezza Rice, wrote: “A new Green Revolution demands a global commitment to creating a modern agricultural infrastructure everywhere, adequate investment in training and modern laboratory facilities, and progress toward simplified regulatory approaches that are responsive to accumulating evidence of safety.
The Golden Rice story makes it clear that we do not yet have the will and the wisdom to make that happen.
BELGRADE: It is widely believed that if only Slobodan Milosevic were removed from power, Serbia would be set on a path of renewal.
But reality here is more complex and more troubling.
If Serbia is to avoid a humanitarian disaster this winter, all of its politicians must put ambition aside so that the country can begin to rebuild.
Even before the disaster of Kosovo, Serbia was an economic basket case.
Key economic reforms that transformed much of postcommunist Europe -- macro-economic stabilization, freeing prices and foreign trade, privatization -- were scorned in order to sustain an authoritarian regime.
Instead of integrating Serbia into the international community and stopping the rot in the country's living standards, the regime opted to cow its people into submission through high inflation, a brutal black market economy, and tolerance of massive corruption.
NATO's bombing was the coup de grace for an economy dying on its feet.
So stark are conditions now that the very survival of the nation is at stake.
Bomb damage has been estimated at $30 billion, triple this year's GDP.
Industrial production will drop this year to one fifth of its value in 1989, while GDP per capita will be only $975, a third of its value ten years ago.
One out of every two people in Serbia are unemployed.
Without international help, and if our country "relies on our own resources" to rebuild, which is the stated policy of the regime, it will take between 40 and 80 years for Serbia to return to the economic level it enjoyed when President Milosevic first took power a decade ago.
Serbia's people recognize that without reintegration into the world community reconstruction is impossible.
Continued isolation will mean generations of misery.
The truth is that the regime knows this, too, but seems to want the nation to go down with it.
Although the government realizes that there is no money for reconstruction at home and that its accounts abroad are frozen, it tries to buy time by declaring its intention to reform and cooperate with the world, and by using pathetic marketing ploys such as glamorous opening ceremonies for pontoon bridges (one was washed away the next day), ferry-ports, and other quick-fix rebuilding jobs.
Of course, everyone is aware that the incumbent government could not, even if it wished, cooperate with the world since not a single member of it can obtain a visa to travel.
All that the politicians indicted by the Hague War Crimes Tribunal may now do is run a prison economy, which is what they are doing.
Discontent is mounting. Protests and rallies increase in size and frequency.
Serbia could witness one of two scenarios before year's end: (1) a spontaneous, large scale revolt whose outcome and consequences (think of the bloodshed in Bucharest in December, 1989 or the Tien An Mien massacre) are uncertain or (2) the peaceful demise of the Milosevic regime.
The second scenario envisions change through democratic elections.
But fair elections in Serbia are currently impossible, not only because the regime holds all the media cards and controls the election process, but because the country is in such ruin that no party program could realistically be disseminated.
In any case, elections could not be organized in time to avoid a humanitarian disaster this winter.
That is why Group 17 – an organization of leading economists and social scientists who aim to create in Serbia a market economy and open and democratic society under the rule of law – is proposing a "Serbian Stability Pact" as a peaceful and fast solution to end the crisis.
The "Serbian Stability Pact" is based on the judgement that all Serbia's political protagonists must take responsibility in the current crisis.
Thus, the plan, calls for the following:
* A constitutional means to remove Mr. Milosevic from power, with the ruling party renouncing its executive power for a period of one year;
* All opposition parties will renounce their aspirations to power for the same period and their leaders will refrain from joining transitional forms of government;
* A transitional government of technocrats will be formed (the most serious candidate to head this government is Dragoslav Avramovic, who enjoys wide popular support), its members pledging not to run in the elections to follow their one-year term, nor will this transitional government support any single political party that might run;
* Radical economic reform.

Since its creation on July 18th, the "Serbian Stability Pact" has gained the backing of opposition parties and groups, previously divided -- among them Vuk Draskovic of the Serbian Renewal Party and Zoran Djinjic of the Allliance for Change -- as well as the strong support of the Serbian Orthodox Church, the only institution in Serbia with its credibility intact, it having condemned the crimes committed in Kosovo, the patriarch having called for the resignation of President Milosovic.
Like the Roman Catholic Church in the years of Solidarity's struggle in the 1980s, the Serbian Orthodox Church is widely seen as a surrogate for our lost national identity.
Its participation in the Stability Pact provides additional legitimacy and a guarantee for a peaceful transition.
On August 19th, many thousands of Serbs will gather in front of the Federal Parliament in Belgrade to demonstrate their determination to effect political change peacefully.
All the leading opposition parties, whose coming together seemed unlikely only a few weeks ago, will participate.
By rallying behind this domestic "Stability Pact" Serbia can proclaim its intention to make itself a viable candidate for partnership in implementing the Stability Pact for South-Eastern Europe that the leaders of the world community initiated in Sarajevo a few weeks ago.
In an incredibly short period of time the Serbian Stability Pact has united more political protagonists than any previous democratic movement in Serbia since the break-up of Yugoslavia.
Our hope must be that, beginning on August 19th, the voice of reason will begin to prevail in Serbia, and that a transitional government can begin to rebuild the country in genuine freedom and democracy.
NEW YORK – After the Greek and Irish crises and the spread of financial contagion to Portugal, Spain, and possibly even Italy, the eurozone is now in a serious crisis.
There are three possible scenarios: “muddle through,” based on the current approach of “lend and pray”; “break-up,” with disorderly debt restructurings and possible exit of weaker members; and “greater integration,” implying some form of fiscal union.
The muddle-through scenario – with financing provided to member states in distress (conditional on fiscal adjustment and structural reforms), in the hope that they are illiquid but solvent – is an unstable disequilibrium.
Indeed, it could lead to the disorderly breakup scenario if institutional reforms and other policies leading to closer integration and restoration of growth in the eurozone’s periphery are not implemented soon.
The crisis started with too much private debt and leverage, which became public debt and deficits as crisis and recession triggered fiscal deterioration and private losses were mostly socialized via bailouts of financial systems.
Then, distressed sovereigns that had already lost market access – Greece and Ireland – were bailed out by the International Monetary Fund and the European Union.
But no one will bail out these super-sovereigns if the sovereigns prove to be insolvent.
Thus, the current strategy of kicking the can down the road will soon reach its limits, and a different plan will be needed to save the eurozone.
The first institutional reform takes the form of a larger envelope of official resources, which would mean a quasi-fiscal union.
Official resources currently are sufficient to bail out Greece, Ireland, and Portugal, but not to prevent a self-fulfilling run on the short-term sovereign and financial liabilities of Spain and other potentially distressed eurozone members.
So, even if these countries were to implement the necessary fiscal and structural reforms, an increase of official resources would nonetheless be needed.
Because nervous investors don’t want to be last in line in case of a run, a disorderly rush to the exits is likely when official resources are insufficient.
Short of full fiscal unification – or a variant of it in the form of eurozone bonds – this increase in official resources would occur through a much-enlarged European Financial Stability Facility and a much greater commitment by the European Central Bank to long-term bond purchases and liquidity operations to support banks.
Since quasi-fiscal union implies that the eurozone’s core economies could end up systematically bailing out those on the periphery, only a formal loss of fiscal sovereignty – a credible commitment by the peripheral countries to medium- and long-term fiscal discipline – could overcome the current political resistance of Germany and others.
But even a larger envelope of official resources is not sufficient to stem the insolvency problems of Greece, Ireland, and, possibly, Portugal and Spain.
Thus, a second set of policies and institutional reforms requires that all unsecured creditors of banks and other financial institutions need to be “treated” – that is, they must accept losses (or “haircuts”) on their claims.
This is needed to prevent even more private debt being put on government balance sheets, causing a fiscal blowout.
If orderly treatment of unsecured senior creditors requires a new cross-border regime to close down insolvent European banks, such a regime should be implemented without delay.
Similarly, super-sovereigns cannot continue to bail out distressed sovereigns that are insolvent rather than illiquid.
Thus, in addition to an orderly resolution regime for banks, Europe must also implement early orderly restructurings of distressed sovereigns’ public debt.
Waiting until 2013 to implement these restructurings, as German Chancellor Angela Merkel proposes, will destroy confidence, as it implies a much larger haircut on residual private claims on sovereign borrowers.
Thus, orderly market-based restructurings via exchange offers need to occur in 2011.
Such exchange offers can limit private creditors’ losses if they are done early.
That way, formal haircuts on the face value of debt can be avoided via new bonds that include only a maturity extension and an interest-rate cap that is set below today’s unsustainable market rates.
Waiting to restructure unsustainable debts would only lead to disorderly workouts and severe haircuts for some private creditors.
Finally, Europe needs policies that restore competitiveness and growth to the eurozone’s periphery, where GDP is either still contracting (Greece, Spain, and Ireland) or barely growing (Italy and Portugal).
Without growth, it will be difficult to stabilize public and private debts and deficits as a share of GDP – the most important indicator of fiscal sustainability.
Moreover, without growth, the social and political backlash against painful belt-tightening will eventually undermine austerity and reform.
Unfortunately, fiscal austerity and structural reforms are – at least in the short run – recessionary and deflationary.
So other policies are needed to restore growth.
The ECB should pursue a much looser monetary policy to jump-start growth, with a weaker euro to help boost the periphery’s competitiveness.
In addition, Germany should delay its fiscal consolidation; if anything, it should cut taxes for a couple of years to boost its own growth and – via trade – that of the periphery.
In the next few months, it will become clear whether European policymakers can compromise and implement reforms that dampen the threat of a eurozone breakup.
Either the EU moves in the direction of a more stable equilibrium of closer integration, or the risk of an unstable and disorderly breakup scenario will rise significantly.
NEW YORK – The global recession now underway is the result not only of a financial panic, but also of more basic uncertainty about the future direction of the world economy.
Consumers are pulling back from home and automobile purchases not only because they have suffered a blow to their wealth with declining stock prices and housing values, but also because they don’t know where to turn.
Should they risk buying a new car when gasoline prices might soar again?
Will they be able to put food on the table after this year’s terrifying rise in food prices?
Decisions about business investment are even starker.
Businesses are reluctant to invest at a time when consumer demand is plummeting and they face unprecedented risk penalties on their borrowing costs.
They are also facing huge uncertainties.
What kinds of power plants will be acceptable in the future?
Will they be allowed to emit carbon dioxide as in the past?
Can the United States still afford a suburban lifestyle, with sprawling homes in far-flung communities that require long-distance automobile commutes? 
To a large extent, economic recovery will depend on a much clearer sense of the direction of future economic change.
That is largely the job of government.
After the confused and misguided leadership of the Bush administration, which failed to give any clear path to energy, health, climate, and financial policies, President-elect Barack Obama will have to start charting a course that defines the American economy’s future direction.
The US is not the only economy in this equation.
We need a global vision of sustainable recovery that includes leadership from China, India, Europe, Latin America, and, yes, even Africa, long marginalized from the world economy, but very much part of it now.
There are a few clear points amidst the large uncertainties and confusions.
First, the US cannot continue borrowing from the rest of the world as it has for the past eight years.
America’s net exports will have to increase, meaning that the net exports of China, Japan, and other surplus countries will consequently decrease.
The adjustments needed amount to a sizeable deficit-to-balance swing of around $700 billion in the US current account, or nearly 5% of US GNP.
China’s trade surplus might shrink by half of that amount (with cuts in trade surpluses also spread over other global regions), meaning a shift in Chinese GNP toward internal demand and away from net exports equal to between 5% and 10% of China’s GNP.
Fortunately, China is promoting a major domestic expansion. 
Second, the decline in US consumption should also be partly offset by a rise in US investment.
However, private business will not step up investment unless there is a clear policy direction for the economy.
Obama has emphasized the need for a “green recovery,” that is, one based on sustainable technologies, not merely on consumption spending.
The US auto industry should be re-tooled for low-carbon-emission automobiles, either plug-in hybrids or pure battery-operated vehicles.
Either technology will depend on a national electricity grid that uses low-emission forms of power generation, such as wind, solar, nuclear, or coal-fired plants that capture and store the carbon-dioxide emissions.
All of these technologies will require public funding alongside private investment.   
Third, the US recovery will not be credible unless there is also a strategy for getting the government’s own finances back in order.
George W. Bush’s idea of economic policy was to cut taxes three times while boosting spending on war.
The result is a massive budget deficit, which will expand to gargantuan proportions in the coming year (perhaps $1 trillion) under the added weight of recession, bank bailouts, and short-term fiscal stimulus measures.
Obama will need to put forward a medium-term fiscal plan that restores government finances.
This will include ending the war in Iraq, raising taxes on the rich, and also gradually phasing in new consumption taxes.
The US currently collects the lowest ratio of taxes to national income among rich nations.
This will have to change. 
Fourth, the world’s poor regions need to be seen as investment opportunities, not as threats or places to ignore.
At a time when the major infrastructure companies of the US, Europe, and Japan will have serious excess capacity, the World Bank, the European Investment Bank, the US Export-Import Bank, the African Development Bank, and other public investment funds should be financing large-scale infrastructure spending in Africa, to build roads, power plants, ports, and telecommunications systems.
So long as the credits are long term and carry a modest interest rate (say, 25-year dollar loans at 5% per annum), the recipient countries could repay the loans out of the significant boost in incomes that would result over the course of a generation.
The benefits would be extraordinary, for both Africa and the rich countries, which would be putting their businesses and skilled workers back to work.
Such loans, of course, would require a major global initiative, at a time when even blue-chip companies cannot borrow overnight, much less for 25 years!
In typical business cycles, countries are usually left to manage the recovery largely on their own.
This time we will need global cooperation.
Recovery will require major shifts in trade imbalances, technologies, and public budgets.
These large-scale changes will have to be coordinated, at least informally if not tightly, among the major economies.
Each should understand the basic directions of change that will be required at the national level and globally, and all nations must share in the deployment of new sustainable technologies and in the co-financing of global responsibilities, such as increased investments in African infrastructure.
We have arrived at a moment in history when cooperative global political leadership is more important than ever.
Fortunately, the US has taken a huge step forward with Obama’s election.
Now to action.
NEW YORK – While the United States recently reported 3.5% GDP growth in the third quarter, suggesting that the most severe recession since the Great Depression is over, the American economy is actually much weaker than official data suggest.
But official measures of GDP may grossly overstate growth in the economy as they don't capture the fact that business sentiment among small firms is abysmal and their output is still falling sharply.
Third quarter GDP - properly corrected for these factors - may have been 2% rather than 3.5%.
The story of the US is, indeed, one of two economies.  There is a smaller one that is slowly recovering and a larger one that is still in a deep and persistent downturn.
Consider the following facts.
While America’s official unemployment rate is already 10.2%, the figure jumps to a whopping 17.5% when discouraged workers and partially employed workers are included.
And, while data from firms suggest that job losses in the last three months were about 600,000, household surveys, which include self-employed workers and small entrepreneurs, suggest that those losses were above two million.
Moreover, the total effect on labor income – the product of jobs times hours worked times average hourly wages – has been more severe than that implied by the job losses alone, because many firms are cutting their workers’ hours, placing them on furlough, or lowering their wages as a way to share the pain.
Many of the lost jobs – in construction, finance, and outsourced manufacturing and services – are gone forever, and recent studies suggest that a quarter of US jobs can be fully outsourced over time to other countries.
Thus, a growing proportion of the workforce – often below the radar screen of official statistics – is losing hope of finding gainful employment, while the unemployment rate (especially for poor, unskilled workers) will remain high for a much longer period of time than in previous recessions.
Consider also the credit markets.
Prime borrowers with good credit scores and investment-grade firms are not experiencing a credit crunch at this point, as the former have access to mortgages and consumer credit while the latter have access to bond and equity markets.
But non-prime borrowers – about one-third of US households – do not have much access to mortgages and credit cards.
They live from paycheck to paycheck – often a shrinking paycheck, owing to the decline in hourly wages and hours worked.
And the credit crunch for non-investment-grade firms and smaller firms, which rely mostly on access to bank loans rather than capital markets, is still severe.
Or consider bankruptcies and defaults by households and firms.
Larger firms – even those with large debt problems – can refinance their excessive liabilities in court or out of court; but an unprecedented number of small businesses are going bankrupt.
The same holds for households, with millions of weaker and poorer borrowers defaulting on mortgages, credit cards, auto loans, student loans, and other forms of consumer credit.
Consider also what is happening to private consumption and retail sales.
Recent monthly figures suggest a pick-up in retail sales.
But, because the official statistics capture mostly sales by larger retailers and exclude the fall in sales by hundreds of thousands of smaller stores and businesses that have failed, consumption looks better than it really is.
And, while higher-income and wealthier households have a buffer of savings to smooth consumption and avoid having to increase savings, most lower-income households must save more, as banks and other lenders cut back on home-equity loans and lower limits on credit cards.
As a result, the household savings rate has risen from zero to 4% of disposable income.
But it must rise further, to 8%, in order to reduce the high leverage of household sector.
To be sure, the US government is increasing its budget deficits to put a floor under demand.
But most state and local governments that have experienced a collapse in tax revenues must sharply retrench spending by firing policemen, teachers, and firefighters while also cutting welfare benefits and social services for the poor.
Many state and local governments in poorer regions of the country are at risk of bankruptcy unless the federal government undertakes a massive bailout of their finances.
Moreover, income and wealth inequality is rising again: poorer households are at greater risk of unemployment, falling wages, or reductions in hours worked, all leading to lower labor income, whereas on Wall Street outrageous bonuses have returned with a vengeance.
With the stock market rising while home prices are still falling, the wealthy are becoming richer, while the middle class and the poor – whose main wealth is a home rather than equities – are becoming poorer and being saddled with an unsustainable debt burden.
So, while the US may technically be close to the end of a severe recession, most of America is facing a near-depression.
Little wonder, then, that few Americans believe that what walks like a duck and quacks like a duck is actually the phoenix of recovery.
PALO ALTO – The United States and Europe are two giant free-trade areas, each wealthy but with serious short-run problems and immense long-run challenges.
They are also two single-currency areas: the dollar and, for much of Europe, the euro.
The challenges facing both are monumental.
But only Europe’s currency union faces uncertainty about its future; America faces no existential crisis for its currency.
The two economic powers’ similarities and differences, particularly with respect to internal labor mobility, productivity, and fiscal policies, suggest why – and provide clues about whether the eurozone can weather the crises on its periphery and evolve into a stable single-currency area.
Labor mobility from poorer to richer areas provides a shock absorber against differential economic hardship.
The other natural shock absorber is a depreciating currency, which increases competitiveness in the area hit hardest.
That cannot happen with a common currency, and economic adjustment is doubly difficult when labor is not mobile enough to help mitigate regional contractions in income and unemployment.
The reasons for lower labor mobility in the eurozone than in America are legion.
True, America’s original thirteen colonies were a loose federation, and many Americans considered themselves citizens of their state first and of the US second as late as a century after the Revolution.
But one’s state was not a fully formed nation, with its own shared and deeply ingrained history, culture, ethnic identity, and religion.
Perhaps the most important cultural component of labor mobility is language.
From Mississippi to Maine, and from New York to New Orleans, America’s written language is the same and the spoken language is understandable to all.
Not so from Berlin to Barcelona or Rome to Rotterdam.
(Or, for that matter, from northern to southern China or in multilingual India, where Hindi is spoken by only 42% of the population.)
For eurozone citizens who do not speak a major language, especially English, mobility across national borders within the single-currency area is limited at best.
These are differences that cannot be easily erased.
While some aspects of culture are becoming globalized, variation across borders in Europe is far greater than it is between US states.
For example, until the second half of the twentieth century, today’s eurozone members regularly slaughtered each other on centuries of battlefields.
By contrast, history is more commonly shared among Americans from different states, who, other than in the Civil War, have fought side by side in the nation’s external wars.
All of this means that when California slumps, residents simply leave for the mountain states; when manufacturing jobs disappear in the upper Midwest, people migrate to new jobs in Texas.
That pattern is much less prevalent in Europe.
Moreover, it is a pattern that has closed the gap (now roughly 40%) between per capita income in America’s poorest and richest states, as labor and capital continually adjust by moving to areas where productivity is higher.
The range of productivity and per capita income within the eurozone is considerably wider, making mobility even more important.
Finally, while fiscal systems differ among American states, the overall fiscal burden is under half that of the federal level.
Almost all states’ constitutions require balanced budgets (with exceptions for emergencies).
American states and municipalities do face serious medium- and long-term fiscal challenges from underfunded pension and health-care systems, but citizens living in different states have a common national budget, whereas citizens of different eurozone countries face radically different central-government fiscal positions.   
Indeed, many observers argue that the eurozone’s lack of a common fiscal system is its main problem.
But competition over taxes and services is beneficial, not harmful.
Nevertheless, much tighter constraints, with serious and enforceable penalties, must be placed on permissible budget positions and their transparency if the euro is to survive.
And it can survive.
Those who would write off the euro as a failure should consider that it is only ten years old.
America, too, historically had problems as a single-currency area, from early chaos before the Constitution to the clash between agricultural and banking interests over the gold standard in the late nineteenth century.
While the euro faces strong headwinds, the dollar’s early sailing wasn’t always smooth, either.
The eurozone countries must first deal with the sovereign-debt crisis, reduce their fiscal deficits, and strengthen the woefully undercapitalized banking system.
But, if the eurozone is to survive and prosper beyond the current crisis, it will also need comprehensive structural reforms to boost internal labor mobility and defuse the pressures caused by economic adjustment among nations and regions.
Whether citizens will support politicians who propose the labor, tax, and other reforms needed to enhance mobility, and whether such reforms will be sufficient to overcome linguistic and cultural barriers, are open questions.
Successive generations of post-war European political leaders initiated the European Union and then currency union in order to knit countries so closely together that another major war between them would become impossible.
Whether monetary union was necessary to accomplish that aim is debatable.
Despite the considerable advantages of a common currency (price transparency, lower transaction costs, and inflation credibility, to name a few), the difficulty of macroeconomic management of such diverse economies looms larger than ever.
The euro was always a big gamble, a grand experiment.
Historical efforts at monetary union have sometimes collapsed, and sometimes they have survived multiple crises.
The future of the eurozone may be cloudy, but it will not be dull.
LONDON – Individual elections do not always enhance democracy – a useful reminder that the ballot box is only one part, albeit a central one, in any free, plural society.
Of course, there are also magnificent examples of elections that strengthen both the stability and the institutions of a community.
We have just witnessed an example of the second kind in India, the world’s largest and greatest democracy, where 420 million voters there returned a Congress-led government with a solid majority.
It was in many respects a personal triumph for Prime Minister Manmohan Singh.
His victory shows that it is possible to succeed in politics through decency, honesty, and high intelligence.
Sonia Gandhi and her family should also take credit for putting at the forefront of their campaign a vision of an inclusive society, which rejects divisions on the basis of caste, ethnicity, language, and religion.
The result should help India to continue – not without occasional turbulence – its journey toward becoming a high-growth economy that raises the standard and quality of life for the poor.
I wish we could look forward in Europe to a similarly healthy democratic experience next month when voters throughout the European Union elect new members of the European Parliament.
Since 1979, these MEPs have been elected direct rather than indirectly from national parliaments.
But turnout for these elections has been falling in several countries.
There is a danger that the number voting in June will be lower than ever before.
Moreover, in the current grim economic conditions across Europe, voters who do turn out are all too likely to take the opportunity to punish the major parties and vote for fringe and even extremist politicians.
There are particular circumstances that may encourage this electoral response.
First, everywhere there is a sense of disgust at the way the recent boom seemed to privatize gains while the subsequent bust socialized losses.
A few rich individuals appeared to gain and all taxpayers to lose.
This has spread a sense of unfairness.
Second, globalization has been the target for populist criticism.
It is usually defined to mean everything we dislike – from changes to our traditional way of life to loss of jobs.
It is a brave politician who points out how much liberalizing trade and opening up markets have increased our overall prosperity.
Third, in Britain at least, the entire political class has been discredited by a sleazy scandal about the expenses that many parliamentarians have paid themselves.
Analogies with pigs, snouts, and troughs fill the pages of British newspapers.
But there is another reason for the lack of interest in the EU elections.
The European Parliament has power, but it deals with issues that, while important to voters, do not top their list of concerns.
The EU’s member states retain power over the most sensitive political issues, including taxes, health, education, pensions, the labor market, and foreign policy.
So the questions that dominate national campaigns have little impact on European elections.
The European Parliament deals with the important areas where individual countries have pooled their sovereignty, like trade, the creation of a pan-European market, and the biggest environmental issues.
But these are not often the questions that trigger the most passionate interest.
In addition, the European Parliament’s detachment from national political debates means that it has less political legitimacy than is desirable.
Indeed, those who worry about the creation of a European superstate can rest easy.
There will be no such entity, because there is no European electorate; the electorate remains French, Belgian, Latvian, Greek, and so on.
They all vote at the same time, for the same institution.
But what does an Italian know – or care, for that matter – about British politics?
Look at our television programs.
We know far more about Europe’s football than we do about Europe’s politics. “The beautiful game” brings people together more effectively and reliably than the European Parliament is able to do.
That is no criticism of those who work – often very hard – in the European Parliament.
We have created a political body that has power to hold European institutions to account but has no obvious European electorate to which it can itself be held accountable.
A parliament without a people inevitably increases the sense of frustration that many European voters feel about the process of making Europe-wide policy choices in their name.
If the Lisbon Treaty is ratified later this year, one of the changes should result in national parliaments becoming more involved in European decision-making.
But we need to look country-by-country at what else we can do to tie Europe’s own parliament into national politics.
Unless we do that better, fewer people will vote for MEPs, more of them will be elected simply on a protest vote and represent Europe’s murky extremes, and the whole practice and principle of European democracy will be discredited.
BANGKOK – The thunderous results of Thailand’s general election on July 3 will seem familiar to anyone attuned to the political upheaval in the Middle East and North Africa.
Entrenched incumbent regimes everywhere are under severe stress from advances in information technology, shifts in demographics, rising expectations, and the obsolescence of Cold War exigencies.
In the absence of a willingness and ability to use violent repression, regime survival can be achieved only through concessions, accommodation, and periodic reinvention.
With 47 million voters and turnout at 75%, Thailand’s latest election results pose a decisive challenge to the country’s long-established regime.
The Pheu Thai party, led by Yingluck Shinawatra, the youngest sister of exiled fugitive former Prime Minister Thaksin Shinawatra, secured a resounding triumph, winning 265 seats in the 500-member assembly, while the ruling Democrat Party mustered just 159.
The return to power of Pheu Thai is extraordinary – and not only because Yingluck will be Thailand’s first female prime minister.
The establishment-aligned courts dissolved the party’s two previous governments, and banned scores of its leading politicians from office for five years.
Pheu Thai’s victory thus suggests that a previously marginalized electorate has been permanently awakened.
A similar majority of the Thai electorate voted for Thaksin’s parties and their pro-poor populist platforms in January 2001, February 2005, April 2006, and December 2007, defying a military coup, a coup-induced constitution, judicial interventions, and army coercion and repression.
The recent election marked a profound break from the past.
In the second half of the twentieth century, Thai elections seemed to alternate with military coups.
Voters were bought and sold like commodities.
After elections, voters hardly ever saw or heard from their MPs, who typically went on to engage in corruption and graft in Bangkok – eventually losing legitimacy and paving the way for military coups.
A new constitution and elections invariably ensued.
This vicious cycle of coups, constitutions, and elections defined Thai politics for decades.
That pattern reflected Cold War imperatives.
The pillars of the Thai state – nation, religion, and the king – struck a unifying, collective chord, and the resulting stability enabled economic development.
While growth was so concentrated that popular resentment simmered, communism was kept at bay.
Challenges to the established order, with the military-monarchy-bureaucracy triumvirate as its anchor, were repeatedly put down.
Back then, Thai schoolchildren sang martial songs each morning, and Thais knew their place in the rigidly elitist pecking order, which was reinforced by socialization and indoctrination in classrooms and living rooms, where only state-controlled media could enter.
Thais were more like obedient subjects than informed citizens.
Dissenting views found little traction.
The rise of Thaksin’s Thai Rak Thai party in 2001 changed all that.
The party pursued a scientific approach to elections, relied on expensive polling by foreign experts, and offered a clear agenda and strong leadership.
It was the first post-Cold War party to capture Thais’ collective imagination.
The voices of neglected swaths of the electorate, particularly in the rural north and northeast of the country, began to count.
Vote-buying became increasingly insufficient.
A bond between party and voters – a bond based on policy – took root.
By 2001, the Cold War was long over.
Political leaders who dissented from the status quo could no longer easily be jailed on communism-related charges.
The advent of the Internet had made it harder for the authorities to shape Thai minds, as media sources multiplied and the resulting diffusion of information undermined the effectiveness of state propaganda.
Moreover, new international norms had come to the fore: external powers that previously turned a blind eye to coups, military dictatorships, and repression now rallied around democracy and human rights.
Thailand’s demographics also changed.
The Cold War curriculum of induced unity and stability has no relevance for today’s schoolchildren; indeed, most university students nowadays were born after the Cold War ended.
These factors fostered a new political environment, and Thaksin, who was a telecommunications tycoon at the time, was well positioned to seize the opportunity.
He overhauled the bureaucracy, delivered on his promises to the poor, mapped out an industrial strategy, and re-designed an overstretched foreign policy agenda, among other innovative measures.
Of course, Thaksin’s rule had a dark underside: corruption, legislated conflicts of interest, cronyism, human rights violations, and abuse of power, among other evidence of misrule.
Such is Thaksin’s mixed legacy.
The opportunities, hopes, and dreams delivered to the downtrodden and the vision and plans for Thailand’s future were enmeshed with his own venality.
But, while Thaksin committed many infractions, his gravest “sin” was to have changed the way Thais think and behave.
Some see this change as usurpation; others view it as Thailand’s deliverance into the twenty-first century.
Thaksin’s adversaries in Thailand’s entrenched regime were unwilling to accede to his policy innovations and populism.
For them, doing so would be tantamount to admitting that most people in this hospitable, well-endowed kingdom had been kept poor by design all along.
For his part, Thaksin has sought to portray the recent election results as being all about him.
But he is best viewed as a self-serving, unwitting agent of political modernization.
It is these twenty-first-century dynamics and changes, underpinned by an increasingly assertive citizenry, with which the Thai establishment must come to terms if the country is to move forward.
There is something tragic about Europe's current development.
Democracy's march across the continent, and the formation of a single market across much of Europe, have created unprecedented stability, security, and prosperity.
The new single currency, the euro, and the European Union's promise to admit as many as ten new members in 2004, are powerful indicators of ongoing integration.
Yet, the ability of European institutions to accommodate deeper and broader integration is increasingly undermined by the persistence of a contradictory and long-obsolete ideal: the nation-state as the basis of political legitimacy and sovereignty.
It is largely because the idea of common European citizenship is often understood by analogy to that of national citizenship that further European integration engenders so much fear and opposition.
The nation-state in the traditional sense presupposed a citizenry that was created as competing collective identities decayed.
Venetians became Italians, Bavarians became Germans, and so on.
Nation-builders throughout Europe promoted - with varying degrees of success, to be sure - the emergence of a dominant culture, an official language, and an identity based partly on distinctions vis-à-vis neighboring states, peoples and cultures.
National minorities everywhere faced expulsion or enormous official pressure to assimilate.
A European nation-state in this sense was untenable even for the original six members of the European Community - all of them highly industrialized countries with similar social and political traditions and institutions.
It is no more feasible today for the EU's 15 members, and further enlargement means that the multitude of collective identities, cultures, languages, religions, and worldviews will become greater still.
The singular "people" that defines citizenship in a traditional nation-state could be forged only by plunging Europe into appalling repression and war lasting generations, if not centuries.
Of course, European integration has been driven from the outset precisely by the shared historical memory of the terrible suffering wrought by aggressive nationalism.
But without an alternative to the nation-state as the basis of citizenship, the legitimacy and effectiveness of EU institutions have come under growing strain.
Witness, for example, Ireland's veto of the institutional reforms adopted at the EU's Nice summit in December 2000 - reforms without which enlargement cannot go forward.
Similarly, opinion polls show that support for EU membership has fallen rapidly even in many candidate countries.
Political leaders such as Vaclav Klaus in the Czech Republic and Viktor Orban in Hungary welcome the common market, but argue that their nation-states did not re-gain theirde facto sovereignty from Moscow only to surrender itde jure to Brussels.
Yet free movement of goods and services, labor, capital, and ideas (the single market's "four freedoms") makes irrelevant much of what traditional European nation-states do - namely, defending these freedoms within a smaller territory.
With the EU's internal borders reduced to purely administrative boundaries, this task has passed to institutions that wield immense preemptive authority over member states.
An alternative must therefore be found to a definition of citizenship that regards these institutions as merely some sort of formalized representation of member states' common political will.
What should an alternative conception of European citizenship look like?
The US model of political identity, shaped by a legacy of immigration and voluntary cultural integration, cannot be simply transposed to Europe, where distinct traditions, cultures, and attitudes are so deeply entrenched.
But a conception of citizenship that isbasic and minimal is essential where a Pole and a Swede may fall in love while studying in Spain, begin their careers in Germany, and settle down to raise a family in Italy.
Common citizenship does not require a common form of life, common existential values or a common historical past.
Indeed, this is theonly democraticand stable definition of European citizenship, because it alone is capable of eliciting the consent and allegiance of every individual.
Clearly, people in the real world do not ordinarily get to choose the basic structure of their society.
But imagine, in the spirit of the philosopher John Rawls's famous thought experiment in his bookA Theory of Justice, that youdo get to choose the rules - although without knowing who you will be in such a hypothetical society.
Assuming that you are rational, you must calculate that you may be a member of a cultural minority.
Obviously, you will not choose rules that define citizenship in terms of a particular cultural identity.
On the contrary, you will seek to hedge your bets by ensuring that citizenship is constituted by individual rights of participation in collective projects, backed up by a legal system that guarantees these rights.
Citizenship in this sense views political sovereignty and legitimacy as features of institutions that fostervoluntary social cooperation by embodying rules of interaction that are viewed as fair and efficient from the perspective of everyone.
If repression were enough to secure compliance with the rules, democratic legitimacy would be unimportant.
As the collapse of communism in Eastern Europe demonstrates, repression alone is a poor guarantee of stability.
European citizenship understood in this way is compatible with a multitude of collective identities ranging from family or friendship groups to professional associations and corporations, regionally defined communities, and shared cultural, political and religious affinities.
Such a conception stabilizes social cooperation within Europe because it reflects a basic normative consensus on the design of institutions and thus orients individual behavior toward preserving these institutions.
In fact, a well-developed conception of democratic citizenship will always emphasize individual rights.
Citizenship is not constituted by groups, but by individuals interactingas citizenswith specific interests and goals.
This means that they pursue their interests and goals within commonly accepted rules of interaction including, naturally, rules of conflict resolution between different collective identities.
LONDON – This is a tough time to be a decision-maker.
We live in an era of low predictability.
The world appears in constant flux.
The challenges are immense.
And most of all, there is, in many instances a clash between the correct short term politics and the correct long term policy.
On the economy, the climate debate and security, the immediate pressures pretty much run one way: increase the role of government in the economy; put the climate deal off to more congenial financial times; and get out of substantial military commitment to fighting global terrorism.
Yet in each case the right long-term policy almost certainly points to the opposite course.
What is the way to bridge this gap between short and long term?
To decide how to do that is to decide fundamentally what we believe in and what we want from our future.In deciding this, only the head can guide us in how to do it; but the heart must tell us what it is we truly believe in doing.
In the economy, the near universal conventional wisdom after the collapse of the banking system, was that the market had failed and the state had to step in.
Old copies of John Kenneth Galbraith’sThe Great Crash of 1929 and Keynesian tracts were dusted off and avidly re-read.
And it is true: the market did fail and the state had to step in.
The fiscal and monetary stimuli were important in themselves, but even more so because they indicated that the strength of government was going to be utilised to prevent contagion and further collapse.
But if we move to analysing what sort of recovery we can expect and what sort of future economy we are trying to fashion, it is by no means clear that we need a continuing, intrusive state role.
On the contrary, we need the private sector to regain its sense of enterprise, innovation and vigour; we need to be careful of regulating so as to squeeze the availability of credit; and we should certainly avoid protectionism.
True, the private sector will have much re-structuring to go through and the big deficits have been accumulated in the crisis must be unwound.This will mean a radical re-structuring of the state and its services.
But in the end, business not government will power the global economy forward.
In other words, the claim that “the market failed” is too alarmingly broad.Actually, one part of the market failed, but government and regulators were part of that failure.
If we believe that this is true, it will ultimately be the creativity (in the best sense) of the private sector that will see us return to prosperity.
So we need to make decisions in the coming weeks and months which help the private sector and not harm it.
Likewise, in respect of the environment and energy, whatever the financial pressures, if we think that the earth’s climate is probably changing as a result of human activity, we need to set the global economy on a low carbon path to the future.
This doesn’t mean that we can come out with unrealistic propositions as we struggle for a new global treaty to succeed the Kyoto Protocol.
We should not make the best the enemy of the good.
There are major things we can do on the basis of existing knowledge – on deforestation, energy efficiency and renewables – to make a big difference over the next decade.
We will then require a long-term framework of incentives to develop the technologies of the future.
But the point is: now is not the time to put off action.
The seriousness of China on this issue, and now India, the enthusiasm of Brazil and others in the emerging markets to participate in tackling climate change: all of this offers a huge opportunity that should be grasped.
And for the West, we should all remind ourselves about $100 a barrel oil.
There are exemplary reasons of energy security why we need to change the nature of our economies to drive down carbon dependence.
In security questions, the choices here are perhaps the hardest of all.
A public, understandably disheartened by the length of the current military campaigns and loss of life in Afghanistan and Iraq, is sympathetic to the idea of disengagement.
But this is also where, most of all, we need to decide what it is we truly believe in.
The reason it is hard going in Afghanistan right now, for example, is that the forces we are facing are making it so.
They are doing this by the use of terrorism and by brutal intimidation of the civilian population and in defiance of the expressed and plain will of the international community.
Time and again what is clear is that people, given the chance, do want governments that are accountable, proper rule of law and the ability to choose their own destiny.
Those using terror, whether in Afghanistan, Pakistan, Iraq, Somalia, Yemen and the list could go on and on, do so to de-stabilise nations and to thwart the will of the people to live in peace.
Disengaging now will not leave people free from our interference; it will put them at the mercy of groups whose extremism threatens the very way of life that we stand for and to which they aspire.
So no matter how difficult it is, we should remember what it is we believe in and why.
So now is a moment, even amongst all the uncertainty, for some clarity and that clarity comes best from a worked out strategy based on a strong set of convictions.
Any good international investment banker knows that the end of April is a bad time to come peddling his services, for that is when the world’s finance ministers return home from the IMF meetings in Washington, chastened that risks to the global economy could spill over into their own backyards.
Ministers are too busy recovering from their trauma to think about paying fat fees for big new international bond issues.
Who wants to build up debt if there might be a financial crisis around the corner?
Better to keep socking away US Treasury bills, even if the return is far lower than on most other investments.
Or is it?
With today’s global economy in the middle of a sustained and increasingly balanced expansion, has the time come to start considering upside risks?
In particular, should governments, especially those that are endlessly building up dollar reserves, instead start thinking about how to build up their roads, bridges, ports, electric grids, and other infrastructure?
Has the time come to start laying the groundwork to sustain future growth, especially in poorer regions that have not yet shared in today’s prosperity?
Don’t get me wrong, I am not arguing for fiscal profligacy.
But the balance of risks has shifted over the past few years.
Yes, within the next three to five years, there will probably be another global recession.
And, yes, there will probably be another rash of financial crises – perhaps in Central Europe, which now looks like Asia did before its 1997 crisis.
Recent jitters about Iceland’s gaping trade deficit and Brazil’s new finance minister rippled around the world, reminding global investors that while many emerging markets are gradually moving towards investment-grade status, most are not there yet.
But the risks are two-sided, and sound economic policy is just as much about capitalizing on good times as avoiding bad ones.
Economic gurus at places like the World Bank have developed a ridiculously long list of steps that countries should take to raise their growth rates (the so-called “extended Washington Consensus”).
Like maintaining good health, it is not enough to concentrate on a single component.
But if there is one area where obvious opportunities exist, and where policy can really make a difference, it would have to be infrastructure investment.
India’s infrastructure problems are legendary, with airports and railroads that are comically inadequate.
However, aside from a few countries – including China, of course, but also Spain – low infrastructure spending is epidemic.
Even the United States has infrastructure that is hobbled by neglect, with collapsing bridges and a dangerously overburdened electrical grid.
Land-rich Brazil, too, is a case study in the consequences of under-investment.
Its infrastructure systems might be adequate to support the country’s tepid 3-4% growth rates, but they are hardly adequate to support the 6-7% rates that it ought to be enjoying amidst the current global boom.
Russia, despite Siberia’s massive oil and gas riches, isn’t even investing enough to support healthy growth in its energy industries, much less human development in the country’s impoverished areas (including hapless Siberia).
True, government infrastructure spending is often wasted.
My hometown of Boston recently managed to spend an astounding $15 billion dollars to move a few highways underground.
And that so-called “Big Dig” looks like a model of efficiency next to many of Japan’s infamous bridges to nowhere.
But there are ways to waste less.
Transparency in procurement works wonders.
So, too, does private sector involvement.
The Nobel laureate economist William Vickrey argued tirelessly in favor of privately financed toll roads.
Private oversight can often produce better and more efficient construction, and, in theory, toll roads help alleviate traffic congestion.
(Ironically, Vickery died while sitting in a traffic jam.)
Even China, which has added more than 50,000 kilometers of roads and dozens of airports over the past five years, makes use of private financing.
True, countries that have not cleaned up their fiscal act, such as India, must not recklessly plunge ahead with big government projects without counterbalancing reforms to ensure sustainability.
Fiscal prudence and stable inflation rates are cornerstones of today’s relatively healthy global economic environment.
But for countries that have scope to invest more, particularly those that are holding a surfeit of precious development dollars in idle US Treasury bills, the time may be ripe to reassess the balance of risks.
The IMF is absolutely right to remind ministers each April of downside risks.
Countries’ need for better infrastructure is no license to throw prudence out the window.
But when the world’s finance ministers recover from their April shock therapy, they also need to look at the opportunities.
NEW YORK – The upcoming G-20 meeting is a make-or-break event.
Unless it introduces practical measures to support the countries at the periphery of the global financial system, global markets will suffer another round of decline, just as they did after United States Treasury Secretary Timothy Geithner’s failure in February to produce practical measures to recapitalize America’s banking system.
The current financial crisis is different from all the others we have experienced since World War II.
On previous occasions, whenever the financial system came to the brink of a breakdown, the authorities got their act together and pulled it back from the brink.
This time the system actually broke down in the aftermath of Lehman Brothers’ collapse last September, and it had to be put on artificial life support.
Among other measures, both Europe and the US have effectively guaranteed that no other important financial institution will be allowed to fail.
This step was necessary, but it produced unintended adverse consequences: many other countries, from Eastern Europe to Latin America, Africa, and Southeast Asia, could not offer similarly convincing guarantees.
Abetted by the determination of national financial authorities at the center of the world economy to protect their own institutions, capital fled from the periphery.
Currencies fell, interest rates rose, and credit default swaps soared.
When the history of this crisis is written, it will be recorded that – in contrast to the Great Depression – protectionism first prevailed in finance rather than trade.
The International Financial Institutions (IFIs) are now faced with a novel task: to protect the periphery countries from a storm that emanated from the center.
They are used to dealing with governments; now they must learn to deal with the collapse of the private sector.
If they fail to do so, the periphery economies will suffer even more than those at the center.
Countries on the periphery tend to be poorer and more dependent on commodities than the more developed world, and they must repay more than $1.4 trillion in bank loans in 2009 alone.  These loans cannot be rolled over without international assistance.
British Prime Minister Gordon Brown recognized the problem and placed it on the G-20’s agenda.
But, in the course of preparations, profound attitudinal differences have surfaced, particularly between the US and Germany. 
The US has recognized that only using the credit of the state to the fullest extent possible can reverse the collapse of credit in the private sector.
Germany, traumatized by the memory of hyperinflation in the 1920’s and the consequent rise of Hitler in the 1930’s, is reluctant to sow the seeds of future inflation by incurring too much debt.
Both positions are firmly held and can be buttressed by arguments that are valid from the point of view of the country concerned.
But the controversy threatens to disrupt the April 2 meeting.
It should be possible for each side to respect the other’s position without abandoning its ownand to find common ground.
Instead of setting a universal target of 2% of GDP for stimulus packages, it is enough to agree that the periphery countries need international assistance to protect their financial systems and engage in countercyclical policies.
That is in the common interest.
If the periphery economies are allowed to collapse, developed countries will also be hurt.
As things stand now, the G-20 meeting will produce some concrete results: the resources of the International Monetary Fund are likely to be effectively doubled, mainly by using the mechanism of the New Arrangement to Borrow (NAB), which can be activated without resolving the vexing question of reapportioning voting rights in the IFIs.
This will be sufficient to enable the IMF to come to the aid of specific countries in trouble, but it will not provide a systemic solution without conditionality.
Such a solution is readily available in the form of Special Drawing Rights (SDR).
The mechanism exists and has already been used on a small scale.
SDRs are highly complicated and difficult to grasp, but they boil down to the international creation of money.
Countries that are in a position to create their own money do not need them, but the periphery countries do.
Rich countries should therefore lend their allocations to the countries in need.
This would not create a budget deficit for rich countries.
Recipient countries would have to pay the IMF a very low interest rate: the composite average treasury bill rate of all convertible currencies.
They would have free use of their own allocations, but the IFIs would supervise how the borrowed allocations are used to ensure that the borrowed funds are well spent.
It is difficult to think of a scheme where the cost/benefit ratio is so favorable.
In addition to the one-time increase in the IMF’s resources, there ought to be substantial annual SDR issues, say, $250 billion, as long as the global recession lasts.
To make the scheme counter-cyclical, the SDR issues could be callable in tranches when the global economy overheats.
It is too late to agree on issuing SDRs at the upcoming G-20 meeting, but if it were proposed by President Barack Obama and endorsed in principle by the majority of participants, it would be sufficient to give heart to the markets and make the meeting a resounding success.
CAMBRIDGE – The world economy enters 2009 with more uncertainty (and anxiety) than at any time in recent memory.
Although the financial crisis appears to be contained in the United States and Europe, its full repercussions will not be clear for some time.
The advanced countries are in for the worst economic downturn since the Great Depression.
But how long and deep will this recession be, and how badly will it affect emerging and developing nations?
We don’t have the answers to these questions, in part because the consequences will depend on what actions policymakers take.
The right responses will ensure that the world economy can begin to recover by late 2009.
Poor policy choices, on the other hand, will at best delay recovery and at worst do permanent damage.
Here is a list of things to watch for.
Will the US response be “bold” enough?
Barack Obama has promised that it will be, echoing at least part of Franklin D. Roosevelt’s famous call for “bold, persistent experimentation” at the height of the Great Depression in 1932.
Obama has a first-rate group of economists on his side, which ensures that he will not do anything silly.
But America’s circumstances are sufficiently exceptional that he will need advisers who are willing to try new, untested ideas – in other words, experimentation à la FDR.
In particular, he will need to go beyond Keynesian fiscal-stimulus policies to heal the deep wounds to economic confidence that lie at the root of the current crisis.
So far, confidence-building measures have been limited to financial markets, through public guarantees, liquidity support, and capital injections.
But workers who worry about being laid off are unlikely to go spend, regardless of how much money fiscal stimulus puts in their pockets.
Just as banks are hoarding cash, households will try to preserve wealth by increasing their saving.
So incentives targeted directly at preserving employment will have to be part of the solution.
Will Europe get its act together?
This could have been Europe’s moment.
After all, the crisis originated in the US and left American policy focused on its domestic troubles, opening up room for global leadership by others.
Instead, the crisis demonstrated the deep divisions within Europe – on everything from financial regulation to the requisite policy response.
Germany has dragged its feet on fiscal stimulus, stymieing what should have been the second leg of a globally coordinated fiscal action plan.
If Europe wants to pull its weight on the global stage, it will have to act with greater unity of purpose and shoulder a greater share of responsibility.
Alas, the best that can be hoped for at this stage is that Europe will not undermine the global fiscal stimulus that even the International Monetary Fund, the guardian of fiscal orthodoxy, regards as absolutely essential.
Will China hold together?
Even though a weak US response is the biggest risk on the economic side, what happens in China may well have deeper and more lasting consequences on the broader historical canvas.
For China is a country of enormous hidden tensions and cleavages, and these may erupt into open conflict in difficult economic times.
Experts on China differ on the rate of economic growth needed to create employment for the millions of Chinese who flock into the country’s cities every year.
But it is virtually certain that China will fall short of this threshold in 2009.
This explains the almost continuous stream of measures that emanate from Beijing these days: increased public spending, monetary easing, pressure on state enterprises to expand activity, subsidies to exporters, partial convertibility of the remninbi to spur trade with neighboring countries, and so on.
But will this do enough to stem the slowdown in an economy that has become hooked on external demand in recent years?
If social tensions rise, China’s government is likely to respond with greater repression, which will bode ill both for its relations with the West and for its medium-term political stability.
Experience shows that democracies hold the edge over authoritarian regimes when it comes to handling the fallout from crises.
It was democratic India (in 1991) and South Korea (in 1997-1998) that turned around their economies quickly, while Pinochet’s Chile (in 1983) and Suharto’s Indonesia (in 1997-98) fell into deeper quagmires.
Authoritarian regimes lack the institutions of conflict management that democracies provide.
So tensions spill over into the streets and take the form of riots and protests.
However the Chinese leadership responds, future generations may remember 2009 less for its global economic and financial crisis than for the momentous transformation that it caused in China.
Will there be enough global economic cooperation?
When domestic needs become paramount, global economic cooperation suffers.
But the costs of protectionism in trade and finance are especially large at moments like these.
The Great Depression was aggravated by the trade barriers that countries imposed to protect domestic employment.
This will be a temptation this time around as well.
And banks – whether explicitly nationalized or not – will be under pressure to prioritize domestic borrowers.
So far, the IMF has reacted with newfound vigor, establishing a much-needed short-term lending facility, which may well need to be expanded if emerging markets come under greater pressure.
The World Trade Organization, meanwhile, has wasted valuable time on the irrelevant Doha round.
It should have focused its efforts on monitoring and implementing the G-20’s commitment not to raise trade barriers.
Policymakers need to shed received wisdom and forget useless dichotomies such as “markets versus government” or “nation-state versus globalization.”
They need to come to grips with the reality that national regulations and international markets are inextricably linked with – and in need of – each other.
The more pragmatically and creatively they act, the more quickly the world economy will recover.
BERKELEY – The central insight of macroeconomics is a fact that was known to John Stuart Mill in the first third of the nineteenth century: there can be a large gap between supply and demand for pretty much all currently produced goods and services and types of labor if there is an equally large excess demand for financial assets.
And this fundamental fact is a source of big trouble.
A normal gap between supply and demand for some subset of currently produced commodities is not a serious problem, because it is balanced by excess demand for other currently produced commodities.
As industries suffering from insufficient demand shed workers, industries benefiting from surplus demand hire them.
The economy rapidly rebalances itself and thus returns to full employment – and does so with a configuration of employment and production that is better adapted to current consumer preferences.
By contrast, a gap between supply and demand when the corresponding excess demand is for financial assets is a recipe for economic meltdown.
There is, after all, no easy way that unemployed workers can start producing the assets – money and bonds that not only are rated investment-grade, but really are – that financial markets are not adequately supplying.
The flow of workers out of employment exceeds the flow back into employment.
And, as employment and incomes drop, spending on currently produced commodities drops further, and the economy spirals down into depression.
Thus, the first principle of macroeconomic policy is that because only the government can create the investment-grade financial assets that are in short supply in a depression, it is the government’s task to do so.
The government must ensure that the money supply matches the full-employment level of money demand, and that the supply of safe savings vehicles in which investors can park their wealth also meets demand.
How well have the world’s governments performed this task over the past three years?
In East Asia (minus Japan), governments appear to have been doing rather well.
Shortage of demand for currently produced goods and services and mass unemployment no longer loom as the region’s biggest macroeconomic problems.
Flooding their economies with liquidity, maintaining export-friendly exchange rates, and spending to employ workers directly and boost the supply of safe savings vehicles have made the Great Recession in East Asia less dire than it has been elsewhere.
In North America, governments appear to have muddled through.
They have not provided enough bank guarantees, forced enough mortgage renegotiations, increased spending enough, or financed enough employment to rebalance financial markets, return asset prices to normal configurations, and facilitate a rapid return to full employment.
But unemployment has not climbed far above 10%, either.
The most serious problems right now are in Europe.
Uncertainty about how, exactly, the liabilities of highly leveraged banks and over-leveraged peripheral governments are to be guaranteed is shrinking the supply of safe savings vehicles at a time when macroeconomic rebalancing calls for it to be rising.
And the rapid reductions in budget deficits that European governments are now pledged to undertake can only increase the likelihood of a full double-dip recession.
The broad pattern is clear: the more that governments have worried about enabling future moral hazard by excessive bailouts and sought to stem the rise in public debt, the worse their countries’ economies have performed.
The more that they have focused on policies to put people back to work in the short run, the better their economies have done.
This pattern would not have surprised nineteenth-century economists like Mill or Walter Bagehot, who understood the financial-sector origins of industrial depression.
But it does seem to surprise not only a great many observers today, but also a large number of policymakers.
In May, the world will mark the 60th anniversary of the end of World War II in Europe.
But instead of happily preparing for that occasion, the Baltic countries of Estonia, Latvia, and Lithuania – which scarcely 15 years ago regained the independence they lost in WWII – are uneasy.
The heads of state of all three countries have been invited to participate in the parades to be held in Moscow to celebrate the Red Army’s victory over Nazi Germany.
But the host of the celebration, Russia, in the guise of the Soviet Union, itself caused the war – the bloodiest in European history – whose end is being commemorated.
Of course, the USSR instigated the war in tandem with Adolf Hitler, but its responsibility is undeniable.
By holding these celebrations in Red Square, and thus highlighting the Soviet victory, today’s Russia is also celebrating its gains in that war.
One of those gains was my country, Lithuania, whose incorporation into Stalin’s empire was accompanied by countless tragedies.
Unlike Germany, Russia has never recognized its responsibility for the war and the mass graves of the innocent.
Thus, a former captive nation is now being invited to celebrate its captivity.
This is why almost all Lithuanians – indeed, most residents of the Baltic countries – feel queasy at the prospect of their leaders marking this anniversary in Moscow.
But Estonians, Latvians, and Lithuanians are not the only Europeans who should feel this way.
When Stalin offered Hitler his friendship in the spring of 1939 – formally concluded that summer in the Molotov-Ribbentrop Pact – Nazi aggression was assured of not being knifed in the back from the East and so was left with free hands to do as Hitler pleased in the West.
The Pact came after the pogroms of “Kristallnacht” in Germany, so its Soviet initiators knew pretty well to what destiny they were consigning the Jews of Poland and Lithuania, which, in accord with the first secret Protocol signed by Ribbentrop and Molotov on August 23, 1939, were to go to Hitler.
A month later, in equal secrecy, Hitler sold Lithuania to Stalin.
The other countries situated between Germany and the USSR were similarly sentenced to disappear as nations – sooner or later.
Their peoples were treated practically as though they did not exist; the aggressors’ only concern was territory.
The death sentences and torturing that were then imposed on almost entire nations and millions of people are, it now appears, to be silently accepted and noisily celebrated on May 9 in Moscow.
Some Russian officials want to unveil a monument Stalin to crown the festivities.
When Hitler’s Wehrmacht struck West, the USSR duly supported Germany in its war against Poland, France, Belgium, the Netherlands, Luxembourg, Denmark, Norway, and the United Kingdom.
As a result, cities in those countries were flattened and people killed not only by the Nazis, but also by their Soviet ally, which invaded Poland and supplied the Wehrmacht with the material it needed for its war against the West.
In return, Stalin’s USSR was given a free hand to attack Finland and to occupy Estonia, Latvia, and Lithuania, as well as a part of Romania.
In law, when two criminals seal a contract with the blood of their victims, that act remains a crime, even if the two criminals later have a falling out and spray bullets at one another.
The same applies to the two greatest European criminals of the twentieth century.
We must not forget the crimes that Hitler and Stalin committed together as de facto allies only because they later turned on each other.
The blood of WWII’s victims calls for justice and fairness, but most of all it demands honesty about who and what caused their tragic fate.
If those who gather in Moscow on May 9 do anything to validate Soviet war crimes, they will show themselves insensitive to the silent cries of WWII’s tens of millions of dead innocents.
The only real winner would be the spirit of that evil.
Over the past decade, the global economy has achieved unprecedented prosperity built on trade, international capital flows, and technological innovation.
Amidst this undeniable progress, however, remain widespread poverty, disease, and illiteracy.
In a world made smaller by modern telecommunications, satellite TV, and the Internet, the vast challenges of development that we continue to face confront us everyday.
Perhaps no individual has done more to raise the alarm – earning deserved credit for many successes and understanding all too clearly the remaining shortcomings – than James Wolfensohn, the outgoing President of the World Bank.
As Managing Director of the IMF, I have had the privilege of working closely with Jim Wolfensohn, seeing up close a man with an extraordinary mission: the sustainable reduction of global poverty.
Wolfensohn left a successful business career to lead the global campaign against poverty.
It is perhaps the ultimate tribute to his commitment and tenacity that his efforts over the past 10 years have attracted criticism as well as praise, for he has stood at the center of every major campaign aimed at alleviating the economic ills of our generation.
Wolfensohn led the World Bank onto the cutting edge of every important development debate, and was at the forefront of the effort to combat HIV/AIDS, as well as other deadly diseases that threaten so many impoverished countries.
He has been a forthright spokesman for women’s rights and a champion of environmental concerns, as well as a formidable advocate in arguing for debt reduction for the most heavily indebted nations.
He also has placed the World Bank at the center of the effort to help rebuild nations emerging from devastating civil conflict, from Bosnia to Sierra Leone to East Timor.
As World Bank president, Wolfensohn argued consistently that the world cannot be divided into “haves” and “have-nots.”
Poverty anywhere means poverty everywhere, and equitable growth is needed for the stability and security of all.
Indeed, that is the true meaning of globalization.
At the same time, Wolfensohn made a big contribution to development work by arguing that poverty must be treated as a multidimensional problem.
It is now widely accepted that financial assistance alone will not bring about effective poverty reduction.
Rather, sustainable, pro-poor growth is the key, requiring political stability – that is, peace and security for individuals – good governance, and ownership of policies by all stakeholders.
Under Wolfensohn, the World Bank followed through on this comprehensive and coordinated approach in a concrete fashion, making significant inroads into global poverty.
In the last 10 years, the Bank was the largest external financier of primary education, basic health care, HIV/AIDS programs, and programs aimed at protecting the environment and biodiversity.
This agenda goes to the heart of improving human dignity and maintaining sustainable development.
Wolfensohn’s insistence that corruption be confronted as part of the development process was another valuable step forward.
It used to be that even mentioning corruption in some official circles was considered taboo.
But corruption poses the single largest obstacle to growth and development in many countries, especially as it diverts resources from the poor.
The World Bank insisted that corruption be seen as a cancer, and that fighting it be made synonymous with fighting poverty.
Indeed, outspokenness was a hallmark of Wolfensohn’s tenure.
Many a government minister, Bank officer and NGO representative has experienced his blunt criticism, as well as his effusive praise.
The IMF has not been immune to this treatment. The strength of the Bretton Woods institutions lies in intellectual diversity, and the Fund benefited from Wolfensohn’s honesty, as well as from his commitment to Bank-Fund cooperation, which progressively deepened during the past decade.
The work of our two institutions — in areas as diverse as poverty reduction strategies, debt relief, and the unheralded joint program to analyze financial sectors in our member countries — strengthened the global economy.
Ultimately, development is about people.
Jim Wolfensohn’s greatest strength has been his genuine caring for the world’s poor.
His legacy will include a World Bank that is firmly committed to a world free of poverty.
The poor around the world may feel poorer from losing him as their champion and advocate.
In fact, their prospects are brighter because of his work over the past decade.
When is a free-trade agreement bad?
When the treaty's underlying purpose is neither about trade nor freedom.
Such a pact - calling for a "united economic space" - is now being entered into by Russia, Ukraine, Kazakhstan, and Belarus.
On the surface, a "united economic space" sounds like something to applaud.
But, sadly, the treaty will only entrench postcommunism's corrupt and criminal business practices, not increase trade or prosperity.
A huge benefit for the accession countries in preparing themselves to join the EU was that they were forced to conform to European business, political, and legal norms.
The proposed "united economic space" will also have its own norms - the ways of the oligarch, the corrupt bureaucrat, the crony capitalist, and the politically motivated prosecutor.
Does anyone doubt that the jailing of Mikhail Khodorkovsky, chairman of Yukos oil, is politically motivated?
I myself have endured numerous politically inspired investigations and prosecutions of my former business as a means to drive me out of politics.
Can anyone imagine such a prosecution occurring in the EU?
That Mr. Khodorkovsky is spending months in jail before he is formally charged tells us much about the nature of business, politics, and law in the nations of the former Soviet Union.
In the countries of the "united economic space," the rule of law typically means, "I rule, and I am the law." So, instead of promoting growth, the "united economic space" will retard it by discouraging competition and investment.
Instead of enhancing European stability, it will undermine it by dividing Europe into the EU's single market and an economic trading area ruled by arbitrary fiat and decree.
But, as a matter of economic principle, practical diplomacy, and visionary politics, aren't regional free-trade areas at least a step in the right direction?
After all, countries that scrap tariffs among themselves trade more and often raise their economic grow rates as a result.
Moreover, free-trade agreements are typically seen as politically valuable: countries tied by commerce are supposedly less likely to shoot at each other.
Unfortunately, the "united economic space" promises no such benefits.
By definition, it discriminates against countries outside the club, with which trade will not be liberalized.
Members will specialize in industries in which they lack comparative advantage, undercutting the main reason to support free trade in the first place.
Worse yet, markets will be carved up for political, not commercial, reasons, locking in inefficiencies.
The "political" argument - that regional trade bodies promote peaceful foreign relations - is simply wrongheaded in the post-Soviet case.
After all, Ukraine managed to eliminate its nuclear weapons and reach accommodation over the Black Sea fleet without joining a private economic bloc with Russia.
On the other hand, not long after the "united economic space" was announced, Russia began to cast covetous eyes on the Ukrainian Black Sea island of Tuszla.
Economic borders cannot and will not disappear until Russia and Ukraine agree on their territorial borders.
Because the proposed members of this new "united economic space" share Russian as alingua franca and a common past within the USSR, outsiders may dismiss too readily subtler differences in culture, outlook, and even vocabulary.
Because the region shares many outward forms of European culture, it is a short step to assuming that recent moves to free-markets and democracy will be seamless and permanent.
But the "united economic space" is also a perversion because the presence of Belarus and Kazakstan will ensure that democracy remains low on the agenda.
Another perversion of democracy is the fact that the supra-national body that is to administer the "united economic space" grants Ukraine and its 49 million people only 9.9% of votes, while it gives Russia and its 140 million people 83%.
That gross imbalance in representation is a shameful betrayal of Ukraine's sovereignty.
It is a deal that can only have been agreed to as the price of Russian support for Ukraine's President Leonid Kuchma as he desperately seeks to extend his presidency beyond the two-term limit that he faces this year.
My opposition to the "united economic space" is not opposition to Russia.
The more Ukraine trades abroad, the better; if more of that open trade goes Russia's way, so be it.
But that trade should reflect Ukraine's competing with the world, unconstrained by a private deal that excludes outsiders and their demands for a stable and predictable legal environment and the best business practices.
I am not one of those people who think Russia is so naturally collectivist that free trade and an open economy cannot work there.
Nor do I believe that Russia is so inherently autocratic that democracy must invariably fail.
But I do believe that, for these canards to be discarded, Russia and Ukraine must open themselves to global competition, not isolate themselves with each other.
Dmitri Likhachev, one of Russia's most respected intellectuals in the communist era, said that there is no such thing as the Russian soul; "we can create whatever future we want."
Ukraine and Russia, too, can create the future they want, but not by closing themselves off in a "united economic space" that, in reality, is nothing more than another dark corner.
Italy may have defeated France to win the World Cup, but the real winner was the “Old Europe” that Donald Rumsfeld once derided.
After all, who would have predicted a World Cup final between France and Italy?
It looks as if the national teams of the two “sick men of Europe,” felt obliged to change their countries’ images in the world.
In the Italian case, following the corruption scandals that have nearly sunk Il Calcio, Italy’s premier football league, the national team had to rehabilitate the game in the eyes of their fellow citizens.
More globally, however, it is as if “Old Europe” had decided that it was time to set the record straight and prove more dynamic than the world’s emerging forces.
Indeed, in the new global balance, where football has become much more than sport, Europe is back with a vengeance.
What has been unfolding in front of our eyes in the last four weeks has been a modern and reduced version of the balance-of-power system that dominated Europe and the world in the eighteenth and nineteenth centuries.
If football and its culminating moment, the World Cup, has become the universal religion of the global age, this is above all because it fulfills, in a non-spiritual way, contradictory instincts in human nature.
Football magnifies the cult of the individual and the glorification of the hero, but it is also a celebration of the cooperative team spirit.
More than any other collective activity, it channels the search for identity and identification that dominates our age.
Thanks to the World Cup, one is a citizen of the world, enjoying a spectacle together with billions of others on “Planet Soccer.”
Even in Washington, where I arrived at the beginning of the tournament, I was greeted at the airport by television screens showing the game.
The program was in English, but the advertisements were in Spanish.
In terms of football at least, the Hispanic community’s influence has brought the United States closer to Europe (though not, of course, in its team’s performance on the pitch).
At the same time, during the World Cup, fans are not only universal; they are also unique, and they can express their difference with impunity, sometimes in the most assertive, aggressive, and, unfortunately, occasionally racist manner.
In a world of “multiple identities,” to choose one’s team is in part to decide who one is.
From this standpoint, this year’s World Cup has not only witnessed the triumph of European nations – all semi-finalists were European for the first time since 1982 – but also the absence of even a glimmer of European emotions.
In my country, France, most supporters were clearly motivated more by post-colonial references than by European allegiance.
African teams, except when they were playing against France, were favored over those from the European Union.
As I watched the Croatia-Australia match early in the tournament, I surprised myself, too, as I realized that my emotions were with the Australian team, whatever that could mean, given that there were so many Croatians playing for Australia.
This deep search for identification should not be confused with a simple surge of nationalism.
Reality is more complex.
And this is not only because many coaches of the national teams are, like in the good old days, “foreign mercenaries,” with this Cup’s Swiss guards including the Brazilian coaches of Japan and Portugal, the Swedish coach of England, and the French coach of Tunisia.
The Cup’s explosions of proud nationalism hide more tortured realities.
Nostalgia is not what it used to be.
In 1998, when France won the Cup for the first time, the three colors of the French flag (blue, white, and red) were celebrated alongside with the three colors (“black, white, andbeur,the skin color of North Africans born in France to immigrant parents) of the members of the French team.
But that innocence has been lost because it is no longer possible to celebrate the triumph of the French model of integration.
Indeed, after the violent episodes of the last year, France’s immigrant communities have a very different message to deliver: “Without us, you would not have had this World Cup success.
Do you believe you can continue to ostracize the communities from which your soccer heroes come?”
From ping-pong diplomacy with China to the united German Olympic team that competed in 1990 before actual reunification, sport has prefigured political developments, and politicians everywhere have seized on the importance of the World Cup.
Football success has become part of countries’ “soft power.”
France may not have the military might of the US or the growth rate of China and India, but its team reached the World Cup championship, raising its standing in the eyes of billions of people – and perhaps giving a reprieve to its unpopular government.
But sport can also become a kind of gigantic, distracting screen behind which nasty regimes do outrageous things – the very opposite of the Olympic and World Cup spirit.
As the world was watching the football games in Germany, North Korea was testing long-range missiles and Palestinians in the governing Hamas launched attacks on Israel that prompted a bloody invasion of Gaza.
The World Cup is drama, excitement, a dream, but it is also a form of “global escapism.”
Football may explain the world, but it does not improve it.
And now we are back to reality.
For the past several weeks, attention was focused on the war in Iraq and on the fault lines within Europe that the conflict exposed.
But at the same time--perhaps because no one was looking--a critical breakthrough occurred in the Convention for the Future of Europe, where the European Union's new constitution is being framed.
Representatives of 16 countries--Austria, Ireland, Portugal, the three Scandinavian countries, and the ten states that will join the EU in May 2004--submitted a proposal, in the form of a declaration, that calls for preserving the EU's current delicate institutional balance.
They recommend retaining the European Commission as the proto-executive branch, the European Council to speak for national interests, and the European Parliament as the institution that represents Europe's citizens directly.
They reaffirm member states' equality by defending the Council's rotating presidency.
But, in addition to avoiding destructive changes, the proposal suggests a way forward for the Convention.
Specifically, it recommends a way to strengthen the democratic legitimacy of the Commission by allowing its president to be elected either by the Parliament or by an electoral college that also includes representatives from national parliaments.
This proposal is far superior to its predecessors.
Germany and France have proposed a system with two elected presidents--a Council president elected by its members and a Commission president elected by the European Parliament.
This is a strikingly bad idea.
Creating a two-headed executive of this sort would guarantee continuous clashes between the two power centers.
The "Gang of 16" is absolutely right that the EU should have a single president, not two.
In a world of internal and external security threats, the EU will need a stronger executive capable of reacting quickly to unfolding events.
If the Council presidency continues to rotate, then the logical entity to vest with executive authority is the president of the Commission.
But currently the president of the Commission is remote and inadequately accountable to his ultimate constituents.
Fundamental political reform is needed.
Unfortunately, the proposal fails to choose between the two alternatives for reform that it presents: election of the Commission president by the European Parliament or by an electoral college that also includes representatives from national parliaments.
At first sight, these two options may seem similar.
They are not.
The first alternative would steer the EU toward a parliamentary form of government, with the European Parliament entitled to both appoint and remove the Commission through a confidence vote.
The electoral college method, however, could be a first step toward a presidential form of government.
The path to a parliamentary model is more familiar in Europe, and at first it may appear safer.
But in the long run it could become very slippery.
Given Europe's political heterogeneity, the European Parliament is unlikely to be ruled by a single-party majority.
A European Commission accountable to a divided European Parliament would thus be bogged down by the usual inefficiencies of coalition governments.
By contrast, a European Commission that is directly elected would have great legitimacy, as well as being insulated from political fights inside the European Parliament, thereby increasing its political effectiveness.
The main problem is that a directly elected Commission President might be premature: Europe may not be ready for such a radical change.
This is why the electoral college idea is so important: it allows for a gradual transition towards a regime that is desirable in the long run.
An electoral college would allocate seats to each country in proportion to its population, and each candidate would receive electoral college votes proportional to the vote taken in that country, either by universal suffrage or in the national parliament.
This would force presidential candidates to campaign with equal energy in all countries.
Even better, the power to select the members of the electoral college should be given to national parliaments alone.
National parliaments have more legitimacy, attracting far higher voter turnout than elections to the European Parliament.
Europe would be brought closer to its citizens and national parliaments would gain a direct voice in EU decision making.
But delegates to the Convention should not stop there.
Countries should be given the option of allocating their electoral college votes via either universal suffrage or a vote in the national parliament.
The system could evolve toward one of direct election without having to amend the constitution.
Ultimately, the President of the Commission would be accountable directly to voters.
This is how the US gradually evolved into a presidential democracy, towards the mid-19th century.
Delegates to the Convention should keep in mind the provision of the Socratic Oath that reminds physicians, "First do no harm."
Beyond that, they can do genuine good by recognizing the merit of the proposal for an electoral college.
In 1947 Palestinian Arabs and their allies rejected a UN proposal to partition Palestine into a Jewish state and an Arab state, just as ten years before they rejected a similar partitioning proposed by the Peel Commission.
More recently, both at Camp David and at Taba in Egypt, Arab negotiators again rejected proposals that would have led to the creation of a Palestinian state alongside Israel.
Apparently, many Palestinian Arabs, and much of the Arab world, continue to think that they can do better than a two-state solution.
After decades of conflict, it seems that the Arabs have not given up their goal of making all of Palestine into an Arab state.
True, Arab leaders differ over tactics.
From time to time Arab negotiators enter into discussions about the mundane issues that prospective neighboring states would need to resolve, such as political boundaries, security arrangements, and economic relations.
It is possible that at some point the Arabs will agree among themselves that the creation of a Palestinian state that claims to be committed to peaceful coexistence with Israel will be a useful tactic.
American and European governments seem willing to use the carrot of economic aid to encourage this development, in the way that the US pays off Egypt and Jordan to acquiesce in the existence of Israel.
But, unless the Arabs reconcile themselves to the permanent reality of a Jewish state in Palestine, the creation of a Palestinian Arab state will not provide more than the temporary palliative of a tenuous truce between Arabs and Jews.
The Zionist project of creating a Jewish state in Palestine entails a return of the Jewish people to their ancestral homeland, a land in which Jews lived since biblical times and which the Diaspora never abandoned.
Whether or not this historical justification for Israel's creation is convincing, the important fact is that the Palestinian Arabs and their allies do not buy it.
Arabs express their disdain for Zionism by equating the Zionist project to the creation of a colony, to which millions of Jewish settlers have come.
According to this equation the conflict between Jews and Arabs replicates the conflicts between colonial settlers and indigenous peoples.
If the Arabs believe their own argument that Zionism is colonialism, with themselves as the victims, then, whether or not anybody else accepts this view, the lessons that the Arabs glean from colonial experiences become relevant to prospects for peace between Arabs and Israelis.
Over the years Israeli governments encouraged Arabs to participate in Israel's economy.
This policy, which Israelis view to be benevolent, supposes that economic integration of Arabs and Jews is possible without modifying the Zionist concept of Israel as a Jewish state.
But, from the Arab perspective this policy reinforces their equating of Zionism to colonialism.
Arab rhetoric often takes the colonial experiences of Algeria and South Africa as models for their conflict with Zionism.
These analogies are important because in both Algeria and South Africa, colonialism failed.
Descendants of the European settlers in Algeria fled back to Europe.
In South Africa, Blacks achieved political dominance over the descendants of British and Afrikaner settlers, large numbers of whom remain as a tolerated minority.
A permanent end to the conflict over Palestine will not be possible until the Palestinian Arabs and their allies become convinced that the failure of colonialism in countries like Algeria and South Africa is not a relevant lesson for them.
In other words Arabs will have to become convinced that they can neither subjugate the Jews nor drive the Jews out of Palestine.
The negotiating formula of "land for peace" and "breakthroughs" like the Oslo accords failed to dampen the conflict because the Arabs understandably interpret Israeli concessions as signs of weakness.
Unfortunately, the Israelis can show the Arabs that they cannot destroy Israel only by enduring the violent war of attrition that the Arabs are pursuing.
Moreover, there seems no obvious way to speed up the process of convincing the Arabs that Israel is here to stay except by making this war of attrition as costly as possible for them.
But suppose a two-state solution were achieved in the not-too-remote future.
In thinking about this possibility we are drawn to the example of Ireland, where a two-state solution has worked.
Having secured an independent Irish state, Catholics in the Republic of Ireland came to accept the existence of a settler enclave in Northern Ireland.
But, the Irish story has not had a happy ending.
The Catholic minority in Northern Ireland, whose position seems similar to that of the million Arabs who are Israeli citizens, eventually revolted against the dominant Protestants, with decades of violence resulting.
Even if a Palestinian state committed to peaceful coexistence were created, down the road Israel may be unable to avoid the fate of Northern Ireland.
MELBOURNE – Scholars have long dreamed of a universal library containing everything that has ever been written.
Then, in 2004, Google announced that it would begin digitally scanning all the books held by five major research libraries.
Suddenly, the library of utopia seemed within reach.
Indeed, a digital universal library would be even better than any earlier thinker could have imagined, because every work would be available to everyone, everywhere, at all times.
And the library could include not only books and articles, but also paintings, music, films, and every other form of creative expression that can be captured in digital form.
But Google’s plan had a catch.
Most of the works held by those research libraries are still in copyright.
Google said that it would scan the entire book, irrespective of its copyright status, but that users searching for something in copyrighted books would be shown only a snippet.
This, it argued, was “fair use” – and thus permitted under copyright laws in the same way that one may quote a sentence or two from a book for the purpose of a review or discussion.
Publishers and authors disagreed, and some sued Google for breach of copyright, eventually agreeing to settle their claim in exchange for a share of Google’s revenue. Last month, in a Manhattan court, Judge Denny Chin rejected that proposed settlement, in part because it would have given Google a de facto monopoly over the digital versions of so-called “orphan” books – that is, books that are still in copyright, but no longer in print, and whose copyright ownership is difficult to determine.
Chin held that the United States Congress, not a court, was the appropriate body to decide who should be entrusted with guardianship over orphan books, and on what terms.
He was surely right, at least in so far as we are considering matters within US jurisdiction.
These are large and important issues that affect not only authors, publishers, and Google, but anyone with an interest in the diffusion and availability of knowledge and culture.
So, while Chin’s decision is a temporary setback on the way to a universal library, it provides an opportunity to reconsider how the dream can best be realized.
The central issue is this: how can we make books and articles – not just snippets, but entire works – available to everyone, while preserving the rights of the works’ creators?
To answer that, of course, we need to decide what those rights are.
Just as inventors are given patents so that they can profit from their inventions for a limited time, so, too, authors were originally given copyright for a relatively short period – in the US, it was initially only 14 years from the first publication of the work.
For most authors, that would be enough time to earn the bulk of the income that they would ever receive from their writings; after that, the works would be in the public domain.
But corporations build fortunes on copyright, and repeatedly pushed Congress to extend it, to the point that in the US it now lasts for 70 years after the creator’s death.
(The 1998 legislation responsible for the last extension was nicknamed the “Mickey Mouse Protection Act” because it allowed the Walt Disney Company to retain copyright of its famous cartoon character.)
It is because copyright lasts so long that as many as three-quarters of all library books are “orphaned.”
This vast collection of knowledge, culture, and literary achievement is inaccessible to most people.
Digitizing it would make it available to anyone with Internet access.
As Peter Brantley, Director of Technology for the California Digital Library, has put it: “We have a moral imperative to reach out to our library shelves, grab the material that is orphaned, and set it on top of scanners.”
Robert Darnton, Director of the Harvard University Library, has proposed an alternative to Google’s plans: a digital public library, funded by a coalition of foundations, working in tandem with a coalition of research libraries.
Darnton’s plan falls short of a universal library, because works in print and in copyright would be excluded; but he believes that Congress might grant a non-commercial public library the right to digitize orphan books.
That would be a huge step in the right direction, but we should not give up the dream of a universal digital public library.
After all, books still in print are likely to be the ones that contain the most up-to-date information, and the ones that people most want to read.
Many European countries, as well as Australia, Canada, Israel, and New Zealand, have adopted legislation that creates a “public lending right” – that is, the government recognizes that enabling hundreds of people to read a single copy of a book provides a public good, but that doing so is likely to reduce sales of the book.
The universal public library could be allowed to digitize even works that are in print and in copyright, in exchange for fees paid to the publisher and author based on the number of times the digital version is read.
If we can put a man on the Moon and sequence the human genome, we should be able to devise something close to a universal digital public library.
At that point, we will face another moral imperative, one that will be even more difficult to fulfill: expanding Internet access beyond the less than 30% of the world’s population that currently has it.
NEW YORK – The most important contribution of the Universal Declaration of Human Rights, adopted by the United Nations General Assembly 60 years ago, on December 10, 1948, was to assert a powerful idea: rights are universal.
Rights do not depend on membership of a particular community or citizenship in a certain state. They do not derive from a social contract.
Rather, because rights are universal, they are attributes of all human beings.
Indeed, they are part of what makes us human.
Each of us may enjoy rights.
Those who exercise power may do so only in limited ways.
The limits are set by rights.
It is, of course, possible to trace the concept of universal rights at least as far back as seventeenth-century English thinking about natural law.
The concept was partially embraced in the French Declaration of Rights of 1789 and, to a greater extent, in Thomas Jefferson’s language in the same era about “inalienable rights.”  It also shaped the thinking of those in England who led the anti-slavery struggle of the second half of the eighteenth century, the first human rights movement.
Yet the Universal Declaration marked a giant step forward, as the world’s governments – with abstentions from the Soviet bloc states, Saudi Arabia, and apartheid South Africa, but with no votes in opposition – agreed that rights should take precedence over state power.
One way to think about the six decades that have elapsed since the adoption of the Universal Declaration is as a struggle to implement its promises.
For a long time, it was a losing struggle, marked especially by the spread of both communist and anti-communist tyrannies.
Things began to change in the 1980’s with the fall of military dictatorships in Latin America and in such East Asian countries as the Philippines and South Korea, and with the growing number of people engaged in the struggle for human rights in the Soviet empire.
By the end of the decade, many Soviet bloc regimes had collapsed. 
A factor that contributed to their demise was a shift in thinking that transformed the conflict between East and West away from one that emphasized economic systems.  Instead, it was the contrast between totalitarianism and respect for rights that completely discredited the oppressive regimes linked to Moscow and helped to bring them down.
South Africa’s largely peaceful transition to a multi-racial democracy in the early 1990’s was a further advance for rights.
But the last decade of the twentieth century was also indelibly stained by ethnic cleansing in ex-Yugoslavia and genocide in Rwanda, and during the current decade the tide has seemed to turn against the rights cause.
Powerful states such as China and Russia are not limiting themselves to authoritarian rule at home, but are also supporting those in other countries engaged in similar practices.
The same is true of lesser powers such as Iran and Venezuela.
Moreover, the United States has been squandering much of its capacity to promote human rights internationally.  In responding to the terrorist attacks on its own soil on September 11, 2001, the US has resorted to such measures as prolonged indefinite detention without charges, trials before military commissions lacking due process safeguards, and cruel, inhuman, and degrading treatment of detainees, including torture.
Other governments and intergovernmental bodies have not filled the gap left by the US.
The new UN Human Rights Council has so far disappointed those who hoped that it would be a more principled and effective body than its discredited predecessor, the UN Human Rights Commission.
The European Union has been a positive force in promoting rights in those countries aspiring to membership, but it has not demonstrated a capacity to exercise influence worldwide.
Today, the most effective force promoting human rights is global public opinion, informed and mobilized by the large and growing nongovernmental human rights movement, which, as in the recent war between Georgia and Russia, has focused international attention on violations of the laws of armed conflict that protect noncombatants.
It has also led the way in creating international criminal tribunals that prosecute and punish those who commit war crimes, crimes against humanity, and genocide.
These achievements are not stopping war, but they are reducing the number of terrible human rights violations that accompany armed conflict.
It is, of course, dismaying that 60 years after the adoption of the Universal Declaration of Human Rights, so many governments disregard the principles that they endorsed so long ago.
Yet without the legitimacy derived from the Universal Declaration and its role in promoting compliance, the nongovernmental human rights movement could not have developed into a global force.
The fact that the movement continues to secure advances even in difficult times is an indication of the enduring significance of what was achieved in 1948 when the world’s governments declared that rights are universal.
In recent years, many experts and commentators have said that the Atlantic Alliance would crumble or become irrelevant.
As a former ambassador to the North Atlantic Treaty Organization (NATO), I can say from experience that such dire predictions are nothing new.
As America’s current Secretary of Defense, it is clear to me that the transatlantic partnership is as relevant and essential as ever.
Consider the historic events that have taken place in the past year and the role played by the United States and Europe.
NATO added seven new members – nations eager to contribute to the Alliance in powerful ways.
In Afghanistan, eight million voters, 40% of them women, chose their first democratically elected President in 5,000 years.
In the Palestinian Authority, a democratically elected president offers the hope of a new chance for peace.
In Ukraine, ordinary citizens demonstrated the depth of their commitment to free and fair elections.
In Iraq, Saddam Hussein’s former subjects braved threats and voted for the first time with ballots that offered a choice of 70 political parties, rather than only one.
Across the country, voters arrived on crutches and in donkey carts, passing by posters that threatened: “You vote, you die.” What a damaging blow to the extremists, whose ideology the voters so clearly rejected.
While there have been differences over Iraq, such issues among longtime friends are not new.
Consider just a few of the divisions that have come up among NATO allies over the past decades.
In the 1960’s, France decided to pull out of the NATO integrated command and asked NATO forces to leave its territory.
In the 1980’s there was profound disagreement and controversy over President Ronald Reagan’s decision to deploy medium-range missiles in Europe.
In fact, as NATO Ambassador in the 1970’s, I had to fly back to testify against legislation in the US Congress to withdraw America’s forces from Europe in the middle of the Cold War.
Our Atlantic Alliance has navigated through some choppy seas over the years, but we have always been able to resolve the toughest issues.
That is because there is so much that unites us: common values, shared histories, and an abiding faith in democracy.
Today, we also share a common enemy.
Extremists have targeted all civilized societies across the globe: in New York and Washington; Istanbul; Madrid; Beslan; Bali; and more.
They do not seek an armistice with the civilized world.
They will not negotiate a separate peace.
They would like nothing better than for America and Europe to be at odds, rather than working together.
The arrests of numerous terrorist suspects last month by French and German authorities made clear that no one nation can do the critical work necessary to win the struggle against extremists.
Often quietly, America and European nations are sharing intelligence, capturing terrorists, and disrupting their finances.
As a result, some three-quarters of known al-Qaeda leaders have been killed or captured, and others are on the run.
Nor can any one nation stop the proliferation of dangerous weapons.
This is why some 60 nations have joined the Proliferation Security Initiative in an effort to keep deadly weapons from dangerous regimes.
In 2003, German, Italian, British, and American authorities confiscated nuclear equipment bound for Tripoli, leading to Libya’s decision to open its weapons inventories to inspectors.
Every NATO nation has personnel serving in the International Security Assistance Force in Afghanistan, which just changed command from a French to a Turkish general.
One of NATO’s newest members, Lithuania, is taking leadership of a Provincial Reconstruction Team – joining other European nations in contributing to Afghanistan’s stability and progress.
Indeed, more than half of all NATO nations have had forces in both Afghanistan and Iraq.
As the Iraqi people take more steps along the challenging road to democracy, more NATO countries have agreed to help train Iraqi security personnel by providing funds or equipment and by establishing a war college and military academies.
Members of NATO share much more than an alliance; we are united by ties of blood and purpose, a heritage of liberty, and a calling to confront extremists’ violence – and defeat it.
In the 60 years since World War II came to an end, we have counted on each other in times of peril and challenge.
I am old enough to remember both the rise and fall of the Berlin Wall, and the ascent and collapse of Nazism, of Fascism, and of Soviet Communism.
Together the members of NATO have helped to protect Kosovo and recently brought aid to the victims of a devastating tsunami.
Great achievements are possible when the Atlantic community is united.
That unity need not mean a uniformity of tactics or views, but rather a union of purpose.
Those who cherish free political systems and free economic systems share similar hopes.
Working together, those hopes can become realities for many more people.
ISLAMABAD &#45;&#45; As Pakistan gears up for its parliamentary election on February 18, many observers hope that the vote will usher in a period of stability and calm by lending popular legitimacy to the government.
But sometimes democracy is best served by refusing to participate.
The upcoming election, to be held under the illegal Provisional Constitutional Order (PCO) implemented following President Pervez Musharraf’s state of emergency on November 3, is such a case, which is why my party and its coalition partners are boycotting the vote.
To be sure, contesting the election would provide my party with a great opportunity to take issues to the people.
In fact, my party’s support has been growing, with opinion polls now indicating that it is the second most popular in the frontier province – and gaining ground in every other province.
But elections by themselves don’t bring democracy.
Zimbabwe’s president, Robert Mugabe, loves elections.
Egyptian President Hosni Mubarak has been holding elections for 27 years.
Uzbekistan’s Islam Karimov has been in power for 30 years, and has just been “elected” to a fresh seven-year presidential term.
Elections are meaningful only if they are perceived to be free and fair, which requires independent referees.
When my party started eleven years ago, we called ourselves the Movement For Justice.
We demanded an independent judiciary, because we believed that democracy and prosperity are impossible without the rule of law, and that the rule of law requires a judiciary that can act as a constraint on the government.
Having gone to university in western countries, we were inspired by the American system of check and balances.
So it is a shock to us that the US State Department keeps talking about free and fair elections and abolishing the state of emergency, but without mentioning the reinstatement of the judges – including the Chief Justice of the Supreme Court – that Musharraf illegally dismissed.
If the judges are not reinstated, how can there be free and fair elections?
Who decides what is free and fair?
Musharraf?
This is where the battle lines are now drawn, and where the future of the country will be decided.
If the Chief Justice and the judges are reinstated, we can move toward a genuine democratic system.
But if Musharraf manages to get his own PCO judges established in the country, then we will head toward a period of turmoil.
After all, how can the party of a man who has less than 5% support win the election now without rigging it?
Unfortunately, most of the political parties have failed to stand up for the democratic process.
Major parties like the Pakistan Muslim League (Nawaz) have decided to participate, following the lead of the late Benazir Bhutto’s People’s Party.
And, of all the major parties that are contesting the election, only the PMLN is demanding the reinstatement of the judges.
Fortunately, the people of Pakistan – students, opinion makers, and, above all, lawyers – are standing up for the judges, doing the work that should have been done by political parties.
We see lawyers marching, getting beaten up, filling the jails, and yet remaining resolute.
They are suffering huge financial losses by boycotting the courts, and yet they are determined that the Chief Justice must be reinstated.
So the dividing line in Pakistan is not between liberals and extremists, but between those who support the status quo and those who oppose it.
Parties that call themselves democratic are not only going along with Musharraf in this fraudulent election, but are also helping to restore the status quo.
The solution to dysfunctional democracy is not military dictatorship, but more democracy.
Pakistanis understand democracy, because we have a democratic culture.
Our founder was a great constitutionalist, and Pakistan came into being through the vote.
The problem has been that because we have lacked an independent judiciary, we have not had an independent election commission.
So all our elections, except for one in 1970, have been rigged.
India, with which Pakistan shares a similar background, went through 40 years of dysfunctional democracy with a one-party system.
But in the last 16 years it has begun to reap the fruits of genuine democratic competition, because an independent judiciary and electoral commission gives people confidence that their vote can make a difference.
Until we have the same in Pakistan, no election can be free and fair.
For two and a half years, I supported Musharraf and believed his promises to bring genuine democracy to Pakistan.
I’ve learned my lesson about Musharraf.
But, more importantly, no military dictator can succeed where Musharraf has so clearly failed.
Winston Churchill once said, “War is too serious a business for generals.” The same is true of democracy.
Federal Reserve Chairman Ben Bernanke has allowed global stock markets to railroad him into a whopping 75-basis-point cut in interest rates just one week before the regularly scheduled meeting of the Fed’s decision-making Open Market Committee.
European Central Bank President Jean-Claude Trichet would never allow this to happen to the ECB – he manipulates markets; markets don’t manipulate him.
Indeed, with America’s economy in apparent freefall, Trichet is threatening euro-zone trade unions with pre-emptive interest-rate hikes unless they behave as he sees fit.
These threats may be proving counter-productive to the achievement of price stability in the euro-zone economy, the central bank’s primary objective.
For example, to make his threats of an interest-rate hike in the midst of a global slowdown credible, the ECB president is using his press conferences to tell the world how strong European growth is.
Besides being at odds with reality, the claim of strong growth actually encourages the trade unions to ask for even higher wages.
And why shouldn’t they if things are as good as Trichet claims?
Trichet also makes his job more difficult for himself by talking up Europe’s inflationary threat.
His colleague on the ECB Governing Council, Bundesbank president Axel Weber, seems to have gotten the message that the more ECB officials talk up inflationary fears, the more the trade unions will ask.
So he recently toned down his rhetoric by warning that euro-zone inflationary pressures should not be “over-dramatized.” 
How true!
The essential economic reality confronting the ECB today is that the American economy is falling headlong into a serious slump – Bernanke’s surprise cut speaks volumes to this.
It defies economic logic to think that the global economy – including Europe – will escape its consequences. 
As European growth slows, so will inflationary pressures.
So Trichet should relax, stop threatening others, and let the economic slowdown do the work for him.
Even with sticky wages and prices in Europe, the global slowdown will reduce energy, commodity, and food prices on world markets, all of which are important factors behind currently elevated European inflation levels.
The crude oil price already has dropped substantially from its highs at the beginning of the year.
But the evolving slowdown is not the only reason the threat of a wage-price spiral in Europe is overblown.
Germany is facing a key wage negotiation with public-sector unions.
Even if the unions win large wage increases – which is very likely and entirely justifiable given their past restraint – this will have only a negligible effect on Europe’s price stability.
Increased public-sector wage costs mean increased government spending on wages.
If this is financed by cutbacks elsewhere in the budget, the main consequence will be only a re-distribution of government spending, which is not necessarily inflationary.
Nor is it inflationary if the wage increases are financed by higher taxes.
Only if the budget surplus diminishes would there be an inflationary impact, and that would not be due to a wage-price spiral, but to an increase in net government demand, which actually might not be a bad thing for an economy facing a potentially severe economic slowdown.
In the United States, it should be remembered, the need for a fiscal stimulus developed, so it seems, out of the blue.
The same may happen in Europe, especially given the ECB’s refusal to cut interest rates.
A decent settlement with public-sector workers could give Germany a “backdoor” fiscal stimulus just at the right moment – when aggregate demand is flagging.
The real problem with a generous wage settlement with public-sector unions is that private-sector unions could use it to get more than their productivity gains warrant.
Contracts with the metal and chemical workers also are coming up for negotiation this year in Germany, and union leaders are talking tough.
Berthold Huber, the head of Germany’s huge IG Metall engineering union, recently promised his rank and file “a mega year” for pay increases.
But the global slowdown, which takes the fangs out of the strike threat, will keep private-sector workers in line no matter how much their leaders may rant and rave.
Everyone, including bellicose trade unionists, tends to become more reasonable when the economy turns south.
Rather than encourage the unions with exaggerated talk of strong European growth and inflationary excess – and disrespect them with threats and interventions – Trichet should speak softly and let nature take its course.
AMSTERDAM &#45;&#45; When “tolerance” becomes a term of abuse in a place like the Netherlands, you know that something has gone seriously wrong.
The Dutch always took pride in being the most tolerant people on earth.
In less feverish times than these, no one could possibly have taken exception to Queen Beatrix’s speech last Christmas, when she pleaded for tolerance and “respect for minorities.”
But Geert Wilders, leader of the right-wing, anti-Muslim Freedom Party, was so disgusted by the Dutch queen’s “multi-cultural rubbish” that he wanted her to be stripped of her constitutional role in the government.
Wilders, a popular rabble-rouser whose party occupies nine seats in the Dutch parliament, compares the Koran to Hitler’s Mein Kampf, wants to stop Muslims from moving to the Netherlands, and thunders that those who are already in the country should tear up half the Koran if they wish to stay.
Tolerance towards Islam is cowardly appeasement in his eyes.
He thinks that Europe is in peril of being “Islamized.” “There will soon be more mosques than churches,” he says, if true Europeans don’t have the guts to stand up and save Western civilization.
Notwithstanding his call to ban the Koran, Wilders and his admirers claim to believe in unfettered free speech as a Western birthright.
Beatrix stated that the right to free speech does not automatically mean the right to offend.
Wilders disagrees.
No criticism of Islam, however offensive, should ever be hampered by political correctness.
Wilders uses every opportunity to test Muslims’ (often very limited) tolerance.
His latest provocation is a short film denouncing Islam, which is yet to be shown, but has already caused panic all around.
Remarkably for a Dutch politician – and a minor one, at that – news of Wilders’s antics has reached the world press.
So Dutch embassies are bracing themselves for violent demonstrations, and the government is considering special security measures.
Some commentators suggest that Wilders, born and raised as a Catholic in a provincial Dutch town, is, like his Muslim enemies, a true believer, driven by the goal of keeping Europe “Judeo-Christian.”
Perhaps, but this is probably a red herring.
His war on Islam is also, and perhaps even mainly, a war on the cultural and political elites, the Dutch intellectual establishment, the Eurocrats of Brussels, and the liberal-minded queen.
Indeed, his speeches are studded with references to arrogant elites who are out of touch with the feelings of the common man. “Tolerance” is seen as weak and elitist, typical of people who live far removed from the harsh realities of the street, where violent and unruly foreigners menace upstanding Dutch folks.
This notion of the elitist appeaser is not confined to the Netherlands.
In Israel, the educated Jewish activists who criticize Israeli abuses against Palestinians, the peaceniks who believe that negotiation is better than violence and that even Arabs have rights, are called, with a knowing sneer, “beautiful souls.”
The common man, rooted in the real world, supposedly knows better: uncompromising toughness, the hard line, is the only way to get results.
In the United States, the word “liberal,” in the mouths of populist radio hosts and right-wing politicians, has become almost synonymous with “effete East Coast snob” or, worse, “New York intellectual.”
Liberals, in this view, are not only soft, but are somehow distinctly un-American.
The association of elites with foreignness, tolerance, and metropolitan cities is nothing new.
Elites often can speak foreign languages, and big cities are traditionally more tolerant and open to mixed populations.
Modern populism – American politicians running, or pretending to run, “against Washington,” or French populists speaking for “deep France” – is invariably hostile to capital cities.
Brussels, the capital of the European Union, stands for everything populists, whether left or right, hate.
And Muslim immigrants live in Amsterdam, London, or Marseilles, not in the kind of small towns where right-wing populists find most of their support.
Still, the politics of resentment works best when it can tap into real fears.
There are reasons for people to feel anxious about economic globalization, pan-European bureaucracy, the huge and not always effectively controlled influx of immigrants, and the aggression of radical political Islam.
These anxieties have too often been ignored.
There is a sense among many Europeans, not just in the Netherlands, that they have been abandoned in a fast-changing world, that multi-national corporations are more powerful than nation-states, that the urban rich and highly educated do fine and ordinary folks in the provinces languish, while democratically elected politicians are not only powerless, but have abjectly surrendered to these larger forces that threaten the common man.
Tolerance is seen as not just weak, but as a betrayal.
The Muslim threat is, of course, not a fantasy.
A small number of ideological extremists has inflicted real violence in the name of Islam, and will continue to do so.
But the popular resentment of Islam goes deeper and wider.
Wilders, and others like him, are not just attacking Islamic extremists.
His success is based on that sense of tolerance as betrayal.
And, as so often happens, the loathing of elites has found an outlet in the loathing of outsiders, who look different and whose ways are strange.
We must fight Islamic extremism, but not by tapping into the darkest gut feelings of the unthinking mob.
Nothing good ever came from that.
LONDON – Earlier this month, the International Criminal Court (ICC) upheld the request of the court’s chief prosecutor to issue an arrest warrant for Omar el-Bashir, the President of Sudan, charging him with war crimes and crimes against humanity.
Bashir responded by expelling foreign aid agencies looking after the refugee camps in Darfur.
This is the first time that a sitting head of state has been indicted for war crimes, with reaction around the world mainly divided between those who hailed the move as a great step for international justice and those who condemned it as colonialism.
Both positions are hopelessly buried in intellectual and moral fog.
The warrant was no leap forward.
From the legal point of view, it makes no difference whether the accused is a sitting or former head of state.
But it makes an enormous practical difference that an incumbent ruler can do a lot more future damage to his people than an ex-ruler, and therefore should be given no incentive to retaliate.
As a result of Bashir’s policies, 300,000 people are estimated to have died and 2.7 million displaced in Darfur.
The expulsion of the aid agencies has put over a million Darfuris at risk of epidemics and starvation.
According to the statute that established the ICC, the prosecutor is required to ensure that any prosecution is in the interests of the victims as well as of justice.
But, to lawyers like the ICC prosecutor, the abstract claims of justice are more vivid than any concrete duty of protection.
In this case, justice comes with poisoned arrows.
Emboldened by the warrant and its elusive suggestion of international support, the Darfuri rebels, the Justice and Equality Movement, have walked out of peace talks with Sudan’s government.
Meanwhile, Bashir, with little to lose, will no doubt take the opportunity to attack his enemies.
The counter-argument is that the threat of indictment will deter rulers from wicked behavior.
But the law will deter only if its sanctions are credible.
A law that cannot be enforced deters no one.
In fact, it weakens respect for law.
Moreover, while the fear of being hauled off to The Hague may havesome effect in deterring rulers from committing crimes against humanity, the claim that the Bashir warrant will deter the current crop of human rights’ violators is derisory.
Indeed, it is likely to prolong wicked regimes.
Robert Mugabe, for example, refuses to leave office – at great cost to Zimbabwe’s people – for fear of being put on trial.
Whatever the attractions of giving criminals “nowhere to hide, whatever the consequences,” the consequences cannot be ignored when the criminals are heads of state.
The policy of never negotiating with terrorists cannot be scaled up to state level when hundreds of thousands of lives are at stake.
The charge of colonialism, meanwhile, is simply reflex: colonialism no longer exists.
The charge that international law isjust “western law” is also rubbish.
International law is the conscience of mankind.
But the perception that the law is selectively applied happens to be true.
In the Nuremberg trial of 1946, which laid the basis of current international law, the main charge against the Nazi leaders was that of “planning and waging aggressive war.”
Prohibition of war except for self-defense is embedded in the United Nations Charter.
But the ICC’s creators deemed the waging of aggressive war – which the International Military Tribunal at Nuremberg called “the supreme international crime” – to be outside the court’s jurisdiction.
This guaranteed legal immunity for the leaders who carried out the invasion of Iraq.
The charge of selective application also applies to the Bashir warrant.
Bashir stands accused of war crimes and crimes against humanity.
The latter were first defined in the Nuremberg principles of 1950 to include murder, extermination, enslavement, deportation and “other inhumane acts.”
In 1998, these other acts were clarified to mean false imprisonment, torture, rape, persecution of a group, enforced disappearance of persons, and apartheid.
It comes as no surprise, then, to read in theArab News that Bashir’s warrant “reeks of hypocrisy.”
Where, indeed, are the arrest warrants for Bush and Cheney?
Does extraordinary rendition not count as “enforced disappearance of persons”?
Does the waterboarding of Khalid Sheikh Mohammed not count as torture?
Why is Vladimir Putin not standing trial for war crimes in Chechnya?
The answer is simple: where the interests of a UN Security Council member or one of their clients are at stake, the court’s jurisdiction ends.
The ICC is like a cobweb: small flies get stuck, but wasps and hornets get through.
Until the United States ratifies the ICC treaty, the Court is bound to seem to many to be little more than a politicized kangaroo court.
Without American support, it has little hope of earning legitimacy, let alone doing its job effectively.
The Security Council has the power to defer the warrant for Bashir’s arrest for renewable periods of one year.
It can do this indefinitely, and it seems likely that it will.
The idea is that deferring the warrant will give the Security Council leverage over Sudan.
Gareth Evans, a former Australian Foreign Minister, has called it “a powerful diplomatic tool,” while theWashington Post has called for the warrant to be used “as a bargaining chip with Mr. Bashir and his Chinese and Arab allies.”
They believe that the threat of arrest can be used to force Bashir to mend his ways.
If this proves true, the ICC and its sponsors have muddled justice with diplomacy.
If the world can dispense justice only at the expense of the weak and to the advantage of the strong, it should stick to the older tools of crime prevention: force and negotiation, and leave justice out of it.
LOS ANGELES – As the United States stumbles through its economic challenges at home, the pressure of world events will not subside.
But America’s ability to address them has changed.
Its fiscal weakness limits its ability to act as global policeman.
Despite the relatively costless overthrow of the Qaddafi regime, America’s prolonged interventions in Afghanistan and Iraq have severely strained the public’s tolerance for an active foreign policy.
Nonetheless, the US seems destined to remain the world’s most important actor for the foreseeable future.
But today it is an actor without a script – it lacks a strategic guide comparable to the Cold War’s containment doctrine to prioritize policy.
Quite simply, the ad hoc policymaking that directed interventions in the Balkans, Somalia, southwest Asia, and the Middle East in the past two decades will not suffice in this new era of limitations.
This suggests that the US should seek out an overarching strategy to discipline its impulses to fight wars of choice or engage in nation-building efforts.
President Barack Obama’s 2010 National Security Strategy nurtures broad policy aspirations – “[n]ow we must position the United States to champion mutual interests among nations and peoples” – but falls short as a practical guide.
I suggest an alternative strategy, one already embedded in America history, though largely unrecognized.
But making explicit what lies implicit can sharpen US decision-making.
I call this strategy the “Watershed Doctrine.”
A watershed is a tipping point, a turning point, a game changer.
When the US has confronted a “negative watershed” – a lethal threat to the country – it committed meaningful financial and human resources in order to address the risks.
Positive watersheds – opportunities to engineer seismic shifts in international or regional political affairs through nation-building, or to use economic and military assistance to prevent plausible negative watersheds – demand an equal level of commitment.
The Watershed concept provides policymakers with a standard to use – or at the very least to debate.
It is an organizing tool for policymaking: Is an international challenge a watershed or not?
If so, get involved.
If not, stay out.
We find watersheds throughout American history.
The War of 1812 and the Civil War are clear examples.
Had American forces not expelled the British from US territory in the first, and had Abraham Lincoln and the Union not prevailed in the second, the country would have been balkanized and unable to become the dominant power of the twentieth century.
By contrast, America’s flirtation with colonialism in the Spanish American War, its involvement in Mexico, Central America, and the Caribbean throughout the twentieth century, and, arguably, World War I, were not watersheds for the US.
But America’s inability after the Great War to overcome Old World politics at Versailles and isolationism at home marked a failed opportunity to promote a positive watershed.
That failure placed the world on the path to the negative watershed posed by Nazi Germany and Imperial Japan.
Nothing foreordained that the US and its allies would prevail.
Had the Axis’s negative watershed succeeded, the US would have become a far different country.
A positive watershed, under-appreciated today, developed in the years immediately after World War II with the political transformation of Germany and Japan.
America’s remarkable investment of resources in this outcome made both countries stable, peaceful democracies, thereby eliminating them as adversaries and turning them into vital bulwarks against the next harbinger of a negative watershed, the Soviet Union.
Unlike the battle against the Axis, the US fought the Cold War in many ways, on many fronts, and over many decades – using politics, economics, and nuclear deterrence, as well as limited armed action, to ensure the USSR’s containment.
In time, the US had to accept that each political contest or military battle lost was not a watershed as long as its core interests in Europe, the Far East, and Latin America were not threatened.
Through trial and error – backed by a durable political and economic system – the US prevailed and the Soviet Union disintegrated.
The rise of Islamic fundamentalism poses another historic challenge, though one that is far more inchoate than any that the US has faced before.
In other times, the challenge would not even be called a watershed.
But the risk that weapons of mass destruction could be turned against the US makes it so.
Then there is the “Arab Spring,” a potential positive watershed that calls upon the US to decide how deep a political, economic, and military commitment it ought to make to nurture positive results.
Today, the US is a more sober and realistic country than it was in the heyday of the early post-Cold War period.
But, in the aftermath of setbacks in regions where it intervened, and with heightened economic distress at home, the US finds itself uncertain about how to respond to changing global events.
Pursuing a “Watershed Doctrine” might provide the right answer.
LOS ANGELES – A strange sense of déjà vu is gripping Washington these days, as the debate over ratification by the United States Senate of the New Strategic Arms Reduction Treaty (New START) with Russia heats up.
Spats have broken out between the Obama administration, future presidential contenders, senators, and arms control and defense experts.
There may not be nostalgia for the Cold War in any of this, but much of that era’s mindset can be perceived again in the arguments being knocked about.
The Senate must decide whether New START enhances American security.
Unfortunately, whatever the decision -- which has been delayed perhaps until late Fall to allow Obama’s administration more time to muster support for the treaty -- the US and Russian governments will continue to place each other in the nuclear crosshairs for the foreseeable future.
New START builds on a legacy of strategic nuclear arms limitation that goes back to the 1970’s.
Former US Secretary of State Henry Kissinger captured the allure in recent testimony: “The subject of nuclear arms control grew out of the seemingly paradoxical effort of those who had created the largest and most destructive arsenals to avoid by negotiation the ultimate consequences of their own decisions.”
Over the years “avoiding…the ultimate consequences” through limitations butted against the bitter legacy of the surprise attacks suffered by both the US and Russia in World War II.
After the war, each adopted a “never be surprised again” policy, and so went on to invest trillions of dollars in a multitude of hardened, mobile, and concealed nuclear weapons to deter the other.
The result produced tens of thousands of nuclear warheads.
In time, strategic arms control treaties became the measure of the political relationship.
With the Soviet Union’s collapse, a unique opportunity to end the nuclear competition emerged.
While elimination did take place in the former Soviet Republics, the Kremlin hung on to its nuclear arsenal – the last vestige of Russia’s former superpower status.
Likewise, US administrations have remained wedded to the Bomb.
As a result, the “nuclear hostage” relationship of the Cold War continued, capped in 2002 by the Strategic Offensive Reduction Treaty, which set the upper limit on warheads at 2,200 by 2012.
In the spring of 2009, speaking in Prague, Obama advanced a bold ambition: a world without nuclear weapons.
But his audacity confronted a world in which the Bomb remained at the heart of many countries’ deterrence strategies.
Obama muddled his message further by admitting that he did not expect to see abolition in his lifetime.
Nonetheless, New START marks a step in the direction of disarmament.
It would limit each country to 1,550 strategic warheads on 700 deployed delivery vehicles.
Verification relies on 18 on-site inspections, notification of forces in and out of service, missile-test flight information and other data exchanges, plus a consultative commission to iron out compliance.
Were the US Senate to fail to ratify New START, the treaty’s proponents argue that the US would lose predictability about Russia’s nuclear activities, resulting in greater distrust and risk of miscalculation, making both sides less secure.
But arms-control skeptics take issue with this.
Throughout the Cold War, they viewed restraints on America’s development and fielding of nuclear weapons as compromising national security.
Fears that the Soviet Union would cheat reinforced their position.
And cheating did indeed upset the broader superpower relationship.
Today, similar apprehensions stoke opposition to New START.
To allay such concerns, the Obama administration committed to a multi-year increase in the budgets of the US military’s nuclear-weapons laboratories.
And in the April 10 release of the Nuclear Posture Review, Obama’s administration warned nuclear-armed states and others tempted to violate the Nuclear Non-Proliferation Treaty that they would remain nuclear targets.
Missile defense has become another bone of contention.
The language in the preamble to New START states that the agreement will not “undermine the viability and effectiveness of the strategic offensive arms of the Parties.”
Critics contend that the clause, along with the Kremlin’s implied warning that it could withdraw from the treaty unilaterally were America’s defenses to become too robust, provides the Kremlin with leverage to impede deployment of any strategic missile-defense system.
The Obama administration repeatedly denies such claims, along with others that the treaty’s verification provisions remain insufficient.
It scoffs at assertions that Russia would cheat by multiplying warheads on bombers or new rail-based missile carriers, arguing that the Kremlin would want to avoid America’s compensatory response.
But Obama’s team does concede one point: New START fails to curtail Russia’s large numerical advantage in tactical nuclear weapons.
Arguing that short-range devices pose no risk to the American homeland, US negotiators plan to press for reductions in follow-on talks.
Despite the claims by both the Bush and Obama administrations that Russia and the US are no longer adversaries, it seems that the rapprochement has not translated into elimination of mutual nuclear targeting.
The result, even if new START is ratified, should satisfy no one.
NEW YORK – The world is at a crossroads.
Either the global community will join together to fight poverty, resource depletion, and climate change, or it will face a generation of resource wars, political instability, and environmental ruin.
The World Bank, if properly led, can play a key role in averting these threats and the risks that they imply.
The global stakes are thus very high this spring as the Bank’s 187 member countries choose a new president to succeed Robert Zoellick, whose term ends in July.
The World Bank was established in 1944 to promote economic development, and virtually every country is now a member.
Its central mission is to reduce global poverty and ensure that global development is environmentally sound and socially inclusive.
Achieving these goals would not only improve the lives of billions of people, but would also forestall violent conflicts that are stoked by poverty, famine, and struggles over scarce resources.
American officials have traditionally viewed the World Bank as an extension of United States foreign policy and commercial interests.
With the Bank just two blocks away from the White House on Pennsylvania Avenue, it has been all too easy for the US to dominate the institution.
Now many members, including Brazil, China, India, and several African countries, are raising their voices in support of more collegial leadership and an improved strategy that works for all.
From the Bank’s establishment until today, the unwritten rule has been that the US government simply designates each new president: all 11 have been Americans, and not a single one has been an expert in economic development, the Bank’s core responsibility, or had a career in fighting poverty or promoting environmental sustainability.
Instead, the US has selected Wall Street bankers and politicians, presumably to ensure that the Bank’s policies are suitably friendly to US commercial and political interests.
Yet the policy is backfiring on the US and badly hurting the world.
Because of a long-standing lack of strategic expertise at the top, the Bank has lacked a clear direction.
Many projects have catered to US corporate interests rather than to sustainable development.
The Bank has cut a lot of ribbons on development projects, but has solved far too few global problems.
For too long, the Bank’s leadership has imposed US concepts that are often utterly inappropriate for the poorest countries and their poorest people.
For example, the Bank completely fumbled the exploding pandemics of AIDS, tuberculosis, and malaria during the 1990’s, failing to get help to where it was needed to curb these outbreaks and save millions of lives.
Even worse, the Bank advocated user fees and “cost recovery” for health services, thereby putting life-saving health care beyond the reach of the poorest of the poor – precisely those most in need of it.
In 2000, at the Durban AIDS Summit, I recommended a new “Global Fund” to fight these diseases, precisely on the grounds that the World Bank was not doing its job.
The Global Fund to Fight AIDS, TB, and Malaria emerged, and has since saved millions of lives, with malaria deaths in Africa alone falling by at least 30%.
The Bank similarly missed crucial opportunities to support smallholder subsistence farmers and to promote integrated rural development more generally in impoverished rural communities in Africa, Asia, and Latin America.
For around 20 years, roughly from 1985 to 2005, the Bank resisted the well-proven use of targeted support for small landholders to enable impoverished subsistence farmers to improve yields and break out of poverty.
More recently, the Bank has increased its support for smallholders, but there is still far more that it can and should do.
The Bank’s staff is highly professional, and would accomplish much more if freed from the dominance of narrow US interests and viewpoints.
The Bank has the potential to be a catalyst of progress in key areas that will shape the world’s future.
Its priorities should include agricultural productivity; mobilization of information technologies for sustainable development; deployment of low-carbon energy systems; and quality education for all, with greater reliance on new forms of communication to reach hundreds of millions of under-served students.
The Bank’s activities currently touch on all of these areas, but it fails to lead effectively on any of them.
Despite the excellence of its staff, the Bank has not been strategic or agile enough to be an effective agent of change.
Getting the Bank’s role right will be hard work, requiring expertise at the top.
Most importantly, the Bank’s new president should have first-hand professional experience regarding the range of pressing development challenges.
The world should not accept the status quo.
A World Bank leader who once again comes from Wall Street or from US politics would be a heavy blow for a planet in need of creative solutions to complex development challenges.
The Bank needs an accomplished professional who is ready to tackle the great challenges of sustainable development from day one.&nbsp;
NEW YORK – In almost every part of the world, long-festering problems can be solved through closer cooperation among neighboring countries.
The European Union provides the best model for how neighbors that have long fought each other can come together for mutual benefit.
Ironically, today’s decline in American global power may lead to more effective regional cooperation.
This may seem an odd time to praise the EU, given the economic crises in Greece, Spain, Portugal, and Ireland.
Europe has not solved the problem of balancing the interests of strong economies in the North and those of weaker economies in the South.
Still, the EU’s accomplishments vastly outweigh its current difficulties.
The EU has created a zone of peace where once there was relentless war.
It has provided the institutional framework for reuniting Western and Eastern Europe.
It has fostered regional-scale infrastructure.
The single market has been crucial to making Europe one of the most prosperous places on the planet.
And the EU has been a global leader on environmental sustainability.
For these reasons, the EU provides a unique model for other regions that remain stuck in a mire of conflict, poverty, lack of infrastructure, and environmental crisis.
New regional organizations, such as the African Union, look to the EU as a role model for regional problem-solving and integration.
Yet, to this day, most regional groupings remain too weak to solve their members’ pressing problems.
In most other regions, ongoing political divisions have their roots in the Cold War or the colonial era.
During the Cold War, neighbors often competed with each other by “choosing sides” – allying themselves with either the United States or the Soviet Union.  Pakistan tilted towards the Americans; India towards the Soviets.
Countries had little incentive to make peace with their neighbors as long as they enjoyed the financial support of the US or the USSR.
On the contrary, continued conflict often led directly to more financial aid.
Indeed, the US and Europe often acted to undermine regional integration, which they believed would limit their roles as power brokers.
Thus, when Gamal Abdel Nasser launched a call for Arab unity in the 1950’s, the US and Europe viewed him as a threat.  The US undercut his call for strong Arab cooperation and nationalism, fearing a loss of American influence in the Middle East.
As a result, Nasser increasingly aligned Egypt with the Soviet Union, and ultimately failed in the quest to unite Arab interests.
Today’s reality, however, is that great powers can no longer divide and conquer other regions, even if they try.
The age of colonialism is finished, and we are now moving beyond the age of US global dominance.
Recent events in the Middle East and Central Asia, for example, clearly reflect the decline of US influence.
America’s failure to win any lasting geopolitical advantage through the use of military force in Iraq and Afghanistan underscore the limits of its power, while its budget crisis ensures that it will cut its military resources sooner rather than later.
Similarly, the US played no role in the political revolutions underway in the Arab world, and still has not demonstrated any clear policy response to them.
President Barack Obama’s recent speech on the Middle East is a further display of America’s declining influence in the region.
The speech drew the most attention for calling on Israel to return to its 1967 borders, but the effect was undercut when Israel flatly rejected the US position.
The world could see that there would be little practical follow-up.
The rest of the speech was even more revealing, though it drew little public notice.
When Obama discussed the Arab political upheavals, he noted the importance of economic development.
Yet when it came to US action, the most that the US could offer financially was slight debt relief for Egypt ($1 billion), scant loan guarantees ($1 billion), and some insurance coverage for private investments.
The real message was that the US government would contribute very little financially to the region’s economic recovery.
The days when a country could depend on large-scale American financing are over.
We are, in short, moving to a multi-polar world.
The Cold War’s end has not led to greater US dominance, but rather to the dissemination of global power to many regions.  East Asia, South Asia, Latin America, and the Middle East have new geopolitical and economic influence.
Each region, increasingly, must find its own path to economic development, energy and food security, and effective infrastructure, and must do so in a world threatened by climate change and resource scarcity.
Each region, therefore, will have to secure its own future.
Of course, this should occur in a context of cooperation across regions as well as within them.
The Middle East is in a strong position to help itself.
There is a high degree of economic complementarity between Egypt and the oil-rich Gulf States.
Egypt can supply technology, manpower, and considerable expertise for the Arab region, while the Gulf provides energy and finance, as well as some specialists.
The long-delayed vision of Arab economic unity should be returned to the table.
Israel, too, should recognize that its long-term security and prosperity will be enhanced as part of an economically stronger region.
For the sake of its own national interests, Israel must come to terms with its neighbors.
Other regions also will find that the decline of US power increases the urgency of stronger cooperation between neighbors.
Some of the greatest tensions in the world – say India and Pakistan, or North and South Korea – should be defused as part of region-wide strengthening.
As the EU shows, ancient enmities and battle lines can be turned into mutually beneficial cooperation if a region looks forward, to resolving its long-term needs, rather than backward, to its long-standing rivalries and conflicts.
BERLIN: Like old battle horses feeling young as the bugle sounds, Cold War strategists are feeling the adrenalin mount as missile defense becomes front page news.
True, the defense against missiles which Bill Clinton (reluctantly) and George W. Bush (enthusiastically) are proposing – with massive support from America’s Congress – is different from Ronald Reagan’s Star Wars dream of twenty years ago: NMD is supposed to catch only a modest number of warheads, not provide complete protection against enemy missiles.
Nevertheless, the issue rekindles old debates over deterrence, mutual assured destruction and nuclear arms control, and revives the rivalry between the nuclear powers just when nuclear weapons had lost much of their relevance.
Amazingly, debate is heating up even though it is uncertain that NMD will work.
Even if it does work, it will be ten to fifteen years, possibly longer, before NMD is operational.
So tempers are rising over something which, if and when it happens in the distant future, may or may not have much impact.
Normally cautious governments are positioning themselves now as if the future were around the corner.
What explains this odd behavior?
Not blind faith in technology.
After all, the history of missile defense is a tale of technology constantly disappointing its advocates in and out of government.
No one in his right mind can assume that something never achieved before, namely destroying a small number of warheads in flight, will happen over night.
Of the three tests so far conducted, one failed almost, two entirely, which is why President Clinton left the matter to his successor.
If President Bush, as he has hinted, now favors a different design, it will take even more time to develop the architecture and devise a test program.
Nobody can be sure that it will work either.
Governments are worried now, not because of capabilities, but because of America’s real or imagined intentions.
While Americans claim that NMD is not directed against anyone, that all the US wants is to protect its citizens against states like Iraq or North Korea, almost everyone else thinks differently: Russians fear that America wants to cement its military superiority (and Russia's inferiority) forever; the Chinese are concerned that NMD signals American readiness to help Taiwan remain independent; Europeans worry that America's plans invite tensions with Russia and may separate the US from Europe.
Because political intentions, not technical capabilities matter, NMD creates problems now: it pushes Russia into confrontation, heightens Chinese nervousness, and underpins a European sense of estrangement from the US.
Damage is done from the word go while the end of the road remains obscured.
Inflating this political damage is the fact that, thirty years ago, the US and the then Soviet Union renounced effective defense against strategic nuclear missiles.
Normally, a US defense project in its infancy would not cause the excitement NMD generates.
But the 1972 ABM Treaty prohibits, for the indefinite future, systems to protect either country against such nuclear attack.
As the US proceeds with NMD, it will either have to violate the Treaty or give six months notice to quit, something both signatories are entitled to do if they feel their vital security interests demand it.
In the eyes of many, that would amount to America opting out of the structure of nuclear arms control built in the latter part of the Cold War.
The Bush Administration argues that, because the Cold War is over, the formal disappearance of the ABM Treaty would not mean a loss of nuclear stability.
But stability is as much a matter of political perceptions as of technical calculations.
By limiting strategic missile defense, the old treaty provides a certain predictability of deterrence for all nuclear weapon states.
Its disappearance would affect all other arms control agreements.
Russia threatens to scrap all of them once the US leaves the ABM-Treaty.
While this threat lacks credibility (it would harm Russian interests most) it has a certain logic.
The main question NMD poses is not how to prepare for a future world of missile defense but how to dampen today’s political concerns.
Such efforts are getting discretely underway.
Legal experts in Washington suggest that modest preparations for building missile and radar sites do not violate the ABM-Treaty and so do not yet require a US notice to quit.
For now, the Bush Administration will await the outcome of tests before deciding.
Both Moscow and Washington hint at possible deep cuts in their offensive nuclear arsenals.
Skeptical European allies are being mollified by US assurances of close consultation.
The most important of confidence-building measures, a modification of the ABM-Treaty to allow for limited missile defense, is being explored.
Russia’s early "nyet" may not be the last word.
So political turmoil with Russia and Europe might be calmed.
But what about China?
In contrast to Europe and Russia, China is not party to an alliance (as is Europe) or to a network of arms control treaties through which political solutions can evolve (like Russia), factors that contribute to Asian instabilities and Chinese sensitivity.
Here confidence can only be built through the approach taken by the US to China.
Regrettably, there are no indications yet that the problem is recognized in Washington as a serious one.
All this comes as a disappointment to old Cold War strategists.
While brushing up the vocabulary and abbreviations of the age of superpower deterrence, they discover that such a world has gone.
Missile defense is not a threat to US-Russian strategic stability; its mishandling is a threat to political predictability.
By announcing its determination to go ahead with a distant NMD, the US has created political turbulence which it must address now if major damage is to be avoided.
Yukos, once Russia’s leading oil company and a favorite of international investors, is in its death throes.
At what many perceived to be a rigged auction, the company’s best assets were sold off to a previously unknown bidder and are now back in the hands of the Russian state.
The shell of what remains continues to challenge the company’s fate, notably in a Houston, Texas courtroom.
But these spasms will not revive the corpse.
What matters now is whether Russia’s economy will share Yukos’s fate.
The damage to Russia’s economic growth prospects from the Yukos affair may yet prove temporary, barring a repeat performance with other companies.
But whether the Yukos affair proves to be an isolated case, as the Kremlin insists, depends on a reading of Russian President Vladimir Putin’s motives.
One possibility is that Putin is not sincere about his aim of doubling Russia’s GDP in a decade.
Recent opinion polls suggest that this is the view of much of Russia’s cynical public.
On this view, the privatizations of the 1990’s were a scam serving only the powers that be.
But any reversal of those privatizations – such as the effective expropriation of Mikhail Khodorkovsky and his Menatep partners in Yukos – signifies not the dawn of social justice but rather a new group of bosses “expropriating the expropriators,” as Lenin used to say.
A less nihilistic view is that the Yukos affair suggests above all a series of improvisations by Putin rather than a coherent agenda.
This is somewhat reassuring.
Much evidence points to the affair originating not in a systematic nationalization project, but rather in the Kremlin’s perception that Khodorkovsky aimed to use his wealth to privatize the Russian state itself.
Such “state capture” occurred in Russia in the late 1990’s and to an even greater extent under the Kuchma regime in neighboring Ukraine which, ironically, Putin tried to preserve.
Neutralizing the perceived threat from Khodorkovsky meant depriving him of the means to achieve his ambitions by separating his Menatep Group from Yukos’s future cash flows.
The massive tax claims against Yukos used for this purpose were precisely that – the means rather than the end.
Had the goal been mere recovery of tax arrears, there would have been no need to break up the company: Yukos could have settled even these colossal liabilities on a civilized installment schedule.
To be sure, expropriating Menatep made shares in Yukos – a company that by 2003 attracted more domestic and foreign savings than any other in Russia – virtually worthless.
But this seems like collateral damage from the pursuit of an overriding political objective.
Much now depends on whether the same is true of the other major outcome, which is that Yukos’s principal asset – Yuganskneftegaz – is now in state hands, while its remaining units appear doomed to nationalization.
Is this another incidental by-product of the campaign against Khodorkovsky, or is it part of the core Kremlin agenda?
Nationalization certainly seems to appeal to the powerful faction comprising Putin’s former KGB colleagues and associates from his native St. Petersburg, one of whom last year became the chairman of Rosneft, the wholly state-owned oil company which acquired Yuganskneftegaz.
But if the influence of these so-calledsiloviki was unbridled, similar attacks would have been launched against other major companies by now.
As it is, even Roman Abramovich’s Sibneft – potentially the most vulnerable company due to its oligarch ownership and its use of the same tax minimization schemes that were the undoing of Yukos – merely faces a preliminary claim for back taxes.
In contrast to Yukos, the claim does not exceed the company’s cash on hand and so poses no threat to its existence.
Even the nationalization of Yukos’s assets may reflect little more than the absence of alternative buyers, given the obvious political obstacle passing those assets on to other domestic private-sector players (i.e., oligarchs), and the legal and reputational barriers to foreign investors.
So the interpretation that best fits the facts so far is that the political aim of separating Khodorkovsky and Menatep from Yukos led in practice to nationalization, but that this was not the underlying goal.
There is no green light for opportunistic predators in and around the Kremlin who now control Yuganskneftegaz to grab other companies’ assets at will.
If so, the damage caused by the Yukos affair should be minimal.
Yet, even on the assumption that Putin has no plans to nationalize key natural resource companies, he clearly desires strong state control over these “commanding heights” of the economy.
That in itself will result in overall GDP growth falling below potential, owing to the inferior productivity and greater corruption in the major companies that the state controls or heavily influences.
In a speech marking the state gas monopoly Gazprom’s tenth anniversary in 2003, Putin stated his position explicitly, speaking of the company as one of the few strong geopolitical levers left to Russia after the Soviet collapse.
Putin’s geopolitical preoccupations could be accommodated by sensibly preserving state ownership of pipeline infrastructure in the hydrocarbons sector, while allowing private companies to extract, process, and sell Russia’s oil and gas.
Instead, Putin has allowed Gazprom’s management to block proposals from his own government on the long overdue unbundling of the company.
Putin has sought an economic transformation of Russia similar in kind, if not in degree, to China’s boom.
The prize is higher living standards for Russia’s long-suffering people and a recovery in the country’s international standing.
Despite uncertainty about Putin’s intentions, that prize is not out of reach.
Indeed, at this point the only action more harmful than the Yukos affair would be another Yukos affair.
For almost two generations, Abba Eban was Israel's voice - its messenger to the high and mighty among the nations as well as to the Jewish people all over the world.
Since he first appeared at the side of Dr. Chaim Weizmann in the late 1940's during the struggle for Jewish statehood and sovereignty, few people could articulate the Zionist and later the Israeli case with comparable eloquence and conviction.
With his Churchillian prose and almost Shakespearean cadences, his mellifluous phrases and sonorous voice carried for decades a message of hope from a people that could have lost all hope and trust in humanity after the horrors of World War II.
As Ambassador to the United States and the UN, and later as Foreign Minister, he represented an Israel with which the world's liberal imagination could identify.
Larger and more powerful nations were envious of so a powerful spokesman, and his speeches became textbook models for statesmen and diplomats in distant lands.
His books - which he found time to write despite the hectic demands of diplomacy - were a unique combination of enormous erudition and crystalline clarity.
His scholarly training and rhetorical gifts supplemented each other in a rare fashion.
Rarely has a small country been represented by a statesman of such world stature: only Thomas Masaryk and Jan Smuts come to mind to compare with him.
He was a true patriot, in the old-fashioned sense of the word: proud of his people, but never ethno-centric; a man of the world, but deeply embedded in Jewish cultural heritage; focused on the plights and tribulations of the Jewish people, but never losing the universal horizon of mankind.
In short, he was a modern Jew in the best sense of the word.
It was said of Prime Minister Levi Eshkol that he spoke seven languages, all of them in Yiddish.
Of Eban it could be said that he spoke ten languages, and all of them with an Oxford/Cambridge accent.
Yet what appealed to the outside world was not always an asset in the rough and tumble of Israeli politics.
Perhaps Eban was too urbane, too much of a scholar and gentleman to be able to make it - in Disraeli's phrase - to the top of the greasy pole.
Together with Golda Meir and Moshe Dayan he had to leave government in 1974 in the wake of the Yom Kippur War.
He could hardly have been held responsible for the hubris which led to the avalanche of 1973, yet it nonetheless brought him down as well.
He never found his way back, and when confronted with the New Politics of primaries and populism, he became dispirited when he could not cope with this new style.
In the international arena, Eban's pen was his sword, and the spoken word his lance.
He was less adept in political infighting in Israel.
He could be a fierce turf fighter, yet it is fair to say that he could have fought harder for his moderate and dovish views in the post-1967 government in which he served.
It is far from clear if he would have prevailed, given his lack of an independent political base, but his international prestige and standing might have given him a chance if he would have chosen to throw the gauntlet.
He never did.
Eban's silence in the last years was not only a product of his disenchantment with Israeli politics or his failing health.
At a time when public debate in Israel is torn between pseudo-religious nationalist fanatics and anti-Zionists masquerading as post-modernists, the moral certitudes of Eban, for all their urbanity, may sound shallow.
But nation-building requires moral stamina, and Eban provided it to his people and the world in abundance.
Without having spoken to Eban in the last few years, I have no doubt that he would be extremely unhappy about the turn of events after the failure of Camp David and Taba in 2000-01, and the present course of Israeli policies would fill him with foreboding.
Yet in all probability he would have been even more deeply disappointed in the inability of the Palestinians to come to terms with the existence of the Jewish state.
As an Arabist by training, immersed in Arab and Muslim culture, he always hoped that the glorious Arab past could be rejuvenated, that an Arab and Muslim culture of tolerance could triumph over fanaticism and extremism.
This was the bedrock of his hope for reconciliation between Jew and Arab.
That this Arab renaissance - to use the phrase of the great Palestinian scholar George Antonius - did not take place may have been Eban's greatest disappointment.
Despite the high-born image Eban projected, he was an extremely vulnerable person: what some occasionally discerned as traits of vanity may have had their origins in his humble origins.
While appearing to own the Queen's English, Eban was not to the manor born: he came from the extremely modest fringes of Anglo-Jewry.
He was, in the true sense of the word, a self-made man, whose pluck, ambition, drive and inner belief in his destiny carried him to the pinnacle of his achievements.
His was the aristocracy of the spirit.
In this Abba Eban was a true representative of the people he so gloriously represented.
Crown Prince Abdullah’s peace proposal was born in Saudi Arabia but some allege that it was conceived in the US.  Revealed to a visiting American journalist during a private dinner with the Crown Prince, the plan centers on a “full normalization” of relations between Israel and all Arab countries, in return for an Israeli withdrawal from all the Palestinian territories it occupied in 1967.  The proposal may get a boost when Abdullah meet President Bush in Texas later this spring, but its early survival depends first on its reception at the upcoming Arab summit in Beirut.
The suspicions which surround Abdullah’s peace initiative, and which dismiss it as stillborn, are founded in the belief that it was conceived to appease Saudi Arabia’s American critics and to divert them from focussing on Saudi domestic tensions.  Since September 11th, Saudi Arabia has felt intense pressure to explain (and explain away) its links to Osama bin Laden’s al-Qaeda terrorist network because fifteen of the nineteen plane hijackers were Saudis (indeed, the majority of prisoners held by the US at Guantanamo Bay in Cuba are said to be Saudi citizens) and Saudis are often viewed as a major source of al-Qaeda’s finances.  Moreover, it is alleged that the Saudi government has become preoccupied with appeasing America, despite the beginning of the second Palestinian intifada, and Israel’s ongoing occupation of Palestine.
At the same time, Saudi public opinion has been inflamed, mostly because of their rulers’ apparent apathy toward the plight of the Palestinian people, particularly when contrasted with Osama bin Laden’s lethal propaganda.  Since the terrorist attacks of September 11th, Saudi leaders have felt pressed to accommodate public revulsion about the mistreatment of the Palestinians, but worry that doing so may even further jeopardize their now brittle relations with America.
Crown Prince Abdullah’s initiative provoked widespread surprise, not because the idea is so startlingly new, but because of its source and timing.  A proposal for “full normalization” with Israel coming from an Islamic regime that bases its legitimacy on the austere Islamic doctrines of the Wahhabi seems both peculiar and progressive.  But Saudi Arabia’s long-cultivated image of stability, benevolence, and mystical communal harmony has given way under the endless glare of the American press.  Its educational system, too, is increasingly portrayed as a breeding ground for hatred of the West.  Something had to give.
America’s seemingly hostile attention gave rise to the speculation that Crown Prince Abdullah’s initiative really denotes a Saudi public relations counteroffensive, hatched in the Saudi embassy in Washington to cover over the rift with the US.  Indeed, the subsequent, deafening silence by other Saudi leaders to the proposal appears to confirm it as a public relations move for which they need not risk any of their own domestic political capital.
Although Abdullah is usually referred to in the West as Saudi Arabia’s ruler, the debilitated King Fahd’s six full brothers are the ones who truly represent the real power in the Kingdom.  Almost nothing, neither in support nor in opposition, has been uttered by the King and these other brothers, collectively known as the “Sudairis.”
The Sudairis, it seems, have apparently left their half brother alone to twist in the wind.  Abdullah’s proposal could weaken his position domestically, particularly in relation to the country’s powerful Islamists.
For although Crown Prince Abdullah has his own loyal entourage, including the National Guard, he confronts opposition from senior figures in the religious establishment.
The idea of normalizing relations with Israel has incited fierce hostility among some imams in the mosques as well as on the Internet.
As a result, Abdullah’s initial proposal has been diluted, so much so that, by the time of the Arab foreign ministers meeting held in Cairo on 8 March, the phrase “full normalisation” was watered down to the more amorphous phrase “full peace,” the meaning of which no one knows.
Does it mean an Israeli Star of David flag flying in Riyadh, or that Abdullah will visit Jerusalem to be greeted with a kiss from Ariel Sharon?  No one knows, but the very fact that such questions are being raised in Saudi Arabia poses a serious risk to Abdullah.
Objections are also voiced against the fact that the Crown Prince’s plan does not mention the right of exiled Palestinians to return to their homes in the West Bank and Gaza, as well as Israel proper, and that Arabs must tailor their diplomatic initiatives to the taste of the American media.  To the average Saudi, the initiative appears as either a sell-out or the prelude to a fresh Arab humiliation.  In either case, it is widely feared that either of these outcomes is intended simply to appease America.

Reactions in the Middle East reflect longstanding rivalries for leadership, as well as fears about American and Israeli intentions.  Egypt’s leaders deem the proposal a mere conversation, something not nearly as serious as a written diplomatic initiative.  Libya offered its own supposedly more “encompassing and comprehensive” proposal.
Hizbollah’s leader Mohammed Fadlallah defined the initiative as one of Arab submission, while Syria demanded a guarantee of its interests in the Golan Heights.
Arab League officials approved the proposal. 
Crown Prince Abdullah’s initiative is meant to be made official during a speech at the Arab League summit in Beirut of 27-28 March.
How it is received may not only determine the state of Israel-Palestine negotiations for a considerable time to come, but Saudi Arabia’s domestic peace as well.
As a species, human beings have a major self-control problem.
We humans are now so aggressively fishing, hunting, logging, and growing crops in all parts of the world that we are literally chasing other species off the planet.
Our intense desire to take all that we can from nature leaves precious little for other forms of life.
In 1992, when the world’s governments first promised to address man-made global warming, they also vowed to head off the human-induced extinction of other species.
The Convention on Biological Diversity, agreed at the Rio Earth Summit, established that “biological diversity is a common concern of humanity.”
The signatories agreed to conserve biological diversity, by saving species and their habitats, and to use biological resources (e.g., forests) in a sustainable manner.
In 2002, the treaty’s signatories went further, committing to “a significant reduction in the current rate of biodiversity loss” by 2010.
Unfortunately, like so many other international agreements, the Convention on Biological Diversity remains essentially unknown, un-championed, and unfulfilled.
That neglect is a human tragedy.
For a very low cash outlay – and perhaps none at all on balance – we could conserve nature and thus protect the basis of our own lives and livelihoods.
We kill other species not because we must, but because we are too negligent to do otherwise.
Consider a couple of notorious examples.
Some rich countries, such as Spain, Portugal, Australia, and New Zealand, have fishing fleets that engage in so-called “bottom trawling.”
Bottom trawlers drag heavy nets over the ocean bottom, destroying magnificent, unexplored, and endangered marine species in the process.
Complex and unique ecologies, most notably underground volcanoes known as seamounts, are ripped to shreds, because bottom trawling is the “low cost” way to catch a few deep sea fish species.
One of these species, orange roughy, has been caught commercially for only around a quarter-century, but already is being fished to the point of collapse.
Likewise, in many parts of the world, tropical rainforest is being cleared for pasture land and food crops.
The result is massive loss of habitat and destruction of species, yielding a tiny economic benefit at a huge social cost.
After cutting down a swath of rainforest, soils are often quickly leached of their nutrients so that they cannot sustain crops or nutritious grasses for livestock.
As a result, the new pasture land or farmland is soon abandoned, with no prospect for regeneration of the original forest and its unique ecosystems.
Because these activities’ costs are so high and their benefits so low, stopping them would be easy.
Bottom trawling should simply be outlawed; it would be simple and inexpensive to compensate the fishing industry during a transition to other activities.
Forest clearing, on the other hand, is probably best stopped by economic incentives, perhaps combined with regulatory limits.
Simply restricting the practice of land clearing probably would not work, since farm families and communities would face a strong temptation to evade legal limits.
On the other hand, financial incentives would probably succeed, because cutting down forest to create pastureland is not profitable enough to induce farmers to forego payments for protecting the land.
Many rainforest countries have united in recent years to suggest the establishment of a rainforest conservation fund by the rich countries, to pay impoverished small farmers a small amount of money to preserve the forest.
A well-designed fund would slow or stop deforestation, preserve biodiversity, and reduce emissions of carbon dioxide the burning of cleared forests.
At the same time, small farmers would receive a steady flow of income, which they could use for micro-investments to improve their household’s wealth, education, and health.
Aside from banning bottom trawling and establishing a global fund for avoided deforestation, we should designate a global network of protected marine areas, in which fishing, boating, polluting, dredging, drilling, and other damaging activities would be prohibited.
Such areas not only permit the regeneration of species, but also provide ecological benefits that spill over to neighboring unprotected areas.
We also need a regular scientific process to present the world with the evidence on species abundance and extinction, just as we now have such a process for climate change.
Politicians don’t listen very well to individual scientists, but they are forced to listen when hundreds of scientists speak with a united voice.
Finally, the world should negotiate a new framework no later than 2010 to slow human-induced climate change.
There can be little doubt that climate change poses one of the greatest risks to species’ viability.
As the planet warms, and rain and storm patterns change dramatically, many species will find themselves in climate zones that no longer support their survival.
Some can migrate, but others (such as polar bears) are likely to be driven to extinction unless we take decisive action to head off climate change.
These measures are achievable by 2010.
They are affordable, and in each case would ultimately deliver large net benefits.
Most importantly, they would allow us to follow through on a global promise.
It is too painful to believe that humanity would destroy millions of other species – and jeopardize our own future – in a fit of absent-mindedness.
New York – This week the United Nations Human Rights Council will debate the report of the fact-finding mission led by Judge Richard Goldstone on human rights violations in the Gaza conflict.
Let us hope  it is a full and fair examination based on the report’s findings and recommendations.
Goldstone and his team concluded that both Israel and Hamas, the Palestinian group controlling Gaza, committed war crimes and possibly crimes against humanity during the period of the conflict which the investigation addressed. The report calls for credible investigations of  alleged rights violations  and recommends that the UN Security Council require both sides to report back within six months on the results, including any prosecutions they will carry out in connection with the violations identified.
Failure to do so, in the view of Goldstone’s commission, should result in the Security Council referring the matter to the prosecutor for the International Criminal Court in The Hague.
Unfortunately, rather than debating Goldstone’s detailed findings and the merits of his recommendations on ways to move forward, there are indications that governments may focus instead on the process leading up to the investigation and seek to limit full discussion of the report.
As someone involved in that process, I feel it is important to put my views on record, as comments I made previously are now being used as part of the effort to undermine  Judge Goldstone and his important work.
I refused to accept the invitation from the president of the Human Rights Council at the time, Ambassador Martin Uhomoibhi of Nigeria, to lead the investigation following the Human Rights Council’s January 12, 2009 resolution. As a former UN High Commissioner for Human Rights, I felt strongly that the Council’s resolution was one-sided and did not permit a balanced approach to determining the situation on the ground.
It referred only to “the grave violations of human rights in the Occupied Palestinian Territory, particularly due to the recent Israeli military attacks,” and called for a mission to investigate “all violations of international human rights law and international humanitarian law by the occupying power, Israel, against the Palestinian people.”  
I was also aware that the UN Human Rights Council had made repeated condemnations of Israel over the past two years but had focused little attention on large-scale violations of human rights in other countries.
This pattern of action and inaction by the Council has given greater credence to those who believe the UN’s highest human rights body is inherently anti-Israel.  
I decided I could not undertake the mission for these reasons.
I am aware that Judge Goldstone, a dedicated and unimpeachable human rights lawyer and advocate, shared similar concerns when he was initially approached.
But he was able to work with the Council’s president to secure an agreement  he felt confident would permit the mandate to be interpreted in such a way as to allow his team to address the actions taken byboth parties to the conflict.
Experts can debate whether this was in conformity with UN rules and procedures.
I have no doubt that those involved were seeking a way forward that would allow for a full investigation and help overcome the political divisiveness currently  undermining the Human Rights Council within the UN system.
The question now is whether governments will give Judge Goldstone’s findings the serious attention they deserve, or instead fall back into an overtly political posture.
As Goldstone's report makes clear:
Both the Palestinians and the Israelis are legitimately angered at the lives that they are forced to lead: For the Palestinians, the anger about individual events – the civilian casualties, injuries and destruction in Gaza following from military attacks, the blockade, the continued construction of the Wall outside of the 1967 borders – feed into an underlying anger about the continuing Israeli occupation, its daily humiliations and their as-yet-unfulfilled right to self-determination.
For the Israelis, the public statements of Palestinian armed groups celebrating rocket and mortar attacks on civilians strengthen a deep-rooted concern that negotiation will yield little and that their nation remains under existential threat from which only it can protect its people.
In this way, both the Israelis and the Palestinians share a secret fear – for some, a belief – that each has no intention of accepting the other’s right to a country of their own.
This anger and fear are unfortunately ably represented by many politicians. (Para.
1705)
For the sake of human rights and peace in the region, my hope is that the international community will bear witness to these circumstances, consider Judge Goldstone’s report in its entirety and press for accountability for the most serious crimes.
Accounting chicanery will be high on the agenda of the bankers who will meet at the annual IMF/World Bank gathering in Washington, D.C. The IMF should do more than offer the private sector advice about how to fix its accounting problems; governmental accounting tricks and the IMF's own wheezes should also be addressed, says Nobel laureate Joseph Stiglitz.

The Arthur Anderson and Enron scandals in America have focused attention on the problems of accounting in private businesses.
But the scale of this corruption should not blind us to the problem of public sector accounting, where many deceitful things are also being done.
Accounting rules are designed to provide standardized frameworks within which the financial position of a firm, or government, can be assessed.
Bad accounting frameworks always lead to bad information, and bad information leads to bad decisions, with serious long term consequences.
This is true in the public as well as the private sector.
America's business scandals showed how accounting rules can be bent and abused to provide a misleading picture of what is really happening in a company.
The Bush Administration, not to be left behind, has shown how public accounting rules can be bent so as to provide a misleading picture of what is really happening in a national economy.
Indeed, last year saw what may be the largest accounting fraud ever conducted, as a mega-surplus of more than $3trillion for the years 2002 to 2011 was transformed into a $2 trillion deficit.
Investors in Enron waited years before discovering that something was amiss. Though sudden and vast, the change in America's fiscal stance already provides a clear inkling that something was amiss.
It will be years before the full magnitude of President Bush's deception is apparent.
Meanwhile, the Bush Administration will blame the sinking economy, bad luck, and unintentional miscalculations for the vanished surplus.
But America is not alone in allowing for official accounting shenanigans.
In Latin America and elsewhere in the developing world, the IMF imposes accounting frameworks that not only make little sense, but result in excessive austerity.
In some of the poorest countries in the world - ie, those most dependent on aid - the IMF has argued that foreign aid should not be listed as revenue in a government's budget calculations.
But what else is aid if it is not revenue?
The IMF's argument seems to be this: a country cannot rely on foreign aid because aid is too unstable.
The truth, of course, is that aid is more stable than tax revenues in poor countries.
By the IMF's logic, neither aid nor tax revenues should be included in budgets.
If that is the case, every country in the world is in deep trouble.
The absurdity here is the idea that all foreign aid should be added to reserves.
But donor countries want to see the money they give to finance schools or health clinics spent on schools and health clinics; they don't want to see it added to a nation's reserves.
Governments in developing countries have thecorrect answer to the problem of revenue instability: expenditure flexibility.
Build schools when you have aid; stop building them when you don't.
For years, World Bank economists have tried to convince the IMF to see this logic, with little progress.
Other IMF accounting practices, including how the capital expenditures of government-owned enterprises are treated, are also causing outrage.
If a state owned enterprisein Latin America wants to borrow to make an investment, in Latin America such borrowing is treated as an addition to the deficit.
Investors, worried about the size of a government deficit, see only the bottom line.
But if a company can buy a $1 billion asset for $500 million,economic logic says buy the asset.
The balance sheet is improved by $500 million.
But byIMF logic,all you see in the accounts is increased expenditure and borrowing, not the value of the acquired asset.
Because of this rule, investors may only see an apparent worsening of the country's fiscal position, and so may demand higher interest rates.
Of course, foreign investors like this IMF logic: government corporations are put at a distinct disadvantage: their ability to invest inhibited, these firms cannot compete to make acquisitions.
A second IMF accounting distortion involves stabilization funds.
These are national funds that, in boom years, receive revenues from sales of natural resources to be set aside against a rainy day.
This makes sense.
But IMF accounting inhibits the use of these funds to help stabilize an economy through counter-cyclical fiscal spending.
According to Mexican and Chilean officials I have discussed the matter with, spending from a stabilization fund is reportedly treated as if the country is borrowing, thus adding to its deficit.
It is, of course, in times of economic downturn that countries worry most about their credit rating, so the IMF stance is particularly unhelpful.
IMF accounting frameworks, rather than providing useful signals to the market, provide distorted information that exacerbates a troubled country's problems.
Good decisions requireaccurateinformation, and this comes only through good accounting frameworks.
Of course, no perfect accounting framework exists, but some frameworks systematically distort.
Indeed, a hidden agenda often exists in the choice of an accounting framework.
Not including stock options inside the accounting framework served US corporate interests, and those of individual bosses, well.
The IMF's distorted and unfair accounting frameworks may also serve a hidden purpose: to force governments to shrink expenditures.
But there are high economic and social costs to this agenda, one that goes far beyond the IMF's mandate.
BRUSSELS – The tsunami that has swept across financial markets is a global catastrophe.
If handled correctly, however, the crisis may yet raise the esteem of the European Union and its institutions.
The EU’s legitimacy problem has two different aspects: apathy, leading to a low turnout in the European parliamentary elections, and outright euro-skepticism.
The voter-turnout problem partly reflects frustration about the present state of the EU, and also people’s impression that they can exert little influence by voting one way or the other.
Euro-skepticism, on the other hand, and the looming threat of anti-European populism, is directly linked to the idea that the EU is not merely incapable of offering a solution to the crisis, but in fact is part of the problem.
So, although the EU represents our best hope of ensuring that Europe is internationally competitive in today’s increasingly difficult environment, it is actually being blamed for globalization.
Many people confuse these two aspects of the EU’s legitimacy problem, and believe that somehow turnout in European elections can be increased by pointing out to people how good and important the EU is.
But in most cases, this is not possible.
At first sight, the easiest answer to the problem of low voter turnout is to give more power to the European Parliament.
But if this was the solution, then we would not have had steadily declining turnouts since the high point of 63%, at the first elections to the European Parliament in 1979.
After all, since then the EP’s influence and powers of joint decision-making have grown constantly.
The trouble is that, EP elections must be “about” something if voters are to be interested, which means they must involve a real choice.
And a real choice requires Europe-wide election campaigns by all parties.
This would also involve making the choice of the European Commission’s president dependent on the outcome of the EP elections.
But, in fact, both of these conditions have already been met; in 2004, Portuguese Prime Minister José Manuel Durão Barroso was appointed President of the Commission because he came from the political organization with the strongest election result, the European People’s Party.
And this year’s elections saw a more intensive presence of party organizations at European level than ever before.
Instead, I believe that the most important way to reawaken voters’ interest in European elections will be to open up the election of the Commission’s President to them, and create a genuinely Europe-wide political debate during the next election campaign.
The Euro-skepticism problem can be tackled only if the Union itself starts to perform better, and is seen to be doing so.
That is why in the aftermath of the failed referenda four years ago in France and the Netherlands on the Constitutional treaty, the Commission tried to emphasize the idea of a “Europe of Results” that would seek to convince citizens of its worth through concrete achievements.
Given the gravity of the economic crisis, the time has come for the EU to demonstrate its strengths whenever possible.
The aim must be not only to win back the hearts of Europeans who have become skeptical, but also to convince them that the Union is indispensable to meeting the challenges Europeans face.
Europe’s citizens understand that the relatively small nation-states that make up the EU are no longer able to face these enormous challenges on their own.
In Ireland, last autumn’s financial crisis provoked a turnaround in public opinion about the EU, and even in Iceland, although it lies on the periphery of our continent, membership of the EU and the euro have become a priority.
European countries have become so interconnected that isolated national measures on issues like financial-market regulation are hopeless.
A changing world in which new powers like China and India play an increasingly important role will not wait for Europe to make up its mind.
The EU must instead show leadership through its efforts to solve the world’s current problems.
As for the European People’s Party, for us the economy is not an end in itself but should serve the people.
The economic crisis was caused by shortsightedness and a lack of control in the global financial system.
Now we must redefine the role of regulators in financial markets and in the wider economy, for we cannot let the financial sector walk off with the profits and leave taxpayers bearing the losses.
That doesn’t mean that we are advocating a move to socialism; we want better and smarter regulation, not regulation for its own sake.
We see five keys to recovery:
New job creation must be a core priority, with reform and investment in education and life-long learning necessary to create opportunity for all;A prolonged global economic slump must be averted, and European governments must continue to improve coordination on fiscal and monetary policies;The international financial architecture must be rebuilt.
European regulations are not sufficient for a healthy global financial system;The recession is an opportunity to increase investment in green technologies to make Europe less dependent on fossil fuels;Protectionism must be prevented, within Europe and without.
Europe’s internal market is a success story that has indisputably created growth and jobs.A “Europe of Results” is achievable.
It can strengthen the EU’s legitimacy, though, only if policy recommendations such as these, and the successes that result from implementing them, are communicated clearly and effectively to the general public.
MILAN – Although the financial crisis is winding down, the prospects for growth in the global economy are unlikely to pick up.
This is, in part, inevitable.
But it is also the result of poor coordination between governments as the world economy rebalances.
Prior to the crisis, American consumers, on average, either saved nothing or accumulated debt.
That has now changed.
With household wealth seriously damaged by the housing crash and other asset-price declines, pensions and retirement provisions are in disarray.
Because asset prices will not reach pre-crisis levels anytime soon (that is, without inflating another bubble and risking renewed instability), household saving in the United States has risen to about 5% of disposable income, and probably will rise further.
This withdrawal of the US consumer is part (perhaps half) of the process of rebalancing the global economy.
Restoring America’s savings-investment balance implies a reduction in global aggregate demand of around $800 billion.
To be sure, fiscal deficits and emergency measures in advanced economies and some major developing countries have cushioned the sharp decline, substituting in part for missing consumers.
But this substitution cannot continue indefinitely.
In advanced countries, governments will eventually be forced to reduce spending, and central banks will withdraw from emergency credit provisions and guarantees.
As a result, many believe that a “new normal” of slower advanced-country growth is upon us.
Despite a recovery in asset prices in many countries and the deceleration of negative growth, unemployment is high and rising.
Risk spreads have declined from their mid-crisis highs, but credit in many sectors remains tight or barely available, while the financial sector is set to become more conservative – and is likely to be re-regulated with higher capital, reserve, and margin requirements.
And this is just the baseline scenario.
Downside risks include fiscal destabilization resulting from a failure to rein in deficits, inflation and withdrawal of central bank autonomy, and loss of confidence in the dollar, which continues to be the reserve currency for the global economy.
Little wonder, then, that many knowledgeable analysts reasonably expect post-crisis growth in advanced countries to be lower, perhaps by 0.5 to 1%.
A 1% slowdown in advanced-country growth translates into roughly $350 billion of missing aggregate demand every year, in addition to the shortfall because of rebalancing in the US.
If the slowdown in advanced countries persists, pre-crisis growth levels will not be achievable in the developing world either, owing to insufficient demand to absorb the implied increase in output.
Of course, individual developing countries may be spared.
But it is an unfortunate mathematical fact that not everyone can gain market share.
If the advanced-country scenario is right, many developing countries will lose out and experience sharply diminished growth.
Prior to the crisis, many suspected that the mix of aggregate demand that was supporting high growth was unsustainable, though the problem perhaps seemed too hypothetical to compel collective action.
Not anymore.
But the collective action problem is no less daunting, and it requires urgent attention if the world’s growth aspirations are to be achieved.
The problem is all the more pressing because countries can achieve gains in market share not only through higher private-sector competitiveness, but also by means of protectionist measures.
And, as we have seen in many countries’ efforts to ameliorate the crisis, the non-cooperative protectionist response is much more likely to be adopted – despite wide recognition that it is highly destructive – when aggregate demand is in short supply.
So what can be done to shore up global aggregate demand and growth prospects, while preserving the economic openness that has benefited major parts of the developing world so greatly in the past 30 years?
First, countries with current-account surpluses such as Germany, Japan and China must recognize that their own growth (and that of others) depends on reducing the global savings-investment imbalance, which will result in narrowing external deficits elsewhere.
This needs to be done on a sustained basis following the withdrawal of extraordinary fiscal stimulus.
Second, everyone must recognize their stake in restoring balanced advanced-country growth as much and as soon as possible in order to counter the ongoing shortfall in aggregate demand.
After all, advanced countries account for about two-thirds of global GDP, so slow growth in these countries will inevitably impede global growth and truncate the growth potential of much of the developing world.
This challenge, however, is very complex because deleveraging and rebalancing cannot be completed overnight.
But key steps can and should be taken: restoration of fiscal balance in well-communicated plans, commitment to central bank autonomy and low inflation, and striking a thoughtful balance between under- and over-regulation of the financial sector.
Externally, major trading partners and holders of advanced-country assets can support rebalancing by agreeing to avoid sudden and potentially destabilizing shifts in the composition of their balance sheets.
So, two crucial items must claim priority at the top of the world’s economic agenda in the months ahead.
The first is re-regulation of advanced countries financial systems with a view to ensuring greater stability without impairing essential functions or unnecessarily elevating the cost of capital.
The second is a set of understandings and commitments among the major advanced and developing countries to rebalance the global economy in order to restore aggregate demand and growth.
If that can be accomplished, the world will have taken a major step toward a relatively smooth, effective, and equitable global economic recovery.
COPENHAGEN – Striking the right balance between preventing global warming and adapting to its effects is one of the most important – and most vexing – policy questions of our age.
It is also often ignored.
According to the conventional wisdom of many environmental campaigners, we should first do everything we can to mitigate global warming, and only then focus on adaptation strategies.
This seems wrong – even immoral – if we could do more for people and the planet through adaptation.
Moreover, it is inconsistent with the inescapable fact that, whatever we do, we cannot prevent all of global warming’s effects.
If we are ill-prepared, global warming will cause more deaths and devastation, especially in poor countries and fragile societies.
Adaptation would also mean saving many lives from catastrophes not related to global warming.
If we prepare societies for more ferocious hurricanes in the future, for example, we are also helping them to cope better with today’s extreme weather.
There has been a huge amount of research into the ways that humans cause climate change, and how we can reduce it.
Much less work has been devoted to adaptation.
It is important to acknowledge that some adaptation strategies will lead to more greenhouse-gas emissions.
Responding to water scarcity by re-using and treating wastewater, or through deep-well pumping and desalination, will increase fossil-fuel use.
Using more air-conditioning to cool our houses in summer will do the same – although this is vital if we want to save lives.
Adaptation could allow for higher carbon emissions in another way: reducing the damage and harm that we experience from global warming, giving us more time to implement alternatives to reliance on fossil fuels.
Should any of this stop us from using adaptation strategies?
To arrive at an informed answer, we need to work out how the planet will look in 2100 if we invest different amounts in adaptation and carbon cuts.
We need to take into account the increase in emissions that adaptation will cause.
The most critical issue isn’t any rise or fall in emissions. It is how much climate damage we can avoid.
How much of the planet can we help by dealing with rising sea levels?
How many lives can we spare from heat, starvation, or malaria?
These are the real reasons we care about global warming.
Reaching a proper answer to these questions requires extensive economic modeling, with different variables calculated and regional differences analyzed.
New research by three Italian economists, Francesco Bosello, Carlo Carraro, and Enrica De Cian does this, and, ultimately, provides a powerful economic case for a much greater focus on adaptation.
They first look at the different ways that climate change will affect us at mid-century.
This work is based on standard scenarios, and carries the typical caveats of predictions far into the future.
Nevertheless, they find that many of our biggest concerns will turn out to be trivial, or even beneficial.
Sea-level rises will be a very minor concern for every country, with the financial impact adding up to less than 0.1% of GDP.
Health problems will be negligible for all but a few nations.
And global warming’s impact would reduce energy consumption for almost all nations.
The important effects are on agriculture and tourism, where nations will lose, on average, about 0.5% of GDP from each sector.
But much of this damage will be avoided by people choosing for themselves to adapt to a change in their environment.
Farmers will choose plants that thrive in heat.
New houses will be designed to deal with warmer temperatures.
Simple economic models, often quoted in the media, show that unconstrained global warming would cost a substantial 2% of GDP in the rich world by the end of the century.
But this fails to acknowledge that people will change their behavior when the environment changes.
Taking adaptation into account, rich countries will adapt to the negative consequences of global warming and exploit the positive changes, creating a totalpositive effect of global warming worth about 0.1% of GDP.
Poor countries will be hit harder, however.
Adaptation will reduce the climate change-related losses from 5% of GDP to slightly less than 3% – but this is still a significant impact.
The real challenge of global warming, therefore, lies in tackling its impact on the Third World.
Here, more needs to be done, above and beyond the adaptation that will happen naturally.
Importantly, the new research shows that adaptation would achieve a lot more than cuts in carbon emissions.
Reducing emissions to a level that does not extinguish economic growth could avert $3 trillion worth of damage, whereas adaptation could prevent around $8 trillion worth of damage.
For every dollar spent on adaptation, we would achieve about $1.70 worth of positive changes for the planet.
The economic case for focusing more on adaptation is clear.
The crucial next step is to ensure that economic arguments become a stronger part of our political debate about how to address global warming.
WASHINGTON, DC – Dropping bombs as a solution to the world’s trouble spots may be falling out of fashion (with the notable exception of Libya), but finger wagging is definitely back in.
Hardly a day goes by without a major newspaper somewhere in the West offering sage and specific, but often not-so-friendly, advice to distant struggling democracies on what they “must” do to earn the “international community’s” approbation.
Of course, such advice, like much of newspapers themselves nowadays, comes free of charge.
But it is also advice that is free of responsibility, and, as Stanley Baldwin once said, power without responsibility is the prerogative of the harlot.
There is a considerable gap between offers of advice one cannot refuse and the responsibility to deal with the consequences when that advice proves wrong or extremely difficult to implement.
The world’s advice givers might try to keep this in mind when offering to help leaders of distant countries that are grappling with problems with which the adviser has little or no first-hand experience.
Every once in a while, a profession (most frequently, economics) determines that it has reached a consensus on how to solve a problem.
The so-called “Washington Consensus” that held sway before the recent financial crisis was a good example.
In the case of nascent democracies, the formula that is now often made compulsory is this: lift all bans on political activities, liberalize the media, hold elections (the sooner, the better), resolve all minority issues in favor of the minorities, abandon trade barriers, and rid the country of corruption, preferably overnight.
New governments are urged to tackle all of these problems immediately and simultaneously, lest they lose “momentum” and begin backsliding.
The subtext is clear: be like us now.
How to do this is left up to the new leaders, who are often credited with goodness and powers of persuasion they never had and never will have.
In many cases, the cohesiveness of opposition movements that come to power in the wake of a political upheaval may not be what the international media presume it to be.
Indeed, some components of these so-called “democratic coalitions” may not be democratic at all.
Some leaders, such as Nelson Mandela, rise to the historic occasion, against all odds.
Others, such as Kazakhstan’s Nursultan Nazarbayev (popular with Western media when he first came on the scene) plainly has not.
How can we help ensure these movements’ sustainability in such fluid moments?
Modesty is a virtue in private life.
It should also be a guide in dispensing political advice.
I would start by keeping in mind that some countries’ capacity to absorb advice is limited, so it should be offered in smaller portions.
Where to start?
The most important and potentially sustaining feature of a new democracy lies in its effort to commit itself to observing international human-rights standards. In fact, there is a large body of literature that indicates that even countries in the aftermath of internal conflict can reach a higher level of compliance with these standards.
But human rights should not be conflated with democracy.
While democracy is, no doubt, the form of governance that best preserves human rights, the two are not the same thing.
Human rights will not co-exist with dictatorship, or with any other non-democracy, for long.
Setting standards and goals of human rights is a powerful signal that a country is pointing itself in the right direction.
The country is in effect announcing that it is moving toward democratic institutional arrangements.
Banning torture, complying with international standards of prisoners’ rights, and enshrining rights of association and public assembly all immediately come to mind.
The embrace of essential human-rights standards as a cornerstone of a country’s development is one of our era’s seminal innovations.
The notion that a dictator can claim the sovereign right to abuse his people has become unacceptable.
A country that makes progress on human rights and commits to the change of behavior required to meet these international standards can also make a decisive turn toward a better future.
We should therefore focus on meeting international human-rights standards as a goal that a new democracy “must” (to use a favorite word of Western editorial writers) move toward quickly.
But we should not confuse these values with the other essential elements of progress, such as establishing liberalized trade regimes, creating institutional structures with a separation of powers, and rooting out corruption.
These are absolute necessities for democratic success, but they require longer-term development of institutional capacity.
Corruption, for example, may have cultural antecedents and is part and parcel of institutional weakness.
In most cases, neither can be remedied overnight.
Above all, we need to show patience with the new governments of the countries we hope to see evolving toward democracy, and avoid the tendency to expect instant gratification.
A few months of politics will never overcome a few centuries of sociology.
So, as we watch and wait, we need to be as supportive – but not overbearing – as possible.
The violence in France, fueled by staggering unemployment and ruthless policing, reflects the utter failure of the French model of social integration.
But violence elsewhere in Europe, such as the London bombings of July and the brutal murder of Dutch filmmaker Theo van Gogh on the streets of Amsterdam in November 2004, had already made Europe’s failure to integrate its minorities painfully clear.
As the riots in France fade, French politicians are agonizing about how to proceed.
Forty years ago, after legal segregation of blacks and whites formally ended in America, the United States was confronted by similar problems.
America’s response shows, however, that integration cannot be viewed as a one-way street.
In addition to imposing demands and constraints on minorities to join the mainstream, society must be willing to demand of itself that it make room for all its citizens.
As a potential model to be followed, Europe should look at the so-called “affirmative action” policies that America enacted to provide opportunities to blacks.
Affirmative action, or “positive discrimination,” as some have called these policies, began with university admissions.
But, in the early 1970’s, President Richard M. Nixon expanded the scope of affirmative action.
As a result, ethnicity began to be weighed as a positive factor not only in university admissions, but also in public procurement decisions, credit facilities for small enterprises, and government hiring.
The rational for affirmative action in those early years was the fact that, after a long history of systemic injustice, merely outlawing discrimination based on race or gender would not ensure equal opportunity for all.
Such programs are often viewed as contradicting a basic American value, namely that admissions, lending, and hiring decisions should be based on the merits of the individual, not group distinctions.
But they remain in existence three decades later.
Indeed, leading American companies, like General Motors, General Electric, and Walmart, have created affirmative action programs for hiring and selecting suppliers at their own initiative.
Similarly, anchormen and anchorwomen from all ethnic backgrounds populate American television news programs.
In France, by contrast, the appointment of the black anchorwoman Audrey Pulvar was big news on its own, because most of her colleagues in France are white.
Affirmative action in the US has been effective in creating a large African-American middle class.
The percentage of black households earning over $50,000 a year (adjusted for inflation) has more than tripled over the last four decades, from 9.1% in 1967 to 27.8% in 2001.
Indeed, in the US, more people of color and women hold top jobs in the public and private sector than anywhere else in the world.
The fact that a large black underclass remains – something the recent floods in New Orleans revealed in a horrifically dramatic way – is mainly the result of failing school systems.
Affirmative action programs, of course, have always been vulnerable to attack by those who can’t benefit from them.
In 2003, a white student asked the US Supreme Court to declare that the use of race in the University of Michigan’s admission policies violated the Equal Protection Clause of the Fourteenth Amendment of the US Constitution.
The Supreme Court, however, ruled that the program was constitutional, citing a “compelling state interest” in racial diversity. “Effective participation by members of all racial and ethnic groups in the civil life of our nation,” the court said, “is essential if the dream of one nation, indivisible, is to be realized.”
In reaching its decision, the Supreme Court took into account a legal brief submitted by 60 major American businesses, led by General Motors, asking that affirmative action be upheld.
They argued that the skills needed in today’s global marketplace can only be developed through exposure to a wide diversity of people.
Retired military officers and commanders told the court that affirmative action was essential to maintaining an integrated officer corps.
What America’s affirmative action programs may not do is set quotas for minorities, as this prevents competition between different groups.
But, in comparing groups, it is permitted to use an individual’s status as member of an under-represented minority in his or her favor.
As a result, a university may select a black student with a satisfactory score on the admissions test, even if there is a white student with a better score.
From the current French viewpoint, however, laws and regulations based on ethnicity are regarded as an unwelcome encroachment on the Republican ideal.
French President Jacques Chirac vehemently opposes quotas for immigrants, out of fear that such a policy would stigmatize groups.
And French businesses don’t see it as their role to solve the problems of the suburbs.
Moreover, French Interior Minister Nicolas Sarkozy hasn’t done much except hand out some special grants to the smartest immigrants from the suburbs.
France does have affirmative action programs, but they address poverty, not ethnicity.
If European politicians are serious about preventing a schism between population groups, affirmative action is essential – not only at the workplace, but also for small business loans, home loans, public procurement, and school admissions.
Tony Blair, who in July was faced with the shortcomings of integration in the UK, should take advantage of the country’s current presidency of the European Union to make affirmative action programs the top priority at next month’s summit of European government leaders in Brussels.
COPENHAGEN – Public skepticism about global warming may be growing, but the scientific consensus is as solid as ever: man-made climate change is real, and we ignore it at our peril.
But if that issue is settled (and it should be), there is an equally large and important question that remains wide open: what should we do about it?
One prescription that is bandied about with increasing frequency certainly sounds sensible: the world should drastically cut the amount of greenhouse gases that it pumps into the atmosphere each day.
Specifically, we are told, the goal should be a 50% reduction in global carbon-dioxide emissions by the middle of the century.
Even its backers concede that achieving this target won’t be easy – and they are right.
In fact, they are so right that they are wrong.
Allow me to explain.
Our dependency on carbon-emitting fuels is more than enormous.
It is overwhelming.
For all the talk about solar, wind, and other hyped green-energy sources, they make up only 0.6% of global energy consumption.
Renewable energy overwhelmingly comes from often-unsustainable burning of wood and biomass by people in the Third World.
Fossil fuels account for more than four-fifths of the world’s energy diet.
So, in order to cut global carbon emissions in half by the middle of the century, we would obviously have to start getting a lot more of our energy from sources that don’t emit carbon.
Can we do this?
According to the International Energy Agency, here’s what it would take to achieve the goal of cutting emissions by 50% between now and mid-century:
30 new nuclear plants; 17,000 windmills; 400 biomass power plants;Two hydroelectric facilities the size of China’s massive Three Gorges Dam; and42 coal and gas power plants with yet-to-be-developed carbon-capture technology.Now consider this: this list does not describe what we would have to build between now and 2050, but what we would have to build each and every year until then!
One more thing: even if we managed to do all this (which we obviously cannot), the impact on global temperatures would be hardly noticeable by 2050.
According to the best-known climate-economic model, this vast undertaking would likely wind up reducing global temperatures by just one-tenth of one degree centigrade (one-fifth of one degree Fahrenheit), while holding back sea-level rises by only one centimeter (less than half an inch).
That’s not a lot of bang for the buck.
Indeed, the projected costs of this approach – some $5 trillion annually by mid-century – are so much greater than its likely benefits that it makes no sense to call it a solution at all.
Fortunately, there is a better, smarter way to deal with global warming.
What if, instead of spending trillions of dollars trying to build an impossible number of power plants – or, more likely, condemning billions of people around the world to continued poverty by trying to make carbon-emitting fuels too expensive to use – we devoted ourselves to making green energy cheaper?
Right now, solar panels are so expensive – about 10 times more than fossil fuels in terms of cost per unit of energy output – that only well-heeled, well-meaning (and, usually, well-subsidized) Westerners can afford to install them.
But think where we’d be if we could improve the efficiency of solar cells by a factor of ten – in other words, if we could make them cheaper than fossil fuels.
We wouldn’t have to force (or subsidize) anyone to stop burning coal and oil.
Everyone, including the Chinese and the Indians, would shift to the cheaper and cleaner alternatives – and global emission targets would automatically be met.
Can we achieve this technological miracle over the next 20 to 40 years?
In a word, yes.
The price of solar energy has been dropping steadily for 30 years – by about 50% every decade – and we could likely accelerate that decline further with sufficiently large investments in research and development.
How large?
If we were willing to devote just 0.2% of global GDP (roughly $100 billion a year) to green-energy R&amp;D, I believe that we could bring about game-changing breakthroughs not just for solar power, but also for a wide variety of other alternative-energy technologies.
This belief in the potential of technological progress strikes some climate activists as naïve or even delusional.
But is it really?
Consider one of the miracles of the modern age – the personal computer.
These devices didn’t become household items because governments subsidized purchases or forced up the price of typewriters and slide rules.
No, what happened is that, largely as a result of the space race, the United States government poured lots of money into R&amp;D for solid-state physics and electronics engineering.
The resulting breakthroughs not only got Neil Armstrong to the moon in 1969, but also made it possible for Apple to introduce the first Mac in 1976 and IBM to debut the first PC five years later.
We can do the same for clean energy.
Forget about subsidizing inefficient technologies or making fossil fuels too expensive to use.
Instead, let’s fund the basic research that will make green energy too cheap and easy to resist.
Things aren’t going well in Afghanistan.
Sometime at the turn of 2001/2002, the Bush administration concluded that the stabilization and reconstruction of Afghanistan was no longer its top priority and decided to bet instead on military-led regime change in Iraq.
Afghanistan can thus rightly be seen as the first victim of the administration’s misguided strategy.
But the Bush administration is not the sole culprit for the deteriorating situation in Afghanistan.
It was NATO’s job to ensure the country’s stability and security, and thus NATO’s weak General Secretary and the European allies, especially Germany and France, share the responsibility for the worsening situation.
Yet, despite all the difficulties, the situation in Afghanistan, unlike that in Iraq, is not hopeless.
There was a good reason for going to war in Afghanistan in the first place, because the attacks of September 11, 2001, originated there.
Once undertaken, the West’s intervention ended an almost uninterrupted civil war, and is still viewed with approval by a majority of the population.
Finally, unlike in Iraq, the intervention did not fundamentally rupture the inner structure of the Afghan state or threaten its very cohesion.
If the West pursues realistic aims, and does so with perseverance, its main objective – a stable central government that can drive back the Taliban, hold the country together and, with the help of the international community, ensure the country’s development – is still achievable.
There are four preconditions of the West’s success:
establishment of Afghan security forces strong enough to drive back the Taliban, limit drug cultivation, and create domestic stability; willingness on the part of NATO to remain militarily engaged without any national reservations – with Germany and France in particular giving up the special conditions of their involvement; a significant increase in development aid, especially for the so far neglected Southern part of the country; renewal of the regional consensus reached in Bonn in 2001, under which the reconstruction of the Afghan state was to be supported by all the parties concerned. The war in Afghanistan was never just an Afghan civil war; rather, for decades the country has been a stage of regional conflicts and hegemonic struggles.
So, while the rebirth of the Taliban is in part due to the woefully neglected reconstruction of the Pashto Southern and Eastern part of the country, it also has external causes.
Most notably, for more than two years now, Pakistan has been moving away from the Bonn consensus, betting on the rebirth of the Taliban and giving it massive support.
Indeed, without Taliban sanctuaries on the Pakistani side of the Afghan border, and without Pakistani financial backing, the rebirth of the Taliban’s armed insurgency against the central Afghan government would have been impossible.
Pakistan’s actions are explained mainly by its strategic readjustment in light of US weakness in Iraq and the region as a whole, and by the newly strengthened relationships between India and Afghanistan, resulting in an increased Indian presence in Central Asia.
In this connection, Pakistan views the Karzai government in Kabul as unfriendly to Islamabad and a threat to its key strategic interests.
Without Taliban sanctuaries on the Pakistani side of the Afghan border and the backing by the Pakistani intelligence service ISI, the rebirth of the Taliban’s armed insurgency against the central Afghan government would have been impossible.
But, by aiding the Taliban, Pakistan is playing with fire, because there are now also Pakistani Talibans who pose a threat to Pakistan.
US policy toward Pakistan is also dangerously shortsighted and reminiscent of the mistakes the US made in Iran prior to the 1979 Islamic revolution.
Nevertheless, the US at least has a Pakistan policy – which is more than can be said about NATO and Europe.
In fact, it is all but incomprehensible that while the future of NATO is being decided in the Hindu Kush mountains, and while thousands of European soldiers stationed there are risking their lives, Pakistan – the key to the success or failure of the mission in Afghanistan – is not given any role in NATO’s plans and calculations.
Part of NATO’s trouble stems from the fact that a number of member states insist on the right to make their own military and political decisions, and these “national reservations” severely limit NATO’s ability to act.
If NATO is to succeed, this must change without further delay.
A NATO summit, during which all members would take stock of the situation and draw the appropriate conclusions, is therefore long overdue.
The national reservations must be go, and a joint strategy for success must be adopted, including a massive increase in civilian and military aid for Afghanistan, if the country is to be prevented from descending into the same abyss as Iraq.
Moreover, a regional consensus among all the players must be rebuilt, including Pakistan, Iran, and India, whose joint responsibility for peace, stability, and redevelopment in Afghanistan must be recognized by Europe and the US.
To accomplish this, a follow-up conference to the Bonn Agreement is also required.
While the war in Iraq has been based on wishful thinking, the war in Afghanistan was necessary and unavoidable because it was there that the terrorist threat of September 11, 2001, originated.
It would be more than a tragedy – it would be unparalleled political folly – if, because of a lack of commitment and political foresight, the West were to squander its successes in Afghanistan.
Europe would have to pay an unacceptably high price, and NATO’s future would likely be jeopardized.
Roughly 75% of Afghan newborns that die do so because of lack of food, warmth, and care.
Unloved little girls fare the worst.
In Afghanistan as a whole, a woman dies of pregnancy-related causes every 27 minutes – and perhaps even more frequently, because many such deaths go unrecorded.
Many, perhaps most, are under sixteen years of age.
The Taliban – blamed nowadays for just about all of Afghanistan’s ills – have officially been gone for nearly seven years, so why are conditions still so abysmal?
In Kabul and Herat, mobile phones abound, a tooth-eroding concoction called “Afghan Cola” is sold, the Internet works (sometimes), there are ATM machines, sophisticated heroin laboratories, four-wheel drive vehicles, five-star hotels, ads for private banks – all the trappings of globalized modernity.
Yet so many women die like flies, in pools of blood and deep-rooted indifference.
While billions of dollars in aid have led to improvements in urban areas, where health facilities have been built and midwives trained, the overall maternal death figures have hardly changed.
As one doctor told me: “A competent midwife or nurse would rather be out of work in Kabul than stuck in a remote village.” But most Afghans live in remote villages – those in Badakhshan can be reached only after a day’s bumpy ride on a donkey.
This miserable situation has been attributed to various causes, mainly lack of infrastructure and local economic conditions.
But cultural questions must also be addressed, because gender discrimination is the most important cause of maternal mortality.
In Afghan society, discrimination begins at birth.
One obvious reason is that a boy is destined to support his parents and much of his family all his life, and therefore represents a long-term investment, whereas a girl will be given over to her husband’s family as soon as possible.
Feeding a girl is seen as effectively looking after someone else’s property.
Once, I heard a dreadful story of a breech birth which a traditional midwife did not know how to handle.
In the end, she wrenched the baby’s body out, severing it from its head, which remained inside the mother’s womb.
It took six days to get the woman to a hospital in Jalalabad though it was not very far from where she lived.
She somehow survived, with major health complications, including permanent fistula, which will condemn her to a life of exclusion from her family and unrelieved misery.
That tragedy can be read on many levels, each more heart-rending than the next.
But note that it occurred near a health facility.
As soon as the midwife saw that the baby was coming out feet forward, she must have known that there was little she could do to save either mother or baby.
Even before that, she would have noticed that the child had not turned properly, and that major problems were on the way.
This means that someone – a husband or mother-in-law – had taken the decision not to send the young woman to the hospital, instead keeping her in inhuman suffering for nearly a week.
The solution is not just to build more hospitals, but also to change deep-rooted disdain for women.
And, sadly, things have become worse in the past 30 years, as Afghanistan’s particular brand of Islam, combined with its legacy of dire poverty and war, compounds an already misogynist pre-Islamic tradition.
Maternal mortality is a sinister consequence of this complex situation.
The legal system, schools, and the media could bring change, but no official entity takes the problem seriously enough to initiate effective action.
The central reason is despairingly simple: women’s lives are not valued, and even women themselves perceive their suffering as being unavoidable.
What Afghanistan needs is an inquest after each death and laws making it a criminal offense to forbid access to medical aid, when available, to women and children (or, more correctly, to children and their children, given that girls are often married by age 14).
Prisons, I fear, would be full of abusive husbands and, I regret to say, vengeful mothers-in-law.
Health education through public media, reaching distant areas of the country, is an urgent priority, but has been utterly ignored in favor of commercial priorities.
Questioning culture is, of course, a politically incorrect approach.
But we must refuse to bow before the altar of tolerance when it comes to what is truly unacceptable, wherever it occurs, and this is what the world is witnessing passively in Afghanistan.
Does diversity authorize such brutal deaths and senseless violence against women simply because some supposedly traditional practice allows them to be married before their bodies are ready and denies them health care when they give birth?
The fight against maternal mortality in Afghanistan must become a global priority.
Ultimately, a society that allows women to be brutalized will remain a breeding ground of generalized violence.
On April 16, more than 300 Afghani women – many of them students – marched together in Kabul in protest of a new law passed by Parliament that would impose a series of Taliban-like restrictions on women.
The law would permit marital rape, limit women’s movements – say, for work or study – without male permission, and even make it illegal for a woman to refuse to dress as her husband wishes.
The women, facing a crowd of furious men calling them “whores” and other epithets, marched two miles under a rain of abuse and delivered their petition against the law to legislators.
Both houses of Parliament had approved the law, and President Hamid Karzai signed it.
The law now affects only the Shia minority, but threatens to affect pending legislation that could restrict the rights of non-Shia women as well.
When Western media sought quotes from the women, they frequently heard a Western-style feminist refrain: “These laws would make women into a kind of property.” In the West, the counterpoint to the notion of woman as property has been a highly individualistic demand for personal autonomy – decision-making based primarily on a woman’s own wishes, rather than as wife, mother, community member, or worshipper.
But, while some Western feminist insights may be useful to Afghani women and other women in the developing world as they resist certain forms of male oppression, we should not assume – as Western feminists often have – that our job is to proselytize “our” feminism.
On the contrary, the feminism expressed by women such as these Afghani heroines should educate us in the West about our own shortcomings.
The core theory with which emerging feminists in more traditional and religious societies are working is far different from that of Western feminism – and in some ways far more profound and humane.
In India, for example, feminists articulated to me a vision of women’s equality that was family-centered rather than self-centered, and that valued service to community rather than personal gratification.
They did not see their struggle as a cultural or ideological clash between men and women, but rather as a very practical effort to live free from violence and sexual assault, forced child marriage and bride-burning, and legal exclusion from parity.
The emerging consensus in India in support of greater rights and freedoms for women, while certainly causing some upheaval and adjustment (especially within the growing middle classes) has not yet – and might never – poison the basic trust and warmth between men and women.
Nor does it seem likely to emulate the splintered, individualized, solitary society – and the commodified sexual revolution – that Western, self-based feminism reflects.
This version of feminism – the notion that women can claim equality and still have a valued role in the home, prize family above all, and view rights in the context of community and spirituality – seems like a much-needed corrective to some of Western feminism’s shortcomings.
Ideally, men’s drive for progress in the developing world would also evolve, uniting the idea of the autonomous self with support for family, community, and other ties, and Western men would learn from this as well.
Moreover, intellectually, these women remind us that Western feminism did not have to evolve the way it did, and can still change and grow to embrace a more satisfying and humane definition of equality.
Simone de Beauvoir, whose seminal bookThe Second Sex laid the groundwork for post-war Western feminism, was an Existentialist who was neither a wife nor a mother nor a woman of faith.
So her work naturally posited female freedom in a secular, solitary, and individualistic context, in which “freedom” means pure autonomy rather than integration within a whole – comprising family, community, and even God – on equal terms.
The good news for all women, East and West, is that President Karzai, under intense international criticism – and not just Western criticism – changed the law less than one week after the march.
This global uproar is a testament to how three decades of Western feminist challenges to leadership have changed the world for the better.
But our (Western) moment of feminist leadership is over now – for good reasons.
We know by now what our problems are as women in the West, and we know the blueprint for solving them.
What we lack now is not analysis, but the organizational and political will to do so.
So the leadership role is shifting to women in the developing world.
Their agenda is more pressing, and their problems, frankly, far more serious than ours, which makes it much more urgent for them to develop theories appropriate to the challenges they face.
If one of those courageous Afghan women who marched in Kabul wrote – as I hope she or one of her sisters in the developing world is doing right now – the seminal text for the next 50 years on non-Western feminism, it would no doubt be equality-driven and practical.
And perhaps, in its likely view of the world as being more than the sum of consuming, competing autonomies, or gender warfare, it would be a valuable challenge to truisms that we Western feminists – and the men who love us – have thought we had to take for granted.
When NATO leaders meet for their summit in Riga at the end of this month, there will be a ghost at the feast: Afghanistan’s opium.
Afghanistan is in danger of falling back into the hands of terrorists, insurgents, and criminals, and the multi-billion-dollar opium trade is at the heart of the country’s malaise.
Indeed, NATO’s top general, James Jones, has called drugs the “Achilles heel” of Afghanistan.
This year’s record harvest of 6,100 tons of opium will generate more than $3 billion in illicit revenue – equivalent to almost half of Afghanistan’s GDP.
Profits for drug traffickers downstream will be almost 20 times that amount.
Opium money is corrupting Afghan society from top to bottom.
High-level collusion enables thousands of tons of chemical precursors, needed to produce heroin, to be trucked into the country.
Armed convoys transport raw opium around the country unhindered.
Sometimes even army and police vehicles are involved.
Guns and bribes ensure that the trucks are waved through checkpoints.
Opiates flow freely across borders into Iran, Pakistan, and other Central Asian countries.
The opium fields of wealthy landowners are untouched, because local officials are paid off.
Major traffickers never come to trial because judges are bribed or intimidated.
Senior government officials take their cut of opium revenues or bribes in return for keeping quiet.
Perversely, some provincial governors and government officials are themselves major players in the drug trade.
As a result, the Afghan state is at risk of takeover by a malign coalition of extremists, criminals, and opportunists.
Opium is choking Afghan society.
Within Afghanistan, drug addiction is rising.
Neighbors that used to be transit states for drugs are now major consumers, owing to similar dramatic increases in opium and heroin addiction.
Intravenous drug use is spreading HIV/AIDS in Iran, Central Asia, and the former Soviet Union.
In traditional Western European markets, health officials should brace for a rise in the number of deaths from drug overdoses, as this year’s bumper opium crop will lead to higher-purity doses of heroin.
What can be done?
First, the veil of corruption in Afghanistan must be lifted.
Afghans are fed up with arrogant and well-armed tycoons who live in mansions and drive top-of-the range Mercedes limousines – this in a country where barely 13% of the population have electricity and most people must survive on less than $200 a year.
It is time for the Afghan government to name, shame, and sack corrupt officials, arrest major drug traffickers and opium landlords, and seize their assets.
Donors have trained police and prosecutors and built courts and detention centers.
Now it is up to the government to use the judicial system to impose the rule of law.
It will be difficult, but not impossible, to re-establish confidence in the central government.
Putting major drug traffickers behind bars at the new maximum-security prison at Pul-i-Charki, near Kabul, would be a good start.
Of course, Afghanistan does not bear sole responsibility for its plight.
The heroin trade would not be booming if Western governments were serious about combating drug consumption.
It is a bitter irony that the countries whose soldiers’ lives are on the line in Afghanistan are also the biggest markets for Afghan heroin.
Furthermore, Afghanistan’s neighbors must do more to stop insurgents, weapons, money, and chemical precursors from flowing across their borders into the country.
Coalition forces should take a more robust approach to the drug problem.
Counter-insurgency and counter-narcotics are two sides of the same coin.
Improving security and the rule of law must include destroying the opium trade.
Allowing opium traffickers to operate with impunity gives them a free hand to raise money to pay for the arms and fighters battling the Afghan army and NATO forces.
The United Nations Security Council has authorized the International Security Assistance Force to take all necessary measures to fulfill its mandate.
NATO troops should be given the green light to help the Afghan army fight opium – destroy the heroin labs, disband the opium bazaars, attack the opium convoys, and bring the big traders to justice.
And they should be given the tools and manpower to do the job.
There is no point in trying to win the hearts and minds of major drug traffickers.
Farmers are a different story.
Forced eradication risks pushing farmers into the hands of extremists, and thus will not lead to the sustainable reduction of opium fields.
Indeed, as we have seen in some Andean countries, it can be counter-productive.
Therefore, security and development must go hand in hand.
To achieve this, Afghanistan needs more development assistance.
International support so far has been generous, but it is still well below per capita equivalents for other post-conflict situations – and the need is much greater.
Farmers will be weaned off opium over the long term only if they have sustainable livelihoods.
At the moment, Afghanistan’s drug lords are prospering, and rural communities are suffering.
That situation needs to be reversed.
We must punish the traffickers and reward the farmers.
We cannot afford to fail in Afghanistan.
Recent history has given us graphic evidence of what would happen if we do.
But any solution in Afghanistan depends on eliminating its opium.
British Prime Minister Tony Blair has declared that the two issues at the center of the G-8 Summit this July will be African poverty and global climate change.
These may seem to be distinct issues.
In fact, they are linked.
A trip I took to a village in the Tigre region in northern Ethiopia shows why.
One morning, I was taken to a dry riverbed at the village’s edge.
Farmers were digging a pit in the riverbed, down to the water table approximately two meters below ground level.
They explained that until recently this was a perennial river – one that flows throughout the year – but now the river stops flowing during the dry season.
Only when the annual rains begin in the summer does water reappear in the river bed.
Until then, water-starved communities dig for water, if they can find it and if they can afford to pump it out.
In northern Ethiopia, as in much of Africa, the rain cycle has changed markedly in recent years.
Ethiopian village life has long depended on two crops, one during a short rain in March and April, and the main crop during the long rain in the summer months.
In recent years, the short rains have failed entirely, and long rains have been erratic.
Hunger is omnipresent.
Perhaps half of the children are severely underweight.
Much of arid sub-Saharan Africa, notably in the Sahel (the region just south of the Sahara desert), has experienced a pronounced drop in rainfall over the past quarter-century.
This decline coincided with a rise in the surface temperature of the neighboring Indian Ocean, a hint that the decline in rainfall is in fact part of the longer-term process of man-made global warming.
Failures of rainfall contribute not only to famines and chronic hunger, but also to the onset of violence when hungry people clash over scarce food and water.
When violence erupts in water-starved regions such as Darfur, Sudan, political leaders tend to view the problems in narrow political terms.
If they act at all, they mobilize peacekeepers, international sanctions, and humanitarian aid.
But Darfur, like Tigre, needs a development strategy to fight hunger and drought even more than it needs peacekeepers.
Soldiers cannot keep peace among desperately hungry people.
One course of action must be to help impoverished African regions to “adapt” to climate change and to escape the poverty trap.
Water-stressed regions like Ethiopia and Sudan can adapt, at least in part, through improved technologies such as “drip irrigation,” rainwater harvesting, improved water storage facilities, deep wells, and agro-forestry techniques that make best use of scarce rainfall.
Better land-management practices (the re-planting of degraded forests, for example) can recharge underground water aquifers.
Poor countries cannot afford these technologies on their own.
Nor should they have to.
Help for poor countries in Africa and elsewhere to adapt to climate change should not be described as charity or aid, but rather as compensation for damages being imposed on the poorest people on the planet.
Greater help for these countries to escape from extreme poverty has been promised for decades but has not been delivered.
In addition to adapting to climate change, the world must also reduce future risks to the planet by cutting back on emissions of greenhouse gases, which are the source of man-made climate change.
While adaptation to climate change is necessary – because it is already occurring – this is not enough.
If the world fails to mitigate future climate change, the effects of rising temperatures, increasing droughts, more numerous and severe tropical storms, rising sea levels, and a spread of tropical diseases will pose huge threats to the entire planet.
The famines in Ethiopia and the violence in Darfur suggest what can lie ahead.
The best way to reduce long-term climate change is to reduce carbon emissions.
There are at least three options: shift to non-carbon energy sources such as solar or nuclear energy; capture and dispose of the carbon dioxide emitted at carbon-based power plants; economize on energy use, for example by shifting to hybrid automobiles and trucks.
Most likely, all three of these methods will have to play a role.
The effort to reduce greenhouse gases will require decades of action, but, given the long lead times in overhauling the world’s energy systems, we must start now.
Rich countries need to lead the way.
It is ironic that the United States, which portrays itself as a friend of democracy and impoverished countries, gives the smallest share of its GNP in aid among the rich countries, and also refuses to participate in global efforts to reduce greenhouse gas emissions.
This is especially ironic because African countries like Ethiopia stand steadfastly and bravely with the US in the fight for freedom and against terrorism, even as they struggle with hunger, disease, and famine.
Moreover, countries like Ethiopia are making valiant, indeed remarkable, efforts to overcome their problems, despite the lack of adequate, and long-promised, help from the world’s richest countries.
Africans suffering from hunger and drought, and indeed poor people everywhere, have a right to ask much more of the US and other rich countries.
Tony Blair is right to call on his rich-country colleagues to follow through on their unfulfilled promises.
I visited Ghana recently and like many others left asking: how can a "developing" country be developed?
But there was something troubling about this formulation, in particular with the word "developing," which is often a euphemism for theabsence of economic development.
Do countries stop developing because outsiders are so intent on developing them?
My hosts, the Kweku Hutchful Foundation, invited me with a different question in mind: How can Ghanaian leaders be developed?
Something troubled me about this formulation, too.
It was that word "development" again.
Do we really "develop" leaders or countries?
Do multinational companies, international non-governmental organizations, and multilateral lenders really understand local needs?
Just because some "best practice" works in New York, does that mean it will work in Accra, Ghana?
Imagine how American managers would react to consultants arriving from Ghana with their "best practice": "It worked in Accra, so it is bound to work in New York!"
Of course, there is a prominent example of just that: Kofi Annan, under whose stewardship the UN has undergone a remarkable improvement.
Annan spent most of his career outside of Ghana, and had some of his higher education in the US.
But, as one of Annan's advisors once put it, he "runs the UN like an old-fashioned African village, with long discussions among the elders, periods of reflection, and eventually a decision."
Of course, Annan can hardly control the UN by imposing great strategies on everyone else, as American corporate CEOs do.
But perhaps he knows better.
Unlike most American CEOs, Annan was not parachuted in from outside; he is the first career employee to lead the UN.
So he knew what was wrong and appreciated that it had to be fixed carefully and patiently, by engaging the staff rather than intimidating them.
His re-election to a second term as UN Secretary General was supported by nations all over the world, rich and poor, as well as by UN employees.
Was Kofi Annan "developed?"
Perhaps we don't develop leaders so much as foster the conditions that bring out leadership.
If so, then a key condition must be the self-respect that comes from working things out for ourselves, individually and collectively.
This self-respect is fostered by organizations and institutions that can likewise stand on their own feet, building on the best of their own cultural traditions.
Passive importation of techniques, controls, and beliefs, via agencies and experts that run around solving everyone else's problems, may be the biggest impediment to development--just another form of outside exploitation, of which Africa has had more than enough.
Is it not time for indigenous development, of countries and leaders alike?
One thing is clear.
Countries like Ghana do not lack enterprise.
Markets and personal initiative are pervasive.
At a red light in New York, a squeegee kid or two might approach your car; in Accra, a stopped car is immediately surrounded by a virtual supermarket.
What Ghana and most of Africa lacks is not enterprise, butenterprises.
Micro-financing--small loans to self-employed craftspeople and the like--can help.
But development at this level may not be the problem.
The problem is the lack of indigenous enterprises incorporated beyond the efforts of individuals and small families.
Instead, foreign corporations, with their funds, controls, and experts--and, just as importantly, their beliefs--dominate larger enterprise.
To be sure, foreign corporations can do good things: bring in fresh ideas, techniques, and processes, as well as capital and the scale required in some contemporary forms of manufacturing.
But nothing they do--aside from cosmetic modifications to consumer products and marketing tactics--responds to local conditions.
Development as now practiced often fails because it does not build on a country's unique strengths, respect its social traditions, or foster the autonomy necessary to develop indigenous leaders and enterprises.
All too often, it isforced development, imposed against people's natural inclinations and will.
Pride, dignity, and self-confidence do not figure in economic theory: they cannot be measured.
But they figure prominently in just about every story of success, whether of countries or of leaders.
How people feel about themselves, personally and collectively, greatly influences the energy with which they develop themselves.
America, for example, did not develop by depending on an imposed ideology or outside experts.
It developed through the indigenous efforts of Americans acting in their own way--assisted by extensive state intervention, through land grants to farmers, railroads, and mining companies, military spending that stimulated the economy (and still does), and, of course, tariff barriers.
Likewise, indigenous development played a key role in Japan and Germany after WWII, in South Korea more recently, and the UK long before.
In fact, hasany country ever developed primarily through the wholesale importation of capital, expertise, and beliefs--the equivalent of globalization today?
For the answer to how to develop an economy, we need look no further than those economies that have developed: begin with a great deal of indigenous initiative, support it with concerted state intervention, and reinforce it with the appropriate importation of external help.
Globalization must not be allowed to blind us.
Ghana certainly needs to develop economically, because material wealth is required to improve health, provide education, and sustain democracy.
But the reverse is also true: a deep-rooted sense of democracy--precisely what globalization lacks--seems necessary to support economic efforts.
The (economically) developed West should consider importing that lesson.
As a boy, when you join an army, you think you are going to see war as in the movies.
It's not like that.
In my first combat, I thought I was going to die, that I would never see my mother again.
It was the mid-1980s, and we were attacking a fortified garrison in western Uganda.
I was 15 years old and part of a movement that aimed to rid my country of the corrupt regime of Milton Obote, who had succeeded the murderous Idi Amin.
My leader was an inspiring, brave and talented man, Yoweri Museveni, now Uganda's President.
Museveni believed that young fighters not only needed martial skills but also a political awareness of the cause for which they fought - an end to the greed and self-delusion of Africa's post-independence leadership.
While still a teenager, I learned that the goal of war was social and political transformation.
In battle, I came to pity enemy prisoners because I had a cause to fight for and they did not.
Motivated by a political agenda - renovation of my battered country - I rose through the ranks to become a trusted aide in the circle around Museveni.
In 1986, not long after my 16th birthday, Museveni ousted Obote.
The war was over.
But not for me.
No longer a rebel but now a leader in the Ugandan army, I was sent for military training to Cuba, Libya and North Korea.
I became an expert in tank warfare.
While I hungered for an education - and even enrolled at university - I remained valuable as a soldier.
First, in my country, I helped Tutsi refugees from Rwanda, where they were a minority, fight a war against the Hutu majority there.
In the summer of 1994, when the Hutus slaughtered the Tutsis by the hundreds of thousands, our cause grew in urgency, as did our fighting spirit.
For three years I fought alongside Tutsis, finally serving as personal aide to Paul Kagame, now Rwanda's president and his country's leading political and military strategist.
Soon President Kagame asked me to fight in the Congo in order to bring an end to the monumentally corrupt regime of Mobutu.
In the Congo I led hundreds of fighters - many of them children - and helped capture pieces of the country.
In May 1997, I even helped to capture Kinshasa and chase Mobutu from power. I had "liberated" a third country, and I was only 27 years old.
Tired of war, the following year I turned politician, winning a seat in parliament as a member of Museveni's "Movement" group, the only legal party in Uganda.
Last year, I began to fear that Museveni had become yet another African dictator, more concerned with power than principle.
Part of my quarrel with him concerned his failure to establish a genuine multi-party democracy; also, I objected to mounting corruption.
The World Bank and other foreign donors supply half of the Ugandan government's budget, but a third of the money is wasted on senseless military actions such as Uganda's invasion of the Congo.
Museveni holds ultimate responsibility for this corruption.
I defected to a new opposition party and campaigned on behalf of Museveni's opponent in last year's presidential election.
Even though Museveni faced no risk of losing, he took no chances, arresting his opponent's aids and supporters.
Though I had fought faithfully in Museveni's army as a child, I was now an adult and a critic, so he arrested me too.
Tortured by my own brother (Museveni's chief of internal security), I was released after local and international pressure, and I left Uganda for Britain.
In tranquil London, I now contemplate my life as a child soldier.
I have no regrets, I offer no apologies.
Yet I am aware of how human rights advocates deplore the enlistment of youth into Africa's wars, where the lives of many children are ruined.
Injustice provokes children to pick up guns.
So does poverty.
In parts of Africa, poverty means that youth look at guns as a way of earning a living.
Powerless politically and economically, some children feel that they can only assert themselves by joining an army.
In Uganda, and in most other sub-Saharan countries, more than 40% of the population is under the age of 15.
Every country groans under the burden of educating, employing and absorbing so many young people.
Of course, no child should go to war.
But condemning child soldiers won't make them go away.
Only education will.
African youth must be introduced to democracy and pacifism in the classroom.
When a child picks up a gun, he becomes a man and inspires fear, if not respect.
In my experience, African youth are forgotten except when politicians need them for battle.
If African youth are given a better education and the means to influence their communities, then they will be less likely to be used as cannon-fodder, less likely to pick up a gun, and more likely to read a book.
Seventeen years ago, against the wishes of my father, I picked up a gun, hoping to change the world.
I survived and learned.
I learned the limits of the gun.
Many of my comrades were robbed of that chance, for few remain alive.
Of those living, most hold senior posts in the Ugandan army; a few are in politics.
Yet most died in combat or of AIDS.
Young Africans should remember this when they look for ways to make their mark.
One side effect of the American/British occupation of Iraq is that it sparked public debate on a dark secret of international finance: the debts taken on by odious regimes.
As Iraq's new rulers debate what to do about the billions of dollars in foreign debts inherited from Saddam Hussein's regime, voices ranging from the charity Oxfam-International to US defence guru Richard Perle are calling for debt repudiation on the grounds that the debts Iraq now bears were contracted to sustain a corrupt, oppressive regime.
Iraq is not the only country burdened by such debts.
Across sub-Saharan Africa, many of the world's poorest people struggle with the crippling legacy of profligate lending to corrupt, oppressive rulers.
During his 32-year dictatorship, Congo's former president Joseph Mobutu accumulated a personal fortune estimated at $4 billion, while his government ran up a $12 billion foreign debt.
More of the same in Angola, where last year an IMF investigation revealed that $4 billion disappeared from Angola's treasury over the past five years.
It so happens that the Angolan government borrowed a similar sum from private banks in this period, mortgaging future oil revenues as security.
Much of Africa's ill-gotten wealth is now stashed abroad.
In a study of 30 sub-Saharan African countries, we estimate that total capital flight for the period 1970-1996 amounted to $187 billion.
Adding imputed interest earnings, the stock of Africa's capital flight stood at $274 billion - a sum equivalent to 145% of the debts owed by those countries.
In other words, sub-Saharan Africa is a net creditor to the rest of the world: its external assets exceed its external debts.
The difference is that the assets are private and the debts public.
Statistical analysis reveals that roughly 80 cents on every dollar borrowed by African countries flowed back as capital flight in the same year.
Foreign borrowing and capital flight were connected by a financial revolving door, as funds borrowed in the name of governments were captured by politically connected individuals and channeled overseas as their private wealth.
Moreover, every dollar added to a country's total debt generated 3 to 4 cents of extra capital flight per year in subsequent years, implying that capital flight was partly a response to the deteriorating economic environment associated with rising debt burdens.
In the last decade, sub-Saharan Africa recorded a "net transfer" (new borrowing minus debt service on past loans) ofnegative $11 billion.
That is, more money flowed out of Africa to creditors than returned as fresh lending.
The countries of the region spend more on debt service than on health.
Despite this haemorrhage, the debt burden grows ever larger.
But there is a remedy at hand.
The doctrine of "odious debt" dates from the end of the 19th century, when the US government repudiated Cuba's external debt after seizing the island in the Spanish-American war.
America's authorities argued that Cuba's debt had not been incurred for the benefit of the Cuban people, nor with their consent, and that foreign loans helped to finance their oppression.
Similar reasoning can be applied today not only to Iraq, but to Africa as well.
Properly functioning financial markets require creditors to bear the consequences of imprudent lending.
The notion that lenders should always be repaid, regardless of how and to whom they lend, is indefensible.
The logic of sound banking tells us that current and future African governments should accept liability only for those portions of public debts that were incurred to financebona fide domestic investment or public consumption.
Invoking the doctrine of odious debt, they could selectively repudiate that portion of the debt for which no such uses can be demonstrated.
This policy poses two practical problems.
The first is to determine who should bear the burden of proof in identifying which debts are "odious."
Given the evidence of widespread capital flight fueled by external borrowing, African governments can rightly insist that creditors have the responsibility of establishing that their loans were used forbona fidepurposes.
If the fate of borrowed money cannot be traced, then they must infer that it was diverted into private pockets.
The second problem is that creditors may withhold new lending from governments that have the nerve to reject odious debts.
But today resources flow from Africa to creditors, rather than the reverse.
In the short run, African countries will save money by staunching this outflow.
In the long run, selective repudiation of odious debts will benefit both borrowers and creditors by promoting more responsible lending practices.
If Iraq's occupation gives impetus to legal challenges that free Africans from the burden of odious debts, then the war will have succeeded in dismantling at least one weapon of mass destruction.
NAIROBI – When I met Eunice Wangari at a Nairobi coffee shop recently, I was surprised to hear her on her mobile phone, insistently asking her mother about the progress of a corn field in her home village, hours away from the big city.
A nurse, Wangari counts on income from farming to raise money to buy more land – for more farming.
Even though Wangari lives in Kenya’s capital, she is able to reap hundreds of dollars a year in profit from cash crops grown with the help of relatives.
Her initial stake – drawn from her nursing wages of about $350 a month – has long since been recovered.
Wangari is one of thousands of urban workers in Kenya – and one of hundreds of thousands, even millions, across Africa – who are increasing their incomes through absentee agriculture.
With prices for basic foodstuffs at their highest levels in decades, many urbanites feel well rewarded by farming.
Absentee agriculture also bolsters national pride – and pride in traditional diets – by specializing in vegetables specific to the region. “For too long our country has been flooded with imported food and Westernized foods,” Wangari says.
“This is our time to fight back – and grow our own.”
Across Africa, political leaders, long dismissive of rural concerns, have awakened to the importance of agriculture and the role that educated people, even those living in major cities, can play in farming.
In Nigeria, former President Olusegun Obasanjo has a huge diversified farm and has pushed for policies to help absentee farmers prosper.
In Uganda, Vice President Gilbert Bukenya routinely travels the country, promoting higher-value farming, such as dairy production.
Perhaps the most visible political support for absentee agriculture is in Liberia, a small West African country where civil war destroyed agriculture, rendering the population dependent on food imports, even today.
President Johnson-Sirleaf, recognizing that educated people could contribute much to an agriculture revival, launched her “Back to the Soil” campaign in June 2008 in large part to encourage urban dwellers to farm.
To be sure, absentee farming by elites and educated urban workers can’t solve all of Africa’s urgent food needs.
Moreover, absentee farmers face unexpected problems.
Because they don’t visit their fields often, they rely heavily on relatives and friends.  When I decided to farm wheat for the first time this spring on leased land in my childhood village, my mother agreed to supervise plowing, planting, and harvesting.
Without her help, I might not have farmed at all.
Even with mother’s help, I have worries.
Although I grew up around wheat fields, my knowledge of farming is thin.
Fertilizer and spraying were both more expensive than I thought.
While my wheat stalks are sprouting on schedule, I now fear that at harvest time – in November – prices will fall and I won’t recoup my costs.
One key tool is the mobile phone.
My hopes for success are buoyed by my ability to call my mother inexpensively and discuss the farm.
We even decided over the phone what kind of pesticide to use and which tractor company to hire.
Because they know both the tastes of fellow city dwellers and rural conditions, many urban farmers are succeeding.
In fact, some city dwellers don’t even bother with acquiring land or gaining distant help.
Certain crops can be grown in their own homes.
James Memusi, an accountant, grows mushrooms in a spare bedroom, selling them to nearby hotels and supermarkets.
Nevertheless, most people living in Africa’s cities have access to land in the countryside, which is why Liberia’s government rightly highlights the potential for farm expansion.
In a new advertising campaign rolled out this summer, the authorities declared, “The soil is a bank; invest in it.”
In Liberia, the main push is to reduce imports of staples such as rice and tomatoes.
In more prosperous countries, African elites are motivated by a complex interplay of national pride, dietary concerns, and the pursuit of profit.
In Zambia, for example, Sylva Banda ignited a craze for authentic traditional meals two decades ago with a chain of popular restaurants.
Now, ordinary Lusakans want to cook similar meals in their own homes, driving demand for farmers who produce such delicacies as dried pumpkin, “black jack” leaves, and fresh Okra.
Similarly, in Nairobi, Miringo Kinyanjui, another woman entrepreneur, is supplying unrefined – and more nutritious – maize and wheat flour.
In another move to distinguish her ingredients from Western versions, Kinyanjui also sells through grocery stores flour flavored with Amarathan, a green vegetable that grows around Kenya.
The revival of traditional foods has attracted the attention of large multinational corporations.
Last year, Unilever’s Kenyan branch ran a “taste our culture” campaign in support of its line of traditional East African herbs and spices.
Such campaigns go hand-in-hand with expanded farming, because sellers of these foods prefer nearby growers – even if these growers increasingly live in the city.
Human migration is as old as history.
Even migration to distant places and remote cultures is nothing new.
In the nineteenth century, millions of Europeans sought liberty and prosperity in the Americas, notably in the United States.
What is new today is the scale of migration, often across huge cultural divides - and often without a definite aim.
The African boat people in the Mediterranean are often not even sure whether they want to be in Italy, Germany, or Britain.
Even those who are certain, like North Africans in Spain and France, or Turks in Germany, had as their priority escaping the hopelessness of their home countries, not arriving at a particular destination.
This modern form of migration raises massive problems for countries on the receiving end.
In Europe, it is probably the most serious social issue today, because no one has a clear idea about how to manage the resulting clash of cultures.
Once upon a time, North America, notably the US, seemed to provide the answer.
It was that of the "melting pot": different peoples made their own contribution to American culture, but, above all, they made every effort to accept what they found and integrate. "No," the Russian woman who came to the US in the early twentieth century replied to the grandchild who asked whether her ancestors arrived with the Pilgrims on the Mayflower.
"Our ship had a different name, but now we are all Americans."
More recently, this has changed, giving rise to a process described by Arthur Schlesinger, the historian and former aide to President John F. Kennedy, in his bookThe Disuniting of America.
No longer are all US citizens Americans.
They have become hyphenated Americans: Italian-Americans, African-Americans, Hispanic-Americans, and so on.
The ingredients of the melting pot are separating.
Even in Israel, the last true immigration country - at least for Jews - assimilation is no longer so easy.
Recent newcomers from Russia have their own political party, and old Europeans have become a distinct minority.
Israel and America continue to have mechanisms to integrate new migrants.
Language is an important underlying factor, and in Israel, there is the army, while in America, the values embodied in the Constitution still represent a shared secular faith.
But these mechanisms are weakening everywhere, and are virtually non-existent in European countries.
Modern societies are characterized by acute problems of belonging.
They don't offer the implicit, unconscious ties of community that citizens felt in the past.
As a result, people have begun to cling to other, more primordial group identities.
They resist assimilation, fearing that it will rob them of their identity without offering a new one.
What then is the alternative to assimilation? The "salad bowl" of so-called multiculturalism is no real alternative, because it does not provide the necessary glue that binds communities together.
All the ingredients remain separate from the outset.
The only viable alternative for which there are examples is probably that of London or New York.
The main characteristic of this alternative is the coexistence of a common public sphere shared by all and a considerable degree of cultural separation in the "private" sphere, notably in residential areas.
The public space is multicultural in terms of people's backgrounds, but is governed by agreed values, even a common language, whereas the people's private lives are - to use an ugly word - ghettoized.
In theory, this is a distinctly second-best solution to the cultural consequences of migration; in practice it is the best answer we have.
But it cannot be had for nothing.
Even the necessary minimum of a common language requires a deliberate effort, to say nothing of certain rules of behavior.
Living in London, I marvel at the way in which we Londoners have come to terms with Indian family shops and West Indian-run public transport, while not asking many questions about whole districts that are Bangladeshi or Chinese.
No one has yet found a name for this new version of the "separate but equal" doctrine that some of us fought so hard against in the 1960's: separate private lives in a common public space that is equal for all.
This is clearly easier in London and New York than it is in smaller towns or even in the capitals of countries where the world language of English is not spoken.
Berlin's Turkish community and the North African communities around Paris seem increasingly separate, with their own public sphere and often language.
Where this happens, an explosive condition can arise, a kind of separatism within, not by historically separate groups but by newcomers against natives.
If we are forced to abandon the hope of assimilation, our efforts should concentrate on creating a public space to which all contribute and that all enjoy.
Ideally, this should be an expanding public space, for in the end, the element of unity in a modern society is the guarantee of its citizens' liberty.
NEW YORK – This year’s annual meeting of the International Monetary Fund made clear that Europe and the international community remain rudderless when it comes to economic policy.
Financial leaders, from finance ministers to leaders of private financial institutions, reiterated the current mantra: the crisis countries have to get their houses in order, reduce their deficits, bring down their national debts, undertake structural reforms, and promote growth.
Confidence, it was repeatedly said, needs to be restored.
It is a little precious to hear such pontifications from those who, at the helm of central banks, finance ministries, and private banks, steered the global financial system to the brink of ruin – and created the ongoing mess.
Worse, seldom is it explained how to square the circle.
How can confidence be restored as the crisis economies plunge into recession?
How can growth be revived when austerity will almost surely mean a further decrease in aggregate demand, sending output and employment even lower?
This we should know by now: markets on their own are not stable.
Not only do they repeatedly generate destabilizing asset bubbles, but, when demand weakens, forces that exacerbate the downturn come into play.
Unemployment, and fear that it will spread, drives down wages, incomes, and consumption – and thus total demand.
Decreased rates of household formation – young Americans, for example, are increasingly moving back in with their parents – depress housing prices, leading to still more foreclosures.
States with balanced-budget frameworks are forced to cut spending as tax revenues fall – an automatic destabilizer that Europe seems mindlessly bent on adopting.
There are alternative strategies.
Some countries, like Germany, have room for fiscal maneuver.
Using it for investment would enhance long-term growth, with positive spillovers to the rest of Europe.
A long-recognized principle is that balanced expansion of taxes and spending stimulates the economy; if the program is well designed (taxes at the top, combined with spending on education), the increase in GDP and employment can be significant.
Europe as a whole is not in bad fiscal shape; its debt-to-GDP ratio compares favorably with that of the United States.
If each US state were totally responsible for its own budget, including paying all unemployment benefits, America, too, would be in fiscal crisis.
The lesson is obvious:&#160; the whole is more than the sum of its parts.
If Europe – particularly the European Central Bank – were to borrow, and re-lend the proceeds, the costs of servicing Europe’s debt would fall, creating room for the kinds of expenditure that would promote growth and employment.
There are already institutions within Europe, such as the European Investment Bank, that could help finance needed investments in the cash-starved economies.
The EIB should expand its lending.
There need to be increased funds available to support small and medium-size enterprises – the main source of job creation in all economies – which is especially important, given that credit contraction by banks hits these enterprises especially hard.
Europe’s single-minded focus on austerity is a result of a misdiagnosis of its problems.
Greece overspent, but Spain and Ireland had fiscal surpluses and low debt-to-GDP ratios before the crisis.
Giving lectures about fiscal prudence is beside the point.
Taking the lectures seriously – &#160;even adopting tight budget frameworks –&#160;can be counterproductive.
Regardless of whether Europe’s problems are temporary or fundamental – the eurozone, for example, is far from an “optimal” currency area, and tax competition in a free-trade and free-migration area can erode a viable state – austerity will make matters worse.
The consequences of Europe’s rush to austerity will be long-lasting and possibly severe.
If the euro survives, it will come at the price of high unemployment and enormous suffering, especially in the crisis countries.
And the crisis itself almost surely will spread.
Firewalls won’t work, if kerosene is simultaneously thrown on the fire, as Europe seems committed to doing: there is no example of a large economy – and Europe is the world’s largest – recovering as a result of austerity.
As a result, society’s most valuable asset, its human capital, is being wasted and even destroyed.
Young people who are long deprived of a decent job – and youth unemployment in some countries is approaching or exceeding 50%, and has been unacceptably high since 2008 – become alienated.
When they eventually find work, it will be at a much lower wage.
Normally, youth is a time when skills get built up; now, it is a time when they atrophy.
So many economies are vulnerable to natural disasters – earthquakes, floods, typhoons, hurricanes, tsunamis –&#160;that adding a man-made disaster is all the more tragic.
But that is what Europe is doing.
Indeed, its leaders’ willful ignorance of the lessons of the past is criminal.
The pain that Europe, especially its poor and young, is suffering is unnecessary.
Fortunately, there is an alternative.
But delay in grasping it will be very costly, and Europe is running out of time.
KIEV: Chernobyl, the world’s most notorious nuclear power plant, will be shut down today, fourteen years after it spewed clouds of radioactive dust into the atmosphere.
Back then, Ukraine became the focus of global attention, but Ukrainians learned of the disaster much later than the rest of the world.
I recall that fateful Saturday afternoon with utter clarity, strolling through Kiev with my six-year-old daughter, oblivious to the danger.
Chernobyl changed Ukraine forever, and was a catalyst for the downfall of the Soviet Union.
Ultimately, Chernobyl changed the world.
Now that Chernobyl will be permanently shut down, world attention again turns to Ukraine, this time in hope, not fear.
Shutting down a vital source of electrical energy, which Chernobyl remains, is no an easy task, particularly with winter upon us.
Ukraine’s energy infrastructure is weak; losing 8-10% of our electricity production and $100 million in revenues will strain the system even more.
We also bear the responsibilities involved in laying off Chernobyl’s workers and depriving the adjacent city of Slavutych (population 28,000), of its main source of income.
Moreover, we must continue dealing with the technical and ecological issues surrounding the Chernobyl sarcophagus, as well as maintain nuclear safety in the remaining nuclear plants in operation in Ukraine, including what is left of Chernobyl.
In recent years, Ukraine alone financed all the costs of dealing with the Chernobyl disaster, consistently spending 5-10% of our state budget revenues to this end.
Dealing with the aftermath of the disaster will remain a financial burden even with the plant closed.
Yet closing the plant proves that we keep our promises.
We committed to shut down Chernobyl this year in an agreement with the G-7 countries and the European Commission.
Closure of the last remaining reactor at Chernobyl, I believe, must mark the beginning of a new phase of cooperation with the European Union and G-7 countries.
Closing Chernobyl may be the most dramatic, but it is only a single episode in our reform efforts.
When we gained independence, the world expected great things from Ukraine.
Over the course of a decade, the world appeared to forget about us.
Now we finally have a chance to break out of the downward spiral of economic decline.
At long last, our society and economy are set on the path to growth and development.
After pro-reform forces secured victory in last year’s presidential elections, all of the branches of government began cooperating to entrench democracy and the market economy in Ukraine.
For the first time since independence, Ukraine recorded growth in industrial output of 12.5% in the first 11 months of 2000, and GDP has grown by 5.4% this year.
Tough decisions were made, not least involving the energy sector.
Barter payments, -- which stifled the energy market -- were eliminated. So too tax breaks and other privileges that skewed the playing field in favor of a select few.
We are also doing everything possible to make Ukraine attractive to foreign investors.
In the energy sector, we are privatizing state-owned energy distributors.
To ensure complete transparency in the tender process, and eliminate problems experienced in the past, Western advisors are assisting us.
For our intention is to attract large Western energy companies with experience in this field as strategic investors.
Ten leading international energy companies, indeed, will participate in the privatization of the first group of companies.
By the end of next year, we will privatize 12 additional energy companies.
In its sheer scale, this may be the largest single energy privatization ever attempted in Europe.
Our energy companies service a territory the size of France; they will all be privatized.
Of course, these reforms are resisted, primarily by the oligarchs who thrive on a lack of transparency and use privileged access to state resources to enhance their business interests.
By eliminating barter and requiring monetary payment, we curtailed their opportunities to profit at the state’s expense.
Although we can and will continue the fight against corruption, we cannot do everything alone.
International support for our efforts is crucial.
A positive sign here is the recent decision by the European Bank for Reconstruction and Development (EBRD) to provide $215 million to complete the nuclear power stations at Rivne and Khmelnytsky, which will compensate for the loss of Chernobyl’s generating capacity.
Euroatom is also helping with a loan of $585 million to finance repairs at Ukraine’s functioning nuclear power plants.
In return, Ukraine will uphold its end of the deal: in addition to closing Chernobyl, we will introduce Western nuclear safety standards and renew cooperation with the IMF via the Extended Fund Facility program.
We still need other potential creditors to confirm their involvement.
Closing Chernobyl will not eliminate the Chernobyl threat.
Our people will be unable to live on thousands of acres of contaminated earth for hundreds of years.
The concrete sarcophagus built over the destroyed reactor must be renovated.
We are grateful to all the donor countries who, with contributions from our own state budget, helped raise the $760 million needed to make the sarcophagus safer.
In the end, Chernobyl’s legacy does not belong solely to Ukraine, for ours is a country located in the heart of Europe.
We are a European nation.
We realize that no one will implement reforms for us.
The West can, however, help speed up and facilitate our efforts, as it did with the closure of Chernobyl.
Cooperation between Ukraine and the West, without a disaster to concentrate everyone’s minds, will benefit all concerned.
BEIJING: China has now finished celebrating the 50th anniversary of Mao's revolution, but the hangover cure that so many people in the West have been urging upon the country -- a healthy dose of devaluation -- is unlikely to be swallowed.
Instead, the government has put forward a fresh round of fiscal stimulation, including a RMB60 billion new bond issue and the introduction of a new 20% tax on the interest on savings.
Devaluation, indeed, remains a taboo.
Why are China's leaders so adamant against devaluing the RMB?
First, Prime Minister Zhu Rongi and his advisors are very uncertain about the short-run benefits to be gained from any devaluation.
Any boost to competitiveness, for example, is likely to be small and brief, as over 50% of China's exports are part of re-export industries using a great deal of imported materials or semi-finished goods.
For these sectors, devaluation means an increase in costs, rather than a gain in competitiveness.
Secondly, devaluation of the RMB may incite tit-for-tat retaliation by other Asian economies.
The decline of China's exports have been mainly caused by a 20% decrease in exports to other Asian markets since 1998.
But as these regional economies are now starting to recover, China's exports to them are starting to grow.
Although a devaluation of the RMB may not have as much impact on the regional markets as before, it is impossible to calculate what way may deliver higher export growth: devaluation or not disturbing the region's increasing stabilization.
Doing nothing seems the safer bet.
Moreover, devaluation will impose heavy burdens on China, for example, it will certainly increase the cost of servicing China's debts and may also worsen the overall balance of payment.
The only foreseeable benefit to be gained through a devaluation is a reduction in uncertainty as an end will be put to the rampant speculation on when the RMB will be devalued.
This may help to increase the foreign investment and reduce the capital flights.
Today, the real issue for China is not devaluation but "de-pegging" – ie, a return to the former "managed float regime" of foreign exchange that prevailed between 1994 and 1997 -- which means giving up the de facto fixed-rate regime which actually pegs the RMB to the US dollar.
Such a break is the only way to prevent over-speculation in the RMB, although de-pegging may cause some initial devaluation under current market conditions.
But the question is: when and how?
The world-wide dilemma over exchange rate management is that when market pressure is not high necessary changes no longer seem so urgent.
People lack the determination to take the action.
But when pressure is high, government leaders charged with financial management feel trapped in a corner during any currency crisis.
For Chinese policy makers, today's market pressures are not high enough to force them to take action, as China still enjoys a decent surplus in its balance of payments, both on current account and capital account.
In addition, China's foreign reserve are rising at an accelerating path in recent months, up to $150 billion at the end of July, 1999.
Last but not the least as a reason not to devalue, China is struggling with deflation and a slowdown in the country's growth rate.
This is mainly caused by domestic problems (the bloated state owned enterprises and the government's failure to reform them, the huge number of non-performing loans on the books of state banks, restrictions to private investment, among many other causes. External conditions are playing little part in China's slowdown.
So devaluation is unlikely to be effective in boosting the overall rate of growth.
In any case, devaluation of the RMB in real terms or in terms of competitiveness in relationship with major Asian currencies has been already been occurring over recent months: All Asian currencies, including the Japanese yen, are appreciating; and domestic prices continue to deflate.
If the US dollar weakens in relation with other major currencies, China may not need to adjust RMB's nominal rate for quite a while.
Sun Tzu and other Chinese military theorists long ago counseled that doing nothing is sometimes the best way to win in the end.
Today's Chinese leadership has adopted that bit ancient wisdom to currency management.
The Kyoto Protocol treaty has now entered into force for the 126 nations who have joined it so far.
Now is the time to start thinking about how to engage all nations, including large emitters, in conversations about what to do after the treaty’s expiration in 2012.
This is exactly what the European Commission did recently by providing its first strategy for a post-Kyoto era, which will be discussed by the European Council next March.
While the Kyoto Protocol represents only a modest reduction of carbon emissions in industrialized countries – 5.2% between 2008-2012 relative to 1990 levels, with varying targets for individual countries – real progress can be made in sustaining development efforts and preserving our planet.
But first, all countries must integrate climate concerns into policy planning, and improve their governance in key sectors such as energy, infrastructure, and transport.
In other words, we must act in accordance with the recognition that climate change and its effects on people in both rich and poor countries remains a threat to global security.
At the end of the day, the long-term approach is likely to include a rules-based system, an incentives system, and investments in technology change.
Increasingly, adaptation at the national level will be recognized as a major issue that will require appropriate funding.
Dealing with the impacts of climate change and with emission reductions should not be mutually exclusive, but complementary.
Looking ahead to the post-Kyoto world offers us the chance to start a new dialogue and to look at new options on climate change.
Nations could set the more ambitious goal of limiting the long-term change in the earth’s temperature, and then assign emissions rights among countries in such a way that will eventually limit temperature increases to an acceptable level.
This would require increasing investments in energy research and development for new and improved technologies – a process that needs to be supported by stronger public-private partnerships.
Up to now, with only 15% of the world’s population, rich countries have been responsible for more than 75% of global carbon dioxide (CO2) emissions, and thus most of the environmental damage.
However, it is the developing countries – and thus the world’s poor – who are most vulnerable.
It is unrealistic to ask poor countries, where more than 1.6 billion people do not have access to clean energy and technologies, to bear the costs associated with the much needed technological change.
Working with partners, the World Bank is supporting financial strategies to assist developing countries in meeting the costs caused by climate change.
To date, over $1 billion dollars in Global Environment Facility (GEF) grants, together with about $8 billion in co-financing, have been committed to programs related to climate change.
While the regulatory mechanisms of both Kyoto and the European Trading Scheme have contributed to the establishment of an emerging market for carbon trading, interested parties are now concerned about the immediate future.
Without a regulatory framework beyond 2012, the window of opportunity for initiating project-based transactions will close by 2006/2007.
Given the long lead time between project preparation and the first benefits of emissions reductions, project developers have only a few years to act before carbon payments cease to make a meaningful contribution to project finance in the current context.
Developing infrastructure projects is a long process that requires 3-7 years from identification, through licensing, financing, and construction, and finally to the first certification of carbon emission reductions.
Therefore, projects need to be operational at the latest by 2007.
The World Bank has been instrumental in advancing carbon finance as a viable development tool, and in facilitating private-sector participation in the market.
The Bank is focused on representing the interests of its borrowing countries, helping them to develop assets for carbon trading according to their own priorities.
But, without a commitment by governments to limit greenhouse gas emissions beyond 2012, the carbon market will remain uncertain, and the private sector – vital to the market’s success – is unlikely to expand its participation in a meaningful and sustained way.
According to a recent World Bank-supported survey of companies interested in carbon finance, only one in five respondents declared that they were interested in buying post-2012 emissions reductions.
Now is the chance to look forward and enlist the global community – with no exclusions, although with differentiated responsibilities – in the pursuit of a more secure world, one that avoids the dire risks of environmental degradation and social conflict implied by inaction.
Two decades of applying neoliberal economic policies to the developing world have yielded disappointing results.
Latin America, the region that tried hardest to implement the "Washington Consensus" recipes--free trade, price deregulation, and privatization--has experienced low and volatile growth, with widening inequalities.
Among the former socialist economies of Eastern Europe and the Soviet Union, few have caught up with real output levels that prevailed before 1990.
In Sub-Saharan Africa, most economies failed to respond to the adjustment programs demanded by the IMF and World Bank.
The few instances of success occurred in countries that marched to their own drummers--and that are hardly poster children for neoliberalism.
China, Vietnam, India: all three violated virtually every rule in the neoliberal guidebook, even as they moved in a more market-oriented direction.
It is time to abandon neoliberalism and the Washington Consensus.
But the challenge is to provide an alternative set of policy guidelines for promoting development, without falling into the trap of promulgating yet another impractical blueprint, supposedly right for all countries at all times.
The record suggests that an adequate growth program needs to be anchored in two strategies: an investment strategy designed to kick-start growth in the short term, and an institution-building strategy designed to provide an economy with resilience in the face of adverse shocks.
The key to investment strategy is to get domestic entrepreneurs excited about the home economy.
Encouraging foreign investment or liberalizing everything and then waiting for things to improve does not work.
An effective strategy must accomplish two tasks: encourage investment in non-traditional areas, and weed out projects and investments that fail.
For this, governments must deploy both the carrot and the stick.
Learning what a country is (or can be) good at producing is a key challenge of economic development.
The carrot is needed because there is great social value in discovering, for example, that cut flowers, or soccer balls, or computer software can be produced at low cost, because this knowledge can orient the investments of other entrepreneurs.
The entrepreneur who makes the initial "discovery" can capture only a small part of the social value that this knowledge generates, as other entrepreneurs will quickly emulate him.
Consequently, entrepreneurship of this type--learning what can be produced--will typically be under-supplied in the absence of non-market incentives.
In turn, the stick is needed to ensure that these incentives do not lock in unproductive and wasteful investments.
Implementing such a strategy may differ from country to country, depending on administrative capacity, the prevailing incentive regime, the flexibility of the fiscal system, the degree of sophistication of the financial sector, and the underlying political economy.
Time-bound subsidy schemes, public venture funds, and export subsidization are some of the ways in which this approach can be implemented, but there are many others.
No single instrument will work everywhere.
Governments without adequate capacity to exercise leadership over their private sectors are likely to mess things up rather than improve allocation of resources.
The job can be done, but economic growth requires more than eliciting a temporary boost in investment and entrepreneurship.
It also requires effort to build four types of institutions required to maintain growth momentum and build resilience to shocks:
Market-creating institutions (for property rights and contract enforcement);
Market-regulating institutions (for externalities, economies of scale, and information about companies);
Market-stabilizing institutions (for monetary and fiscal management);
Market-legitimizing institutions (for social protection and insurance).
Building and solidifying these institutions, however, takes time. Using an initial period of growth to experiment and innovate on these fronts can pay high dividends later on.
A key point here is that institutional arrangements are, by necessity, country-specific.
Discovering what works in any one country requires experimentation.
After all, institutions are not hot-house plants capable of being planted in any soil and climate.
Reforms that succeed in one setting may perform poorly or fail completely in others.
Such specificity helps explain why successful countries--China, India, South Korea, and Taiwan, among others--usually combined unorthodox elements with orthodox policies.
It also accounts for why important institutional differences persist among the advanced countries of North America, Western Europe, and Japan in areas such as the role of the public sector, the legal system, corporate governance, financial markets, labor markets, and social insurance.
While economic analysis can help in making institutional choices, there is also a large role for public deliberation and collective choice.
In fact, we can think of participatory democracy as a meta-institution that helps select among the "menu" of possible institutional arrangements in each area.
Designing such a growth strategy is both harder and easier than implementing standard neoliberal policies.
It is harder because the binding constraints on growth are usually country-specific and do not respond well to standardized recipes.
But it is easier because once those constraints are appropriately targeted, relatively simple policy changes can yield enormous economic payoffs and start a virtuous cycle of growth and institutional reform.
Adopting this approach does not mean abandoning mainstream economics--far from it.
Neoliberalism is to neoclassical economics as astrology is to astronomy.
In both cases, it takes a lot of blind faith to go from one to the other.
Critics of neoliberalism should not oppose mainstream economics--only its misuse.
NEW YORK – It has become popular to suggest that when the dust settles from the global financial crisis, it may become clear that the United States-led post-war world has come to an end.
If so, the global system that has secured peace, security, openness, and economic growth over the past six decades could be in grave danger.
Inspired by American leadership since World War II’s end, Europe, then Japan, then much of Asia and the world rose to new levels of prosperity; the world economy globalized upon the foundation of international institutions, norms, and standards; and foreign students educated in American universities returned home with new ideas about free markets, entrepreneurship, and democracy.
The US military’s protective umbrella gave large swaths of the world a vacation from war, making it easier for them to focus on economic growth and regional integration.
America not only took the lead role in building the institutions of a globalizing world – the United Nations, World Bank, IMF, NATO– it also became the model that many other countries looked to for inspiration.
After eight years of compromised American leadership, a botched war of choice in Iraq, failure to take the lead in global efforts to address climate change, Abu Ghraib, Guantánamo Bay, running up a $10 trillion debt, and igniting a global financial crisis – America’s once-glittering model has lost a good deal of its luster and America’s leadership has been questioned by many.
The point was driven home at the 7th Asia-Europe Meeting (ASEM) in Beijing this autumn, where European and Asian leaders began exploring ideas for a new global financial structure.
For much of the past 60 years, it would have been impossible to hold such a fundamental dialogue without US participation.
Today, it is almost becoming a new global norm that neither the international committee nor the US is prepared for.
Despite talk about American decline, the world is not prepared for a post-American era.
As irksome as some of America’s actions have been, particularly over the past eight years, America remains the world’s most critical champion of the progressive values that have lifted hundreds of millions of people out of abject poverty and political repression.
If the US were to play a relatively smaller role in world affairs, and no other system was created to pick up the slack, these values could be at risk.
Although many states now hide behind an alleged universal principle of inviolable state sovereignty, for example, would the international community really want to go back to the old model where states did whatever they wanted to their citizens within the confines of their own borders?
Do countries around the world believe that they will be better off if the global trade system breaks down or international shipping lanes become less secure?
Are countries like China willing to step up and pay their fair share of dues to keep the UN running (China currently pays 2.1% of UN dues, compared to more than 25% for the US), or to capitalize revised international financial institutions or the Global Fund to Fight AIDS, Tuberculosis, and Malaria in a meaningful way?
Unless other countries become more willing to step forward for the common good, a post-American world could quickly become a far more frightening environment than what it would replace.
To make its case for a continued global leadership role, America must, however, step up to the plate.  While the go-it-alone impulse of the Bush administration has been discredited by its consequences, the inverse lessons regarding how important collaborative action is in today’s interconnected world are still being learned.
Even at the apex of American power, America’s greatness was always based on inspiring others, and the opportunities for building market share in that particular category remain unlimited.
It is impossible to overestimate how significant a step Barack Obama’s election is in this direction, but America’s actions over the coming years will be the ultimate determinant of whether the power of America’s model can be restored.
America can and should, for example, become the global leader combating climate change through major investments in alternative energy, conservation, and energy efficiency, and by taking strong actions at home to reduce America’s greenhouse gas emissions.  It should transform its immigration policy to recruit the best and brightest people from around the world to move to the US and become citizens, and remain the world’s leading champion of open markets, especially during the current financial crisis.
Closing the prison at Guantánamo and reaffirming America’s commitment to international law and human rights will also be an important step in this direction.
The world wants to believe in an America that lives up to its own best values.
The prospect of a truly global community of nations working together to achieve the greater good for all is indeed exciting.
But, although America has been far from perfect over the last six decades, the end of thepax Americanahas the potential to create a dangerous void in international affairs.
If the world is going to shift in the direction of a new and more globally democratic system, other nations will need to meaningfully step forward to assume new responsibilities.
It is in America’s and the world’s interest that they do so.  The evidence of this will be seen not only in global institutions but also in places like Darfur, Zimbabwe, and Burma.
Until this happens, let us all hope that America can get back on track as the global champion of collaborative action to address the world’s greatest challenges and work with as many other countries  as possible to move collectively in the right direction.
A decade ago, people spoke of the end of history, meaning the ultimate triumph of a liberal capitalist political order.
Nowadays, many scoff at that notion as too simplistic.
Nonetheless, we are at both the end and beginning of something remarkable.
In the wake of the death of the utopian - and often bloody - certainties of the 19th and 20th centuries (Communism's collapse was but the latest spectacular example), and with fading belief in the liberal welfare state, traditional views about work, retirement, education, the Church, solidarity, and other social institutions are changing rapidly.
The central driver of all this is today's enormous acceleration in the underlying pace of technological and economic change.
Call itfast-forward modernization.
Of course, the worldwide crash of high-tech stocks in 2000 chilled the hype about a "new economy" that seemed to be emerging at the "end of history."
But falling share prices should not blind us to the fact that on top of the ongoing information revolution, three fresh waves of revolutionary technology are poised to hit: bio-technology (including new medical technologies and genetic engineering, such as the creation of human embryos through cloning), nanotechnology, and robotics.
Each is its own industrial revolution, and will profoundly alter our lives and ways of thinking.
Indeed, the revolution is already upon us.
For the first time in history, a global techno-market order is transforming the world of finance, business, politics and, indeed, physiology, beyond recognition.
This new techno-market system is shaped and characterized by a belief in the increasing importance of knowledge, new ideas, innovations and new technologies, and a higher pace of what the economist Joseph Schumpeter famously called "creative destruction."
As a result, corporate capitalism is rapidly becoming obsolete, replaced by a creative capitalism in which entrepreneurship, combined with a greater willingness to adopt innovations, transforms the business landscape.
Innovative start-up firms become huge companies faster than ever before.
But these infant giants are quickly threatened with eclipse by even newer enterprises.
Take the example of computers.
It took 15 years for other countries to compete successfully with America's Silicon Valley in semi-conductors, but less than five years in Internet technology.
This system provides unprecedented financial incentives to scientists and entrepreneurs to aggressively develop new technologies and thus become rich.
But the revolution is not only for the elite; it also offers a realistic (non-utopian) promise of dramatically improved lives for many people around the entire globe - not in 100 years, but in the foreseeable future.
We are notjust witnessing a simple adaptation of social structures and ways of living to suit new technologies.
The Nobel laureate Robert Fogel argues that a new synergism between technological and physiological improvements has produced a radically new form of human evolution, which he callstechnophysio evolution.
Only this, Fogel believes, can explain recent trends in longevity, body size, the durability of vital organs, and chronic diseases.
These changes are also triggering changes in human consciousness.
The result is a litany of "post-utopian" values that include a stronger emphasis on individual freedom and personal responsibility.
In this world without utopia, individual freedom is the supreme value.
But, as with any change of such magnitude, there are holdouts.
Indeed, politics everywhere now seems dominated by the "war of lifestyles" that has emerged from today's emphasis on individual autonomy.
Not so long ago, issues such as the environment, the balance of work versus leisure in daily life, and the role of marriage, abortion, and other family concerns were secondary political disputes, as politicians fought over who would receive what share of a nation's wealth.
Now these issues define domestic political agendas.
Much of the new battle over lifestyles is undoubtedly misunderstood, perhaps because debates about them are conducted in a simplistic way: anti-global movements versus multi-nationals, environmentalists versus corporate polluters, small farmers versus agro-business, and so on.
But, beyond slogans, there is an underlying fault line between those who have the cultural capacity to embrace change and those who resist it by adhering to traditional ideas about how one's life and, by extension, society, should be organized.
This conflict exists globally.
In societies that have been preparing themselves by opening their markets and embracing universal education, the disruptions of this revolution can probably be absorbed and handled.
Conflict is most acute in closed societies characterized by a politically repressive climate and culturally induced obstacles to growth.
Such obstacles include the absence of an informed and capable workforce, instinctive mistrust and rejection of new ideas and technologies just because they come from the West, lack of respect for those who acquire new knowledge, and endemic discrimination against women.
The new battle of lifestyles has given rise to new enemies of open societies, such as the Taliban and Al Qaeda.
It is no coincidence that terrorism thrives in societies that are intrinsically hostile to today's modernizing values and belief in individual autonomy.
So long as these ideas clash, violence will lurk.
To defend post-utopian values in the longer-term, politicians (and generals and spymasters) cannot seek security by drastically curtailing fundamental freedoms, because to do so risks forfeiting public support and a weakening of the pillars of the post-utopian market order.
In challenging groups like Al Qaeda, they must understand that they are engaged in a war of ideas; winning the hearts - and the lifestyles - of societies is the only way to win that battle.
LONDON – Even after the passage of new financial regulations in the United States, the Dodd-Frank Act, and the publication of the Basel Committee’s new capital requirements, the financial sector’s prospects over the next few years remain highly uncertain.
There has been some recovery in prices for bank shares from the lows of 2008, of course, but that rally faltered recently.
Quite apart from their concerns about the robustness of the rebound in the economy, investors are uncertain about many financial firms’ business models, and about the future size, shape, and profitability of the financial sector in general.
After all, banks remain deeply unpopular in all developed countries.
Bankers are still social pariahs, as lowly valued by the public as drug dealers or journalists.
They are reviled if they lose money, and assailed if they make it.
For banks and their shareholders, it looks a case of heads they win, tails we lose.
Thus, as banks return to profitability, politicians in North America and Europe have begun to talk again about new taxes that would skim those profits off to the benefit of taxpayers, whose support kept banks in business at the height of the crisis.
This is a huge contrast with the financial sector’s position in the previous three decades.
From the late 1970’s until 2007, the financial sector grew far more rapidly than the real economy.
In 1980, financial assets – stocks, bonds, and bank deposits – totaled around 100% of GDP in the advanced economies.
By 2007, the figure was over 400% in the US, the United Kingdom, and Japan.
During this period, credit expanded rapidly as a share of GDP, reaching more than 300% at the peak.
In the UK, the profits of financial intermediaries, which had averaged around 1.5% of the whole economy’s profits in the 1970’s, reached 15% in 2008.
In the US, bank profits were an even larger share of the total.
This was the golden age of finance.
Bankers’ pay soared alongside profits – indeed, it grew even faster.
To paraphrase William Wordsworth, bliss was it in that dawn to be alive, and to be a derivatives trader was very heaven.
But the expansion came to a shuddering halt in 2008, the first year in decades in which aggregate financial assets fell, and there is still little sign of a sustained recovery.
Is this a short-term phenomenon?
Will the financial sector return to pre-crisis growth rates when the economic situation has been fully stabilized?
Will financial “deepening” continue?
Will bank stocks once again outperform the market?
A recent study by Andy Haldane and others at the Bank of England casts doubt on the prospect of a return to the status quo ante.
They note that the Golden Age was in fact an unusual period, if you look at the last two centuries of economic history.
Haldane bases his analysis on the trend in the Gross Value Added (GVA) of the financial sector.
Over the last 160 years, the GVA of finance has grown by two percentage points a year faster than that of the economy as a whole.
But this excess growth has not been evenly spread.
During the two decades leading up to World War I, the financial sector grew almost four times faster than the economy, in the first wave of financial deepening and globalization, but from 1918 until the 1970’s, finance expanded less rapidly than average economic growth.
Only when markets were deregulated and liberalized from the early 1970’s onwards did finance once again leap ahead.
In the US, financial sector GVA was only 2% of the total in the 1950s, but stands at 8% today.
Haldane believes that this growth spurt is well and truly over.
He argues that much of the apparent growth in value added has in fact been illusory, based on increased leverage, excess trading, and banks writing deep out-of-the-money options – for example, credit-default swaps (a $60 trillion market in 2007). “What all these strategies had in common,” writes Haldane, “was that they involved banks assuming risk in the hunt for yield – risk that was often disguised because it was parked in the tail of the return distribution.”
From a regulator’s perspective, this is a powerful argument for requiring higher capital to constrain the risk that banks can take on.
Indeed, the Basel Committee plans to require more capital in the future, though the new requirements will be delayed, owing to concerns about the cost and availability of credit to sustain the recovery.
Against that background, it is hard to believe that we will quickly return to the heady growth in financial assets, credit, and risk we saw from the 1970’s to 2007.
Financial-sector returns are likely to be lower.
Returns of 20% on equity targets are a thing of the past.
And lower profitability will reduce pay more effectively than any direct regulatory controls.
For most of us, unless we remain seriously overweight in financial stocks, this may not be a bad prospect.
We do not want to inflate another asset-price bubble on the scale of the one that burst in 2007-2008.
But there is a risk for regulators and central banks.
If they over-constrain the financial sector, risk may migrate outside the regulatory frontier, where it will be harder to measure and monitor.
That is why it is important to maintain some flexibility, to allow currently unregulated institutions like hedge funds and private-equity funds to be swept into the regulatory net if they become large and systemically important.
The tighter their controls on risk in banks, the more frontier police the regulators will need.
The Middle East is a place where the dust hardly ever settles.
When it occasionally does, even for a short interval – as UN Resolution 1701 for cessation of hostilities in Lebanon seems to be holding – it is time to take stock of events in the hopes that a responsible debate may influence those in power.
Let’s start with the United States.
President George W. Bush has been short on neither initiatives nor catchy slogans and acronyms.
Recent years are littered with them: “Global War on Terror” (GWOT), “Road Map,” “Middle East Partnership Initiative “ (MEPI), “Broader Middle East and North Africa” (BMENA) – originally “Greater Middle East Initiative (GMEI) – Democracy Assisted Dialogue (DAD), and so on.
His latest reverie, envisioned in the thick of the recent fighting between Israel and Hezbollah, was the New Middle East (NME), with US clients Israel, Egypt, Jordan, and Saudi Arabia serving as the pillars of regional order.
But like all his previous initiatives since the terrorist attacks on New York and Washington almost five years ago now, the NME ran into trouble from the outset.
Secretary of State Condoleezza Rice announced its birth while rejecting an immediate ceasefire in Lebanon.
Her poor timing made the initiative appear heartless, as thousands of civilians were being uprooted, killed, or maimed by Israel’s efficient but ruthless artillery and air force.
This so embarrassed the three Arab NME partners that each raced to distance itself from the US-sponsored initiative.
Saudi Arabia, which had remained silent for nearly two weeks, did so with a $500 million contribution to rebuilding devastated areas of Lebanon and another billion to support Lebanon’s threatened currency.
Egypt’s heir apparent Gamal Mubarak followed suit in the fourth week of the fighting by heading a 70-member delegation on a solidarity visit to Beirut.
But, rather than earning him the respect of an outraged Egyptian public, revelations in the opposition press that his plane had to obtain a safe passage and authority to land from the Israelis garnered only howls of derision.
As for America, anything it touches in the Middle East has become radioactive, even for longstanding clients and friends.
In the course of maneuvering to delay the UN ceasefire, Bush and Rice continually reiterated the need for a Security Council resolution that deals forcefully with “the roots of the problem.”
Of course, for them and for Israel, this was Hezbollah and the need to eradicate or at a minimum disarm it and force its fighters to a safe distance from settlements and towns in northern Israel.
While this is a reasonable demand, the rest of the Middle East – and, indeed, much of the world, including Europe – regard the root cause of the conflict as Israeli intransigence and arrogance, together with America’s blind support for it.
Both America and Israel have cited foot-dragging in implementing UN Resolution 1559, which calls for disarming all non-state actors in Lebanon and the deployment of government forces all the way to the southern border.
But for years the US and Israel have not uttered a word about the dozens of UN resolutions, going back as far as Resolution 49 on partition in 1947, which called for the establishment of distinct Arab and Jewish states on roughly half of Mandated Palestine.
This and numerous other resolutions seeking redress for injustices toward Palestinians have been ignored by the US.
Thus, for 300 million Arabs and more than one billion Muslims the “root cause” of the Middle East conflict is not Hezbollah.
As its leader, Hassan Nasrallah aptly put it, “We are just a reaction to chronic injustice.”
It may well be that there is more than one root cause – every party to the conflict has a favorite one.
There is no point in belaboring whose pain is greater or whose root cause is deeper.
In fact, arguing over grievances merely drives the sides further apart.
The long overdue UN Resolution 1701 may, with its adoption, indicate that all parties are fatigued, or could no longer withstand international pressure.
This is good news for all concerned and provides an opportunity to tackle each party’s “root cause.”
Seizing the opportunity requires that humility rather than moral supremacy prevails.
Empathy, not ethnocentrism, should be the order of the day now that the guns are falling silent and we have rediscovered the limits of military force.
But if we have learned anything at all from the tragic assassinations of the region’s greatest peacemakers, Anwar Sadat and Yitzhak Rabin, it is that the guns do not remain silent for long.
During any lull, a fanatic from either side could jump to center stage and, through an act of utter madness, kick up the settling dust and dash the hopes of the many on both sides who still long for a lasting peace.
``Failed state'' is a term applied frequently to Afghanistan and is often deemed the cause for why terrorists gained such influence there.
But a country does not fail of its own volition, nor is it weakened by unknown causes.
A country fails, when it fails, for definite, identifiable reasons.
These must be addressed if Afghanistan is to be revived.
Twenty years of invasion, civil war, and drought have left Afghanistan's institutions in ruin.
Millions of Afghans huddle in refugee camps or are displaced from their homes.
Land-mines defile the countryside.
Millions are sick and poor; many live at starvation levels.
For these and many other reasons, rebuilding Afghanistan's economy will require not only economic reconstruction but an effort to reinvent the country's political and cultural institutions.
Such a massive effort will be doomed to failure, however, if Afghanistan's neighbors intervene in ways that promote economic upheaval all over again.
Afghanistan is no place for quick fixes.
Rebuilding the country cannot be done cheaply.
Any thought that the anti-terror coalition will be able to bail out fast (as the West did when it abandoned Afghanistan to its fate after the Soviet withdrawal ten years ago) should be forgotten.
The West must stick with Afghanistan until its reconstruction is established.
Otherwise, it runs the risk of renewed chaos and violence, but this time in a more destabilized region, as Pakistan's current problems demonstrate.
Three problems are of immediate concern, the most important being feeding the Afghan people - both within the country and in refugee camps outside Afghanistan.
Humanitarian aid is being delivered, but a distribution system safe from the predations of Afghanistan's warlords needs to be built.
Indeed, the warlords have been given too big a say in distributing aid already, and it may be hard to strip them of this power.
But stripped they must be.
The second problem involves relocating Afghan refugees now living in Pakistan and Iran, as well as those displaced within Afghanistan.
To achieve this goal, the agricultural economy must be revived in order to revive this industry, providing jobs and food for people.
A massive impediment here is the millions of mines left over from the Soviet invasion that must be removed.
The West has a big incentive to be generous to Afghanistan's rural poor.
Starving farmers, if unassisted, may return to cultivating a very reliable cash crop: the opium poppy, long a staple of the warlord economy.
Eliminating it will not only help farmers and the West as it tries to curtail heroin use, but also Afghanistan's infant government as it struggles to assert its national authority against the warlords.
A bankrupt warlord, after all, cannot buy weapons or bribe people to maintain their loyalty.
Major infrastructure investments will also be needed if the economy is to be revived.
Housing, particularly for returning refugees, will need to be constructed fast.
Cities such as Kabul, Mazar, Herat and others will need to be rebuilt as centers of economic and cultural life.
Village housing must be provided at a massive level.
Roads, airports and communications systems must also be revitalized if trade is to be restored.
The educational system needs to be rebuilt almost from scratch, and with so many women anxious to return to teaching, a revived educational system will also help Afghanistan's democratic politicians gain a powerful lobby of workers.
Particular attention should be given to elementary schools and libraries outside of cities.
Afghanistan poses particular difficulties in reconstruction, as it is not a society with a strong political center.
Planners should take advantage of the country's decentralized nature and emphasize private sector participation in reconstruction.
A decentralized system will respond better to local needs and avoid an over-bureaucratic public sector.
But autonomous economic regions should be avoided as a threat to Afghan national unity because they would play into the hands of the warlords.
Moreover, poorer regions would do badly in such a system.
In the long run, Afghanistan has resources that can be exploited.
There is the potential for oil and gas exploration, and of mining iron ore and precious metals.
These activities should be explored in a framework of economic development across Central Asia.
Afghanistan, indeed, must be integrated into the regional pipeline and other development schemes.
Afghans can contribute in a tangible way here by reopening the North-South route connecting the resource rich economies of Central Asia to densely populated India and Pakistan.
None of this will be possible unless Afghanistan's young males are disarmed and given productive work.
Essential here, is to attract expatriate Afghans with skills and professional achievements to help in rebuilding the country by establishing small firms that will suck up the unemployed.
Expatriate involvement will also likely support the rights of women to participate fully and legally in economic and political life, as was the case before 1978.
Finally, donor countries must apply the lessons learned in restoring the war-ravaged states of the former Yugoslavia.
Grants and planning must be coordinated, and the consent of Afghanistan's neighboring countries assured.
If the latter are ignored, regional interests can incite chaos once again.
An international conference on Afghanistan should be called by the US and held under UN auspices.
It must affirm not only Afghanistan's territorial integrity, but insure that donor commitments meet the scale of the job and that these promises are kept.
A decade ago, the West turned its back on Afghanistan and chaos ensued.
To abandon the country again would be criminal folly.
NEW HAVEN – The devastation – both human and physical – from the earthquake and tsunami in Japan is unfathomable.
It is impossible at this point to gauge the full extent of the damage with any degree of precision.
But we can nonetheless begin to assess its potential spillover effects on the rest of Asia and other major economies around the world.
The narrow view of the catastrophe’s economic impact is that Japan doesn’t really matter anymore.
After all, more than 20 years of unusually sluggish trend growth in Japanese output has sharply reduced its incremental impact on the broader global economy.
The disaster may produce some disproportionate supply-chain effects in autos and information-technology product lines such as flash drives, but any such disruptions would tend to be transitory.
On the surface, the world’s two largest economies have little to fear.
Japan accounts for only 5% of America’s exports and 8% of China’s.
Under the worst-case outcome of a complete disruption to the Japanese economy, the direct repercussions on the United States and Chinese economies would be small – shaving no more than a few tenths of a percentage point off their annual growth rates.
Within the so-called G-10 developed economies, Australia has the largest direct exposure to Japan – the destination of about 19% of its total exports.
The eurozone is at the opposite end of the spectrum, with Japan accounting for less than 2% of its exports.
Among emerging-markets, the Philippines and Indonesia are the most exposed to Japan, which absorbs about 16% of their total exports.
South Korea, the third-largest economy in East Asia, is at the other end of the scale, relying on Japanese demand for only about 6% of its exports.
But the narrow view misses the most critical consideration: this “Japan shock” has not occurred at a time of great economic strength.
That is true not only of Japan itself, where two lost decades have left a once-vigorous economy on a less-than-1% growth trajectory since the early 1990’s.
But it is also true of the broader global economy, which was only just beginning to recover from the worst financial crisis and recession since the 1930’s.
Moreover, the Japan shock is not the only negative factor at work today.
The impacts of sharply rising oil prices and ongoing sovereign debt problems in Europe are also very worrisome.
While each of these shocks may not qualify as the proverbial tipping point, the combination and the context are disconcerting, to say the least.
Context is vital.
Notwithstanding the euphoric resurgence of global equity markets over the past two years, the world economy remains fragile.
What markets seem to have forgotten is that post-bubble, post-financial-crisis recoveries tend to be anemic.
Economies grow at something much closer to their stall speeds, thus lacking the cyclical “escape velocity” required for a self-sustaining recovery.
As a result, post-crisis economies are far more vulnerable to shocks and prone to relapses than might otherwise be the case.
Alas, there is an added complication that makes today’s shocks all the more vexing: governments and central banks have exhausted the traditional ammunition upon which they have long relied during times of economic duress.
That is true of both monetary and fiscal policy – the two mainstays of modern countercyclical stabilization.
Policy interest rates are close to zero in the major economies in the developed world, and outsize budget deficits are the norm.
As a result, unconventional – and untested – policies, such as so-called “quantitative easing,” have become the rage among central bankers.
All along, such unconventional policies were viewed as a temporary fix.
The hope was that policy settings soon would return to pre-crisis norms.
But, with one shock following another, the “exit strategy” keeps being deferred.
Just as it is next to impossible to take a critically ill patient off life-support treatment, it is equally difficult to wean post-bubble economies from their now steady dose of liquidity injections and deficit spending.
In an era of extraordinarily high unemployment, political pressures only compound the problem.
This raises perhaps the most troublesome concern of all: with a post-crisis world getting hit by one shock after another, and with central banks having no latitude to cut interest rates, it is not hard to envision a scenario of open-ended monetary expansion that ends in tears.
The dreaded inflationary endgame suddenly looms as a very real possibility.
None of this detracts from the resilience factor.
Yes, Japan will rebuild, which will undoubtedly spur some type of recovery in its disaster-battered economy.
That happened in the aftermath of the Hanshin (Kobe) earthquake in 1995, and it will happen this time as well.
But, just as the post-Kobe rebuilding did little to end the first of Japan’s lost decades, a similar outcome can be expected this time.
The upside of rebuilding – beyond the urgent restoration of normal life for thousands of people – is only a temporary palliative for an impaired economy.
That’s only one of the lessons that Japan offers the rest of us.
The Japanese economy has, in fact, been on the leading edge of many of the more serious problems that have afflicted the global economy in recent years.
From asset bubbles and a dysfunctional financial system to currency suppression and monetary-policy blunders, Japan has been in many respects the laboratory of our future.
Unfortunately, the world has failed to learn the lessons of Japan. And now it risks missing another important clue.
The significance of the earthquake and tsunami of 2011 is not the relatively low magnitude of Japan’s direct impact on the broader global economy.
The more meaningful message is how these shocks box the rest of us into an even tighter corner.
NEW YORK – It is said that Americans have a genius for simplification.
Gradually, however, the quest for it has become a global trend, one that continues to conquer new territories, just as blue jeans once did.
The speed of our daily life is visibly increased – and not for the better – by this unstoppable evolution.
The tyranny of pragmatism seems to mark all of the complex dilemmas of our time.
Too many valid choices are ignored or skirted through the routine of short-cuts.
Nowhere is this trend more damaging than in today’s mercantile approach to art.
Even the much-praised notion of competition seems fake and cynically manipulated by the “corporate” mentality that now pervades the world of culture – by the financial pre-selection that determines what publishers, producers, and other impresarios will support.
Just imagine what might have happened with the works of, say, Proust, Kafka, Musil, Faulkner, or Borges had they been subjected to mass-market competition like shoes or cosmetics.
Culture is a necessary pause from the daily rat race, from our chaotic and often vulgar political surroundings, and it is a chance to recover our spiritual energy.
Great books, music, and paintings are not only an extraordinary school of beauty, truth, and good, but also a way of discovering our own beauty, truth, and good – the potential for change, of bettering ourselves and even some of our interlocutors.
If this respite and refuge is gradually narrowed and invaded by the same kind of “products” as those that dominate the mass market, we are condemned to be perpetual captives of the same stunted universe of “practicalities,” the ordinary agglomeration of clichés packaged in advertisements.
I was thinking again about these old and seemingly unsolvable questions during my re-reading of a quite challenging novel by a close friend and a great writer, not very present in the vivid landscape of American letters of today.
The theme, style, and echo of his work says a lot, I think, about our simplified world.
The novel is Blinding, by Claudio Magris.
Hailed in Europe as one of the great novels of the twentieth century, Blinding arrived in America only after a great delay, and never received the attention that it deserved.
Unfortunately, that is no surprise.
The number of literary translations done nowadays in the United States is, according to a United Nations report, equal to that of Greece, a country one-tenth the size.
Imported books are thought to be too “complicated,” which is another way of saying that literature should deal with simple issues in a simple way, obeying the rules of the mass market, with its tricks of packaging, accessibility, advertisement, and comfort.
At the core of Magris’ book is the destiny of a group of Italian communists who travel to Yugoslavia after the Second World War to contribute to the construction of a socialist society, only to be caught in the conflict between Stalin and Tito.
They are imprisoned for their Stalinist allegiance; when they are finally allowed to return to Italy, their old comrades refuse to accept them.
The book’s plot spans two centuries of revolution.
Then, suddenly,
“the party vanished, overnight, as if all of a sudden a giant sponge had drained the entire sea, Adriatic and Austral, leaving litter and clots of mud, and all the boats stranded.
How can you go home again if the sea has been sucked down a vast drain that opened up beneath it, emptying it who knows where, into a void?
The earth is arid and dead, but there won’t be another one, nor another heaven.”
The solitude of the individual facing his faith alone, without collective illusions, and forced to do something with himself in the arid, noisy world tells us something important about the exiled world of modernity and its complex and contradictory problems.
Magris’s novel is not only an important literary achievement; it also has a deep connection to the dangers that we face now, particularly the wave of fanaticism, from Mumbai to Oslo, in the name of a holy war against the “other.”
Are all the extremists searching for a new coherence, for a lost illusion of togetherness and a new hope of resurrection?
Can we ever forget September 11, 2001, the start of a bloody century in which the mystical force of hatred and destruction has recovered its strength?
Are Osama Bin Laden’s minions, the bloody Hamas-Hezbollah battalions, or troubled loners like Timothy McVeigh, Theodore Kaczynski, and now Norway’s Anders Behring Breivik, the “heroes” of our contemporary nightmare?
Is this the “rebel” response to an overly globalized, incoherent, and ultimately disturbing reality?
If so, their barbarism demands scrutiny – in relation to both historical precedent and to our modernity – rather than merely being labeled “monstrous” (though it certainly is that).
The new religious militants, fighting in the name of their particular and peculiar God, seem as fanaticized as the Fascists, Nazis, and Communists of earlier decades.
Magris’s main character is a rebel in more than one embodiment: as Salvatore Cipico, one of the inmates in the communist concentration camp in Yugoslavia; as Jurgen Jurgensen,  ephemeral king of Iceland and a convict forced to build his own jail; and as Jason, the mythic adventurer searching for the volatile truth.
A multilayered and complex chronicle of the devastating tragedies of the twentieth century, Blinding is an insistent, informed, and irreplaceable incursion into the moving landscape of the human soul, its wounds and voids, its vitality and versatility, its deep distortions and its unpredictable dynamics.
It is a fascinating story about the conflict between ideals and reality, or Utopia and humanness; about being faithful to a cause and betraying it; and about sacrifice and solidarity.
It is also a rich and original literary achievement that challenges today’s consumerist ethic.
By renouncing simplicity, it also repudiates today’s prevailing confusion of information with literature, of facts with creativity, and best-selling products with true works of art.
The release of Alan Greenspan’s ghostwritten memoirs The Age of Turbulence has elicited charges that he was not such a great central banker after all.
Stan Collender of National Journal sees the fingerprints of the White House on these attacks: Greenspan is harshly critical of George W. Bush’s administration, after all, and to attack the credibility of Republican ex-policymakers who are critical of Bush is standard counterpunching for it.
But what is one to make of the criticisms of Greenspan’s tenure at the Federal Reserve?
The indictment contains four counts: that Greenspan wrongly cheered the growth of non-standard adjustable-rate mortgages, which fueled the housing bubble; that he wrongly endorsed Bush’s tax cuts; that he should have reined in the stock market bubble of the 1990’s; and that he should have done the same with the real estate bubble of the 2000’s.
To the first two counts, Greenspan now pleads guilty.
He says that he did not understand how the growth of non-standard mortgages had lured borrowers and investors into bearing dangerous risks.
He was, he now says, focusing on how fixed-rate mortgages are relatively bad deals for borrowers in times of low inflation, which was a mistake.
Greenspan also pleads guilty to a mistake in early 2001.
He thought that he was giving balanced testimony to Congress on government budget issues.
He testified that it is important to run surpluses to pay down the debt, but that surpluses must not be so large that the government winds up owning American industry.
He also testified that tax cuts are better than spending increases to keep surpluses from growing too large, but that uncertainty is enormous, so that any tax cuts should be canceled if they threatened to bring us back to an age of deficits.
Robert Rubin and Kent Conrad warned him that the press would not interpret his testimony as being balanced, and that Congress would interpret it as an excuse to abandon fiscal discipline.
They were right.
Greenspan also pleads guilty to misunderstanding the character of the Bush administration.
He thought that his old reality-based friends from the Ford administration were back in power.
He thought that he – and Treasury Secretary Paul O’Neill – could win the quiet “inside game” for sensible policy without resorting to an “outside game” that would make his reappointment in 2004 unlikely.
He was wrong.
But how serious are these policy-political crimes to which Greenspan now pleads guilty?
In my view, they are misdemeanors.
Against them you have to set what former Treasury Secretary Larry Summers calls Greenspan’s “golden glove” performance at avoiding and minimizing recessions during his years at the Fed.
The “felonies” of which Greenspan stands accused are the other two charges: that he should have done more to stop the stock market bubble of the late 1990’s, and that he should have done more to stop the housing bubble of the early 2000’s.
Here, Greenspan holds his ground, and pleads not guilty.
The only way, he says, for the Fed to have kept stock prices in reasonable equilibrium ranges in the late 1990’s would have been to raise interest rates so high that they hit the real economy on the head with a brick.
Interest rates high enough to curb stock market speculation would also have curbed construction and other forms of investment, raised unemployment, and sent the economy into recession.
To cause a significant current evil in order to avoid a possible future danger when our knowledge is limited and our judgments uncertain is, Greenspan believes, unwise.
In this, he is following a tradition of caution that extends from Edmund Burke to John Maynard Keynes.
Greenspan mounts a similar defense concerning the housing bubble.
High construction employment has been good for American workers in the past half-decade – a period that has not produced much good for them.
Higher interest rates to reduce the housing boom seem, even in retrospect, ill advised if the cost is mass unemployment.
And Greenspan eschews paternalism: he would not assume the role of a regulator telling people that they cannot buy a house even though a lender is willing to finance it.
But Greenspan would have served the country and the world better if he had been somewhat more paternalist in slowing the growth of non-standard adjustable-rate mortgages.
He would have served the country and the world better had he been less of a loyal Republican working the inside game of trying to convince Bush’s political advisors that good policy was important, and more of a nonpartisan steward of America’s long-term fiscal stability.
Of course, such a Greenspan would never have been re-appointed.
All in all, Greenspan served the United States and the world well through his stewardship of monetary policy, especially by what he did not do: trying to stop stock and housing speculation by halting the economy in its tracks.
CAMBRIDGE – When the next full-scale global financial crisis hits, let it not be said that the International Monetary Fund never took a stab at forestalling it.
Recently, the IMF proposed a new global tax on financial institutions loosely in proportion to their size, as well as a tax on banks’ profits and bonuses.
The Fund’s proposal has been greeted with predictable disdain and derision by the financial industry.
More interesting and significant are the mixed reviews from G-20 presidents and finance ministers.
Governments at the epicenter of the recent financial crisis, especially the United States and the United Kingdom, are downright enthusiastic, particularly about the tax on size.
After all, they want to do that anyway.
Countries that did not experience recent bank meltdowns, such as Canada, Australia, China, Brazil, and India, are unenthusiastic.
Why should they change systems that proved so resilient?
It is all too easy to criticize the specifics of the IMF plan.
But the IMF’s big-picture diagnosis of the problem gets a lot right.
Financial systems are bloated by implicit taxpayer guarantees, which allow banks, particularly large ones, to borrow money at interest rates that do not fully reflect the risks they take in search of outsized profits.
Since that risk is then passed on to taxpayers, imposing taxes on financial firms in proportion to their borrowing is a simple way to ensure fairness.
“What risks?” the financial firms demand to know.
The average cost of the bailouts was “only” a few percentage points of GNP.
And the crisis was a once-in-a-half-century event.
The IMF rightly points out that these claims are nonsense.
During the crisis, taxpayers were on the hook for almost a quarter of national income.
Perhaps the next crisis will not turn out so “well,” and the losses borne by the public will be staggering.
Even with the “success” of the bailouts, countries suffered massive output losses due to recessions and sustained subpar growth.
But, while regulation must address the oversized bank balance sheets that were at the root of the crisis, the IMF is right not to focus excessively on fixing the “too big to fail” problem.
A surprising number of pundits seem to think that if one could only break up the big banks, governments would be far more resilient to bailouts, and the whole “moral hazard” problem would be muted.
That logic is dubious, given how many similar crises have hit widely differing systems over the centuries.
A systemic crisis that simultaneously hits a large number of medium-sized banks would put just as much pressure on governments to bail out the system as would a crisis that hits a couple of large banks.
There are altogether too many complex ideas floating around that look good on paper, but might well prove deeply flawed in a big-time crisis.
Any robust solution must be reasonably simple to understand and implement.
The IMF proposal seems to pass these tests.
By contrast, some finance specialists favor forcing banks to rely much more on “contingent” debt that can be forcibly converted to (possibly worthless) stock in the event of a system-wide meltdown.
But how this form of “pre-packaged bankruptcy” could be implemented in a world of widely different legal, political, and banking systems is unclear.
Financial history is littered with untested safety-net devices that failed in a crisis.
Better to rein in the growth of the system.
The IMF is on much weaker ground, however, in thinking that its one-size-fits-all global tax system will somehow level the playing field internationally.
It won’t.
Countries that now have solid financial regulatory systems in place are already effectively “taxing” their financial firms more than, say, the US and the UK, where financial regulation is more minimal.
The US and the UK don’t want to weaken their competitive advantage by taxing banks while some other countries do not.
But it is their systems that are in the greatest and most urgent need of stronger checks and balances.
Let’s not go too far in defending the “holdout” countries that are resisting the IMF proposal.
These countries need to recognize that if the US and the UK do implement even modest reforms, a lot of capital will flow elsewhere, potentially overwhelming regulatory systems that seemed to work well until now.
And what about the second tax proposed by the IMF, on banks’ profits and bonuses?
Such a tax is politically appealing, but ultimately it makes little sense – except, perhaps, in a crisis year when bank subsidies are glaringly transparent.
It would be better to improve financial-market regulation directly and let national tax systems handle banks’ income like that of any other industry.
The IMF’s first effort at prescribing a cure may be flawed, but its diagnosis of a financial sector bloated by moral hazard is manifestly correct.
Let’s hope that when the G-20 leaders meet later this year, they decide to take the problem seriously instead of tabling discussion for a decade or two until the next crisis is upon us.
BEIJING – Now that the “green shoots” of recovery have withered, the debate over fiscal stimulus is back with a vengeance.
In the United States, those who argue for another stimulus package observe that it was always wishful thinking to believe that a $787 billion package could offset a $3 trillion fall in private spending.
But unemployment has risen even faster and further than expected.
Combine this with the continued fall in housing prices, and it is understandable that consumer spending remains depressed.
The banks, having been recapitalized only to the extent necessary to keep them afloat, still have weak balance sheets.
Their consequent reluctance to lend constrains investment.
Meanwhile, state governments, seeing revenues fall as a result of lower taxable incomes last year, are cutting back like mad.
If there was a case for additional stimulus back in February, that case is even stronger now.
But the case against additional stimulus is also strong.
The US federal deficit is an alarming 12% of GDP, and public debt as a share of national income is already projected to double, to 80% of GDP.
The idea that the US can grow out of its debt burden, as did Finland and Sweden following their financial crises in the 1990’s, seems unrealistic.
Given all this, more deficit spending will only stoke fears of higher future taxes and inflation.
It will encourage the reemergence of global imbalances.
And it will not reassure consumers or investors.
It is possible to argue the economics both ways, but the politics all point in one direction.
The US Congress lacks the stomach for another stimulus package.
It has already faced intense criticism for its failure to get the country’s fiscal house in order.
The slowness with which the first stimulus has been rolled out, and the fact that it will take even more time for its full effects to be felt, provides more fodder for the chattering classes.
Disappointment over the effects of the TARP has already destroyed popular – and Congressional – support for more public money to recapitalize the banks.
So, even those who find the economic logic of arguments for fiscal activism compelling must acknowledge that the politics are not supportive.
A second stimulus simply is not in the cards.
If there is going to be more aggregate demand, it can come from only one place.
That place is not Europe or Japan, where debts are even higher than in the US – and the demographic preconditions for servicing them less favorable.
Rather, it is emerging markets like China.
The problem is that China has already done a lot to stimulate domestic demand, both through government spending and by directing its banks to lend.
As a result, its stock market is frothy, and it is experiencing an alarming property boom.
Through May, property prices were up 18% year on year.
Understandably, Chinese officials worry about bubble trouble.
The obvious way to square this circle is to spend more on imports.
China can purchase more industrial machinery, transport equipment, and steelmaking material, which are among its leading imports from the US.
Directing spending toward imports of capital equipment would avoid overheating China’s own markets, boost the economy’s productive capacity (and thus its ability to grow in the future), and support demand for US, European, and Japanese products just when such support is needed most.
This strategy is not without risks.
Allowing the renminbi to appreciate as a way of encouraging imports may also discourage exports, the traditional motor of Chinese growth.
And lowering administrative barriers to imports might redirect more spending toward foreign goods than the authorities intend.
But these are risks worth taking if China is serious about assuming a global leadership role.
The question is what China will get in return.
And the answer brings us back, full circle, to where we started, namely to US fiscal policy.
China is worried that its more than $1 trillion investment in US Treasury securities will not hold its value.
It wants reassurance that the US will stand behind its debts.
It therefore wants to see a credible program for balancing the US budget once the recession ends.
And, tough talk notwithstanding, the Obama administration has yet to offer a credible roadmap for fiscal consolidation.
Doing so would reassure American taxpayers worried about current deficits.
Just as importantly, it would reassure Chinese policymakers.
We live in a multipolar world where neither the US nor China is large enough to exercise global economic leadership on its own.
For China, leadership means assuming additional risks.
But for this to be tolerable, the US needs to relieve China of existing risks.
Only by working together can the two countries lead the world economy out of its current doldrums.
NEW YORK – Does monarchy – constitutional monarchy, that is, not the despotic kind – have any redeeming features left?
The arguments against maintaining kings and queens are mostly quite rational.
It is unreasonable in this democratic age to pay special deference to people solely on the basis of their birth.
Are we really supposed to admire and love modern monarchies, such as the British House of Windsor, even more so today, just because some new princess has been plucked from the middle class?
Monarchy has an infantilizing effect.
Witness how otherwise sensible adults are reduced to nervously grinning sycophants when they are granted the privilege of touching an extended royal hand.
At great monarchical displays, such as the royal wedding in London, millions become enthralled by child-like dreams of a “fairy-tale” marriage.
The mystique of immense wealth, noble birth, and great exclusivity is further sustained by the global mass media that promote these rituals.
Now, one might argue that the dignified pomp of Queen Elizabeth II is preferable to the tawdry grandiosity of Silvio Berlusconi, Madonna, or Cristiano Ronaldo.
In fact, the British monarchy, especially, has been reinventing itself by adopting many of the most vulgar features of modern showbiz or sports celebrity.
And the worlds of royalty and popular fame often overlap.
For example, David Beckham and his ex-pop-star wife Victoria, live out their own dream of royalty, aping some of its gaudiest aspects.
They also happened to be among the favored guests at the latest royal wedding.
Similarly, while Britain has many outstanding musicians, the favorite of the royal court is Elton John.
Infantile or not, there is a common human craving for taking vicarious pleasure in the lives of kings, queens, and other shining stars.
To call these people’s ostentatious displays of extravagance wasteful is to miss the point: a world of glittering dreams that must remain entirely beyond our grasp is precisely what many people want to see.
But there is another, darker side to this craving, which is the wish to see idols dragged through the mud in vicious gossip magazines, divorce courts, and so on.
This is the vengeful side of our fawning, as though the humiliation of worshipping idols must be balanced by our delight in their downfall.
Indeed, to subject people who are born into royal families, or people who marry into them, to lives in a fishbowl, where they are on constant display, like actors and actresses in a continuous soap opera, where human relations are distorted and stunted by absurd rules of protocol, is a terrible form of cruelty.
The current Japanese empress and her daughter-in-law, both from non-aristocratic families, have had nervous breakdowns as a result.
Likewise, movie stars often fall victim to alcohol, drugs, and breakdowns, but at least they have chosen the lives they live.
Kings and queens, on the whole, have not.
Prince Charles might have been far happier as a gardener, but this was never an option.
One thing to be said for monarchs is that they provide people with a sense of continuity, which can be useful in times of crisis or radical change.
The King of Spain provided stability and continuity after the end of Franco’s dictatorship.
During World War II, European monarchs kept a sense of hope and unity alive among their subjects under Nazi occupation.
But there is something else, too.
Monarchies are often popular with minorities.
Jews were among the most loyal subjects of the Austro-Hungarian Emperor.
Franz Joseph I stood up for his Jewish subjects when they were threatened by German anti-Semites.
To him, Jews, Germans, Czechs, or Hungarians were all his subjects, wherever they lived, from the smallest Galician shtetl to the grand capitals of Budapest or Vienna.
This offered some protection to minorities at a time of rising ethnic nationalism.
In this sense, monarchy is a little like Islam, or the Catholic Church: all believers are supposed to be equal in the eyes of God, or the Pope, or the Emperor – hence the appeal to the poor and the marginalized.
This might explain some right-wing populists’ animus against monarchy.
The Dutch populist leader Geert Wilders, for example, has denounced Queen Beatrix on several occasions as a leftist, elitist, and multiculturalist.
Like the new wave of populists worldwide, Wilders promises to take his country back for his followers, to stop immigration (especially of Muslims), and to make the Netherlands Dutch again, whatever that means.
Beatrix, like Franz Joseph, refuses to make ethnic or religious distinctions between her subjects.
That is what she means when she preaches tolerance and mutual understanding.
To Wilders and his supporters, this is a sign of her molly-coddling of aliens, of appeasing Muslims.
To them, the queen seems almost anti-Dutch.
To be sure, like all European royal families, the origins of the Dutch royal family are decidedly mixed.
The emergence of kings and queens as specifically national figureheads is a relatively recent historical development.
Empires contained many nations, after all.
Queen Victoria, mostly of German blood, did not regard herself as a monarch of Britons alone, but of Indians, Malays, and many other peoples, too.
This aristocratic tradition of standing above the narrow strains of ethnic nationalism may be the best argument to hang on to royalty a little longer.
Now that many European nations have become increasingly mixed in terms of ethnicity and culture, the only way forward is to learn to live together.
If monarchs can teach their subjects to do so, then let us give at least one cheer for the remaining kings and queens.
Not surprisingly, the atmosphere at this year’s World Economic Forum was grim.
Those who think that globalization, technology, and the market economy will solve the world’s problems seemed subdued.
Most chastened of all were the bankers.
Against the backdrop of the sub-prime crisis, the disasters at many financial institutions, and the weakening of the stock market, these “masters of the universe” seemed less omniscient than they did a short while ago.
And it was not just the bankers who were in the Davos doghouse this year, but also their regulators – the central bankers.
Anyone who goes to international conferences is used to hearing Americans lecture everyone else about transparency.
There was still some of that at Davos.
I heard the usual suspects – including a former treasury secretary who had been particularly vociferous in such admonishments during the East Asia crisis – bang on about the need for transparency at sovereign wealth funds (though not at American or European hedge funds).
But this time, developing countries could not resist commenting on the hypocrisy of it all.  There was even a touch of schadenfreude in the air about the problems the United States is having right now – though it was moderated, of course, by worries about the downturn’s impact on their own economies.
Had America really told others to bring in American banks to teach them about how to run their business?
Had America really boasted about its superior risk management systems, going so far as to develop a new regulatory system (called Basle II)?
Basle II is dead – at least until memories of the current disaster fade.
Bankers – and the rating agencies – believed in financial alchemy.
They thought that financial innovations could somehow turn bad mortgages into good securities, meriting AAA ratings.
But one lesson of modern finance theory is that, in well functioning financial markets, repackaging risks should not make much difference.
If we know the price of cream and the price of skim milk, we can figure out the price of milk with 1% cream, 2% cream, or 4% cream.
There might be some money in repackaging, but not the billions that banks made by slicing and dicing sub-prime mortgages into packages whose value was much greater than their contents.
It seemed too good to be true – and it was.
Worse, banks failed to understand the first principle of risk management: diversification only works when risks are not correlated, and macro-shocks (such as those that affect housing prices or borrowers’ ability to repay) affect the probability of default for all mortgages. 
I argued at Davos that central bankers also got it wrong by misjudging the threat of a downturn and failing to provide sufficient regulation.
They waited too long to take action.
Because it normally takes a year or more for the full effects of monetary policy to be felt, central banks need to act preemptively, not reactively.
Worse, the US Federal Reserve and its previous chairman, Alan Greenspan, may have helped create the problem, encouraging households to take on risky variable-rate mortgages by reassuring those who worried about a housing bubble that there was at most a little “froth” in the market.
Normally, a Davos audience would rally to the support of the central bankers.
This time, a vote at the end of the session supported my view by a margin of three to one. 
Even the plea of one of central banker that “no one could have predicted the problems” moved few in the audience – perhaps because several people sitting there had, like me, explicitly warned about the impending problem in previous years.
The only thing we got wrong was how bad banks’ lending practices were, how non-transparent banks really were, and how inadequate their risk management systems were.
It was interesting to see the different cultural attitudes to the crisis on display.
In Japan, the CEO of a major bank would have apologized to his employees and his country, and would have refused his pension and bonus so that those who suffered as a result of corporate failures could share the money.
He would have resigned.
In America, the only questions are whether a board will force a CEO to leave and, if so, how big his severance package will be.
When I asked one CEO whether there was any discussion of returning their bonuses, the response was not just no, but an aggressive defense of the bonus system. 
This is the third US crisis in the past 20 years, after the Savings &amp; Loan crisis of 1989 and the Enron/WorldCom crisis in 2002.
Deregulation has not worked.
Unfettered markets may produce big bonuses for CEO’s, but they do not lead, as if by an invisible hand, to societal well-being.
Until we achieve a better balance between markets and government, the world will continue to pay a high price.
NEW YORK – In the aftermath of the Great Recession, countries have been left with unprecedented peacetime deficits and increasing anxieties about their growing national debts.
In many countries, this is leading to a new round of austerity – policies that will almost surely lead to weaker national and global economies and a marked slowdown in the pace of recovery.
Those hoping for large deficit reductions will be sorely disappointed, as the economic slowdown will push down tax revenues and increase demands for unemployment insurance and other social benefits.
The attempt to restrain the growth of debt does serve to concentrate the mind – it forces countries to focus on priorities and assess values.
The United States is unlikely in the short term to embrace massive budget cuts, à la the United Kingdom.
But the long-term prognosis – made especially dire by health-care reform’s inability to make much of a dent in rising medical costs – is sufficiently bleak that there is increasing bipartisan momentum to do something.
President Barack Obama has appointed a bipartisan deficit-reduction commission, whose chairmen recently provided a glimpse of what their report might look like.
Technically, reducing a deficit is a straightforward matter: one must either cut expenditures or raise taxes.
It is already clear, however, that the deficit-reduction agenda, at least in the US, goes further: it is an attempt to weaken social protections, reduce the progressivity of the tax system, and shrink the role and size of government – all while leaving established interests, like the military-industrial complex, as little affected as possible.
In the US (and some other advanced industrial countries), any deficit-reduction agenda has to be set in the context of what happened over the last decade:
·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; a massive increase in defense expenditures, fueled by two fruitless wars, but going well beyond that;
·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; growth in inequality, with the top 1% garnering more than 20% of the country’s income, accompanied by a weakening of the middle class – median US household income has fallen by more than 5% over the past decade, and was in decline even before the recession;
·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; underinvestment in the public sector, including in infrastructure, evidenced so dramatically by the collapse of New Orleans’ levies; and
·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; growth in corporate welfare, from bank bailouts to ethanol subsidies to a continuation of agricultural subsidies, even when those subsidies have been ruled illegal by the World Trade Organization.
As a result, it is relatively easy to formulate a deficit-reduction package that boosts efficiency, bolsters growth, and reduces inequality.
Five core ingredients are required.
First, spending on high-return public investments should be increased.
Even if this widens the deficit in the short run, it will reduce the national debt in the long run.
What business wouldn’t jump at investment opportunities yielding returns in excess of 10% if it could borrow capital – as the US government can – for less than 3% interest?
Second, military expenditures must be cut – not just funding for the fruitless wars, but also for the weapons that don’t work against enemies that don’t exist.
We’ve continued as if the Cold War never came to an end, spending as much on defense as the rest of the world combined.
Following this is the need to eliminate corporate welfare.
Even as America has stripped away its safety net for people, it has strengthened the safety net for firms, evidenced so clearly in the Great Recession with the bailouts of AIG, Goldman Sachs, and other banks.
Corporate welfare accounts for nearly one-half of total income in some parts of US agro-business, with billions of dollars in cotton subsidies, for example, going to a few rich farmers – while lowering prices and increasing poverty among competitors in the developing world.
An especially egregious form of corporate special treatment is that afforded to the drug companies.
Even though the government is the largest buyer of their products, it is not allowed to negotiate prices, thereby fueling an estimated increase in corporate revenues – and costs to the government – approaching $1 trillion dollars over a decade.
Another example is the smorgasbord of special benefits provided to the energy sector, especially oil and gas, thereby simultaneously robbing the treasury, distorting resource allocation, and destroying the environment.
Then there are the seemingly endless giveaways of national resources – from the free spectrum provided to broadcasters to the low royalties levied on mining companies to the subsidies to lumber companies.
Creating a fairer and more efficient tax system, by eliminating the special treatment of capital gains and dividends, is also needed.
Why should those who work for a living be subject to higher tax rates than those who reap their livelihood from speculation (often at the expense of others)?
Finally, with more than 20% of all income going to the top 1%, a slight increase, say 5%, in taxes actually paid would bring in&nbsp;more than $1 trillion over the course of a decade.
A deficit-reduction package crafted along these lines would more than meet even the most ardent deficit hawk’s demands.
It would increase efficiency, promote growth, improve the environment, and benefit workers and the middle class.
There’s only one problem: it wouldn’t benefit those at the top, or the corporate and other special interests that have come to dominate America’s policymaking.
Its compelling logic is precisely why there is little chance that such a reasonable proposal would ever be adopted.
A democratic tide seems to be sweeping across the Arab world.
Even the traditional Arab monarchies and Emirates are changing in its wake.
Kuwait now allows women to vote, Qatar has embraced an ambitious reform program, Bahrain has shown great tolerance of mass demonstrations, and the U.A.E. is allowing something like a free press.
But Saudi Arabia continues to be deeply wary of any sort of change, and thus remains a huge and seemingly immovable obstacle to region-wide reform.
Although the Saudi ruling family, the al-Saud, is under enormous pressure to follow the example of its neighbors, internal resistance to doing so remains very strong.
So the al-Saud have become Janus-faced: looking in one direction, the royal family encourages democratic reformers to speak out; looking in the opposite direction, it jails them when they do.
On May 15, in a closed trial without legal representation for the accused, three leading reformers – Ali Al Dumaini, a well-known journalist and poet, and university professors Abdullah Al Hamid and Matruk al Falih – were condemned and sentenced to prison terms ranging from six to nine years.
Their crime was to call for a constitutional monarchy.
The official verdict states that they threatened national unity, challenged those in authority, and incited public opinion against the state while using “foreign,” that is, Western, terminology.
Not long after the September 2001 terrorist attacks in the United States, these liberal reformers joined with 160 other professionals to write and sign a petition to Crown Prince Abdullah asking for reforms.
The petition called for the monarchy to work within constitutionally prescribed limits, and for an independent judiciary.
The reformers believe that such reforms are the only way for Saudi Arabia to survive the threat of violence, instability, and national fragmentation that is looming on its horizon.
Only a constitution, they argue, can restore much needed legitimacy to a political system that is widely perceived as deeply corrupt and inept.
Crown Prince Abdullah, Saudi Arabia’s de facto ruler in place of his incapacitated half-brother King Fahd, is keen to be seen as a champion of reform.
He received these proposals with a warm welcome in January 2003.
But his half-brother and more powerful rival, Prince Naif, the Minister of Interior, ordered the arrests, trial, and imprisonment of 13 reformers in March 2004.
Crown Prince Abdullah offered not a peep of opposition, leaving the reform agenda that he initiated in a political netherworld.
In order to maintain absolutist power and to minimize public anger, the Saudi princes, led by Prince Naif, asked the reformers to sign an agreement that they would never again ask for reform.
Prince Naif bans the very word “reform” from public discourse, because it suggests that there is something wrong with the system; his preferred term is “development.”
Of the thirteen reformers who were arrested, ten submitted to this demand, but the other three refused and have paid the price.
They remained in jail in Riyadh without legal representation until the final verdict.
Those who submitted had their passports withdrawn, lost their jobs, and were forbidden to speak to the press.
Under regional and international pressure, the Saudi ruling family has constructed a Potemkin village of reform while retaining absolute control over all political developments.
Earlier this year, they staged partial, and tightly regulated municipal elections, with no independent opinion permitted to influence when and how the ballots were held.
These entire female population was excluded, and only one-quarter of the male population was eligible to vote.
Inevitably, Wahhabi Islamists did best.
The al-Saud face two threats: one from violent Islamists, and the other from liberal reformers.
There is every indication that they fear the reformers far more.
Perhaps the princes believe that it is easier to kill “terrorist” criminals than to crush demands for social justice.
Indeed, killing violent Islamists and al-Qaeda affiliates is applauded by the international community, especially the United States, as success in the “war on terrorism.”
But as they hunt down and kill violent domestic extremists, they are quietly tightening the noose around all those who want moderate reform.
This repression of liberal reformers passes unnoticed in the wider world, with America’s silence particularly noticeable.
This silence is vital to the princes, for what the al-Saud care about most is US support.
As things stand in Saudi Arabia, the US administration has no credible ally for change outside of the existing regime.
So, unlike in Ukraine, Georgia, Kyrgizstan, and Lebanon, it does nothing to encourage popular opposition.
As long as the Saudi regime meets America’s oil needs and fights Islamist radicals, it will continue to receive US support and silence – and hence its tacit consent.
But turning a blind eye is shortsighted, for America and for the Saudis.
Those who make peaceful revolutions impossible make violent revolutions inevitable.
The liberal reformers who have been jailed could have paved the way for a peaceful transition to a reformed Saudi Arabia.
By jailing them, the regime has made it clear that violence is the only avenue open to those seeking change.
Talk is growing of a change in US defense doctrine to allow for pre-emptive strikes on states that harbor weapons of mass destruction.
That talk is sending shudders across Europe, where many people connect it with America's oft-stated desire to remove Saddam Hussein from power in Iraq.
Ever since the Gulf war, Iraq has been a source of friction among the western permanent members of the UN Security Council.
By the end of 1999, divergence was complete: the United States and Britain were employing their air power to enforce the no-fly zones while France joined Russia and China in abstaining on resolution 1284.
As this UK-sponsored resolution was meant to bring the Iraq issue back to the Security Council after the withdrawal of the UN weapons inspectors and subsequent American air strikes of December 1998, hope for progress on Iraq within the Security Council was scant.
This rapidly changed after last September 11th.
On May 14, 2002, the Security Council gave the tottering sanctions regime a new lease on life by unanimously adopting a simplified screening procedure.
Even Iraq showed signs of being prepared to consider a possible return of the UN weapons inspectors.
At first sight this seems to bode well for the transatlantic relationship.
In reality, the current relaxation is more likely a lull before the storm.
Most Europeans take it for granted that the US will attack Iraq, and that this act of unilateralism, coming in the wake of all the other irritants such as the ABM Treaty, the Kyoto Agreement, the steel tariffs and the International Criminal Court, will have a devastating effect on transatlantic relations.
Europe would be ill-advised to become mesmerized by this approaching disaster.
Everyone understands that the Iraqi government's improved attitude is caused by the Bush administration's sabre-rattling, but no one can tell whether this is a prelude to an inevitable war or a stratagem to make Iraq cooperate with UN weapons inspectors.
Obviously, the US cannot remove this uncertainty without robbing the sabre-rattling of its beneficial effect.
Given this ambiguity, there remains time for Europe to engage the US in a serious discussion of the options for dealing with Saddam.
The common aim should be to remove the threat posed by a dictator with so well-documented a predilection for weapons of mass destruction.
The options vary from resumed inspections to `regime change'.
There are arguments which make the choice far less clear-cut than it may seem.
Several of these are also being advanced within the Bush administration.
Europe can constructively participate in such discussion provided it first clears the way by:
1. ridding itself of its constantindignation about the conduct of the Bush administration.
That indignation seems strongest among those who have not even bothered to read the American arguments.
Europe does not increase its influence by berating the US for acting in its national interest;
2. showing some understanding for the view of some in the Bush administration that the US should not be bogged down by a continent that is soft, decadent and moralizing.
This is not a pleasant way of putting it, but many Americans remember how on two occasions in the former Yugoslavia - a pre-eminently European theatre - Europe was helpless until American warplanes showed up;
3. making clear that Europe and the US areon the same side, not only in the war on terror generally but also in dealing with Saddam.
The demonstrations that will rock European cities the day Iraq is attacked must be counteracted in advance by unequivocal European statements to that effect.
This debate about how to deal with Saddam might go as follows.
It is not difficult to overthrow Saddam, but it is impossible to predict who or what will take his place.
Iraq may even disintegrate, leaving us with a much stronger Iran, also a member of theaxis of evil but one with a more dangerous mix, namely nuclear ambitionsplus fundamentalism.
Moreover, Saddam may already possess a weapon of mass destruction but has been deterred from using it.
Once he is attacked by the US, he may use it against Israel, which will retaliate.
So it may well be wiser to induce Iraq to readmit the UN weapons inspectors and make sure they can do their job.
This will not entirely remove the Iraqi threat but will make it controllable.
Should this be the outcome, European governments would breathe a sigh of relief.
But the debate may also go the other way.
Saddam will cooperate with UN inspectors only as long as the American threat remains, and the US may conclude that it cannot afford that.
If President Bush then opts for regime change, Europe should not opt out.
This is easier said than done. Many Europeans will argue that they cannot condone military action without a Security Council mandate.
But they already did, twice.
They condoned or even supported American air strikes against Baghdad in December 1998, and they supported or even participated in NATO's air strikes against the Federal Republic of Yugoslavia in March 1999.
True, some will say, but that was under the Clinton administration.
If Europe conveys the impression that its friendship with America depends on who wins the US presidential elections, it is likely to freeze the transatlantic relationship for years.
That hardly seems a rational policy for a continent in profound transition.
Deeply frustrated by the Bush administration’s policies, many people and governments in Europe hope for a fundamental change in American foreign policy after the upcoming presidential election.
But it would take a medium-sized political miracle for these hopes not to be disappointed, and such a miracle will not happen – whoever is elected.
The Bush administration made numerous foreign-policy blunders with far-reaching consequences.
But Bush neither invented American unilateralism nor triggered the transatlantic rift between the United States and Europe.
To be sure, Bush reinforced both trends, but their real causes lie in objective historical factors, namely America’s being the sole world power since 1989 and Europe’s self-inflicted weakness.
As long as America remains the sole world power, the next US President will be neither able nor willing to change the basic framework of America’s foreign policy.
It will, of course, be important who wins the presidency: a candidate expected to continue Bush’s foreign policy or someone ready for a new beginning.
In the former case, the transatlantic rift will deepen dramatically.
Four, or even eight, more years of US policy à la Bush would inflict such damage on the substance of the transatlantic alliance as to threaten its very existence.
But if America’s next president is committed to a new direction, US foreign policy might again become more multilateral, more focused on international institutions and alliances, and willing to bring the relationship between military force and diplomacy back to within its historical proportions.
That is the good news.
The bad news is that, even under such auspicious conditions, the US, as a world power, will not relinquish its “free-hand” policy or forget its strength and its claim to preeminence among nations.
Another piece of bad (or good?) news is that a more multilateral American policy will increase the pressure on Europeans to take on more responsibility for international crisis management and conflict resolution – in Afghanistan, Iran, Iraq, the Middle East, Transcaucasia, and Russia, and with respect to Turkey’s future.
To this common agenda, the Europeans should add Africa, climate change, and reform of the United Nations and the world trading system.
For a long time, Europe has underestimated its weight and importance.
Europe’s geopolitical, economic, and social weight is quite obvious.
But Europe’s integration of sovereign states’ interests by means of common institutions could also be an example for much of the world.
In particular, the way Europe, in the process of its enlargement, has projected its power to achieve lasting peace across the whole continent, and fostered development by integrating entire economies, states, and societies within its institutional framework, could become a model for shaping a cooperative world order in the twenty-first century.
This modern, progressive, and peaceful model is unique and superior to all other currently available approaches to the fundamental questions of political order.
But could doesn’t mean will.
Europe’s global influence is feeble because of its internal quarrels and lack of unity, which render the European Union weak and limit its ability to act.
Objectively strong, subjectively infirm – that is how the EU’s present condition can be described.
The current moment of American weakness coincides with a substantially changed international political environment, defined largely by the limits of US power, Europe’s ineffectiveness, and the emergence of new global giants like China and India.
In light of these developments, does it still make sense to speak of “the West”?
I believe it does, more than ever, because the rift between Europe and America leaves both sides substantially weaker in global terms.
The unilateral overstretching of American power offers a chance for a new beginning in US-European relations.
America, more than in the past, will depend on strong partners and will seek such partnerships.
So what are the Europeans waiting for?
Why not start now to overcome the traditional tension between NATO and the EU – especially as French policy toward NATO under President Nicolas Sarkozy has been moving in the right direction?
A regular mutual presence of the Secretary General of NATO and of the head of EU foreign policy in the councils of both organizations doesn’t require much time and effort.
Why not initiate EU-US consultations at a high political level (with the Secretary-General of NATO participating in security matters) – for instance, by inviting the US Secretary of State and other members of the administration, such as the Treasury Secretary or the Administrator of the Environmental Protection Agency, to sit several times a year on the appropriate EU Council meetings?
Why not have routine annual meetings between the European Council and the US President?
Periodic meetings between the appropriate committees of the US Congress and the European Parliament would also be of great importance, as ultimately both bodies will have to ratify any international treaties.
The fate of the Kyoto Protocol should be a lesson to all parties involved.
No such US-EU consultations would require any new agreements, so they could start without any further preliminaries.
There is one certainty that Europeans can take home from the US election campaign even today: with a more multilaterally oriented US foreign policy, Europe won’t be riding comfortably in the US world-political slipstream much longer.
And that is a good thing.
The new transatlantic formula must be greater say in decision-making in exchange for a greater share of responsibility.
America is currently transfixed with the problem it has created for itself in Iraq, but the presidential candidates are also beginning to ask what principles should guide United States foreign policy after Iraq.
In my view, a focus on global public goods – things everyone can consume without diminishing their availability to others – could help America reconcile its preponderant power with others’ interests.
Of course, pure public goods are rare.
Most only partially approach the ideal case of clean air, where none can be excluded and all can benefit simultaneously.
Combating global climate change is probably the most dramatic current case.
If the largest beneficiary of a public good (like the US) does not take the lead in devoting disproportionate resources toward its provision, smaller beneficiaries are unlikely to be able to produce it because of the difficulties of organizing collective action when large numbers are involved.
While this responsibility often lets others become “free riders,” the alternative is no ride for anyone.
The US could gain doubly, both from the public goods themselves, and from the way they legitimize its preponderant power in the eyes of others.
America can learn from the lesson the nineteenth century, when Great Britain was a preponderant power and took the lead in maintaining the balance of power between Europe’s major states, promoting an open international economic system, and maintaining freedom of the seas.
These issues remain relevant today, and the establishment of rules that preserve access for all remains as much a public good now as it was then, even though some of the issues are more complex.
Maintaining regional balances of power and dampening local incentives to use force to change borders provides a public good for many (but not all) countries.
Similarly, maintaining open global markets is a necessary (though not sufficient) condition for alleviating poverty in poor countries even as it benefits the US.
Today, however, global public goods include new issues – not only climate change, but also preservation of endangered species, outer space, and the “virtual commons” of cyberspace.
A reasonable consensus in American public opinion supports ensuring both these and the “classic” global public goods, even if the US has failed to lead on some issues, notably global climate.
There are also three new dimensions of global public goods in today’s world.
First, the US should take the lead in helping to develop and maintain international laws and institutions to organize collective action to deal with not only trade and the environment, but also weapons proliferation, peacekeeping, human rights, and other concerns.
Others benefit from the order that such efforts provide, but so does the US.
Likewise, while unilateralists complain that the US is constrained by international regimes, so are others.
Second, the US should make international development a higher priority.
Much of the poor majority of the world is mired in a vicious circle of disease, poverty, and political instability.
Financial and scientific help from rich countries is important not only for humanitarian reasons, but also to prevent failed states from becoming sources of disorder for the rest of the world.
Here, too, America’s record is less than impressive.
Protectionist trade measures often hurt poor countries most, and foreign assistance is generally unpopular with the American public.
Development will take a long time, and the international community needs to explore better ways to make sure that help actually reaches the poor, but both prudence and a concern for soft power suggest that the US should take the lead.
Finally, as a preponderant power, the US can provide an important public good by acting as a mediator and convener.
By using its good offices to mediate conflicts in places like Northern Ireland, Morocco, and the Aegean Sea, the US has helped in shaping international order in ways that are beneficial to other nations.
The Middle East is the crucial current case.
It is sometimes tempting to let intractable conflicts fester, and there are some situations where other countries can play the mediator’s role more effectively.
Even when the US does not want to take the lead, it can share leadership with others, such as with Europe in the Balkans.
But often the US is the only country that can bring parties together.
When successful, such leadership increases American soft power while reducing sources of instability.
The US can also encourage other countries to share in production of such public goods.
Welcoming the rise of Chinese power in terms of that country’s becoming a “responsible stakeholder” is an invitation to begin such a dialogue.
Nevertheless, the US is likely to remain the world’s preponderant power even after it extricates itself from Iraq.
But it will have to learn to work with other countries to share leadership.
That will require combining the soft power of attraction with the hard power of military might to produce a “smart power” strategy for providing global public goods.
NEWPORT BEACH – Judging from the skittishness of both markets and “consensus expectations,” the United States’ economic prospects are confusing.
One day, the country is on the brink of a double-dip recession; the next, it is on the verge of a turbo-charged recovery, powered by resilient consumers and US multinationals starting to deploy, at long last, their massive cash reserves.
In the process, markets take investors on a wild rollercoaster ride, with the European crisis (riddled with even more confusion and volatility) serving to aggravate their queasiness.
This situation is both understandable and increasingly unsettling for America’s well-being and that of the global economy.
It reflects the impact of fundamental (and historic) economic and financial re-alignments, insufficient policy responses, and system-wide rigidities that frustrate structural change.
As a result, there are now legitimate questions about the underlying functioning of the US economy and, therefore, its evolution in the months and years ahead.
One way to understand current conditions – and what is needed to improve them – is to consider two events that recently attracted considerable worldwide attention: the launch of Boeing’s Dreamliner passenger jet and the tragic death of Apple’s Steve Jobs.
Let us start with some simple aeronautic dynamics, using an analogy that my PIMCO colleague, Bill Gross, came up with to describe the economic risks facing the American economy.
For the Dreamliner to take off, ascend, and maintain a steady altitude, it must do more than move forward.
It has to move forward fast enough to exceed critical physical thresholds, which are significantly higher than those for most of Boeing’s other (smaller) planes.
Failure would mean succumbing to a mid-air stall, with tepid forward motion giving way to a sudden loss of altitude.
Unless we are convinced of the Dreamliner’s ability to avoid stall speed, it makes no sense to talk about all the ways in which it will enhance the travel experience for millions of people around the world.
America’s economy today risks stall speed.
Specifically, the question is not whether it can grow, but whether it can grow fast enough to propel a large economy that, according to the US Federal Reserve, faces “balance-sheet deleveraging, credit constraints, and household and business uncertainty about the economic outlook.”
And, remember, it is just over a year since certain US officials were proclaiming the economy’s “summer of recovery” – a view underpinned by the erroneous belief that America was reaching “escape velocity.”
Stall speed is a terrifying risk for an economy like that of the US, which desperately needs to grow robustly.
Without rapid growth, there is no way to reverse persistently high and increasingly structural (and therefore protracted) unemployment; safely de-leverage over-indebted balance sheets; and prevent already-disturbing income and wealth inequalities from growing worse.
The private sector alone cannot and will not counter the risk of stall speed.
What is desperately needed is better policymaking.
Specifically, policymakers must be open and willing to understand the unusual challenges facing the US economy, react accordingly, and possess sufficiently potent policy instruments.
Unfortunately, this has been far from the case in America (and in Europe, where the situation is worse).
Moreover, US policymakers in the last few weeks have been more interested in pointing fingers at Europe and China than in recognizing and responding to the paradigm shifts that are at the root of the country’s economic problems and mounting social challenges.
This is where the insights of Steve Jobs, one of the world’s best innovators and entrepreneurs, come in.
Jobs did more than navigate paradigm shifts; he essentially created them.
He was a master at converting the complicated into the simple; and, rather than being paralyzed by complexity, he found new ways to deconstruct and overcome it.
Teamwork was an obligation, not a choice.
And he eschewed the search for the single “big bang” in favor of aiming for multiple breakthroughs.
Underlying it all was a willingness to evolve – a drive for perfection through experimentation.
Moreover, he excelled at selling to audiences worldwide both his vision and his strategy for realizing it.
So far, America’s economic policymakers have fallen short on all of these fronts.
Rather than committing to a comprehensive set of urgently-needed reinforcing measures, they seem obsessed with the futile search for the one “killer app” that will solve all of the country's economic problems.
No surprise that they have yet to find it.
Teamwork has repeatedly fallen hostage to turf wars and political bickering.
Little has been done to deconstruct structural complexity, let alone win sufficient public support for a medium-term vision, a credible implementation strategy, and a set of measures that is adequate to the task at hand.
The longer the policymaking impasse persists, the greater the stall-speed risk for an economy that already has an unemployment crisis, a large budget deficit, many underwater mortgages, and policy interest rates floored at zero.
This is an atmosphere in which unhealthy balance sheets come under even greater pressure, and healthy investors refuse to engage.
In the process, the risk of recession remains uncomfortably high, the unemployment crisis deepens, and inequities rise as already-stretched social safety nets prove even more porous.
US Secretary of Defense Donald Rumsfeld's petulant remark of last year about "old and new Europe" was right for the wrong reasons.
He meant it to refer to Europe's divisions, but in May, ten additional states joined the European Union.
The expanded Europe truly forms a new Europe.
Should America be nervous?
Fifty-four years after the announcement of the Schuman Plan that began to knit together the economies of France and Germany, the EU now has 25 countries and a population larger than that of the United States.
Eight of the new members are former Communist countries that were locked behind the Iron Curtain for nearly half a century.
Their attraction to the Union is a sign of the appeal - the "soft power" - of the idea of European unification.
Of course, this new Europe faces many problems.
The per capita income of the new countries is less than half of that of the fifteen members they are joining.
Concerns have been raised about the influx of cheap labor.
But average GDP growth rates in the new members are twice as high as in the original members, and this can provide a welcome stimulus to stagnant labor markets and sluggish economies.
Political arrangements are somewhat more problematic.
Negotiations are underway to revise a draft EU constitution.
Some Europeans worry that the constitution will enable courts to carry the integration process further and faster than public opinion in member states will tolerate.
Lack of grassroots support might lead to rejection of the constitution in countries like Britain, where referenda have been promised before the new arrangements come into force.
Across the Atlantic, most Americans (to the extent they pay attention) regard these changes with general approval.
But some express concern that the new Europe will be defined in opposition to the US.
Not only do the remarks of French leaders about recreating a multi-polar world arouse alarm, but recent public opinion polls show a decline in the popularity of the US among Europeans and a desire for more independent policies.
The Iraq War proved costly to American soft power, with the US losing about 30 percentage points of attractiveness on average in Europe, including in countries like Britain, Spain, and Italy, whose governments supported the war.
The recent photographs of detainees being abused and sexually degraded in Baghdad's Abu Ghraib prison added fuel to the fire.
Now some American neo-conservatives argue that the US should drop its longstanding support for European integration.
Such a policy change would be a serious mistake.
Not only would it add to anti-American attitudes and fail to accomplish its objectives, but it over-estimates the extent to which the new Europe is being formed in opposition to the US.
Whatever the rhetoric in France, for example, the policies and attitudes in countries such as Britain or Poland demonstrate that good trans-Atlantic relations can be maintained.
If anything, the risks of a US-Europe split will be reduced rather than increased by the EU's recent enlargement.
Moreover, there are several objective reasons why the current friction between Europe and the US is unlikely to lead to divorce.
For one thing, the divisive war in Iraq may turn out to be the last act of the twentieth century rather than a harbinger of the twenty-first.
American unilateralism is much less in evidence in the world's other hot spots, such as North Korea and Iran, both because of the costs of the war in Iraq and the realities of the situation in those other regions.
Moreover, while the common security threat from the Soviet Union has disappeared, both the US and Europe face a new common threat from radical jihadist terrorism.
Neither side of the Atlantic is immune to the threat, despite the efforts of Osama bin Laden to drive a wedge between Europe and America.
Transnational terrorism can only be confronted by close civilian cooperation such as intelligence sharing, police work across borders, and tracing financial flows.
These forms of cooperation survived the divisions over Iraq.
Europe and America also share a common structure of economic interests and values.
While trade produces frictions in democracies, it also enhances wealth.
If one looks at foreign direct investment, it is clear that the two sides of the Atlantic are closely integrated.
In terms of values, while some differences exist between Europe and America, at the fundamental level of democracy and human rights, no other two parts of the globe share more.
As the writer Robert Kagan concluded in the revision of his book in which he declared Europeans to be from Venus and Americans from Mars, it turns out that Americans seeking democratic legitimization of their policies and self-images cannot escape Europe.
In short, it is good for Americans - and for the world - that old and new Europe are becoming one.
We can all benefit from the soft power of an enlarged Europe.
NEW YORK – Economists generally agree on the advantages of openness in trade.
But the case for non-discrimination in trade is also a compelling one.
So good trade policy should push for multilateral trade liberalization such as at the Doha Round, rather than preferential trade agreements (PTAs) such as free-trade areas (FTAs), and also ensure that any retreat into protectionism does not degenerate into discriminatory trade practices.
The last G-20 meeting in Canada was a disappointment on the first front.
At the insistence of the United States, an earlier reference by the G-20 to a definite date for completing the Doha Round was dropped.
Instead, unwittingly rubbing salt into the wound, President Barack Obama announced his administration’s willingness to see the US-South Korea FTA through.
On the second front, there are distressing recent reports that the US Commerce Department is exploring ways to strengthen the bite of anti-dumping actions, which are now generally agreed to be a form of discriminatory protectionism aimed selectively at successful exporting nations and firms.
Equally distressing is Obama’s decision in August 13 to sign a bill, approved in a rare special session of the Senate, that raises visa fees on H1(b) and L-1 temporary work visas in order to pay for higher border-enforcement expenditures.
This proposal gained its legs from long-standing worries about the H1(b) and L-1 programs on the part of Republican Senator Chuck Grassley and Democratic Senator Richard Durbin, and had recently attracted the sponsorship of the influential Democratic Senator Charles Schumer of New York.
Schumer had long agitated against “outsourcing” as inimical to American economic interests, even allying himself with the supply-side economist Paul Craig Roberts.
But he gained clout with the onset of the current crisis, and concern over intractable unemployment numbers is enabling politicians to justify all sorts of superficially attractive remedies.
Thus, it was asserted that a tax on foreign workers would reduce the numbers coming in and “taking jobs away” from American citizens.
Many supporters of the proposal claimed, incoherently, that it would simultaneously discourage foreign workers from entering the US and increase revenues.
Obama’s surrender exemplified the doctrine that one retreat often leads to another, with new lobbyists following in others’ footsteps.
Perhaps the chief mistake, as with recent “Buy American” provisions in US legislation, was to allow the Employ American Workers Act (EAWA) to be folded into the stimulus bill.
This makes it harder for companies to get governmental support to hire skilled immigrants with H1(b) visas: they must first show that they have not laid off or plan to lay off American workers in similar occupations.
Whatever the shortcomings of such measures in economic-policy terms, the visa-fee-enhancement provision is de facto discriminatory, and thus violates WTO rules against discrimination between domestic and foreign firms, or between foreign firms from different WTO countries.
While the visa-fee legislation is what lawyers call “facially” non-discriminatory, its design confers an advantage on US firms vis-à-vis foreign firms.  
The fee applies to both foreign and US firms that employ at least 50 workers, of which 50% or more are H1(b) workers.
But US firms have additional access to foreign workers under the immigration laws.
India would be the chief loser relative to US firms, and, with several sizeable firms, such as Infosys and Wipro, adversely affected by the measure, it would also be the chief loser vis-à-vis smaller outsourcing firms from other countries.
The Indian government has lost no time in raising these objections – as well as the prospect of a formal WTO Dispute Settlement Mechanism complaint.
Such acts of discrimination in trade policies find succor in the media and in some of America’s prominent think tanks.
For example, in the wake of the vast misery brought by flooding to the people of Pakistan, the US and other governments have risen to the occasion with emergency aid.
But there have also been proposals to grant duty-free access to Pakistan’s exports.
But this would be discriminatory toward developing countries that do not have duty-free access, helping Pakistan at their expense.
Astonishingly, Nancy Birdsall of the Center for Global Development, who favors such discrimination, even wrote cynically and approvingly that such a policy “would have little impact on US textile producers.”
Unfortunately, major US media, including The New York Times and The Wall Street Journal, have endorsed this deplorable assault on whatever non-discrimination remains in the world trading system.
Is it too unrealistic to hope that the Obama administration, which has so far been far too responsive to weak economics and strong politics, will stand up to these demands?
Cambridge &#45;&#45; As the United States’ epic financial crisis continues to unfold, one can only wish that US policymakers were half as good at listening to advice from developing countries as they are at giving it.
Americans don’t seem to realize that their “sub-prime” mortgage meltdown has all too much in common with many previous post-1945 banking crises throughout the world.
The silver lining is that there are many highly distinguished current and former policymakers out there, particularly from emerging market countries, who have seen this movie before.
If US policymakers would only listen, they might get an idea or two about how to deal with financial crises from experts who have lived through them and come out safely on the other side.
Unfortunately, the parallel between today’s US crisis and previous financial crises is not mere hyperbole.
The qualitative parallels are obvious: banks using off-balance loans to finance highly risky ventures, exotic new financial instruments, and excessive exuberance over the promise of new markets.
But there are strong quantitative parallels as well.
Professor Carmen Reinhart of the University of Maryland and I systematically compared the run-up to the US sub-prime crisis with the run-up to the 19 worst financial crises in the industrialized world over the past 60 years.
These include epic crises in the Scandinavian countries, Spain, and Japan, along with lesser events such as the US savings and loan crises of the 1980’s.
Across virtually all the major indicators – including equity and housing price runs-ups, trade balance deficits, surges in government and household indebtedness, and pre-crisis growth trajectories – red lights are blinking for the US.
Simply put, surging capital flows into the US artificially held down interest rates and inflated asset prices, leading to laxity in banking and regulatory standards and, ultimately, to a meltdown.
When Asia and Latin America had their financial meltdowns in the 1990’s and early 2000’s, they took advice not only from the IMF, but also from a number of small panels composed of eminent people representing diverse backgrounds and experiences.
The US should do the same.
The head of the IMF, Frenchman Dominique Strauss-Kahn, could easily select a superb panel from any range of former crisis countries, including Mexico, Brazil, Korea, Turkey, Japan, and Sweden, not to mention Argentina, Russia, Chile, and many others.
Admittedly, the IMF’s panel would have to look past America’s current hypocrisy.
The US Treasury strongly encouraged Asia to tighten fiscal policy during its 1990’s crisis.
But today the US Congress and President are tripping over themselves to adopt an ill-advised giant fiscal stimulus package, whose main effects will be to tie the hands of the next president in simplifying the US tax code and closing the budget deficit.
Americans firmly told Japan that the only way to clean up its economy was to purge insolvent banks and regenerate the financial system through Schumpeterian “creative destruction.”
Today, US authorities appear willing to contemplate any measure, no matter how inflationary, to insure that none of its major banks and investment houses fails.
For years, foreign governments complained about American hedge funds, arguing that their non-transparent behavior posed unacceptable risks to stability.
Now, many US politicians are complaining about the transparency of sovereign wealth funds (big government investors mainly from Asia and the Middle East), which are taking shares in trophy American assets such as Citibank and Merrill Lynch.
In fact, having countries like Russia and China more vested in the well-being of the US economy would not be a bad thing.
Yes, the IMF ought to develop a voluntary code of conduct for SWF’s, but it should not be used as a weapon to enforce financial protectionism.
For years, I, along with many others, have complained that emerging markets need greater representation in global financial governance.
Today, the issue goes far beyond symbolism.
The US economy is in trouble, and the problems it spins off are unlikely to stop at the US border.
Experts from emerging markets and elsewhere have much to say about dealing with financial crises.
America should start to listen before it is too late.
The IDB, the world's largest regional development bank, works in Latin America and the Caribbean purportedly to “contribute to the acceleration of economic and social development.”
Its actions in Haiti, however, have severely undermined those goals.
Roughly $54 million in IDB loans for water infrastructure in Haiti, home to literally the world’s worst water, offered a proven path to preventing deadly water-borne diseases. Designed to assist in fulfilling the right to water in the most impoverished nation in the Western Hemisphere, these loans and the lives they could have saved instead have become pawns in a deliberate political power play.
In 2001, US officials threatened to use their influence to stop previously approved IDB funding unless Haiti’s majority political party submitted to political demands to accept a particular apportionment of seats in a Haitian electoral oversight body.
Soon after, at the behest of the US, instead of disbursing the loans as planned, the IDB and its members took the unprecedented step of implicitly adding conditions to require political action by Haiti before the funds would be released.
These actions violated the IDB’s own charter, which strictly prohibits the Bank and its members from interfering in the internal political affairs of member states.
Internal emails reveal that a US legal counselor inside the IDB proposed to the US Treasury Department that, though the loans faced no legitimate technical obstacles, the US could effectively block them by “slowing” the process.
Indeed, by requesting further review of the loans, Haiti would have to make scheduled payments before the funds were even disbursed. “While this is not a ‘bullet-proof’ way to stop IDB disbursements,” the counsellor wrote, “it certainly will put a few more large rocks in the road.”  
In 2001, then-US Ambassador to Haiti Dean Curran publicly and explicitly linked the withholding of IDB loans to the demand that Haiti’s political parties reach a compromise that America wanted.
These tactics worked.
Deprived of funds that had already been committed and expected, Haiti fell into arrears on money owed for loan repayment, triggering IDB policies that prevented the Bank from releasing loans.
In subsequent years, the US employed additional delaying tactics, working with the IDB to move the goal posts whenever Haiti appeared to be meeting their demands.
The results have been devastating.
The town of Port-de-Paix, slotted ten years ago by the IDB as the first project site due to its particularly deplorable water situation, has yet to see the implementation of any water projects.
A study conducted by Zanmi Lasante, Partners In Health, the Robert F. Kennedy Memorial Center for Human Rights, and New York University’s Center for Human Rights and Global Justice found no functioning public water sources in the city.
Researchers found three-quarters of water sources in the city contained high levels of coliform bacteria, a key indicator of contamination with fecal matter.
A frightening 15% of households reported symptoms likely related to typhoid.   
If the US and other member states join the IDB and take on the responsibility to improve conditions in the Americas, they cannot then use their membership to undermine the basic rights of the people they claim to serve simply to advance their own political agenda.
The IDB and the US government must take responsibility for their actions and implement the necessary transparency mechanisms to ensure that such abuses do not recur.  Congressional inquiries and annual reviews of the Treasury Department by the Government Accountability Office could provide the oversight necessary to prevent future political misuse of the IDB and its funds.
The people of Haiti, as well as US taxpayers, deserve a system that makes public the status of IDB loans and projects in Haiti in order to ensure that the US and IDB member states uphold their commitments to development and human rights.
As an American, I am appalled, ashamed, and embarrassed by my country’s lack of leadership in dealing with global warming.
Scientific evidence on the risks mounts by the day, as most recently documented in England’s magisterialStern Report.
Yet, despite the fact that the United States accounts for roughly 25% of all man-made global carbon emissions, Americans show little will or inclination to temper their manic consumption.
The first George W. Bush administration was probably right to refuse to sign the so-called “Kyoto Protocol,” albeit for the wrong reasons.
Among other problems, the Kyoto Protocol does not go far enough towards redistributing carbon emission rights towards developing countries.
But why can’t the US bring itself to raise taxes on gasoline and other sources of carbon emission like coal burning power plants?
It is not like the US government, running a huge deficit despite an economic boom, does not need the money.
Many people seem to think that the Bush administration is the problem.
Put a Texas oilman and his buddies in charge and what do you expect, conservation?
Unfortunately, that is a facile excuse.
American citizens’ resistance to moderating energy consumption for the sake of the global environment is much more deeply embedded.
Consider former US Vice President Al Gore, for example, whose documentary film on global warming,An Inconvenient Truth, is celebrated for its unflinching look at how fossil fuel consumption is leading mankind to the brink of catastrophe.
The evidence on global warming is considerably more muddled than Gore’s film suggests, but the basic problem is real.
Unfortunately, however, Gore was not successful in carrying the torch on global warming when he was a politician.
One cannot commend the 1990’s Clinton-Gore administration for taking any brave steps aimed at radically reducing carbon emissions.
Small wonder: the American public is fiercely resistant to anything that seriously forces them to compromise on their energy-burning, gas-guzzling lifestyle.
It is not just politicians who have failed to provide leadership here.
The venerableNew York Times editorial page was apparently opposed to an energy tax until only recently, when the newspaper finally endorsed the idea.
Like many liberals, theTimes’ editors worried that higher energy taxes would fall disproportionately on the poor.
The typical argument one hears is, “What about the poor guy with the gas-guzzling 1980 Chevy car, who has no other way to get to work?” It is a legitimate point, but if ocean levels start rising, as theStern Report predicts, a lot of our children will beswimming to work some day.
The need for corrective measures to alleviate inequality is no excuse for inaction on global warming.
The change of position by theTimes, unfortunately, does not herald an about-face in the American electorate.
Mention the idea of an energy tax to any potential 2008 US Presidential candidate, and their faces will pale.
It is fine to say that you care about the environment or to claim, as Bush seems to do, that miracle technologies will solve the problem without too much pain.
But any 2008 Presidential candidate that dares to talk about making sacrifices now for a safer environment later will really be sticking his neck out.
Until Americans suck it up and start fixing global environmental problems that they, more than anyone, have caused, it will be difficult to get the wholehearted support of the rest of the world.
Developing countries ask why they should pay attention to global warming if rich countries are not prepared to curtail their own emissions sharply?
Why should poor countries worry about how deforestation contributes to global warming when rich countries remain so profligate?
The scientific evidence suggests that carbon emissions from anywhere in the world have about the same impact on global warming.
For this reason, a wide range of economists favor a uniform (“harmonized”) global tax that would tax carbon emissions equally everywhere in the world, and from whatever source – whether coal, oil, or gas, and whether consumers or businesses.
Such a tax is the most flexible and market-friendly approach, and would have the least impact on economic growth.
Instead, the complex system of quotas favored by the Europeans and embodied in the Kyoto Protocol is likely to lead to much larger inefficiencies and costs.
For this reason, England’sStern Report is probably far too optimistic when it calculates that an eclectic approach to reducing carbon emissions will cost the world only 1% per year of income.
But theStern Report is still right to argue that the potential risks of continued inaction are far greater.
America’s unwillingness to take the lead on environmental issues may some day be regarded as one of the country’s most profound political failures.
One hopes that it changes course soon, before we all are forced to wear swimsuits to work.
AMMAN – Without much fanfare, the past few months have seen no anti-American demonstrations and no burning of American flags across the Arab world.
Arabs seem increasingly willing to accept – and even applaud – the Obama administration’s policy toward the region.
Of course, Arabs are still unhappy with the United States’ continued bias towards Israel.
Its inability to end the 44-year military occupation of Palestinian lands has not gone unnoticed.
But many Arabs nowadays prefer to give the US a break.
With the exception of the Obama administration’s lack of resolve in denouncing the treatment of protesters by the US-allied regimes in Bahrain and Yemen, America’s position on the Arab revolts has been welcomed.
Arabs, especially young Arabs, who comprise the majority of the region’s population, look up to America for its global power when it upholds democratic morals and values.
There is high respect for the concept of rule of, by, and for the people, as well as for the US Constitution’s guarantee of freedom of expression.
It is precisely the failure to apply these values in areas such as Palestine or Iraq that has made – and can still make – countless Arabs vehemently anti-American.
President Barack Obama’s election two years ago positively shocked Arabs and empowered Arab democrats, who saw it as proof of America’s true democratic nature.
Obama’s Cairo speech, delivered on one of his first foreign trips, promised a new US-Arab beginning, and certainly invigorated Arab democrats.
But the first test of Obama’s foreign leadership disappointed many Arabs.
A US veto of a Security Council resolution – supported by the Council’s 14 other members – to oppose Israeli settlements seemed to signal that Obama had crumbled under pressure from America’s pro-Israel lobby.
The US had not revised its policy, even with an African immigrant’s son living in the White House.
A more positive view of Obama emerged when the Arab revolts began in Tunisia and Egypt –countries with pro-US regimes.
While the US initially demonstrated prudence in word and deed, it quickly understood that the revolts truly reflected the will of the people and acted to align itself with the democratic cause.
The same people that Obama had called on in his Cairo speech to seek democracy had now formed the most important nonviolent movement the world had seen in decades.
Arab youth had finally moved, and Obama and his team made the right statements to encourage them, while also making it clear to the Egyptian and Tunisian regimes that they could no longer hide behind the claim that they were fighting America’s war in north Africa.
Pulling away from dictators without trying to take credit for or hijack the revolt was exactly what was required.
Arab youth had to fight and win democracy for themselves.
All that what was wanted from America, most of the young people thought, was withdrawal of its support for allies like Hosni Mubarak and other Arab dictators.
In Libya, however, the need was different.
The same energy on display in Cairo and Tunis was evident among Libyan youth, but this time, America was able to do little diplomatically because it had no relationship with Col. Muammar el-Qaddafi.
So, no surprise, the energy of Libyan youth ran head-on into Qaddafi’s inclination toward brutality and, more importantly, into his paid mercenaries.
America had a moral responsibility to protect the young people whom Obama had encouraged.
Another type of help was needed, but deciding what form it should take was complicated.
Arab countries, especially Egypt, had hundreds of thousands of their nationals working in Libya.
Their governments saw themselves as Qaddafi’s hostages.
But what the Arab countries couldn’t do with military support, they were able to do by providing political cover for the military intervention led by the US, Britain, and France.
The Gulf countries, which have no citizens working in Libya, were the first to denounce Qaddafi.
Then the Arab League met to follow the Gulf states’ lead.
With angry young Arabs from different countries demonstrating outside its Cairo offices and demanding support for their Libyan brethren, the Arab League took an uncharacteristic position: it agreed to denounce a fellow Arab leader.
Clearly, the Arab world was changing, and the US was suddenly no longer an enemy, but a friend.
After gaining Security Council support, the US, Europe, and some Arab countries began doing exactly what should be expected of the international community when a government is preparing to butcher its own citizens: prevent the slaughter.
Of course, America’s problems with Arabs and its challenges in the Middle East are far from over.
Obama must still fulfill his promises to celebrate with Palestinians their full membership of the UN this fall and to draw down its forces in Afghanistan.
But, for the moment, Arabs are not demonstrating against America.
Instead, with America’s help, they are enjoying the first blush of freedom.
Almost all of the world’s developed countries consider themselves, and are, social democracies: mixed economies with very large governments performing a wide array of welfare and social insurance functions, and removing large chunks of wealth and commodity distribution from the market.
The United States is something different.
Or is it?
Whatever it has been in the past, the US in the future will have to choose whether, and how much, it will be a social democracy.
Once upon a time, according to mythology at least, America had little downward mobility.
On the contrary, before the Civil War you could start out splitting rails, light out for the Western Territory, make a success of yourself on the frontier, and wind up as President – if you were named Abraham Lincoln.
In the generation after World War II, you could secure a blue-collar unionized manufacturing job or climb to the top of a white collar bureaucracy that offered job security, relatively high salaries, and long, stable career ladders.
This was always half myth.
Setting out for the Western Territory was expensive.
Covered wagons were not cheap.
Even in the first post-WWII generation, only a minority of Americans – a largely white, male minority – found well-paying stable jobs at large, unionized, capital-intensive manufacturing companies like GM, GE, or AT&T.
But if this story was half myth, it was also half true, particularly in the years after WWII.
Largely independent of education or family, those Americans who did value stability and security could grasp it in the form of jobs with “a future.”
Even for those not so lucky, economic risks were usually fairly low: the unemployment rate for married men during the 1960’s averaged 2.7%, and finding a new job was a relatively simple matter.
It was during this era – roughly from 1948 to 1973 – that sociologists found that a majority of Americans had come to define themselves not as working class, but as middle class.
The post-WWII period stands as a reference point in America’s collective memory, but it was in all likelihood an aberration.
In the early postwar decades, foreign competition exerted virtually no pressure on the economy, owing to the isolation of America’s continental market from the devastation of WWII.
At the same time, the war left enormous pent-up demand for the products of mass production: cars, washing machines, refrigerators, lawn mowers, television sets, and more.
Government policy back then began with a permanent military program of spending and R&D and continued through massive public works program and suburbanization, underpinned by the Federal Highway Program and subsidized home ownership loans from the Federal Housing Administration.
The regulatory institutions and behavioral norms that originated in the New Deal and developed during WWII came into full force: social security, a system of unionized labor relations, market regulation.
Favorable macroeconomic circumstances, the absence of foreign competition, a system of government support and regulation, and large-scale private provision of what in Europe would have been public social insurance all combined to give post-WWII America many of social democracy’s benefits without the costs.
The economy did not stagger under the weight of ample benefits or high taxes.
Americans – at least white, male Americans – did not have to worry about tradeoffs between security and opportunity, because the US offered the advantages of both.
Corporate welfare capitalism substituted for what in Europe would have been government provided social democracy.
America was thus a special place.
It had its cake and ate it, too: a combination of security with opportunity and entrepreneurship.
It seemed that this was the natural order of things.
Hence there was little pressure for government-sponsored social democracy: Why bother?
What would it add?
Now things are very different.
The typical American employer is no longer General Motors.
It is Wal-Mart.
Private businesses are providing their workers with less and less in the form of defined-benefit pensions, health insurance, and other forms of insurance against life’s economic risks.
Sharply rising income inequality has raised the stakes of the economic game.
A government that cannot balance its own finances cannot be relied on to provide macroeconomic stability.
Indeed, former Chairman of the US Federal Reserve Paul Volcker sees the US as so macroeconomically vulnerable as to be running a 75% chance of a full-fledged dollar crisis over the next several years.
The coming generation will be one of massive downward mobility for many Americans.
The political struggles that this generates will determine whether America will move more closely to the social democratic norm for developed countries, or find some way to accept and rationalize its existence as a country of high economic risk and deep divisions of income and wealth.

CAMBRIDGE – On November 4, Americans will elect their 44th president amidst the worst financial turmoil the country has known since the onset of the Great Depression in 1929.  Both candidates are United States senators with little experience as executives, so their ability to manage the crisis has become a central issue in the election.
At the beginning of the campaign, many observers predicted that Iraq would be the major issue in 2008.
Instead, it is the financial crisis.
In principle, this should help Barack Obama and the Democrats, because polls show them stronger on economic issues, whereas Republicans and John McCain do better on security issues.
After the Republican convention, polls showed McCain ahead in early September, but after the financial meltdown, Obama took the lead.
Although both men have warily embraced the $700 billion bailout of the financial sector, the contrasts between the two men are sharp.
Obama is not only the first African-American nominee of a major party, but also one of the youngest candidates ever.
McCain has experience as a naval aviator and more than two decades in the Senate.
If elected, he would be the oldest incoming president.
The two men differ in temperament as well as experience.
McCain is a man of strong traditional values who prides himself on his willingness to act quickly and decisively, which he sought to do during the negotiations on the bailout by suspending his campaign to return to Washington.
That effort appears to have backfired, because the Republicans that he leads initially balked at passing the legislation.
But McCain has shown himself to be resilient.
In 2007, many people wrote off his campaign, but he had the skills to resurrect it and capture the Republican nomination.
His choice of Alaska’s Governor Sarah Palin as his running mate shook up the presidential campaign.
Obama, while an inspirational orator, has shown a cool and calm demeanor in responding to both the financial crisis and the turbulence of political campaigning.
When embarrassed by comments made by the pastor of his church, he delivered an exceptional speech about race in America.
If anything, some of Obama’s Democratic supporters wish he would show more emotion in responding to criticism.
One should be careful, however, about reading too much into national opinion polls measuring the candidates’ popular support.
American presidents are elected by an Electoral College in which each state votes in proportion to the number of members it has in Congress.
Since even the smallest states have two senators, this leads to overrepresentation of lightly populated Western states that tend to vote Republican.
In 2000, Al Gore won the popular vote, but George W. Bush prevailed in the electoral college.
Thus, the two candidates’ campaigns are focusing heavily on a dozen or so states in which voters are closely divided and could sway the electoral college outcome.
Each campaign is now desperately trying to gauge the impact of the financial crisis on these battleground states.
Not only does the Electoral College confuse predictions based on national opinion polls, but there is also the possibility of surprises which can lead to last-minute reversals.
A mistake in a presidential debate can turn the tide of public opinion overnight, as happened to President Gerald Ford in his debate with Jimmy Carter in 1976.
Conversely, Ronald Reagan’s performance in his debate with Carter in 1980 is often credited with his victory. 
Another event that could turn the tables would be an “October surprise” associated with terrorism, which could switch the agenda from the financial crisis back to security, the Republicans’ stronger suit.
In 2004, shortly before the election, Osama bin Laden released a video tape that may have helped President Bush defeat Senator John Kerry.
From bin Laden’s point of view, Bush’s policies were more useful for his efforts to recruit supporters than Kerry’s might have been.
One would assume that Obama would prove even more unsettling to bin Laden.
A recent BBC poll of 22 countries found that if the world could vote, Obama would win in a landslide.
The pro-Obama margin varied from 82% in Kenya (where Obama’s father was born) to 9% in India.
But Americans do not like outside interference in their elections.
When Obama attracted a crowd of 200,000 to a speech in Berlin last summer, Republicans criticized him as an elitist who appeals to crowds overseas but not to blue-collar workers at home.
On the other hand, in a September poll that asked Americans to rate a series of foreign-policy goals for the next president, 83% ranked “improving America’s standing in the world” as most important.
And certainly the election of the first African-American as president would do wonders to restore the soft power that the Bush administration squandered over the past eight years.
Some people worry that Obama might be good for American soft power, but not for its hard power.
Machiavelli famously said that it is more important for a prince to be feared than to be loved.
Machiavelli may be correct, but we sometimes forget that the opposite of love is not fear, but hatred.
And Machiavelli made it clear that hatred is something a prince should carefully avoid.
When the exercise of hard power undercuts soft power, it makes leadership more difficult – as Bush found out after the invasion of Iraq.
Both McCain and Obama possess impressive hard-power political and organizational skills; otherwise, they would not be where they are today.
But when it comes to the soft power skills of emotional intelligence, vision, and communication, Obama outranks McCain.
Whether that will sway American voters wary of financial turmoil on November 4 remains to be seen.
Buenos Aires – For 20 years, Americans have denounced the “crony capitalism” of Third World countries, especially in Asia.
But, just as those regions have been improving their public and corporate governance – Hong Kong just witnessed a breakthrough court decision against a telecom tycoon who is the son of the province’s richest and most powerful man – crony capitalism is taking root in the United States, a country that the world long considered the gold standard of a level playing field in business.
The recently completed “stress tests” of US banks are but the latest indication that crony capitalists have now captured Washington, DC.  
It is no surprise that stock markets liked the results of the stress tests that US Treasury Secretary Timothy Geithner administered to America’s big banks, for the general outcome had been leaked weeks before.
Indeed, most professional investors trashed the tests as dishonest even as their holdings benefited from a rising market.
EvenThe Wall Street Journal, usually financial markets’ loudest cheerleader, openly disparaged the tests’ integrity.
The government had allowed bankers to “negotiate” the results, like a student taking a final examination and then negotiating her grade.
The tests were supposed to reveal the true conditions of banks saddled with unaudited toxic assets in housing loans and financial derivatives.
The reasoning behind the tests seemed unimpeachable.
But was it?
As any seasoned banker knows, a well-managed bank should undertake internal “stress tests” regularly as a matter of good housekeeping.
The financial crisis should have mandated a running stress test to keep senior management up to date daily. Why, then, did the US need the government to conduct a financial exercise that bankers themselves could and should have done far better and faster?
The truth is that the tests were not designed to find answers.
Both Wall Street’s chieftains and the Obama administration already knew the truth.
They knew that if the true conditions at many big banks were publicly revealed, many would have been immediately declared bankrupt, necessitating government receivership to stop a tsunami of bank runs.
But the Obama administration did not want to be tagged as “socialist” for nationalizing banks, however temporarily, even though experts such as former US Federal Reserve Chairman Paul Volcker had recommended just that.
Moreover, nationalizing banks would have required dismissing Wall Street captains and their boards for grossly mismanaging their firms.
Wall Street’s titans, however, had convinced Obama and his team that their continued stewardship was essential to getting the world out of its crisis.
They successfully portrayed themselves as victims of a firestorm, rather than as accessories to arson.
Geithner and Larry Summers, Obama’s chief economic advisor, share Wall Street’s culture as protégés of Robert Rubin, the former treasury secretary who went on to serve as a director and senior counselor at Citigroup.
Neither man found it difficult to accept the bankers’ absurd logic.
The stress tests were meant to signal to the public that there was no immediate threat of bank failures.
This message, it was hoped, would stabilize the market so that prices for “toxic” assets could rise to a level at which bankers might feel comfortable selling them.
After all, senior bankers had been claiming that these assets were “mispriced,” and that pricing them at market levels would penalize the banks unnecessarily.
So far, Geithner seems to have succeeded in his “tests,” as the stock market has indeed more than stabilized, with prices of bank shares such as Citigroup and Bank of America quadrupling from their lows.
The feared implosion of Wall Street seems to have been avoided.
But no one ever seriously thought that the US would allow Citigroup and Bank of America, to name just two, to fail.
In fact, the stock market bottomed out last winter.
Markets had factored into share prices the belief that the US government would not allow any more banks to collapse.
What the world wanted was an accurate picture of what the banks were worth and “mark-to-market” valuations to guide investors as to how much new capital they needed.
The world also wanted to see the US retaking the high road in reinforcing business ethics and integrity – so lacking under the last administration.
As taxpayers had already put huge sums into rescuing failing banks, with the prospect of more to come, a transparent process to reveal how the money was being used was imperative.
Substantial public rescue funds have reportedly been siphoned off to foreign banks, Goldman Sachs, and staff bonuses for purposes unrelated to protecting public interests.
None of this was either revealed or debunked by Geithner’s tests.
Instead, public servants now appear to be in cahoots with Wall Street to engineer an artificial aura of profitability.
Moreover, the value of toxic assets remains as murky as ever.
Once sacrosanct accounting principles have been amended at Wall Street’s behest in order to allow banks to report essentially whatever they want.
And now negotiated stress test results have been released to “prove” that the banks are a lot healthier.
Calling this a Ponzi scheme might be too harsh.
But few financial professionals have been fooled.
Meanwhile, Wall Street chieftains and their boards of directors have nothing to fear from government.
On the contrary, they are now the government’s partners in a joint venture to manage this dishonest scheme.
Like swine flu, crony capitalism has migrated from corrupt Third World countries to America, once the citadel of sound public and private governance.
Is it any wonder that China is perceived as an increasingly credible model for much of the developing world, while the US is now viewed as a symbol of hypocrisy and double standards?
NEWPORT BEACH – It has been raised more than 70 times in the last 50 years, mostly without commotion.
It must be raised again this summer if the United States government is to continue paying its bills on time.
But now America’s debt ceiling has become the subject of intense political posturing and touch-and-go negotiations behind closed doors.
And, obviously, the outcome has implications that go well beyond the US.
As part of America’s system of checks and balances, Congress gets to do more than just approve the annual federal budget.
It also sets a limit on how much debt the US Treasury is allowed to issue.
Beyond this ceiling, the government can spend only from current revenues.
US Treasury Secretary Timothy Geithner recently informed members of Congress that the government will be in this situation on or around August 2.
Having already officially hit the ceiling, the Treasury is moving money around and tapping various pots of unused funds to pay its bills.
In a few weeks, this “flexibility” will be used up.
With the US government now borrowing around 40% of every dollar it spends, a truly binding debt ceiling would immediately force the government to reduce spending radically and in a disorderly fashion.
Politicians across the political spectrum know that such a situation would unsettle an already fragile US economy, severely weaken the dollar, and raise serious concerns about the country's ability to meet its debt-service obligations, including to the many foreign creditors that the US will need in the future.
Yet, in today’s polarized environment in Washington, Republicans and Democrats are unwilling to compromise – or at least to compromise “too early.”
By holding out, Republicans wish to force President Barack Obama’s administration into massive spending cuts.
Democrats respond that such a one-sided approach would be economically harmful and socially unjust.
In the meantime, both sides risk disrupting transfer payments (including to the elderly) and the provision of public services, as well as eroding further America’s global credit standing.
The overwhelming – and sensible – expectation is that the two parties will compromise and raise the debt ceiling before inflicting serious economic and financial dislocations.
The most recent precedent was the bipartisan agreement reached earlier this year on another fiscal issue that threatened to disrupt the normal functioning of government: the absence of a formally approved budget for this year.
A compromise would allow both parties to declare partial victory, for it would likely entail commitments to cut spending and some steps to make taxation more socially just.
But, like many last-minute agreements, it would have little durable impact.
In effect, the political system would again be kicking the can down the road, with real progress on necessary fiscal reforms expected only after the November 2012 presidential election.
Two scenarios for the timing of an interim compromise are possible, depending on whether it is a one- or two-step process.
Most observers expect a one-step process for bipartisan agreement before August 2.
But politicians may need two steps: an initial failure to agree, and then a quick deal in response to the resulting financial-market convulsions.
In the meantime, the Treasury would temporarily re-prioritize and slow outgoing payments.
This two-step process would be similar to what happened in 2008, when Congress was confronted with another cliffhanger: the Bush administration’s request for $700 billion to prevent a financial-market collapse and an economic depression.
Congress initially rejected the measure, but a dramatic 770-point drop in the stock market focused politicians’ minds, bringing them back to the table – and to agreement.
But the two-step scenario involves incremental risks to the US economy, and to its standing in the global system.
And the longer America’s politicians take to resolve the debt-ceiling issue, the greater the risk of an inadvertent accident.
This brings us to a third, and even more unsettling possibility: a longer and more protracted negotiation, resulting in greater disruptions to government entitlement payments, other contractual obligations, and public services.
Creditors would then ask many more questions before adding to their already-considerable holdings of US government debt, generating still more headwinds in a US economy that already faces an unemployment crisis and uneven growth.
The next few weeks will provide plenty of political drama.
The baseline expectation, albeit subject to risk, is that Democrats and Republicans will find a way to avoid disruptions that would damage the fragile US economy, but that the compromise will not meaningfully address the need for sensible medium-term fiscal reforms.
Such political paralysis on key economic issues is increasingly unsettling for the US private sector, and for other countries that rely on a strong US at the core of the global economy.
This helps to explain why so many companies continue to hoard cash, rather than investing domestically, and why a growing number of countries want to diversify gradually away from dependence on the dollar as the reserve currency and on US financial markets for intermediation of their hard-earned savings.
The world economy is hard-wired to the assumption of a strong America, and Americans benefit from this.
But the more their politicians argue over the debt ceiling, the greater the risk that the wiring will become irreparably frayed.
The pessimists who have long forecasted that America’s economy was in for trouble finally seem to be coming into their own.
Of course, there is no glee in seeing stock prices tumble as a result of soaring mortgage defaults.
But it was largely predictable, as are the likely consequences for both the millions of Americans who will be facing financial distress and the global economy.
The story goes back to the recession of 2001.
With the support of Federal Reserve Chairman Alan Greenspan, President George W. Bush pushed through a tax cut designed to benefit the richest Americans but not to lift the economy out of the recession that followed the collapse of the Internet bubble.
Given that mistake, the Fed had little choice if it was to fulfill its mandate to maintain growth and employment: it had to lower interest rates, which it did in an unprecedented way – all the way down to 1%.
It worked, but in a way fundamentally different from how monetary policy normally works.
Usually, low interest rates lead firms to borrow more to invest more, and greater indebtedness is matched by more productive assets.
But, given that overinvestment in the 1990’s was part of the problem underpinning the recession, lower interest rates did not stimulate much investment.
The economy grew, but mainly because American families were persuaded to take on more debt, refinancing their mortgages and spending some of the proceeds.
And, as long as housing prices rose as a result of lower interest rates, Americans could ignore their growing indebtedness.
In fact, even this did not stimulate the economy enough.
To get more people to borrow more money, credit standards were lowered, fueling growth in so-called “subprime” mortgages.
Moreover, new products were invented, which lowered upfront payments, making it easier for individuals to take bigger mortgages.
Some mortgages even had negative amortization: payments did not cover the interest due, so every month the debt grew more.
Fixed mortgages, with interest rates at 6%, were replaced with variable-rate mortgages, whose interest payments were tied to the lower short-term T-bill rates.
What were called “teaser rates” allowed even lower payments for the first few years: they were teasers, because they played off the fact that many borrowers were not financially sophisticated, and didn’t really understand what they were getting into.
And Alan Greenspan egged them to pile on the risk by encouraging these variable-rate mortgages.
On February 23, 2004, he pointed out that “many homeowners might have saved tens of thousands of dollars had they held adjustable-rate mortgages rather than fixed-rate mortgages during the past decade.”
But did Greenspan really expect interest rates to remain permanently at 1% – a negative real interest rate?
Did he not think about what would happen to poor Americans with variable-rate mortgages if interest rates rose, as they almost surely would?
Of course, Greenspan’s behavior meant that under his watch, the economy performed better than it otherwise would have.
But it was only a matter of time before that performance became unsustainable.
Fortunately, most Americans did not follow Greenspan’s advice to switch to variable-rate mortgages.
But even as short-term interest rates began to rise, the day of reckoning was postponed, as new borrowers could obtain fixed-rate mortgages at interest rates that were not increasing.
Remarkably, as short-term interest rates rose, medium- and long-term interest rates did not, something that was referred to as a “conundrum.”
One hypothesis is that foreign central banks that were accumulating trillions of dollars finally figured out that they were likely to be holding these reserves for years to come, and could afford to put at least some of the money into medium-term US treasury notes yielding (initially) far higher returns than T-bills.
The housing price bubble eventually broke, and, with prices declining, some have discovered that their mortgages are larger than the value of their house.
Others found that as interest rates rose, they simply could not make their payments.
Too many Americans built no cushion into their budgets, and mortgage companies, focusing on the fees generated by new mortgages, did not encourage them to do so.
Just as the collapse of the real estate bubble was predictable, so are its consequences: housing starts and sales of existing homes are down and housing inventories are up.
By some reckonings, more than two-thirds of the increase in output and employment over the past six years has been real estate-related, reflecting both new housing and households borrowing against their homes to support a consumption binge.
The housing bubble induced Americans to live beyond their means – net savings has been negative for the past couple of years.
With this engine of growth turned off, it is hard to see how the American economy will not suffer from a slowdown.
A return to fiscal sanity will be good in the long run, but it will reduce aggregate demand in the short run.
There is an old adage about how people’s mistakes continue to live long after they are gone.
That is certainly true of Greenspan.
In Bush’s case, we are beginning to bear the consequences even before he has departed.
NEW YORK – America’s political and economic crisis is set to worsen following the upcoming November elections.
President Barack Obama will lose any hope for passing progressive legislation aimed at helping the poor or the environment.
Indeed, all major legislation and reforms are likely to be stalemated until 2013, following a new presidential election.
An already bad situation marked by deadlock and vitriol is likely to worsen, and the world should not expect much leadership from a bitterly divided United States.
Much of America is in a nasty mood, and the language of compassion has more or less been abandoned.
Both political parties serve their rich campaign contributors, while proclaiming that they defend the middle class.
Neither party even mentions the poor, who now officially make up 15% of the population but in fact are even more numerous, when we count all those households struggling with health care, housing, jobs, and other needs.
The Republican Party recently issued a “Pledge to America” to explain its beliefs and campaign promises.
The document is filled with nonsense, such as the fatuous claim that high taxes and over-regulation explain America’s high unemployment.
It is also filled with propaganda.
A quotation by President John F. Kennedy states that high tax rates can strangle the economy, but Kennedy’s was speaking a half-century ago, when the top marginal tax rates were twice what they are today.
Most of all, the Republican platform is devoid of compassion. 
America today presents the paradox of a rich country falling apart because of the collapse of its core values.
American productivity is among the highest in the world.
Average national income per person is about $46,000 – enough not only to live on, but to prosper.
Yet the country is in the throes of an ugly moral crisis.
Income inequality is at historic highs, but the rich claim that they have no responsibility to the rest of society.
They refuse to come to the aid of the destitute, and defend tax cuts at every opportunity.
Almost everybody complains, almost everybody aggressively defends their own narrow and short-term interests, and almost everybody abandons any pretense of looking ahead or addressing the needs of others.
What passes for American political debate is a contest between the parties to give bigger promises to the middle class, mainly in the form of budget-busting tax cuts at a time when the fiscal deficit is already more than 10% of GDP.
Americans seem to believe that they have a natural right to government services without paying taxes.
In the American political lexicon, taxes are defined as a denial of liberty.
There was a time, not long ago, when Americans talked of ending poverty at home and abroad.
Lyndon Johnson’s War on Poverty in the mid-1960’s reflected an era of national optimism and the belief that society should make collective efforts to solve common problems, such as poverty, pollution, and health care.
America in the 1960’s enacted programs to rebuild poor communities, to fight air and water pollution, and to ensure health care for the elderly.
Then the deep divisions over Vietnam and civil rights, combined with a surge of consumerism and advertising, seemed to end an era of shared sacrifice for the common good.
For 40 years, compassion in politics receded.
Ronald Reagan gained popularity by cutting social benefits for the poor (claiming that the poor cheated to receive extra payments).
Bill Clinton continued those cuts in the 1990’s.
Today, no politician even dares to mention help for poor people.
The big campaign contributors to both parties pay to ensure that their vested interests dominate political debates.
That means that both parties increasingly defend the interests of the rich, though Republicans do so slightly more than Democrats.
Even a modest tax increase on the rich is unlikely to find support in American politics.
The result of all of this is likely to be a long-term decline of US power and prosperity, because Americans no longer invest collectively in their common future.
America will remain a rich society for a long time to come, but one that is increasingly divided and unstable.
Fear and propaganda may lead to more US-led international wars, as in the past decade.
And what is happening in America is likely to be repeated elsewhere.
America is vulnerable to social breakdown because it is a highly diverse society.
Racism and anti-immigrant sentiments are an important part of the attack on the poor, or at least the reason why so many are willing to heed the propaganda against helping the poor.
As other societies grapple with their own increasing diversity, they may follow the US into crisis.
Swedes recently gave enough votes to a right-wing, anti-immigrant party to give it representation in parliament, reflecting a growing backlash against the rising number of immigrants in Swedish society.
In France, Nicolas Sarkozy’s government has tried to regain popularity with the working class by deporting Roma migrants, a target of widespread hatred and ethnic attacks.
Both examples show that Europe, like the US, is vulnerable to the politics of division, as our societies become more ethnically diverse.
The lesson from America is that economic growth is no guarantee of wellbeing or political stability.
American society has become increasingly harsh, where the richest Americans buy their way to political power, and the poor are abandoned to their fate.
In their private lives, Americans have become addicted to consumerism, which drains their time, savings, attention, and inclination to engage in acts of collective compassion.
The world should beware.
Unless we break the ugly trends of big money in politics and rampant consumerism, we risk winning economic productivity at the price of our humanity.
BERKELEY – There are always two paths to boost employment in the short term.
The first path is to boost demand for goods and services, and then sit back and watch employment rise as businesses hire people to make the goods and services to meet that demand.
The second path is not to worry about production of goods and services, but rather to try to boost employment directly through direct government hiring.
The first path is better: not only do you get more jobs, but you also get more useful stuff produced.
The problem is that it does not take effect very quickly.
It is subject to what Milton Friedman called “long and variable lags.”
Thus, policies aimed at boosting employment by the end of, say, this calendar year needed to be put in place about a year ago to have time to have reached their full effect.
Some countries – China, for example – did, indeed, implement such job-creation policies a year ago and are already seeing the benefits.
Others, like the United States, did not, and so unemployment remains at around 10%. 
This is not to say that the Obama administration did not try to boost employment.
A year ago, it set five policy initiatives in motion:
• Additional deficit spending;
• Recapitalization of banks that appeared very vulnerable;
• Asset purchases by the US Treasury and other executive-branch entities to reduce the quantity of risky assets that the battered and risk-intolerant private sector was holding;
• Continued monetary easing via very low Federal Funds rates;
• Expansion of extraordinary policy interventions by the Federal Reserve.
The stress tests conducted by the US Treasury last year suggested that the banking sector had re-attained sufficient capital.
And the Fed has continued its low-interest monetary policy.
But the dysfunctional US Senate capped additional deficit spending at $600 billion over three years – only half of the $1.2 trillion that was the technocratic goal.
Moreover, the Fed became gun-shy and did not continue to increase its balance sheet beyond $2 trillion.
And large-scale market interventions funded and guided by the Treasury never came to pass on a sufficiently large scale to have any tangible effect on jobs.
In short, perhaps two and a half out of the Obama administration’s five policy initiatives came to fruition.
And, in the face of a recessionary crisis that turned out to be roughly twice as large as was forecast at the end of 2008, such limited action was not enough to keep the US unemployment rate below 10% – or even set it on a downward trajectory.
This brings us to the present moment, with US unemployment unacceptably high and refusing to fall.
As a result, there is now a very strong case to turn the focus of the US economy from measures aimed at increasing demand to measures aimed at boosting employment directly (without worrying much about whether these measures are efficient in the sense of substantially raising the quantity of goods and services produced).
In practice, that means that the government either hires people and puts them to work or induces businesses to hire more people.
We are talking about either direct government employment programs, or large tax credits for businesses that increase the number of workers they employ.
There is still time for a substantial shift in federal spending toward high-employment (but in all likelihood low-value) projects to reduce unemployment before the end of 2010 – if Congress acts quickly.
And there is still time for a substantial temporary and incremental new-hire tax credit aimed at getting businesses to boost employment before the end of 2010.
But will Congress act quickly?
Given the depth of political polarization in the US, and thus the need for 60 of 100 votes in the Senate to end a Republican filibuster, there is no sign of it being able to do so.
Such a plan can get off the ground only if 50 Democratic senators are willing to rely on the budget reconciliation process – used to combine the bills adopted by the House of Representatives and the Senate – and are willing to accelerate that process and complete it within a month.
Don’t hold your breath.
Many of today’s war zones – including Afghanistan, Ethiopia, Iran, Iraq, Pakistan, Somalia, and Sudan – share basic problems that lie at the root of their conflicts.
They are all poor, buffeted by natural disasters – especially floods, droughts, and earthquakes – and have rapidly growing populations that are pressing on the capacity of the land to feed them.
And the proportion of youth is very high, with a bulging population of young men of military age (15-24 years).
All of these problems can be solved only through long-term sustainable economic development.
Yet the United States persists in responding to symptoms rather than to underlying conditions by trying to address every conflict by military means.
It backs the Ethiopian army in Somalia.
It occupies Iraq and Afghanistan.
It threatens to bomb Iran.
It supports the military dictatorship in Pakistan.
None of these military actions addresses the problems that led to conflict in the first place.
On the contrary, American policies typically inflame the situation rather than solve it.
Time and again, this military approach comes back to haunt the US.
The US embraced the Shah of Iran by sending massive armaments, which fell into the hands of Iran’s Revolutionary Government after 1979.
The US then backed Saddam Hussein in his attack on Iran, until the US ended up attacking Saddam himself.
The US backed Osama bin Laden in Afghanistan against the Soviets, until the US ended up fighting bin Laden.
Since 2001 the US has supported Pervez Musharraf in Pakistan with more than $10 billion in aid, and now faces an unstable regime that just barely survives.
US foreign policy is so ineffective because it has been taken over by the military.
Even postwar reconstruction in Iraq under the US-led occupation was run by the Pentagon rather than by civilian agencies.
The US military budget dominates everything about foreign policy.
Adding up the budgets of the Pentagon, the Iraq and Afghanistan wars, the Department of Homeland Security, nuclear weapons programs, and the State Department’s military assistance operations, the US will spend around $800 billion this year on security, compared with less than $20 billion for economic development.
In a stunning article on aid to Pakistan during the Bush administration, Craig Cohen and Derek Chollet demonstrated the disastrous nature of this militarized approach – even before the tottering Musharraf regime’s latest crackdown.
They show that even though Pakistan faces huge problems of poverty, population, and environment, 75% of the $10 billion in US aid has gone to the Pakistani military, ostensibly to reimburse Pakistan for its contribution to the “war on terror,” and to help it buy F-16s and other weapons systems.
Another 16% went straight to the Pakistani budget, no questions asked.
That left less than 10% for development and humanitarian assistance.
Annual US aid for education in Pakistan has amounted to just $64 million, or $1.16 per school-aged child.
The authors note that “the strategic direction for Pakistan was set early by a narrow circle at the top of the Bush administration and has been largely focused on the war effort rather than on Pakistan’s internal situation.” They also emphasize that “US engagement with Pakistan is highly militarized and centralized, with very little reaching the vast majority of Pakistanis.”
They quote George Bush as saying, “When [Musharraf] looks me in the eye and says…there won’t be a Taliban and won’t be al-Qaeda, I believe him, you know?”
This militarized approach is leading the world into a downward spiral of violence and conflict.
Each new US weapons system “sold” or given to the region increases the chances of expanded war and further military coups, and to the chance that the arms will be turned on the US itself.
None of it helps to address the underlying problems of poverty, child mortality, water scarcity, and lack of livelihoods in places like Pakistan’s Northwest Frontier Province, Sudan’s Darfur region, or Somalia.
These places are bulging with people facing a tightening squeeze of insufficient rainfall and degraded pasturelands.
Naturally, many join radical causes.
The Bush administration fails to recognize these fundamental demographic and environmental challenges, that $800 billion of security spending won’t bring irrigation to Afghanistan, Pakistan, Sudan, and Somalia, and therefore won’t bring peace.
Instead of seeing real people in crisis, they see caricatures, a terrorist around every corner.
A more peaceful world will be possible only when Americans and others begin to see things through the eyes of their supposed enemies, and realize that today’s conflicts, having resulted from desperation and despair, can be solved through economic development rather than war.
We will have peace when we heed the words of President John F. Kennedy, who said, a few months before his death, “For, in the final analysis, our most basic common link is that we all inhabit this small planet.
We all breathe the same air.
We all cherish our children’s future.
And we are all mortal.”
BERKELEY – In 1950, finance and insurance in the United States accounted for 2.8% of GDP, according to US Department of Commerce estimates.
By 1960, that share had grown to 3.8% of GDP, and reached 6% of GDP in 1990.
Today, it is 8.4% of GDP, and it is not shrinking.
The Wall Street Journal’s Justin Lahart reports that the 2010 share was higher than the previous peak share in 2006.
Lahart goes on to say that growth in the finance-and-insurance share of the economy has “not, by and large, been a bad thing....Deploying capital to the places where it can be best used helps the economy grow...”
But if the US were getting good value from the extra 5.6% of GDP that it is now spending on finance and insurance – the extra $750 billion diverted annually from paying people who make directly useful goods and provide directly useful services – it would be obvious in the statistics.
At a typical 5% annual real interest rate for risky cash flows, diverting that large a share of resources away from goods and services directly useful this year is a good bargain only if it boosts overall annual economic growth by 0.3% – or 6% per 25-year generation.
There have been many shocks to the US economy over the past couple of generations, and many factors have added to or subtracted from economic growth.
But it is not obvious that the US economy today would be 6% less productive if it had had the finance-insurance system of 1950 rather than the one that prevailed during the past 20 years.
There are five ways that an economy gains from a well-functioning finance-insurance system.
First, people are no longer as vulnerable to the effects of fires, floods, medical disasters, unemployment, business collapses, sectoral shifts, and so forth, because a well-working finance-insurance system diversifies and thus dissipates some risks, and deals with others by matching those who fear risk with those who can comfortably bear it.
While it might be true that America’s current finance-insurance system better distributes risk in some sense, it is hard to see how that could be the case, given the experience of investors in equities and housing over the past two decades.
Second, well-functioning financial systems match large, illiquid investment projects with the relatively small pools of money contributed by individual savers who value liquidity highly.
There has been one important innovation over the past two generations: businesses can now issue high-yield bonds.
But, given the costs of the bankruptcy process, it has never been clear why a business would rather issue high-yield bonds (besides gaming the tax system), or why investors would rather buy them than take an equity stake.
Third, improved opportunities to borrow allow one to spend more now, when one is poor, and save more later, when one is rich.
Households are certainly much more able to borrow, thanks to home-equity loans, credit-card balances, and payday loans.
But what are they really buying?
Many are not buying the ability to spend when they are poor and save when they are rich, but instead appear to be buying postponement of the “unpleasant financial retrenchment” talk with the other members of their household.
And that is not something you want to buy.
Fourth, we have seen major improvements in the ease of transactions.
But, while electronic transactions have made a great deal of financial life much easier, this should have been accompanied by a decrease, not an increase, in the finance share of GDP, just as automated switching in telecommunications led to a decrease in the number of telephone switchboard operators per phone call. Indeed, the operations of those parts of the financial system most closely related to technological improvements have slimmed down markedly: consider what has happened to the checking operations of the regional Federal Reserve Banks.
Finally, better finance should mean better corporate governance.
Since shareholder democracy does not provide effective control over entrenched, runaway, self-indulgent management, finance has a potentially powerful role to play in ensuring that corporate managers work in the interest of shareholders.
And a substantial change has indeed occurred over the past two generations: CEOs focus much more attention than they used to on pleasing the stock market, and this is likely to be a good thing.
Overall, however, it remains disturbing that we do not see the obvious large benefits, at either the micro or macro level, in the US economy’s efficiency that would justify spending an extra 5.6% of GDP every year on finance and insurance.
Lahart cites the conclusion of New York University’s Thomas Philippon that today’s US financial sector is outsized by two percentage points of GDP.
And it is very possible that Philippon’s estimate of the size of the US financial sector’s hypertrophy is too small.
Why has the devotion of a great deal of skill and enterprise to finance and insurance sector not paid obvious economic dividends?
There are two sustainable ways to make money in finance: find people with risks that need to be carried and match them with people with unused risk-bearing capacity, or find people with such risks and match them with people who are clueless but who have money.
Are we sure that most of the growth in finance stems from a rising share of financial professionals who undertake the former rather than the latter?
DENVER – Patience might be a virtue, but not necessarily when it comes to American foreign policy.
Consider “the long war,” a bold concept embraced a few years ago to describe the continuing struggle against terrorism, the grudging progress that could realistically be achieved, and the enormous financial burden that it would impose for years to come.
It was also a realpolitik acknowledgement of the setbacks to be expected along the way (the “slog,” as then Defense Secretary Donald Rumsfeld put it).
Above all, the term was an effort to communicate to Americans, accustomed to waging war with speed and decisiveness (and insistent on it since Vietnam), the long-term sacrifice and commitment needed to win a war of survival.
Its proponents also understood that the war would not be limited to weapons, but would need to be a sustained effort, involving, as they put it, the “whole of government,” with civilian agencies marshaled behind military – or paramilitary – objectives.
Daunting as the effort would be, its advocates assumed a sustainable political consensus to support it.
After all, the United States had been attacked.
Today, that consensus is unraveling as America’s politicians wrestle with a federal budget that is itself turning into a long war – one with its own casualties.
The battle lines in this struggle suggest that there is little accord among political elites for any spending, let alone for a long war with far-flung commitments.
As a result, basic assumptions are being questioned at every turn.
Indeed, the current budget war seems to be reopening old divisions about America’s view of itself and the world.
The outcome is far from certain, but even isolationism, a perennial American malady, seems to be making a comeback.
Isolationism is a familiar refrain in US foreign policy among those elements of the right that consider the US too good for the world, as well as among those on the left who consider America a destructive global force.
But this time, as perhaps never before, a bipartisan isolationist impulse is being driven by the budget.
America’s fiscal crisis is profound, and it is not just about numbers.
As the emotions in Washington today suggest, the aversion to tax increases runs far deeper than concern about their effect on current economic performance and job growth.
In part, it represents a fundamental – some would say fundamentalist – view that taxes are to government what a bottle of whisky is to an alcoholic.
Government, as Ronald Reagan told us, is the problem, not the solution.
That message is bad news for American diplomacy.
The linkage between politicians’ unwillingness to fund domestic programs and the imperiled commitment to “the long war” might elude those in US foreign-policy circles, but it is not lost on the rest of the country.
Opinion surveys suggest that Americans want to maintain many of the “discretionary” domestic programs – schools, hospitals, transportation infrastructure, recreational parks, etc. – that are now on the chopping block in budget negotiations.
In places like rural El Paso County, on the eastern plains of Colorado, far from the federal budget debate’s epicenter, spending cuts are the order of the day.
School districts are increasing class sizes as they shed teachers, as well as deferring maintenance projects and curtailing the school-bus service.
These cuts are having a very real and immediate impact on El Paso County’s residents.
Can they, and other Americans who are losing vital services, really be expected to rise above it all and support funding to build new schools in Afghanistan?
Not only are America’s public schools starting to look second-rate, but so is its infrastructure, which had long been a source of national pride.
How many travelers nowadays can fail to note the difference between Asia’s new, efficient airports and the aging, clogged antiques in some major US cities?
The budget war is not producing any consensus on fixing America’s infrastructure, but it is beginning to produce a view that Afghanistan and Pakistan are far from being core US national interests.
Why, people ask, are schools and roads in Afghanistan and Iraq more important than those in Colorado or California?
At one point in 2008, the US military picked up the cost of transporting a tiger for the Baghdad zoo.
When was the last time the US government did that for a US zoo (outside of Washington, of course)?
How this debate sorts itself out will have profound consequences for how America conducts itself in the world.
But it might also take a toll on how the world reacts to America’s fastest-growing export: unsolicited advice.
Countries take others’ advice for many reasons.
Sometimes they respect the adviser’s wisdom and insights (fairly rare in diplomacy).
Or they might fear the consequences of not taking the advice (an offer one cannot refuse, so to speak).
Or, as is true of many of America’s diplomatic transactions, accepting advice could open the way to a better relationship and to additional assistance.
In short, diplomacy – and US diplomacy, in particular – often involves money.
But what if there is no money to offer?
What if Americans, tired of the budget cuts in their neighborhoods, refuse to support funds even for “the long war”?
At that point, senior US officials might well arrive in a country, offer advice, and find that nobody is bothering to listen.
NEW YORK – The 2008 financial crisis marked the end of the global order as we knew it.
In advance of the upcoming G-8 summit, it is impossible to overlook the fact that, for the first time in seven decades, the United States cannot drive the international agenda or provide global leadership on all of today’s most pressing problems.
Indeed, the US has trimmed its presence abroad by refusing to contribute to a eurozone bailout, intervene in Syria, or use force to contain Iran’s nuclear breakout (despite strong Israeli support).
President Barack Obama officially ended the war in Iraq, and is withdrawing US troops from Afghanistan at a pace constrained only by the need to save face.
America is handing off the leadership baton – even if no other country or group of countries is willing or able to grasp it.
In short, US foreign policy may be as active as ever, but it is downsizing and becoming more exacting about its priorities.
As a result, many global challenges – climate change, trade, resource scarcity, international security, cyber-warfare, and nuclear proliferation, to name a few – are bound to loom larger.
Welcome to the G-Zero world, a more turbulent, uncertain environment in which coordination on global policy issues falls by the wayside.
Paradoxically, this new environment, though daunting, is less troublesome for the US; in fact, it provides fresh opportunities for the US to capitalize on its unique position.
The G-Zero world is not all bad for the US – if it plays its cards right.
Many residual strengths take on greater importance in such a world, and America remains the world’s only true superpower and its largest economy – still more than twice the size of China’s.
Its defense expenditures represent nearly half the world total, and exceed those of the next 17 countries combined.
The dollar remains the world’s reserve currency, and investors’ scramble into US government debt at every peak in the crisis since 2008 has underscored America’s safe-haven status (even in crises that America caused).
Likewise, the US continues to lead in entrepreneurship, research and development, higher education, and technological innovation.
Moreover, it is now the world’s largest natural-gas producer and calorie exporter, which has reduced its vulnerability to price shocks or food shortages.
No country rivals America’s promotion of the rule of law, liberal democracy, transparency, and free enterprise.
While other countries certainly support these values, only the US has been willing, healthy, and big enough to ensure that they prevail.
So, as America curtails its global leadership, it will find itself in more demand.
Consider Asia, for example.&nbsp;As China’s economic importance and regional influence grows, its neighbors are seeking to deepen ties with the US.
Japan, Australia, Indonesia, and Taiwan have all recently closed trade and security-related deals with the US.
Even Burma has gotten on board, resuming diplomatic engagement with the US while trying to work its way out of China’s shadow.
In other words, in a G-Zero world, an increasingly aggressive global environment makes the US all the more appealing to countries seeking to hedge their bets.&nbsp;As a result, the US has an opportunity to act more precisely in its own interests.
Supplying less leadership allows the US to weigh opportunity costs before taking action, and to select the issues and circumstances that suit it the best.&nbsp;In this environment, military intervention in Libya does not necessitate the same in Syria.
The extent to which the US will capitalize on these opportunities remains to be seen.
In fact, America’s short-term advantages pose the biggest obstacle to its long-term outlook.
Call this the “safe-haven curse”:&nbsp;as long as the US remains the safest port in any storm, it faces no immediate pressure to address its weaknesses.
For example, for all of the hand-wringing about America’s national debt, investors will continue to loan the US money.
Over the long term, however, US policymakers must make steady progress in restoring confidence in the nation’s fiscal health by cutting politically sacred programs like social security, Medicare, and defense.
Officials will have to put aside short-term motives and party orthodoxy to bolster America’s aging infrastructure, reform its education and immigration systems, and pursue long-term fiscal consolidation.
America’s advantages in the G-Zero world afford it the chance to invest in the future.
But, by cushioning against sufficiently calamitous risks, the same advantages allow the US to procrastinate.
American politicians need to recognize the new G-Zero reality and rebuild America’s domestic sources of strength, even if only incrementally.&nbsp;If they do, the US will have the vigor and flexibility to shape the next world order.
America’s political system usually works well in crises.&nbsp;But, thanks to its residual advantages in a leaderless world, the US need not rely on a crisis to precipitate action.
It need only seize the G-Zero moment.
LONDON – Groucho Marx has always been my favorite Marxist.
One of his jokes goes to the heart of the failure of the ideology – the dogmatic religion – inflicted on our poor world by his namesake, Karl.
“Who are you going to believe,” Groucho once asked, “me, or your own eyes?” For hundreds of millions of citizens in Communist-run countries in the twentieth century, the “me” in the question was a dictator or oligarchy ruling with totalitarian or authoritarian powers.
It didn’t matter what you could see with your own eyes.
You had to accept what you were told the world was like.
Reality was whatever the ruling party said it was.
The designated successor to Mao Zedong in China, Hua Guofeng, raised this attitude to an art form.
He was known as a “whateverist.”
The Party and people should faithfully follow whatever Mao instructed them to do.
Groucho posed two insuperable problems for the “whateverists” of communism.
First, your own eyes and your reason would surely tell you before long that the communist idyll – the withering away of the state and the triumph over need – would never come.
Communism, like the horizon, was always just beyond reach.
It would be interesting to know how many of those at Beijing’s Central Party School – the party’s main educational institute – believe that the Chinese state is about to wither away, or ever will.
The second application of Groucho’s question was that citizens of most Communist countries soon learned that the loss of freedom that they suffered was not compensated by greater prosperity or a higher quality of life.
The more that Russians, Poles, Czechs, and others saw of the life-style in the Western democracies, the more they questioned their own system.
In his magisterial bookThe Rise and Fall of Communism, Archie Brown notes how travel abroad opened Mikhail Gorbachev’s eyes to the failure of the system that he had lived under all his life.
So, in the political sphere, reason has trumped both faith in an unattainable goal and self-delusion about the consequences of its pursuit.
Authoritarian party-states, such as China and Vietnam, survive, but not through commitment to communism.
Their legitimacy depends on their ability to deliver economic growth through state-managed capitalism.
Democracies, of course, allow people to use their reason to make choices based on the evidence of their own eyes.
When you don’t like a government, you can turn the rascals out without overthrowing the whole system.
Change can be made in an evolutionary, rather than a revolutionary, way.
But no one should think that debate in democracies is always based on reason, or that democracy necessarily makes people more rational.
Sometimes reason does prevail.
This is what appeared to happen in the last Indian election, and the election in the United States of President Barack Obama was also plainly a supremely rational moment.
But reason does not seem to be getting much of a hearing during the current health-care debate in the US.
Outsiders, even admirers, have often wondered how the most globalized country in the world – a continent inhabited by people from every land – can be so irrationally insular on some issues.
We scratch our heads about America’s gun laws.
We were astonished during President George W. Bush’s first term at the administration’s hostility to science, reflected in its stance on climate change and Charles Darwin’s theory of evolution.
The opposition to health-care reform is a similar cause of bemusement.
We know that despite its great wealth – and its groundbreaking medical research – America’s health-care system is awful.
It is hugely expensive.
Its costs overwhelm workplace health-insurance schemes.
The poor go unprotected.
Too many of the sick are untreated.
Overall health statistics are worse than those in comparable countries.
Yet Obama’s attempts to reform health care have run into hysterical opposition.
His proposals would lead, it is said, to the state murdering the elderly.
They would introduce Soviet communism into the US – just like what apparently exists in Canada and Britain, with their state-sponsored health systems.
Communism in Toronto and London?
Or just better, cheaper, more reliable health care for all?
Reason seems to be having a hard time of it in the US just now.
Maybe it’s no coincidence that Groucho Marx was an American citizen.
But surely the way a society cares for its sick and needy and elderly is sufficiently important to deserve serious and thoughtful argument based on what we really can see with our own eyes rather than on uninformed partisan prejudice.
There are times when being proven right brings no pleasure.
For several years, I argued that America’s economy was being supported by a housing bubble that had replaced the stock market bubble of the 1990’s.
But no bubble can expand forever.
With middle-class incomes in the United States stagnating, Americans could not afford ever more expensive homes.
As one of my predecessors as Chairman of the US President’s Council of Economic Advisers famously put it, “that which is not sustainable will not be sustained.” Economists, as opposed to those who make their living gambling on stocks, make no claim to being able to predict when the day of reckoning will come, much less identifying the event that will bring down the house of cards.
But the patterns are systematic, with consequences that unfold gradually, and painfully, over time.
There is a macro-story and a micro-story here.
The macro-story is simple, but dramatic.
Some, observing the crash of the sub-prime mortgage market, say, “Don’t worry, it is only a problem in the real estate sector.” But this overlooks the key role that the housing sector has played in the US economy recently, with direct investment in real estate and money taken out of houses through refinancing mortgages accounting for two-thirds to three-quarters of growth over the last six years.
Booming home prices gave Americans the confidence, and the financial wherewithal, to spend more than their income.
America’s household savings rate was at levels not seen since the Great Depression, either negative or zero.
With higher interest rates depressing housing prices, the game is over.
As America moves to, say, a 4% savings rate (still small by normal standards), aggregate demand will weaken, and with it, the economy.
The micro-story is more dramatic.
Record-low interest rates in 2001, 2002 and 2003 did not lead Americans to invest more – there was already excess capacity.
Instead, easy money stimulated the economy by inducing households to refinance their mortgages, and to spend some of their capital.
It is one thing to borrow to make an investment, which strengthens balance sheets; it is another thing to borrow to finance a vacation or a consumption binge.
But this is what Alan Greenspan encouraged Americans to do.
When normal mortgages did not prime the pump enough, he encouraged them to take out variable-rate mortgages – at a time when interest rates had nowhere to go but up.
Predatory lenders went further, offering negative amortization loans, so the amount owed went up year after year.
Sometime in the future, payments would rise, but borrowers were told, again, not to worry: house prices would rise faster, making it easy to refinance with another negative amortization loan.
The only way (in this view) not to win was to sit on the sidelines.
All of this amounted to a human and economic disaster in the making.
Now reality has hit: newspapers report cases of borrowers whose mortgage payments exceed their entire income.
Globalization implies that America’s mortgage problem has worldwide repercussions.
The first run on a bank occurred against the British mortgage lender Northern Rock.
America managed to pass off bad mortgages worth hundreds of billions of dollars to investors (including banks) around the world.
They buried the bad mortgages in complicated instruments, buried them so deep that no one knew exactly how badly they were impaired, and no one could calculate how to re-price them quickly.
In the face of such uncertainty, markets froze.
Those in financial markets who believe in free markets have temporarily abandoned their faith.
For the greater good of all (of course, it is never for their own selfish interests), they argued a bailout was necessary.
While the US Treasury and the IMF warned East Asian countries facing financial crises ten years ago against the risks of bail-outs and told them not to raise their interest rates, the US ignored its own lectures about moral hazard effects, bought up billions in mortgages, and lowered interest rates.
But lower short-term interest rates have led to higher medium-term interest rates, which are more relevant for the mortgage market, perhaps because of increasing worries about inflationary pressures.
It may make sense for central banks (or Fannie Mae, America’s major government-sponsored mortgage company) to buy mortgage-backed securities in order to help provide market liquidity.
But those from whom they buy them should provide a guarantee, so the public does not have to pay the price for their bad investment decisions.
Equity owners in banks should not get a free ride.
Securitization, with all of its advantages in sharing risk, has three problems that were not adequately anticipated.
While it meant that American banks were not hit as hard as they would otherwise, America’s bad lending practices have had global effects.
Moreover, securitization contributed to bad lending: in the old days, banks that originated bad loans bore the consequences; in the new world of securitization, the originators could pass the loans onto others.
(As economists would say, problems of asymmetric information have increased.)
In the old days, when borrowers found it impossible to make their payments, mortgages would be restructured; foreclosures were bad for both the borrower and the lender.
Securitization made debt restructuring difficult, if not impossible.
It is the victims of predatory lenders who need government help.
With mortgages amounting to 95% or more of the value of the house, debt restructuring will not be easy.
What is required is to give individuals with excessive indebtedness an expedited way to a fresh start – for example, a special bankruptcy provision allowing them to recover, say, 75% of the equity they originally put into the house, with the lenders bearing the cost.
There are many lessons for America, and the rest of the world; but among them is the need for greater financial sector regulation, especially better protection against predatory lending, and more transparency.
A great puzzle in today’s world economy is the continued low level of long-term real interest rates in the United States.
Conventional macroeconomists like me look at America’s current-account deficit, now running at 7% of GDP, and know that such vast deficits are inevitably followed by large currency depreciations.
So we expect a substantial depreciation premium on US interest rates.
If the dollar falls 20% more against the euro sometime in the next ten years, US long-term interest rates should be two percentage points higher than euro rates.
If it falls 40% against the yen sometime in the next ten years, US long-term interest rates should be four percentage points higher than Japanese rates.
If it falls 60% against China’s currency, the yuan, sometime in the next ten years, US long-term interest rates should be six percentage points higher than Chinese rates.
But we are not seeing signs of anything like this.
The puzzle is not only that long-term rates are too low when viewed in the international context, but also that they are too low when viewed in America’s domestic context.
The Bush administration continues to have no plans to sew up the veins it has opened with its medieval economic policy, which holds that bleeding revenue from the government cures all economic problems.
This means that unless America’s domestic savings rate rises mightily – which it shows no signs of doing – and unless investment expenditure remains abnormally low for the rest of this decade, the supply of loanable funds to finance investment will soon be much less than demand when the current-account deficit narrows to sustainable levels.
But when supply is less than demand, prices rise sharply.
In this case, the price of loanable funds is the real interest rate.
An expectation that interest rates will be high sometime in the next decade should mean high interest rates on long-term bonds today.
Yet financial markets are not pricing dollar depreciation and a rise in long-term US interest rates accordingly.
When we macroeconomists talk to our friends on Wall Street, we find that they don’t view this as a puzzle at all.
On the contrary, they are puzzled about why we view the current low level of US long-term interest rates as worrisome.
From their perspective, today’s high demand for long-term dollar-denominated securities is easily explained: Asian central banks are buying in order to hold down their currencies, the US Treasury is borrowing short (and thus not issuing that many long-term securities), and US companies are not undertaking the kinds of investments that would lead them to issue many long-term bonds.
But for every market mispricing there is a profit opportunity: if long-term interest rates are, indeed, too low and long-term bond prices too high, investors will short long-term US bonds, park the money elsewhere, wait for bond prices to return to fundamentals, and then cover their short positions.
By doing so, they will push prices close to fundamentals today.
Wall Streeters, however, offer a counterargument: for any financial institution to, say, bet on the decline of the dollar against the yuan over the next five years in a serious, leveraged way is to put its survival at risk should the trades go wrong.
And trades do go wrong: remember the collapse of Long-Term Capital Management.
The existence of large financial-market actors that do not care about maximizing their profits magnifies the riskiness of the bets.
If, say, the Bank of China and the Federal Reserve decided to teach speculators a lesson by pushing the dollar’s value relative to the yuan up by 20% for a month, they could do so, bankrupting many financial institutions with short positions.
Similarly, any financial institution that bets on a sharp rise in long-term interest rates over the next five years in a serious, leveraged way also puts its survival at risk.
For where should they park their money?
Real estate rental yields and stock-market payouts are low, and real estate and stock prices may well fall as much as or more than bond prices if interest rates spike.
Only businesses that can borrow long-term now, lock in a low real interest rate, and invest in expanding their capacity can make the domestic bet that interest rates will rise.
But America’s businesses see enough risk in the future to be wary of getting stuck with unutilized capacity.
First, short-term interest rates were already so low that everyone would see further cuts as temporary only.
They would thus have little effect on the longer-term rates that really drive business investment.
Second, short-term interest rates were so low that additional cuts would spook the financial markets: if even the Fed thought conditions warranted cuts, the argument went, businesses would respond not by increasing their investments but by reducing them.
The Fed's judgment appeared to be that it was largely (if not completely) powerless: it had done all that it could, and the levers of monetary policy were no longer strongly connected to determining the level of economic activity.
So the US in 2002 joined Japan in what economists have for sixty-five years called a Liquidity Trap: a situation in which the short-term nominal interest rates the central bank controls are so low and so loosely connected to the level of aggregate demand that further reductions are ineffective in fighting a recession.
America's situation was not unique: Japan had been in been in thrall to a liquidity trap since the mid-1990s.
But there had been no other examples since the Great Depression of the 1930s.
Whether America now really is in a liquidity trap is uncertain.
How long this state of affairs will last is unknown.
Nevertheless, even if America is only on the edge of a liquidity trap, and even if it moves away from the current state of affairs soon, this is a frightening situation.
If monetary policy is not effective, the only lever the American government has to manage its economy is fiscal policy: changes in the government's tax and spending plans to change the government's direct contribution to aggregate demand.
But the lesson of the decades since World War II is that the US government - with its complex, baroque, eighteenth-century organization - is incapable of changing policy fast enough to make effective use of fiscal policy as a tool for managing the economy.
It simply takes too long for changes in taxes and spending to work their way through Congress and the bureaucracy.
An America caught in a liquidity trap is, quite simply, a country with no effective tools of macroeconomic management.
There have been two eras since World War II when policymakers - American policymakers, at least - believed that they had solved the riddle of the business cycle and had learned how to manage a modern industrial or post-industrial economy.
The first was the Keynesian high-water mark of confidence in demand management of the 1960s.
It was destroyed by the inflation of the Vietnam era and the oil-price shocks of the 1970s.
The second was the decade of successful business-cycle management by Alan Greenspan's independent, apolitical, and technocratic Fed during the 1990s.
This second era now appears to have been as fleeting as the first.
Eighty years ago, John Maynard Keynes argued that governments needed to take responsibility for maintaining full employment and price stability - that the pre-World War I gold standard had not been the golden age people thought it was, and that its successes were the result of a lucky combination of circumstances unlikely to be repeated.
Keynes was an optimist in believing that governments could learn to manage the business cycle.
He would be shocked to look at today's world: a Europe with stubbornly high unemployment, a Japan mired in a decade of near stagnation, and now an America lacking the policy tools to deal with any additional unexpected economic bad news.
MUNICH – Under substantial external pressure, the eurozone’s crisis-hit countries are, at long last, bringing themselves to make painful cuts in their government budgets.
Salaries are being slashed and public employees sacked to reduce new borrowing to a tolerable level.
And yet, competitiveness in Greece and Portugal, in particular, is not improving.
The latest Eurostat figures on the evolution of the price index for self-produced goods (GDP deflator) show no tendency whatsoever in the crisis-stricken countries towards real devaluation.
But real devaluation, achieved by lowering prices vis-à-vis their eurozone competitors, is the only way to re-establish these countries’ competitiveness.
A reduction in unit labor costs can also increase competitiveness only to the extent that it actually results in price reductions.
After all, it was price inflation in the crisis countries, fueled by massive inflows of cheap credit following the introduction of the euro, that resulted in their loss of competitiveness, ballooning current-account deficits, and accumulation of enormous foreign debt.
Now that capital markets are no longer willing to finance these deficits, prices should be going into reverse, but this, obviously, is not happening.
In 2010, inflation in some of the crisis countries lagged slightly behind that of their eurozone competitors.
The latest Eurostat figures for the third quarter of 2011, however, are already showing a different picture: the price level in Portugal and Greece has remained practically unchanged over the course of the year, and in Italy and Spain it even rose slightly (by 0.4% and 0.3%, respectively).
Only Ireland continued on a path of rapid deflation – as it has since the country’s real-estate bubble burst in 2006 – with a relative price decrease of 2.2%.
On the whole, Ireland has become cheaper relative to its eurozone competitors by a total of 15% over the course of the past five years.
This internal devaluation is paying off: while Ireland was still running a current-account deficit of 5.6% of GDP in 2008, the European Commission expects the outturn for 2011 to have been a 0.7%-of-GDP current-account surplus.
True, much of this is mere debt-service relief, given that Ireland was able to repay its foreign liabilities with self-printed money, for which it pays only 1% interest.
However, Ireland’s big trade surplus did improve further.
Ireland owes much of this turnaround to its efficient export sector, whose supporters were able to enforce a political U-turn.
Greece, on the other hand, is under the influence of a strong import lobby.
As the Greek economics minister, Michalis Chrysochoidis, has said, this is attributable to European Union subsidies, which drove entrepreneurs to follow the easy money into the import sector.
Now these importers form a powerful bulwark against any policy that causes deflation, even though lowering prices – and thereby redirecting Greek demand from foreign to domestic products and helping tourism – is the only way to put the Greek economy back on its feet.
Since Greece’s current-account deficit as a share of GDP was three times higher than Ireland’s, Greek prices would have to fall by about half to achieve the same kind of success.
It is inconceivable that Greece could manage that within the eurozone without widespread social unrest, if not conditions approaching those of civil war.
But it isn’t just importers who are blocking real devaluation.
Unions, too, are resisting the necessary wage reductions, and public and private debtors fear the prospect of insolvency if their assets and revenues are assessed at a lower value, while their debts remain unchanged.
The situation is intractable.
Many people regard debt relief and socialization of debts as the only way out.
This help has been given.
The recent agreement gave Greece relief of €237 billion ($316 billion), about 30% more than Greece’s net national income of roughly €180 billion euros.But such help only entrenches the wrong prices – and thus the economy’s lack of competitiveness.
The debts will re-emerge like a tumor, growing year by year, while undermining the creditworthiness of stable eurozone countries.
If that happened, the euro would eventually collapse.
Only a price reduction would create current-account surpluses and enable the crisis countries to pay off their foreign debts.
It is time for Europe to come to terms with this remorseless truth.
Those crisis countries that do not want to take it upon themselves to lower their prices should be given the opportunity to leave the eurozone temporarily in order to devalue prices and debts.
In other words, they should take a kind of euro sabbatical – a proposal that has now also been taken up by American economist Kenneth Rogoff.
After the ensuing financial thunderstorm died down, the sun would come out again very quickly.
The creditor countries would have to shoulder big losses from write-downs, but they would still end up with more than they would have gotten had the crisis countries remained within the eurozone, because these countries’ new prosperity, gained by leaving, offers the only chance of recovering any assets at all.
Longtime members of the European Union now seem to doubt the Union’s future, but we in Ukraine look at the European Union with hope and admiration.
To join in the EU’s progress is the basic object of our foreign policy, for Ukraine has discovered that nationhood is not an end, but a beginning.
Indeed, European unity is indivisible: when one nation is ostracized, all are not free.
We Europeans are caught in an inescapable net, tied in a single garment of destiny.
Every aspect of our shared culture, if not the last century of shared suffering, confirms that for us.
Whatever affects one European directly, affects all indirectly.
Never again can we afford to live with the narrow notion of two Europes, of haves and have-nots, of insiders and outsiders.
Anyone who lives within the European continent cannot – indeed, must not – be considered a stranger to its Union.
Today’s great Pax Europa and today’s pan-European prosperity depend on this.
Of course, some people mutter that Ukraine is not Europe.
Let them come to Kyiv and speak to the people, young and old, factory worker, farmer’s wife, the lawyers and doctors and teachers who stood and stayed in the cold and snow for weeks on end last winter to defend their freedoms.
Are they not united with those who stood alongside General de Gaulle in the French Resistance?
Are they not one with those who died fighting for the Spanish Republic in the 1930’s, who liberated Budapest in 1956 and ended fascism in Spain and Portugal in the 1970’s?
Are they not animated by the same spirit as Poland’s Solidarity and the peaceful masses that created Prague’s Velvet Revolution in 1989?
That is the true European spirit, and no doubts can crush it.
To those who say that Ukraine is too backward for EU membership, I say: Let them, too, come to my country and see the mothers who stay late at night at work teaching their children to use their workplace computer.
Let them come to the language classes in every village and city where young people are readying themselves for Europe by learning French and German and English.Those who doubt Ukraine’s European vocation should understand that Europe is not a matter of hardware and superhighways; it is the unquenchable desire for freedom, prosperity, and solidarity.
I believe that our future is as promising as Europe’s past is proud, and that our destiny lies not as a forgotten borderland on a troubled region, but as a maker and shaper of Europe’s peace and Europe’s unity.
Self-determination no longer means isolation, because achieving national independence nowadays means only to return to the world scene with a new status.
New nations can build with their former occupiers the same kind of fruitful relationship that France established with Germany – a relationship founded on equality and mutual interests.
That is the type of relationship that my government seeks with Russia, and achieving it is how we can help extend the zone of Europe’s peace.
Of course, it is premature to do more than indicate the high regard with which we view the prospect of EU membership.
We know that our part in that great edifice will not be built overnight.
We know that the great works of European unification lay not in documents and declarations, but in innovative action designed to better the lives and insure the security of all Europeans.
Building a Ukraine worthy of EU membership will not be easy, cheap, or fast.
But, like the Union itself, it will be built and it will be done.
We know the challenge is great, but the prize is worth the struggle, and Europe should know that this is our goal.
Part of the work of renewing Ukraine is a creative battle to put an end to a nightmarish century during which fascism and communism – ideologies born in the heart of Europe – battled for mastery.
Only a few months ago, in cities throughout Ukraine, our children and our parents confronted armed troops, snarling dogs, and even death.
Only a few years ago, a young journalist, Georgi Gongadze, seeking to inform the public about our old regime’s corruption, was brutalized and beheaded by that regime’s thugs.
But our Orange Revolution last winter shows that Ukraine’s people prevailed.
So, despite today’s doubts and difficulties, I retain an abiding faith in Europe.
I refuse to accept despair as the final response to the ambiguities and horrors of Ukraine’s history.
I refuse to accept the view that Ukraine is so tragically bound to the starless midnight of communism’s legacy that we can never see the bright daybreak of peace and true European unity.
When the EU’s citizens ponder Ukraine’s place in Europe, they should look both beyond and more closely at the face they see.
They should look beyond the ravaged wastelands that communism inflicted, beyond the poverty, and beyond the social divisions through which our discarded ex-leaders sought to prolong their misrule.
Instead, they should look closely at the face of our president, Viktor Yushchenko, ravaged by poison during last year’s election campaign, and recall the words of the great Frenchman André Malraux, for whom “the most beautiful faces are those that have been wounded.”
As the European Constitutional Convention assembles to debate the fine points of the European Union's future institutions, now is the moment to think the unthinkable about where Europe is heading.
Or at least, to consider perhaps a quite different question: where would it be reasonable for the EU to move?
Communism's fall saw the appearance of several small states in Europe.
Estonia, Latvia, and Lithuania reemerged from Soviet occupation.
Czechoslovakia split into two separate states.
Yugoslavia gave way to Slovenia, Croatia, Bosnia, Serbia, Macedonia; it may perhaps shortly disgorge Kosovo and Montenegro as well.
Although the Baltic republics merely reestablished their pre-WWII independence, and Yugoslavia's breakup was a bloody affair like so many other wars of independence, there is something tantalizing new in all this as well.
In the interwar years, the Baltic states were often viewed as impractical, artificial creations of the Great Powers.
Czechoslovakia and Yugoslavia came into existence because their constituent parts were not seen as viable independent states.
Why was this?
Because 80 years ago, when Wilson, Clemenceau, and Lloyd George redrew the map of Europe, small states were dysfunctional in times of both war and peace.
To be viable, a state needed to be large enough to defend itself and to constitute a relatively self-contained economic market.
None of this holds true today.
With the prospect of entry into the EU, national markets matter less.
Both EU and NATO membership make war among European member states unthinkable, and an attack on even the smallest NATO member would bring a response from all NATO members.
Lacking such external threats, the ties between, say, Czechs and Slovaks (to say nothing of Serbs and Croats!) are too weak to warrant a common national level of government.
Does this tell us something about the future of Europe as a whole?
The difference between Czechoslovakia and Italy or Germany is mostly one of 50 years.
After all, wasn't Italy, until 1860s, a collection of kingdoms and principalities?
Wasn't Germany's unification a matter of ``blood and iron''?
France and Spain are older, but is the marriage of Basques, Catalans, and Corsicans with their national states that much happier than the former Czech/Slovak marriage?
Is there really that much reason why the Scots and Welsh should be part of the same national state as the English?
Abstract for a second from the idea of French or German or Italian identity, patriotism, the collective memories of war and carnage that cemented the consciousness of today's linguistic communities and think of this: why do Europeans need an intermediate level of government, between the common European framework and their local institutions?
Why do Piemontese, Bavarians, or Scots need intermediate national bureaucracies to run their tax policies, welfare programs, securities laws, and the largely useless, duplicative armies?
Wouldn't life be easier if a common market, currency, foreign policy, army, and a few other things were run on a Europe-wide basis, with the rest left to more meaningful local units?
It is fashionable to mock the bureaucratic minutia of European regulation.
But European regulation is as nothing compared to the mountains of national laws and decrees, billions wasted in political patronage, and the colossal state machines that eat up 30-40% of the economic product of Europe's nation states.
Could any common European state do worse?
Indeed, the creation of a European federal government and the elimination of national intermediaries would probably lead to the greatest liberalization of the economy (and society as a whole) in Europe's entire history.
Look at America in 1787: creation of the federal government swept away the balkanized system of pre-revolutionary colonies, ushering in an era of entrepreneurial expansion across the entire American Continent.
The simple fact is that Europe as a whole is too diverse to be captured by the economic and political interest groups that now dominate national states.
It is only as anadditional level of government that the EU appears onerous and bureaucratic.
If it were todisplace national governments, its burden would be weightless in comparison to what exists today.
Nations also put Europe's constitutional balance out of kilter.
Germany and Italy are simply too big, as compared to Portugal or Belgium (itself a rather questionable amalgam of the Flemish and the Walloons), and this creates the types of imbalances reminiscent of the heavy foot of Prussia in the old Bismarckian empire.
Could a federal Europe replace today's national identities?
Could the French and the British feel as spiritually at home in ``Europe'' as they feel in their national states?
No, but must they?
When Europeans think of future institutions, the tension is always seen as that between national differences and the common European identity.
But what if common European institutions are not viewed through the prism of national institutions?
What if the evolution of European consciousness proceeds not by an upward transfer of attachment to supranational institutions, but by adevolution of loyalties, and a revival of smaller, more meaningful, communities?
Of course, the demise of national states is not imminent, but not because they are so deeply rooted in the consciousness of their citizens.
Indeed, national identities are mostly impoverishing abstractions, clichés, like race, class, and other ideological creations.
Think of how much more genuine diversity would there be in a united Europe if national states did not squat in the middle.
But Europe's nation states are not going to disappear for a while because they arecenters of power.
After all, forty cents out of every euro of GDP is a lot to fight about.
If, however, Europeans gain a sense of where they should be going, perhaps in time the national identities forged in the last couple of hundred years (for they are not much older than that) will become like the appendix - a part of the human body responsible for little else but an occasional inflammation.
NEW HAVEN – The global economy is in the midst of its second growth scare in less than two years.
Get used to it.
In a post-crisis world, these are the footprints of a failed recovery.
The reason is simple.
The typical business cycle has a natural cushioning mechanism that wards off unexpected blows.
The deeper the downturn, the more powerful the snapback, and the greater the cumulative forces of self-sustaining revival.
Vigorous V-shaped rebounds have a built-in resilience that allows them to shrug off shocks relatively easily.
But a post-crisis recovery is a very different animal.
As Carmen Reinhart and Kenneth Rogoff have shown in their book This Time is Different, over the long sweep of history, post-crisis recoveries in output and employment tend to be decidedly subpar.
Such weak recoveries, by definition, lack the cushion of V-shaped rebounds.
Consequently, external shocks quickly expose their vulnerability.
If the shocks are sharp enough – and if they hit a weakened global economy that is approaching its “stall speed” of around 3% annual growth – the relapse could turn into the dreaded double-dip recession.
That is the risk today.
There can be no mistaking the decidedly subpar character of the current global recovery.
Superficially, the numbers look strong: world GDP rebounded by 5.1% in 2010, and is expected to rise another 4.3% in 2011, according to the International Monetary Fund.
But because these gains follow the massive contraction that occurred during the Great Recession of 2008-2009, they are a far cry from the trajectory of a classic V-shaped recovery.
Indeed, if the IMF’s latest forecast proves correct, global GDP at the end of 2012 will still be about 2.2 percentage points below the level that would have been reached had the world remained on its longer-term 3.7% annual-growth path.
Even if the global economy holds at a 4.3% cruise speed – a big “if,” in my view – it will remain below its trend-line potential for over eight years in a row, through 2015.
This protracted “global output gap” underscores the absence of a cushion in today’s world economy, as well as its heightened sensitivity to shocks.
And there have certainly been numerous such blows in recent months – from Europe’s sovereign-debt crisis and Japan’s natural disasters to sharply higher oil prices and another setback in the US housing recovery.
While none of these shocks appears to have been severe enough to have derailed the current global recovery, the combined effect is worrisome, especially in a still-weakened post-crisis world.
Most pundits dismiss the possibility of a double-dip recession.
Labeling the current slowdown a temporary “soft patch,” they pin their optimism on the inevitable rebound that follows any shock.
For example, a boost is expected from Japan’s reconstruction and supply-chain resumption.
Another assist may come from America’s recent move to tap its strategic petroleum reserves in an effort to push oil prices lower.
But in the aftermath of the worst crisis and recession of modern times – when shocks can push an already weakened global economy to its tipping point a lot faster than would be the case under a stronger growth scenario – the escape velocity of self-sustaining recovery is much harder to achieve.
The soft patch may be closer to a quagmire.
This conclusion should not be lost on high-flying emerging-market economies, especially in Asia – currently the world’s fastest-growing region and the leader of what many now call a two-speed world.
Yet with exports still close to a record 45% of pan-regional GDP, Asia can hardly afford to take external shocks lightly – especially if they hit an already weakened baseline growth trajectory in the post-crisis developed world.
The recent slowdown in Chinese industrial activity underscores this very risk.
Policymakers are ill prepared to cope with a steady stream of growth scares.
They continue to favor strategies that are better suited to combating crisis than to promoting post-crisis healing.
That is certainly true of the United States.
While the US Federal Reserve Board’s first round of quantitative easing was effective in ending a wrenching crisis, the second round has done little to sustain meaningful recovery in the labor market and the real economy.
America’s zombie consumers need to repair their damaged balance sheets, and US workers need to align new skills with new jobs.
Open-ended liquidity injections accomplish neither.
European authorities are caught up in a similar mindset.
Mistaking a solvency problem for a liquidity shortfall, Europe has become hooked on the drip feed of bailouts.
However, this works only if countries like Greece grow their way out of a debt trap or abrogate their deeply entrenched social contracts.
The odds on either are exceedingly poor.
The likelihood of recurring growth scares for the next several years implies little hope for new and creative approaches to post-crisis monetary and fiscal policies.
Driven by short-term electoral horizons, policymakers repeatedly seek a quick fix – another bailout or one more liquidity injection.
Yet, in the aftermath of a balance-sheet recession in the US, and in the midst of a debt trap in Europe, that approach is doomed to failure.
Liquidity injections and bailouts serve only one purpose – to buy time. Yet time is not the answer for economies desperately in need of the structural repairs of fiscal consolidation, private-sector deleveraging, labor-market reforms, or improved competitiveness.
Nor does time cushion anemic post-crisis recoveries from the inevitable next shock.
It’s hard to know when the next shock will hit, or what form it will take; otherwise, it wouldn’t be a shock.
But, as night follows day, such a disruption is inevitable.
With policymakers reluctant to focus on the imperatives of structural healing, the result will be yet another growth scare – or worse.
A failed recovery underscores the risks of an increasingly treacherous endgame in today’s post-crisis world.
Turkey has been given what looks like an ultimatum from the EU Commission: open your ports for ships from Cyprus within a month, or you may risk a halt to the EU accession talks now underway.
At the same time, the Commission’s latest report on Turkey’s progress toward accession notes that political reforms have slowed down, further calling into question the country’s future EU membership.
The Commission’s progress report will be dealt with by the European Council next month.
At that meeting, European leaders should ask themselves the following questions: Has the EU given Turkey a fair deal in the case of Cyprus?
Has the EU’s behavior been consistent in supporting political reform in Turkey?
What are the EU’s long-term interests vis-à-vis Turkey?
If the answers to the first two questions are “no” – as I believe they are – the third question becomes vitally important.
True, Turkey has closed its ports to ships from (Greek) Cyprus, and this is a violation of agreements.
But it is also true that the northern Turkish part of Cyprus is denied access to free trade and other benefits from EU-membership.
This is because Cyprus remains a divided island.
It was assumed that Cyprus should be united when the country joined the EU in 2004.
A United Nations plan for unification was accepted by the Turkish part.
But the Greek Cypriots voted against the plan because their leaders did not live up to the implicit deal with the EU to support it.
Nevertheless, Cyprus became an EU member – but only the Greek part.
This was clearly a mistake, because it made the EU part of the conflict.
It gave Greek Cypriot leaders the possibility of blocking progress in negotiations between the EU and Turkey.
So how can Turkey under these conditions maintain confidence in the EU’s fairness?
Political and legal reforms in Turkey in recent years have been remarkably far-reaching, for they have clearly been spurred by Turks’ wish to move closer to the EU.
But Turkish public support for EU membership has fallen dramatically as Turks have grown to feel that they are not being given a fair deal.
This has given new strength to those who want Turkey to develop in another direction, towards a more Islamic society instead of a modern secular state.
Therefore, the recent lack of progress in Turkey’s reform process can to a large extent be explained by the EU’s behavior.
This leaves us with the third question: what kind of Turkey does the EU want?
There should be no doubt about the answer: it is clearly in the EU’s interest to see Turkey’s democracy and economy continue to strengthen.
More than 40 years ago, it was promised that once Turkey lives up to the preconditions for membership, it will be welcome in the EU.
It is high time that European leaders take this promise seriously.
It is a sad fact that a large majority of voters in the EU are against Turkish membership.
But they are reacting to the current situation.
When they are asked if they would like a reformed Turkey as a partner – a Turkey that lives up fully to the conditions for membership described in the Copenhagen Criteria (democracy, rule of law, respect for human rights, and an effective market economy) – many more are inclined to say yes.
European leaders must therefore take up two challenges.
First, they should say clearly to their own voters that the EU must live up to its promises to Turkey, and that this is in the larger interest of all Europeans.
Second, they should give Turkey a fair deal in the negotiations.
The first litmus test on European leadership concerns the practical problem of access to harbors.
Here the Finns, who chair the EU right now, have taken an initiative to implement a pragmatic solution that takes into consideration both sides in the conflict.
The Finnish initiative should be given strong support from all European leaders.
At the same time, a new effort should be made to bring life to the UN’s proposals regarding Cyprus.
If this means putting pressure on some actors within the EU’s own ranks, so be it.
The agreement on climate change reached at Heiligendamm by the G8 leaders merely sets the stage for the real debate to come: how will we divide up the diminishing capacity of the atmosphere to absorb our greenhouse gases?
The G8 leaders agreed to seek “substantial” cuts in greenhouse gas emissions and to give “serious consideration” to the goal of halving such emissions by 2050 – an outcome hailed as a triumph by German Chancellor Angela Merkel and British Prime Minister Tony Blair.
Yet the agreement commits no one to any specific targets, least of all the United States, whose president, George W. Bush, will no longer be in office in 2009, when the tough decisions have to be made.
One could reasonably ask why anyone thinks such a vague agreement is any kind of advance at all.
At the United Nations Conference on Environment and Development in Rio de Janeiro in 1992, 189 countries, including the US, China, India, and all the European nations, signed the UN Framework Convention on Climate Change, thereby agreeing to stabilize greenhouse gases “at a low enough level to prevent dangerous anthropogenic interference with the climate system.”
Fifteen years later, no country has done that.
US per capita greenhouse gas emissions, already the highest of any major nation when Bush took office, have continued to rise.
In March, a leaked Bush administration report showed that US emissions were expected to rise almost as fast over the next decade as they did during the previous decade.
Now we have yet another agreement to do what these same nations said they would do 15 years ago.
That’s a triumph?
If Bush or his successor wants to ensure that the next round of talks fails, that will be easy enough.
In justifying his refusal to sign the Kyoto Protocol, Bush has always referred to the fact that it did not commit China and India to mandatory emission limits.
Now, in response to suggestions by Bush and other G8 leaders that the larger developing nations must be part of the solution to climate change, Ma Kai, the head of China’s National Development and Reform Commission, has said that China will not commit to any quantified emissions reduction targets.
Likewise, the spokesman of India’s foreign minister, Navtej Sarna, has said that his country would reject such mandatory restrictions.
Are China and India being unreasonable?
Their leaders have consistently pointed out that our current problems are the result of the gases emitted by the industrialized nations over the past century.
That is true: most of those gases are still in the atmosphere, and without them the problem would not be nearly as urgent as it now is.
China and India claim the right to proceed with industrialization and development as the developed nations did, unhampered by limits on their greenhouse gas emissions.
China, India, and other developing nations, have a point – or rather, three points.
First, if we apply the principle “You broke it, you fix it,” then the developed nations have to take responsibility for our “broken” atmosphere, which can no longer absorb more greenhouse gases without the world’s climate changing.
Second, even if we wipe the slate clean and forget about who caused the problem, it remains true that the typical US resident is responsible for about six times more greenhouse gas emissions than the typical Chinese, and as much as 18 times more than the average Indian.
Third, the richer nations are better able than less well-off nations to absorb the costs of fixing the problem without causing serious harm to their populations.
But it is also true that if China and India continue to increase their output of greenhouse gases, they will eventually undo all the good that would be achieved by deep emissions cuts in the industrialized nations.
This year or next, China will overtake the US as the world’s biggest greenhouse gas emitter – on a national, rather than a per capita basis, of course.
In 25 years, according to Fatih Birol, chief economist at the International Energy Agency, China’s emissions could be double those of the US, Europe, and Japan combined.
But there is a solution that is both fair and practical:
Establish the total amount of greenhouse gases that we can allow to be emitted without causing the earth’s average temperature to rise more than two degrees Celsius (3.6 degrees Fahrenheit), the point beyond which climate change could become extremely dangerous.
Divide that total by the world’s population, thus calculating what each person’s share of the total is.
Allocate to each country a greenhouse gas emissions quota equal to the country’s population, multiplied by the per person share.
Finally, allow countries that need a higher quota to buy it from those that emit less than their quota.
The fairness of giving every person on earth an equal share of the atmosphere’s capacity to absorb our greenhouse gas emissions is difficult to deny.
Why should anyone have a greater entitlement than others to use the earth’s atmosphere?
But, in addition to being fair, this scheme also has practical benefits.
It would give developing nations a strong incentive to accept mandatory quotas, because if they can keep their per capita emissions low, they will have excess emissions rights to sell to the industrialized nations.
The rich countries will benefit, too, because they will be able to choose their preferred mix of reducing emissions and buying up emissions rights from developing nations.
In recent days, Italy’s government fell after losing a parliamentary vote on the country’s troop deployment in Afghanistan, while Britain and Denmark announced that they are to begin withdrawing their troops from Iraq.
Whereas the Bush administration is deploying an additional 21,000 American soldiers in Iraq, and is pushing for more allied troops in Afghanistan, America’s allies are rejecting its Middle East policy.
They are increasingly convinced that “victory” will be elusive in any asymmetric conflict between states, however powerful, and religiously driven armed insurgents.
Donald Rumsfeld’s dogma of military “transformation” – the technological upgrading of an army’s capacity to enable decisive victory with fewer troops – failed resoundingly in Iraq.
Nor could Israel, with its overwhelming technological advantage, defeat Hezbollah in Lebanon.
More rockets and missiles fell on northern Israel in 33 days than hit Britain during all of World War II.
So the Israelis now must reckon with an entirely new phenomenon: an asymmetric entity, Hezbollah, with nation-state firepower.
So the fierce debate over whether to increase the size of American ground forces in Iraq is beside the point.
Neither the Soviet experience in Afghanistan in the 1980’s nor NATO’s today vindicates the claim that troop numbers are what matter most on the modern battlefield.
When geo-strategic military front lines are non-existent, as in Kosovo, Afghanistan, and Iraq, mass no longer equals victory.
The great military thinker Carl von Clausewitz’s notion of “decisive battles” as the “center of gravity” of war is simply irrelevant to conflicts that have no visible “center of gravity.”
Indeed, while wars from the time of Hannibal’s defeat of the Romans in 216 B.C. to the Gulf War of 1991 had this center of gravity, with a massive concentration of force capable of bringing an enemy to its knees, such industrial inter-state wars have now become an historical anachronism.
Most states nowadays lie within borders that are widely accepted as legitimate, and they increasingly abide by international norms of behavior in times of war.
In fact, the obligation of states to abide by humanitarian rules of conduct while their enemies are free to barbarize warfare is what makes asymmetric wars especially insoluble.
Moreover, in an era of global media and international war crimes courts, the criteria for states’ use of military force have become more complex than ever.
Inter-state combat may still occur where strategic front lines can be found, such as Israel’s border with Syria, India’s border with Pakistan, and the border dividing the two Koreas.
In such cases, war, as the Egyptians showed in 1973, might still serve as an avenue to resolving a conflict.
The Syrians might be tempted to launch an offensive against Israel with the objective of breaking the deadlock over the future of the Golan Heights.
However, in the case of Kashmir, the asymmetric conflict currently fought by proxies and terrorist groups might not degenerate into all-out war precisely because India and Pakistan have mutual nuclear deterrence.Indeed, such asymmetric conflicts through proxies have become the new conventional way that states avoid the price of a general war.
This changing nature of the battlefield essentially means that war as a conclusive event in an international conflict has become obsolete.
The facile Clausewitzian wisdom that military action ultimately leads to a political solution is no longer convincing. “Victory” cannot bring peace, simply because there will always be a war after the war.
Thus, for example, the conventional war in Kosovo lasted for two months, only to usher in a six-year asymmetric conflict.
Likewise, America’s three-week “shock and awe” campaign in Iraq in 2003 ended in “victory,” but opened the gates of hell for occupiers and ordinary Iraqis alike.
And six months after the merciless pounding of southern Lebanon, Hezbollah is as strong as it was before.
Nor does the return of the Taliban in Afghanistan six years after their overthrow now seen too far-fetched.
It is during the war after the war that the occupier’s inferiority is revealed, with constant reinforcements increasing the number of targets for the insurgents far more quickly than the occupier can adapt to the changing battlefield.
The insurgents in Iraq, as the British admit, were able in just three years to cope with their enemies’ technological superiority in a way that the IRA in Northern Ireland was unable to do in 30 years.
The Iraq war and Israel’s wars with Hamas and Hezbollah show the limits of what military power can achieve, as well as vindicate diplomacy and conflict resolution.
When it comes to tackling complex political and cultural conflicts, forging international and regional alliances around a legitimate objective is more important than sheer military capacity.
That said, it would be dangerously naïve to believe that the exercise of power and the capacity to intimidate are unnecessary.
But the objectives of the use of force need to be linked to the recognition that in today’s asymmetric conflicts, victory is no longer achieved on the battlefield.
Only better-informed foreign policies that can address the genuine anxieties of civilizations in crisis will yield more sustainable results.
MOSCOW – Twenty-five years ago this month, I sat across from Ronald Reagan in Reykjavik, Iceland to negotiate a deal that would have reduced, and could have ultimately eliminated by 2000, the fearsome arsenals of nuclear weapons held by the United States and the Soviet Union.
For all our differences, Reagan and I shared the strong conviction that civilized countries should not make such barbaric weapons the linchpin of their security.
Even though we failed to achieve our highest aspirations in Reykjavik, the summit was nonetheless, in the words of my former counterpart, “a major turning point in the quest for a safer and secure world.”
The next few years may well determine if our shared dream of ridding the world of nuclear weapons will ever be realized.
Critics present nuclear disarmament as unrealistic at best, and a risky utopian dream at worst.
They point to the Cold War’s “long peace” as proof that nuclear deterrence is the only means of staving off a major war.
As someone who has commanded these weapons, I strongly disagree.
Nuclear deterrence has always been a hard and brittle guarantor of peace.
By failing to propose a compelling plan for nuclear disarmament, the US, Russia, and the remaining nuclear powers are promoting through inaction a future in which nuclear weapons will inevitably be used.
That catastrophe must be forestalled.


As I, along with George P. Shultz, William J. Perry, Henry A. Kissinger, Sam Nunn, and others, pointed out five years ago, nuclear deterrence becomes less reliable and more risky as the number of nuclear-armed states increases.
Barring preemptive war (which has proven counterproductive) or effective sanctions (which have thus far proven insufficient), only sincere steps toward nuclear disarmament can furnish the mutual security needed to forge tough compromises on arms control and nonproliferation matters.
The trust and understanding built at Reykjavik paved the way for two historic treaties.
The 1987 Intermediate-Range Nuclear Forces (INF) Treaty destroyed the feared quick-strike missiles then threatening Europe’s peace.
And, in 1991, the first Strategic Arms Reduction Treaty (START I) cut the bloated US and Soviet nuclear arsenals by 80% over a decade.
But prospects for progress on arms control and nonproliferation are darkening in the absence of a credible push for nuclear disarmament.
I learned during those two long days in Reykjavik that disarmament talks could be as constructive as they are arduous.
By linking an array of interrelated matters, Reagan and I built the trust and understanding needed to moderate a nuclear-arms race of which we had lost control.
In retrospect, the Cold War’s end heralded the coming of a messier arrangement of global power and persuasion.
The nuclear powers should adhere to the requirements of the 1968 Non-Proliferation Treaty and resume “good faith” negotiations for disarmament.
This would augment the diplomatic and moral capital available to diplomats as they strive to restrain nuclear proliferation in a world where more countries than ever have the wherewithal to construct a nuclear bomb.
Only a serious program of universal nuclear disarmament can provide the reassurance and the credibility needed to build a global consensus that nuclear deterrence is a dead doctrine.
We can no longer afford, politically or financially, the discriminatory nature of the current system of nuclear “haves” and “have-nots.”
Reykjavik proved that boldness is rewarded.
Conditions were far from favorable for a disarmament deal in 1986.
Before I became Soviet leader in 1985, relations between the Cold War superpowers had hit rock bottom.
Reagan and I were nonetheless able to create a reservoir of constructive spirit through constant outreach and face-to-face interaction.
What seem to be lacking today are leaders with the boldness and vision to build the trust needed to reintroduce nuclear disarmament as the centerpiece of a peaceful global order.
Economic constraints and the Chernobyl disaster helped spur us to action.
Why has the Great Recession and the disastrous meltdown at Fukushima Daiichi in Japan not elicited a similar response today?
A first step would be for the US finally to ratify the 1996 Comprehensive Test Ban Treaty (CTBT).
President Barack Obama has endorsed this treaty as a vital instrument to discourage proliferation and avert nuclear war.
It’s time for Obama to make good on commitments he made in Prague in 2009, take up Reagan’s mantle as Great Communicator, and persuade the US Senate to formalize America’s adherence to the CTBT.
This would compel the remaining holdouts – China, Egypt, India, Indonesia, Iran, Israel, North Korea, and Pakistan – to reconsider the CTBT as well.
That would bring us closer to a global ban on nuclear tests in any environment – the atmosphere, undersea, in outer space, or underground.
A second necessary step is for the US and Russia to follow up on the New START agreement and begin deeper weapons cuts, especially tactical and reserve weapons, which serve no purpose, waste funds, and threaten security.
This step must be related to limits on missile defense, one of the key issues that undermined the Reykjavik summit.
A fissile material cut-off treaty (FMCT), long stalled in multilateral talks in Geneva, and a successful second Nuclear Security Summit next year in Seoul, will help secure dangerous nuclear materials.
This will also require that the 2002 Global Partnership, dedicated to securing and eliminating all weapons of mass destruction – nuclear, chemical, and biological – is renewed and expanded when it convenes next year in the US.
Our world remains too militarized.
In today’s economic climate, nuclear weapons have become loathsome money pits.
If, as seems likely, economic troubles continue, the US, Russia, and other nuclear powers should seize the moment to launch multilateral arms reductions through new or existing channels such as the UN Conference on Disarmament.
These deliberations would yield greater security for less money.
But the buildup of conventional military forces – driven in large part by the enormous military might deployed globally by the US – must be addressed as well.
As we engage in furthering our Conventional Forces in Europe (CFE) agreement, we should seriously consider reducing the burden of military budgets and forces globally.
US President John F. Kennedy once warned that “every man, woman, and child lives under a nuclear sword of Damocles, hanging by the slenderest of threads, capable of being cut at any moment.”
For more than 50 years, humanity has warily eyed that lethal pendulum while statesmen debated how to mend its fraying cords.
The example of Reykjavik should remind us that palliative measures are not enough.
Our efforts 25 years ago can be vindicated only when the Bomb ends up beside the slave trader’s manacles and the Great War’s mustard gas in the museum of bygone savagery.
Prime Minister Ariel Sharon's announcement that he plans to dismantle Jewish settlements in the Gaza Strip, as well as some settlements in the West Bank, has shocked and caught people off guard both in Israel and around the world.
Many denounced Sharon's plan as a trick.
But that surprise was wrong-headed from the start.
Despite the way it often looks to outsiders, debates in Israel about the future of the occupied territories have never been confined to hawks and doves.
Like everything in Israel, the process is more complicated, especially where the hawks are concerned.
Basically, there are two species of Israeli hawks: call one kind ideological and the other strategic.
Ideological hawks view the occupied territories as an integral part of the historical Land of Israel, the homeland of the Jewish people.
For them, the territories are part of the Jewish patrimony, which is why they insist on referring to the West Bank by its Hebrew historical appellation - Judea and Samaria.
Not all ideological hawks are religious, although those who are base their claim on divine promises and prophecies.
But many ideological hawks are secular nationalists, and their jargon is similar to that of typical Central and Eastern European nationalists.
Former Prime Minister Menachem Begin and Yitzhak Shamir belonged to that category.
Ideological hawks usually come from the National-Religious Party and from members of the Likud.
They are inspired by the nationalist ideology connected with Vladimir Jabotinsky, who founded "Revisionist" Zionism as a challenge to the more moderate version espoused by Israel's Founding Fathers like Chaim Weizmann and David Ben-Gurion.
Then there are the strategic hawks.
For them, given Israel's narrow and vulnerable geographic shape and continuing Arab enmity, controlling the West Bank and Gaza is not an ideological imperative, but is driven by security considerations.
For them, Jewish settlements in the territories are not a return to historical lands, but security outposts, aimed at preventing - or repelling from a better strategic position - an attack on the Israeli heartland.
They may be right or wrong in this assessment, but it is not an ideological one.
Ariel Sharon, who comes from a military background - he grew up in a social milieu much nearer to Labor than to Jabotinsky's ideas - is a strategic hawk.
For ideological hawks, compromises are treason: how can you jeopardize the historical patrimony of the Jewish people, let alone God's promise to Abraham?
Strategic hawks, however, are open to practical bargains and compromises - if the circumstances are right and if the security considerations justify it in their eyes.
It is in this context that Sharon's moves should be seen.
He was elected on the promise that he would bring peace and security.
He has brought neither.
With the defeat and demise of Saddam Hussein, the danger of an "Eastern front" against Israel has diminished.
Absent a Palestinian partner, and given continuing Palestinian terrorism - which Israel's harsh responses fail to quell - what Sharon appears to be doing now follows from his strategic-oriented thinking: set up an effective barrier, move some of the isolated and strategically untenable settlements, and wait for another day.
If one follows Sharon's statements in the last year, a clear pattern emerges.
First, he admitted that "eventually" a Palestinian state would emerge - something unthinkable for dyed-in-the-wool ideological hawks.
A few months later, he scandalized his own Likud party conference by stating that occupation is wrong and untenable - another shock for those who always speak of "liberated" rather than "occupied" territories.
Last December, he explicitly stated that Israel is headed towards unilateral disengagement, and that this would entail the "relocation" of some settlements.
Although this was still merely verbiage, it was novel language for a Likud prime minister.
Sharon's latest statements, though, explicitly specified the settlements to be evacuated; the Director of the National Security Council, General Giora Eiland, was appointed to chair an inter-ministerial Relocation Committee and work out plans for conducting the evacuations, including compensation for relocated settlers.
All of this has radically altered Israel's domestic political map.
Some ideological hawks in Sharon's government threatened to resign; Shimon Peres announced that Labor will offer Sharon a parliamentary safety net; there is even talk about Labor joining a national unity government.
The test, of course, is not in the planning, but in the implementation of withdrawal, and the road is long and bumpy.
Sharon's timing may have been determined by his problems with police investigations into alleged corruption.
Yet anyone who would like to predict Sharon's future behavior should remember that unlike Begin and Shamir, Sharon comes from the military, and for him security - not ideology - is supreme.
So his apparent pragmatism should come as no surprise.
With the final stage of the World Cup approaching, now is a good opportunity for a mid-tournament appraisal.
This year’s Cup, unlike the previous one in Japan and South Korea in 2002, didn’t witness any real upsets in the first round.
Switzerland and Australia surprisingly reached the elimination round, and the Asian and African teams disappointed somewhat, with only Ghana advancing.
There have been just two ugly matches so far, full of fouls, nasty attacks, and unnecessary aggression, as well as numerous yellow and red cards: Italy vs. the US, and Portugal vs. the Netherlands.
Otherwise, we’re experiencing a wonderful Cup in Germany, in terms of both sportsmanship and the overall atmosphere.
As for Germany and the Germans, one hardly recognizes one’s own country and people.
Even Mother Nature has played along.
After a long winter and a non-existent spring, summer started promptly with the first kick-off – and virtually overnight, Germany has flaunted its sunniest and most delightful side.
The weather is Mediterranean, and all of a sudden, so are the people.
The Cup’s organization has been exceptional (as was to be expected), with excellent police work giving hooligans hardly a chance.
The whole of Germany has been celebrating a never-ending party with guests from all over the world (which was not expected).
And the German team has put on a wonderful display of heart warming and modern offensive soccer (which nobody could have expected!).
More importantly, not only in the German team, but also in the country as a whole, a young, cool, laid-back, and carefree Germany is raising its head – a Germany that is cosmopolitan, friendly, and good-humored.
Years of bad news appear to have passed the Germans by without a trace.
Doctors are on strike, taxes are on the rise, the parties in government are mauling each other, and Chancellor Angela Merkel herself proclaimed in a prominent speech that the country is in disastrous shape.
But the Germans, undaunted by it all, simply keep celebrating one great soccer party with their newfound friends from all over the world.
The black, red, and gold German tricolor adorns the entire country as never before, but almost nowhere are there nationalist undertones.
In fact, the flags of many nations fly alongside German.
In Berlin, as in other large German cities, taxis sport the flags of their drivers’ home countries – from Angola to Saudi Arabia.
Fans don not just their nations’ flags, but also fantastic costumes evocative of their home countries’ colors.
Flags are flown in hope of victory, but also serve to dry the tears of defeat.
In short, Germany during the World Cup is reminiscent of a Shakespearean midsummer night’s dream, with a touch of Woodstock to boot.
Outside the stadiums, public screenings of the games have become joyous mass “happenings.”
And how is the soccer?
This World Cup demonstrates three main developments that the sport has undergone.
First, Europe and South America are more dominant than four years ago and remain the unchallenged great powers of international soccer.
So we must hope that the World Cup in South Africa in 2010 will finally bring greater global parity.
Second, international soccer is witnessing the advent of a new generation.
Spain, Argentina, and Germany, to name but a few countries, have put forward very young teams that have played an impressive game.
On the French, English, and Portuguese teams, too, it is the young players that have shone – despite the continuing presence of Zidane, Beckham, and Figo.
Even the Brazilian squad is looking more aggressive and likely to score with young players like Robinho and Juninho than with their aging champions from 2002.
This generational change is accelerated by a third development.
At the top international level, soccer has become faster and more athletic, and the top teams can shrink space on the field more effectively.
A team that is unable to keep going at full speed for the full 90 (or more) minutes, switch from defense to offense quickly with the whole team, and maintain control of the ball to restrict their opponents' movements won’t stand much of a chance.
Here, soccer parallels today’s globalized markets, which make similar restructuring of national economies necessary.
Unlike economic globalization, however, it remains to be seen whether this new, fast-paced style of soccer will prevail (after all, the young blood of Spain lost to the Old Boys of France).
The sport and its fans will certainly profit if it does.
For now, we have a World Cup filled with soccer that is being shaped by a new, young generation both on and off the playing field – light-hearted, enthralling, and beautiful to watch.
Let’s hope that when the last whistle blows at the final in Berlin on July 9, we Germans retain as much of this positive spirit as possible.
Germany urgently needs this kind of optimism, because, unfortunately, two universal principles will continue to apply in the future: first, the winter will return, and, second, the ball is round and the next game is always the most difficult.
Watching the news from Iraq, I recall when I was Poland's Prime Minister during the Gulf War in 1991.
I watched from home on CNN as the first cruise missiles hit Baghdad.
Hours later our military informed me that armed conflict was underway in Iraq. ``Yes, I know,'' I said. ``I've been watching the bombardment on TV.''
Twelve years later, Poland's Prime Minister didn't need a belated call from his military to know that war was underway in Iraq.
All the details of the attack were provided in advance by the US, now Poland's NATO ally.
Indeed, Poland has secured a leading role in Iraq's occupation.
What a distance Poland has travelled since communism's collapse in 1989!
Little of this, however, is the result of design, for (unfortunately) we in Poland have not thought through what sort of foreign policy we need as a member of NATO and putative member of the European Union.
We remain narrowly focussed on whether an initiative will be immediately good or bad for us.
Couple this with a form of foreign policy schizophrenia--some Poles think that by ``simply existing'' we influence Europe's fate; others suffer crippling pessimism, consigning Poland to permanent ``second-class'' status--and you have a recipe for inertia.
Our attitude seems to be that somehow things will sort themselves out.
Much of Europe seems to be stuck in the same mindset: we say that we want a common foreign and security policy, but we do nothing about it until a crisis emerges.
Then we squabble about what to do.
The time for such laxity is over.
For Poland and the other countries of East-Central Europe that have or are about to join NATO, membership in the Alliance didn't really require debate.
Our histories of oppression by powerful neighbours told us that collective security within NATO was theonlyreal option.
EU membership and the global war on terror, however, demand a more deeply considered response.
Why?
Because EU membership affects every aspect of a state, economy, and society, while the war on terror demands a completely new way to conduct diplomacy and security policy.
Today's crisis in transatlantic relations, and our accidental involvement in it as part of Donald Rumsfeld's ``New Europe,'' means that Poland (like every other European state) must now decide what it really wants from the EU and NATO.
We must consider both our attitude to global problems that were once deemed peripheral to European interests, as well what it really means to be an EU partner.
Only answers to these questions can reconcile the divide between the ``new'' and ``old'' Europe, as well as the new and old Atlantic worlds.
Poland as an ally of the US is not the real headache facing President Jacques Chirac or Chancellor Gerhard Schroeder.
Instead, the French and German leaders are really responding to the growing unpredictability of today's emerging European order.
They see new players (say, Spain) rising to shape EU policy, particularly foreign policy, and sense that their traditional leadership is being challenged.
But an EU with 10 new members simply cannot be run as it has for decades.
So the challenge to France and Germany does not arise because Poland is some sort of American ``Trojan Horse.''
Instead, the EU's structure now demands not only a new consensus about Europe's role in the world, but also new means to achieve consensus.
History cannot be put on hold as Europe sorts out its internal balance of power.
The world needs a united continent, ready to go into action.
That consensus must include the US.
During the Cold War, most Europeans tolerated America's tendency to lead unilaterally, because of the Soviet threat and the preponderance of US power.
But America is having a hard time understanding the new circumstances of the post-Cold war era.
Its difficulties are exacerbated by the dramatic disparity in military forces on either side of the Atlantic, and its belief that Europe's ambitions to become a military power will come to nothing because Europeans won't spend the money necessary to achieve that goal.
Here is where Poland can help bridge the Atlantic divide and forge a European consensus.
September 1939 taught every Pole that military power must be real to be effective.
Intentions don't deter invasions.
As Danish Premier Anders Fogh Rasmussen recently said, ``France and Germany are not in a position to guarantee our country's security.
The US is, but security does not come free of charge.''
Most Poles think that Poland's situation is akin to Denmark's.
Indeed, all of Europe is in thrall to American power.
But this dependence should not disguise the fact that there is a commonality of foreign policy interests between Europe and America.
If the EU builds its foreign and security policy on the basis of recognition of this truth, many of today's divisions will disappear.
The EU's foreign policy should be guided by the following goals:
fight terrorism;
prevent local conflict;
promote human rights and democracy;
oblige unpredictable countries to become responsible;
maintain close cooperation between Europe and the US;
help poor countries.
Polish foreign policy, like that of the EU, can only be effective in the long term if it takes realistic steps--and spends the necessary money--to realize these objectives.
They are the only possible bedrock in transatlantic relations, in an expanded Union, and in relations between the ``New'' and ``Old'' Europe.
BERKELEY – Former US Treasury Secretary Lawrence Summers had a good line at the International Monetary Fund meetings this year: governments, he said, are trying to treat a broken ankle when the patient is facing organ failure.
Summers was criticizing Europe’s focus on the second-order issue of Greece while far graver imbalances – between the EU’s north and south, and between reckless banks’ creditors and governments that failed to regulate properly – worsen with each passing day.
But, on the other side of the Atlantic, Americans have no reason to feel smug.
Summers could have used the same metaphor to criticize the United States, where the continued focus on the long-run funding dilemmas of social insurance is sucking all of the oxygen out of efforts to deal with America’s macroeconomic and unemployment crisis.
The US government can currently borrow for 30 years at a real (inflation-adjusted) interest rate of 1% per year.
Suppose that the US government were to borrow an extra $500 billion over the next two years and spend it on infrastructure – even unproductively, on projects for which the social rate of return is a measly 25% per year.
Suppose that – as seems to be the case – the simple Keynesian government-expenditure multiplier on this spending is only two.
In that case, the $500 billion of extra federal infrastructure spending over the next two years would produce $1 trillion of extra output of goods and services, generate approximately seven million person-years of extra employment, and push down the unemployment rate by two percentage points in each of those years.
And, with tighter labor-force attachment on the part of those who have jobs, the unemployment rate thereafter would likely be about 0.1 percentage points lower in the indefinite future.
The impressive gains don’t stop there.
Better infrastructure would mean an extra $20 billion a year of income and social welfare.
A lower unemployment rate into the future would mean another $20 billion a year in higher production.
And half of the extra $1 trillion of goods and services would show up as consumption goods and services for American households.
In sum, on the benefits side of the equation: more jobs now, $500 billion of additional consumption of goods and services over the next two years, and then a $40 billion a year flow of higher incomes and production each year thereafter.
So, what are the likely costs of an extra $500 billion in infrastructure spending over the next two years?
For starters, the $500 billion of extra government spending would likely be offset by $300 billion of increased tax collections from higher economic activity.
So the net result would be a $200 billion increase in the national debt.
American taxpayers would then have to pay $2 billion a year in real interest on that extra national debt over the next 30 years, and then pay off or roll over the entire $200 billion.
The $40 billion a year of higher economic activity would, however, generate roughly $10 billion a year in additional tax revenue.
Using some of it to pay the real interest on the debt and saving the rest would mean that when the bill comes due, the tax-financed reserves generated by the healthier economy would be more than enough to pay off the additional national debt.
In other words, taxpayers win, because the benefits from the healthier economy would more than compensate for the costs of servicing the higher national debt, enabling the government to provide more services without raising tax rates.
Households win, too, because they get to buy more and nicer things with their incomes.
Companies win, because goods and workers get to use the improved infrastructure.
The unemployed win, because some of them get jobs.
And even bond investors win, because they get their money back, with the interest for which they contracted.
So what is not to like?
Nothing.
How, you might ask, can I say this?
I am an economist – a professor of the Dismal Science, in which there are no free lunches, in which benefits are always balanced by costs, and in which stories that sound too good to be true almost inevitably are.
But there are two things different about today.
First, the US labor market is failing so badly that expanded government spending carries no resource cost to society as a whole.
Second, bond investors are being really stupid.
In a world in which the S&amp;P 500 has a 7% annual earnings yield, nobody should be happy holding a US government 30-year inflation-adjusted bond that yields 1% per year.
That six-percentage-point difference in anticipated real yield is a measure of bond investors’ extraordinary and irrational panic.
They are willing to pay 6% per year for “safety.”
Right now, however, the US government can manufacture “safety” out of thin air merely by printing bonds.
The government, too, would then win by pocketing that 6% per year of value – though 30 years from now, bondholders who feel like winners now would most likely look at their portfolios’ extraordinarily poor performance of over 2011-2041 and rue their strategy.
NEW YORK – The campaign to ensure that companies engaged in extractive activities disclose all of their payments in their host countries is gaining momentum – and France is leading the effort.
President Nicolas Sarkozy should be applauded for supporting a new initiative promoting strict transparency standards for petroleum, gas, and mining companies listed on European stock exchanges.
France, at the heart of the European Union and President of both the G-8 and G-20 this year, is in an exceptional position to encourage such a regulatory move.
With French leadership, 2011 offers a golden opportunity for the most important capital markets to adopt clear, precise rules requiring full financial disclosure by extractive-industry companies to governmental authorities.
Oil, gas, and mining generate billions of dollars per year for governments and companies.
Moreover, these industries often play a central role in the economic development of resource-rich countries.
Yet, despite great natural wealth, a majority of people in these countries lives in poverty.
The actual taxes and payments made by mining, oil, and other extractive-industry companies to governments are usually a well-kept secret, even though most of these governments claim to use the revenue for the public good.
In reality, in far too many countries, ordinary citizens do not benefit from any of this money; in fact, they must bear the brunt of the environmental and social costs imposed by mining and drilling operations.
Indeed, these well-kept industry and government secrets can have serious and widespread repercussions.
Witness the upheaval in North Africa and the Middle East.
In these countries, many of which are rich in oil and gas, citizens are staging protests against corruption and political repression.
At bottom, they are protesting against the mismanagement of their countries’ wealth and resources – with implications that affect the security and affordability of the entire world’s energy supplies.
Transparency is an essential part of the solution.
Citizens everywhere must be assured that oil and gas firms, as well as mining companies, publish all of their relevant financial information, broken down by country and by project, and including all payments made to host-country public budgets.
If European regulators can agree on this requirement for all extractive-industry companies listed on their stock exchanges, this transparency norm will be applied to companies regardless of where their headquarters are located.
Regulators must also stipulate that company reports be made available on a regular, timely basis, and that they are easily accessible and comparable across countries and other extractive companies.
The United States has already passed legislation requiring public disclosure of payments to governments, through the 2010 Dodd-Frank law.
That law’s requirement that companies fully disclose their revenue streams by country and by project applies to 90% of international oil and gas companies and to eight of the ten largest mining companies.
This will help citizens track how that money is used, but it will not help them to assess whether their governments are collecting a fair share.
If the EU were to require companies to publish detailed information regarding production and operational numbers, financial and accounting balances, and payments to authorities, companies would become truly accountable to citizens, and government revenues would be augmented.
Such regulatory reform is now under consideration by the European Commission, and French support is imperative if the EU is to announce this month the necessary legislative moves to promote transparency.
French Finance Minister Christine Lagarde recently highlighted the necessity of promoting “initiatives within industrial sectors that aim to enhance governance, integrity, and transparency in economic transactions.”
At its just-completed summit in Deauville, France, the G-8 called for the first time for mandatory reporting by oil, gas, and mining companies.
This is an important advance, but, unfortunately, it is qualified by language that allows voluntary approaches as an alternative, and it focuses only on payments transparency.
Now the world must look to the G-20 summit in Cannes this November to make an unequivocal commitment to the reporting requirements needed, given that important emerging economies such as Brazil, India, and China, as well as South Africa and other resource-rich African countries, will be at the table.
The importance of financial transparency in the extractive industries is not limited to one country or era – and it is too important to be left to voluntary efforts alone.
Greater accountability and stronger governance for such companies could potentially change lives, economies, and political systems around the world.
The late British Prime Minister Harold Wilson used to quip that “a week is a long time in politics.”
So, in the 30 or so weeks between now and the next French presidential election, any prediction made today could be reversed, and reversed again, before the vote.
But two candidates have emerged as clear and constant favorites in opinion polls: Nicolas Sarkozy on the right and Ségolène Royal on the left.
In fact, they have more in common than meets the eye, for each speaks of a rupture with the past while incarnating a form of continuity.
For Sarkozy, “rupture” reflects both mundanely tactical and deeply personal choices.
The 12 years of Jacques Chirac‘s presidency, together with France’s tradition of alternation in power, suggests a victory for the left.
Positioning himself as the candidate who represents a sharp break with today’s unpopular politics is the only means to escape that fate.
This is reflected in Sarkozy’s openly pro-American stance – an act of political courage in a France where anti-Americanism is running high.
Sarkozy’s message is that Chirac and Villepin were right in substance to oppose America’s military adventure in Iraq, but that their style was disastrously wrong.
Thus, his deep admiration for “American values,” while sincere, implies no embrace of President George W. Bush.
It also reassures the French business community, which was shocked by Dominique de Villepin’s flamboyant opposition to the United States when he was Chirac’s foreign minister.
At home, Sarkozy has aimed his message particularly at the young, issuing a patriotic call to the values of work and discipline, a counter-revolutionary revolution.
The revolution that must be overcome is that of May 1968, whose leaders and supporters, according to Sarkozy, may have lost politically to de Gaulle, but deeply weakened France over the succeeding decades with their emphasis on “false values.”
By contrast, rebelling against one’s parents’ generation and rediscovering traditional moral stances will save France – a message that is highly applicable to issues, such as education and immigration, that may dominate the electoral campaign.
In the case of Royal, the meaning of “rupture” is both more obvious and more visible.
She is seeking to become the first woman President of the French Republic.
To achieve her goal, she prefers to emphasize her “essence,” thereby countering Sarkozy’s stress on his record as a “doer.”
Her appeal to voters is simple: “I am a woman, and you have never tried a woman, so be modern and try one now.”
Hiding behind the originality (in French presidential politics) of her gender, Royal has avoided specifying a detailed program.
When challenged by inquisitive journalists demanding greater precision about her policy agenda, her highly effective line of defense (so far!) has been: “You would not dare to ask me such a question if I were not a woman!”
Thus, Royal’s program is her popularity.
In foreign policy, one can only guess what her priorities would be.
As far as Europe is concerned, she seems as “agnostic” as Sarkozy, who, like her, incarnates a new generation of “post-European” leaders.
In terms of values, Royal, too, seems to represent a rupture with May 1968, with her emphasis on discipline and family.
According to public opinion polls, Royal is the clear favorite of the left and the only candidate able to defeat Sarkozy.
Her support is particularly strong among women voters.
For the Socialist Party, which is eager to return to power but has not yet recovered from the humiliating defeat of Lionel Jospin in the first round of the presidential election in 2002, the question is whether it can afford to resist the wave of favorable public opinion behind Royal.
In the opinion of Royal’s many opponents among Socialist leaders and militants, the dominance of the media in the political process is leading to mediocrity: the qualities required to be elected are becoming nearly incompatible with those needed to govern.
According to Royal’s Socialist critics, the “Hollywoodization” of politics from which she benefits entails a new approach in which leaders follow and followers lead.
But the same criticism can be directed at Sarkozy.
Moreover, both candidates embody continuity – with Chirac’s Gaullist side for Sarkozy and with François Mitterrand for Royal – as much as rupture.
Royal openly claims Mitterand’s legacy as she searches for legitimacy, while Sarkozy’s rejection of Chirac’s legacy has more to do with form than substance.
To a large extent, Sarkozy can be seen as Chirac with more, whereas Royal is clearly Mitterrand with less.
When the voters decide in the spring of 2007, their choice may depend more on negative than positive considerations, as it did in 2002, when Chirac faced the odious nationalist Jean-Marie Le Pen in the second round.
As in 2002, the winner next year will be whomever the electorate dislikes or fears less.
But one way or the other, personalities will prevail over programs.
As Europe’s leaders gather in Portugal to put the finishing touches on the new, slimmed down, Reform Treaty, it might be helpful if they all pretended that the last 50 years of European integration had never taken place.
Let’s then imagine what Europe needs to do to confront its most pressing challenges, especially if it were able to do so without the political constraints of 50 years of EU deal-making and ramshackle institution-building.
On top of that, let us make a major leap of imagination and suppose that even though this scenario of the EU at “Year Zero” means we would not have a half-century of intra-European cooperation to draw on, the nations that today make up the EU would nevertheless be keen to adopt far-reaching joint policies.
Let’s suspend our disbelief, then, and try to imagine what Europe could and should be doing to tackle some of the most far-reaching and obstinate policy challenges that will determine whether the next 50 years are as constructive as the last.
Or, to put it another way, let’s look at our problems in the light of the EU’s existing mechanisms and its potential for creating far-reaching new policies, and then let’s ask ourselves why the EU isn’t realizing its own potential and delivering the goods.
Broadly, we see three areas in which Europe’s policymakers at both the national and EU levels can do better: global challenges where Europe could show greater leadership, the creation and strengthening of human capital within the EU and worldwide, and improvement in the effectiveness of the EU’s own political machinery.
Europe needs a clearer and more recognizable global agenda.
It needs to build substantially on its leadership on climate change by adopting much tougher EU goals, and then use its international economic and trade clout to champion new global emissions standards that scientific opinion can accept as meaningful.
On conflict and security issues, Europe should be advancing to a new phase in which it takes much clearer and unambiguous positions on issues ranging from nuclear proliferation to sanctions against Burma’s military regime.
The purpose must be to establish Europe as a forceful and fair-minded player on the world stage, rather than as a “broad church” in which different viewpoints co-exist.
The aim should be that “soft power” instruments like EU development aid and economic partnerships would be linked with a growing sense of political and security outreach to ensure Europe is a global player to be reckoned with.
That means, of course, that the EU should seek to widen its transatlantic thinking so that the EU and the United States cooperate more closely on defining – and thus protecting – their common interests in a world where together they account for little more than 10% of the total population.
These points are far from a blanket criticism of the EU’s efforts to create a common foreign and security policy.
But they are intended to underline what many people in Europe know very well, which is that the speed with which problems concerning international development and conflict are growing easily outpaces the EU’s policy responses so far.
Building more human capital in Europe and worldwide is a crucially important element in future EU activities.
Education is by far the most profitable investment Europe can make, so it should be launching its most ambitious strategy ever to create a new knowledge dynamic and employment inside the EU while helping to expand greatly education in the world’s poorest countries.
Europe also must at last grasp the nettle of immigration policy – something that has persistently eluded generations of political leaders.
Agreed EU-wide immigration rules are needed to reconcile shrinking Europe’s hunger for imported labor with widespread fears of cultural tensions and social unrest.
It won’t be easy to create a fairer and more multi-cultural Europe, but failure to address this problem openly will carry an even heavier price.
By much the same token, Europe’s governments should be making a determined new effort to strengthen Europeans’ sense of a shared history and common values.
A stronger European identity is the soundest basis for creating the more multi-cultural society that demographers regard as inevitable.
Meanwhile, doubts still surround the political and institutional machinery the EU will need to realize these and other ambitious goals.
Sighs of relief greeted EU leaders’ mid-year agreement on a Reform Treaty aimed at overhauling the Union’s decision-making mechanisms, but it is still uncertain whether the new pact will survive the ratification process in 27 countries.
We believe, though, that the increased use of qualified majority voting by member governments embodied in the new treaty should also be applied to the ratification process itself.
That way, if a small minority of EU governments prove unable to ratify the treaty, it would not be torpedoed the way that its predecessor, the Constitutional Treaty, was in 2005.
Coral reefs are the world's most biologically rich marine ecosystems, harboring some of the world's most beautiful organisms.
They provide the principal source of protein for over ten million people worldwide.
Reef-based activities (principally fishing and tourism) form the economic livelihood of millions more.
Clearly, the human costs of a worldwide breakdown of these ecosystems are enormous.
Yet global deterioration of coral reefs is severe and ongoing.
Wholesale disintegration of reef ecosystems has occurred in some places, and collapse on a worldwide scale is a real risk.
But there is some good news, too: we know what steps the international community can take now to protect and restore reefs' ``resilience''-- their capacity to maintain integrity in the face of the environmental fluctuations that are a natural part of life in any ecosystem.
We must mediate the severity of global warming, while simultaneously conserving the resilience of coral reefs.
Historically, the principal agents of reef degradation have been over-fishing and pollution, not global warming.
In healthy ecosystems, when prey numbers decline, predators become malnourished, and their numbers decline, too, giving their prey a chance to recover.
But human predators are different.
When our prey numbers decline, their economic value tends to increase, so fishing intensifies.
This means that once predator species become depleted, fishing pressure shifts towards plant-eating fish species, leading to precipitous declines in the numbers of herbivores on coral reefs.
Herbivorous fish are key players on coral reefs.
When coral populations decline in the aftermath of cyclones, diseases, and other disturbances, it is the herbivores that keep seaweed in check, and allow coral populations to recover.
Without them, fast-growing seaweed quickly monopolizes space on the reef, preventing restoration of healthy quantities of coral cover.
Because corals provide the habitat structure on which other reef organisms depend, the decreases in coral cover lead to big decreases in a reef's biodiversity.
Pollution by nutrients and toxins from adjacent land areas further vitiate coral populations' ability to recover, giving seaweed an even greater competitive edge.
Corals are formed by a symbiosis between an animal and a one-celled plant.
The animal provides shelter and nutrients for the plant; the plant converts sunlight into energy, which it shares with the animal.
For reasons that are not yet fully understood, this partnership breaks down when corals experience unusually high temperatures.
The plant is expelled, and corals turn a brilliant white color.
If temperatures soon return to normal, the partnership can be restored.
But if corals remain ``bleached'' for too long, they die.
For many species of coral, this bleaching threshold is usually only a couple of degrees centigrade above the typical maximum temperature for a given location.
Interpreted in light of even the most optimistic global warming scenarios, this is disturbing news.
If coral bleaching thresholds remain steady, local summer temperatures will exceed those thresholds regularly within a few decades.
Corals grow slowly, so reefs sustaining severe bleaching will not recover before they bleach again.
Fortunately, there is evidence that bleaching thresholds evolve.
Most coral species have broad geographical distributions, and bleach at different temperatures depending on location.
Many species that bleach at 28o or 29o centigrade on Australia's Great Barrier Reef routinely tolerate temperatures of 34o or more in the Arabian Sea.
Unfortunately, we do not know how long it takes for such adaptation to occur.
Two things can be done to protect coral reefs.
The first is obvious: minimize global warming by, say, honoring the Kyoto Treaty's emissions targets.
Second, we must restore coral reefs' capacity to cope with environmental change--their resilience--by protecting the fish stocks that keep seaweed in check, and thereby facilitate the recovery of coral populations from bleaching.
These recovery phases enable adaptations to higher temperatures to spread.
Without fish, seaweed dominance will prevent that recovery.
The catastrophic collapse of fish stocks around the world--on coral reefs and elsewhere--has provided hard lessons about managing fisheries.
Many intensively regulated fisheries have collapsed along with the unregulated ones.
So there is a growing consensus that standard techniques for managing fisheries must be complemented with a system of ``no-take zones''--areas in which fishing is prohibited altogether.
As fish populations in these no-take zones recover, they create ``spill-over'' effects, with catches often increasing in areas outside the no-take zones.
More importantly, they provide a refuge for fish populations, a kind of insurance policy against stock collapse.
On coral reefs, these no-take zones can help insure that a portion of coral reef habitat sustains a healthy fish community, and secure the coral reef resilience that this brings.
Scientific evidence indicates that, to be effective, 30-50% of available habitat should be set aside as no-take zones.
This figure is far higher than levels of protection in even the wealthiest countries that harbor significant coral reefs, the US and Australia, where current levels of protection are less than 5%.
Given the magnitude of the threat to the world's coral reefs, the international community's response has been frighteningly slow.
But there is some encouraging news: in June, Australia's government proposed a major increase in no-take areas within the Great Barrier Reef to over 30%.
If adopted, this policy would set a new global standard and perhaps prompt other nations to follow suit.
The future of tropical marine ecosystems, and the millions of people whose lives are linked to them, depend on it.
GAZA – This was supposed to be my first year of medical school.
Instead, I am stuck here in Gaza, in my father’s house inside the Jabalia refugee camp, with few options and no way out.
After I finished high school last year, I decided to become a doctor.
Gaza cries out for bone specialists, but the training I need is available only abroad. 
When I won a place at a medical college in Germany, my parents were proud.
I was excited to follow my older brother, who is already studying there.
In February, the German authorities granted me an entrance visa.
I wasted no time in asking the Israeli authorities for permission to travel to Europe.
But I was told that only patients in need of emergency medical evacuation would be allowed out – not students.
Hundreds of other young people trapped in the Gaza Strip have won admission to study abroad.
For many of us, this is our only opportunity to continue our education.
Gaza is one of the most densely populated places on earth, and one of the poorest – 1.5 million of us live on a patch of land about 41 kilometers long and 6-12 kilometers wide.
The local hospitals lack the equipment needed to perform many important procedures, like radiation treatments for cancer patients and heart surgery. 
Universities in Gaza are overcrowded and starved for supplies.
Many subjects are not even taught, and there are few post-graduate programs.
Instructors from abroad cannot enter Gaza.
Without the ability to go overseas, we cannot learn.
In June, after the United States pressured Israel to allow Fulbright scholarship winners to leave the Gaza Strip, the Israeli military announced that it would grant exit permits for a few more students with “recognized” scholarships – but not “hundreds.”
So hundreds of us are still waiting, most without prestigious scholarships to draw the world’s attention.
I am sure to be one of the many who will not be allowed to leave.
Life in Gaza has bled away my optimism.
My father is a teacher and owns a children’s clothing shop.
My mother is a housekeeper.
I have six brothers and three sisters.
We returned to Palestine in 1996 from Saudi Arabia, where my father had been working as a teacher.
That was at the height of the peace process.
My parents put their hope in the Oslo Accords signed in 1993, and decided that they could give us a better life here.
But when I was ten, the secondintifada began.
The peace process was collapsing throughout my teenage years.
During my third year of high school, the Israeli authorities closed off the Gaza Strip.
Israeli border controls have reduced the flow of people crossing the border to a trickle, and have suffocated Gaza’s economy, choking off imports and exports and cutting fuel deliveries and electricity.
There is no clothing left in my father’s shop, which was supposed to support my brother and me during our studies.
With the backing of the US, Canada, and the European Union, Israel has maintained its blockade in an attempt to defeat Hamas, which won the elections here in 2006.
But the blockade only makes people more desperate.
Hamas and other armed groups, I know, have launched rocket attacks from the Gaza Strip that have killed civilians in Israeli towns and villages.
But I also have witnessed how Israel has retaliated with air strikes and armed incursions into the Gaza Strip, including Jabalia.
Israel’s blockade amounts to collective punishment.
It is hurting all of us, whether we support Hamas or not.
It is also destroying my dream to write “Specialist in Bone Medicine” after my name.
Sometimes, I am sorry that I am from Gaza.
But my hope is still to go abroad, learn skills, and return to help others here.
Sometimes, when there is electricity, I watch television and see how people live in other places.
I ask myself why they have the opportunity to travel, to study, to take vacations, when I cannot go abroad even to learn medicine.
We are students, not soldiers.
We are not fighters in this conflict.
Why doesn’t Israel let us go study?
Why do Europe and America support a blockade of young minds?
Soon, my fellow classmates at the medical college will be starting classes.
When they do, I will probably still be here in my father’s house, waiting for the blockade to end.
BUCHAREST: As Chile’s former dictator, General Augusto Pinochet, under house arrest outside of London, awaits a final decision on whether he is to be extradited to Spain to face charges of having committed crimes against humanity, Romania has tried and convicted one of its own military leaders for his role in the massacre of civilians in the city of Timisoara ten years ago.
The confused reaction to this verdict should, perhaps, give pause to all those who think that putting the past on trial is a straightforward thing.
Generals Atanase Stanculescu and Mihai Chitac were found guilty of ordering the killings of dozens of innocent people in Timisoara in 1989.
Both were sentenced each to long prison terms.
The rulings were met with fierce criticism by some journalists and politicians but were enthusiastically welcomed by others.
Undoubtedly, these verdicts will remain divisive in a society not yet able to come to terms with its past.
The story of General Stanculescu, sentenced to 15 years in prison, reads like a cheap novel, with treason thrown into the mix.
The tall, good-looking officer was among Nicolae Ceausescu’s closest aides.
As the uprising against the Ceausescu regime broke out in December 1989 in Timisoara, Stanculescu (together with General Chitac) was dispatched to the city and ordered to suppress all demonstrations by any available means.
He carried out these orders ruthlessly, his troops shooting down over 100 unarmed street demonstrators.
Summoned back to Bucharest two days later, Stanculescu apparently had second thoughts about his loyalty to the dictator.
He recognized that Ceausescu was doomed. Pretending to have a broken leg, he stalled in making his reappearance.
Then, on the 22 December, as crowds stormed the Central Committee headquarters in Bucharest, Stanculescu arranged for a helicopter to rescue Nicolae and Elena Ceausescu from the building’s roof terrace.
Minutes before the helicopter took off, Elena told the General, who was wearing a fake plaster cast around his leg: “Dearest Victor, look after my children!”
By then, however, the General had turned coats: he had joined "the people" and the newly-born National Salvation Front.
The helicopter was taking the dictator and his wife to prison, not freedom.
Within days, Stanculescu was among those masterminding the show-trial of the Ceausescus which ended with their being sentenced to death and executed on the spot.
Film of Stanculescu at the time show that he had dispensed with his plaster cast.
Stanculescu’s career boomed.
He was appointed industry minister by the new, revolutionary government.
A few months later, he supported a group of young officers who called for army reform and the ouster of General Militaru, the then Defense Minister and a suspected KGB agent.
Militaru was sacked, but when Stanculescu became minister he cashiered the young officers who had helped him.
Reform of the army was put off.
One year later Stanculescu gave up politics and government altogether.
He set up a highly profitable arms trading company. Soon he became one of the country's richest tycoons.
Now, it seems that the tide has turned against him.
But has it?
General Stanculescu has appealed to the Supreme Court to quash his conviction.
A big part of public opinion seems to be behind him, believing his trial politically motivated.
Of course, many people and especially those who took to the streets against Ceausescu in 1989 feel vindicated his conviction.
But many politicians defend Stanculescu; among them, the current Defense Minister Victor Babiuc, former President Ion Iliescu, and most top army officers.
In the wake of the Stanculescu conviction, the Interior Minister reiterated his proposal for a general amnesty for all soldiers involved in the violence of 1989.
Supporters of this view argue that General Stanculescu, unlike President Pinochet, was carrying out orders he could not refuse. Later, they add, he voluntarily joined the "Revolution", fought its enemies and contributed to its victory.
Many Romanian Army officers are unhappy with the notion of soldiers being tried for crimes committed while defending the dying communist regime.
Yet, this is what every one of Romania’s post-revolutionary governments have promised at one time or another.
But these officers (and those who share their views) believe that you cannot assess the deeds of one regime by the standards of another.
Again as in Chile, they suggest that, while political regimes are transient, the heart and honor of a nation always rests with its Army. A soldier has a duty just to carry out the orders of his chiefs, no matter who they are and no matter what orders they give.
Stanculescu did just that in 1989 at Timisoara, and he did so again, a few days later, at Ceausescu’s trial.
These officers dismiss and mistrust the requirements of universal justice, as embodied in the Nuremberg rulings.
Because democratic institutions in Romania have frittered away much of their standing during the almost ten years of postcommunist transition, many politicians tend either to embrace the views of the generals, or, at least, avoid going publicly against them.
After all, opinion polls reveal that the Army and Orthodox Church – two hierarchical and traditional organizations – are, by far, the most trusted Romanian institutions.
Time and again, people seek to learn the truth about Romania’s past.
But, as that past becomes unearthed and its crimes exposed, many recoil from the consequences. The "original sin" of the Romanian Revolution always looms: most postcommunist institutions were created and later run by people deeply involved in the crimes of the communist regime.
Of course, people, at first, love seeing the truth uncovered and powerful wrongdoers punished.
But many would like to see all this while watching TV rather than experience it in real life.
Romania will have to decide whether or not it actually wants to have a past before its people can begin to confront and live with theirs.
Few concepts are as elastic as that of ``Conservatism.''
At one end of its spectrum of meanings, conservatism has (over the last two decades) come to be viewed as promoting too much of a civic life of greed and grab.
At the other end, conservatism in many European countries has historically veered too close for comfort to right-wing extremism.
In Germany today, conservatism was forged in the wake of the Weimar Republic's failures, experiences unknown to Anglo-Saxon conservatives.
This history accounts for the type of conservatism practiced by the Christian-Democratic Union (CDU) and Christian-Social Union (CSU), who focus on moderation and balance, preservation and innovation, and on commanding Germany's political center.
With federal elections due in Germany this autumn, much will be said about the nature of German conservatism.
Some, looking at CDU/CSU candidate for Chancellor Edmund Stoiber's emphasis on Bavaria's economic success, will seek to portray the coalition as shaded dangerously by the ``anything goes'' market conservatism practiced in America.
Others, pointing to the German conservatives' emphasis on social values, will say that we are as statist as the Social Democrats.
The truth itself is far more complex than these facile comparisons, which also makes it more durable.
CDU/CSU policies are, of course, founded on the idea of individual freedom, but we believe in an individualism tempered by Western culture and the Christian tradition.
We are skeptical about unfettered individualism because of our awareness of man's sins, but also because of our profound awareness of the historical defects and aberrations in Germany's 20th century history.
Yet, despite this deeply ingrained skepticism about human nature, we embrace humanity's talent for progress and innovation, because we recognize man's ability to correct mistakes and errors.
These two traits, although they seem to conflict, and are certainly different from the values of American and British conservatives, nonetheless form a sound basis for a realistic pragmatism and the shunning of ideological politics - which is precisely the politics that Germany now requires.
Far from being willing to coerce people to live in a certain way, German conservatives seek a politics that recognizes limits - the limits of the state, the market, and the individual.
We conceive of politics as a mechanism to reconcile enduring conflicts, such as those that exist between freedom and security.
Each, indeed, is unsustainable without the other.
Security is useless without freedom, but freedom makes no sense without security - both national security and economic security.
The social market economy, which we continue to embrace, is based on these principles.
It sees competition as the most effective means to promote economic growth, but also embraces state interference, when necessary, to secure equality of opportunity, social solidarity, and social balance.
This interference is also intended to help avoid the ``economization'' of all aspects of civic life.
The market is merely a tool, not an answer to every human problem.
It is in recognition of this fact that German conservatives strive, for example, to strike a balance between economy and ecology.
We feel responsible, on a global level, for the environment, which is why we disagree with unilateral decisions by individual nations when such decisions ignore the needs of the rest of the world.
For globalization is both a challenge and an opportunity.
As we open ourselves to the wind's of globalization, we must also strengthen the local institutions that foster social ties and identity, such as the family, local and regional communities, religious communities, and the tradition of voluntary worker solidarity - all which have been neglected in recent years.
This is the principle of ``subsidiarity'' which supports placing decision-making power, wherever and whenever possible, in governmental bodies nearest to the individual citizen.
This is of particular importance for our ideas about the European Union, where we seek an effective balance between the nation and Europe.
For German conservatives, European integration and national identity are not warring concepts, as they seem to be to our opponents and so many others.
They are, instead, two sides of the same coin.
The EU was founded in recognition that certain goals could only be achieved through cooperation.
Decades later, the European Union still needs the binding power and legitimacy of its constituent nations, as well as of historical regional political structures within those nations, because a common European identity is emerging only slowly and cannot yet justify a unitary constitutional structure.
In essence, the form of government we seek within Germany and across Europe is built on a sense of moral discourse and moral decision-making rather than on the supposedly eternal truth of some abstract political concept.
Indeed, only an ongoing skepticism of fashionable political nostrums - both of the statist and market fundamentalist variety - can promote pluralism and tolerance, and avoid a ballooning of the bureaucracy that enfeebles our economy.
In a fast changing world, this skepticism of the center is the only sensible attitude a responsible political party and government can strike.
Our political approach embraces this humane and realistic pragmatism, for it is only such an approach that offers a chance to secure a prosperous stability within which necessary change can be made without ending up in an extremist euphoria or a fear of the future.
Moderation, tolerance, and a capacity for reform in equal measure are the watchwords of today's German conservatism.
In 2004, the world economy grew at a rate of 5.1%, the fastest pace in the last 28 years.
While Ifo`s World Economic Climate indicator, generated from quarterly surveys of 1,200 experts in 90 countries, worsened slightly during the first three quarters of 2005, it rose again in the last quarter, indicating a continuation of the boom.
In 2005, growth is estimated to have been about 4.3%, and a similar rate can be expected in 2006, marking a period of sustained rapid global growth unseen since the 1970’s.
But the boom is not uniform.
In the United States, the number of experts giving a favorable assessment of the current situation declined; indeed, a majority believes that the economic situation will worsen during the next six months.
However, in the Asian countries, including China, the optimism is unbroken.
The same is true for Eastern Europe, the ex-Soviet states, and Latin America.
The big surprise is Europe, which, unlike in 2004 and the first half of 2005, now seems to be catching up with the rest of the world.
Whereas growth was a miserable 1.5% in 2005 in the 15 “old” members of the European Union, Ifo expects EU-15 growth to accelerate to 2.1% in 2006.
To be sure, economic performance will vary widely among EU countries.
While Italy will be the laggard, with only 1.1% growth, the Irish rocket will not lose its force, pushing real GDP up by about 4.8%.
In general, the big EU countries are still performing badly, in contrast to the smaller members – hardly surprising, given that the EU is basically an institution to help the smaller countries overcome the drawback of their size by extending the agglomeration advantages that formerly were reserved to the bigger countries.
But even Germany, Europe’s biggest economy, is experiencing an upswing.
The Ifo climate indicator for Germany, based on monthly surveys of 7,000 firms, jumped upwards in the second half of 2005, reaching its highest value since the boom year 2000, with businesses’ assessment of the current situation and expectations improving.
After five years of stagnation, the economy is finally on the move.
The driving force is external demand, as Germany, the world’s second-largest exporter, profits from the global boom.
Exports increased by 6.2% in 2005 and are expected to increase by 7.4% in 2006.
However, as we saw in 2004 and 2005, exports are not enough to create substantial growth if domestic demand does not follow.
The good news for Germany is that investment demand is now growing, too.
While the second half of 2005 was already quite good, Ifo expects investment in equipment to grow by a healthy 6% in 2006.
After many years of contraction, investment in construction also will rise slightly.
Total investment growth is expected to reach 2.9% – weak by past standards, but nonetheless a promising salve for the wounded German mood.
Moreover, any investment growth is vital for Germany, which, according to the latest OECD statistics, currently suffers from the world’s lowest share of net investment in national income.
Even if Germany remains the world’s laggard, rising investment demand as such will contribute to GDP growth, which Ifo estimates at 1.7% in 2006.
That number looks small compared to most other countries.
In fact, all EU countries except Italy and the Netherlands will grow faster.
But everything is relative: Germany’s trend growth rate is just 1.1%, and the country has been the slowest growing EU country since 1995.
Measured against a disappointing past, even Germany is currently experiencing an economic boom.
Indeed, even German unemployment, which has been rising in cycles since 1970, will decline slightly in 2006, from 4.8 to 4.7 million.
The good economic data will reinforce initial favorable impressions of Angela Merkel’s new government, which got off to an excellent start at the EU Summit, where Merkel helped to broker a compromise between Britain and France on the Union’s 2007-2013 budget (by adding another €2 billion to Germany’s annual contribution).
In fact, the government may even have contributed a bit to the good economic data by announcing a serious effort to consolidate Germany’s own public finances – a prerequisite for investor confidence.
According to the government, substantial tax increases will bring the fiscal deficit below the 3%-of-GDP limit set by the Stability and Growth Pact – a target missed for five consecutive years – by 2007.
The real test for the German government is the labor market.
Most observers now agree that Germany needs something like the American earned-income tax credit.
In Germany, it’s called “activating social aid” or “combi wages,” but the principle is the same: the state should reduce the money it pays for doing nothing and pay more for participating in the work force.
That would widen the wage distribution, create jobs, and maintain the living standard of the poor.
Merkel announced in her inaugural speech in the Bundestag that her government will introduce such a system in 2006.
If this is more than lip service, and if she really carries out a serious reform of the German welfare state’s incentive structure, the result could be higher employment and structural economic growth.
In the long term, that would be more promising for the EU – and for the global economy – than the demand-driven performance that Germany is currently enjoying.
NEW YORK – Late next month, a child will be born – the 7th billion citizen of planet Earth. We will never know the circumstances into which he or she was born.
We do know that the baby will enter a world of vast and unpredictable change – environmental, economic, geopolitical, technological, and demographic.
The world’s population has tripled since the United Nations was created in 1945.
And our numbers keep growing, with corresponding pressures on land, energy, food, and water. The global economy is generating pressures as well: rising joblessness, widening social inequalities, and the emergence of new economic powers.
These trends link the fate and future of today’s seven billion people as never before. No nation alone can solve the great global challenges of the twenty-first century. International cooperation is a universal need.
The 66th session of the UN General Assembly is a renewed opportunity for the countries of the world to set aside narrow, short-term interests and commit to cooperative efforts to address humanity’s long-term imperatives.
At a time when all nations are experiencing individual challenges, we need to forge a worldwide common agenda that can help to ensure that the seven billionth baby and future generations grow up in a world characterized by sustainable peace, prosperity, freedom, and justice.
To help create this future, I am focusing my second term as Secretary-General on five global imperatives – five generational opportunities to shape the world of tomorrow by the decisions we make today.

The first and greatest of these imperatives is sustainable development. We all must understand that saving our planet, lifting people out of poverty, and advancing economic growth are one and the same fight. We must connect the dots between climate change, water scarcity, energy shortages, global health, food security, and women’s empowerment. Solutions to one problem must be solutions for all.

In the next five years, we need to create a new economic vision for sustainable development and forge global consensus on a binding climate change agreement.
Fostering economic growth, realizing the Millennium Development Goals, and combating climate change will all depend on creating a new energy system for the twenty-first century and extending it to every person on the planet.
Prevention as a framework for international cooperation is a second opportunity.
This year, the UN peacekeeping budget will total $8 billion. Think of what we could save by avoiding conflicts – by deploying political mediation missions, for example, rather than troops.
We know how to do this.
Our record proves it – in Guinea, Kenya, and Kyrgyzstan.
A third imperative is building a safer and more secure world. In this effort, we must be courageous in standing up for democracy, human rights, and peace.
This year was one of signature achievements in restoring and securing peace – in Côte d’Ivoire, Darfur, Egypt, and elsewhere. But hatred and bloodshed still stand in the way of our vision for peace.  
In the Middle East, we must break the stalemate.
Palestinians deserve a state.
Israel needs security.
Both want peace. A negotiated settlement can produce these outcomes, and the UN is a platform for forging such a peace.
So, too, will we continue our efforts to foster democratic governance in Iraq, Afghanistan, the Democratic Republic of Congo, and Sierra Leone. And, in the name of all of humanity, we will continue to push forward on nuclear disarmament and non-proliferation, in service of realizing a world free of nuclear weapons.
The fourth big opportunity is supporting countries in transition.
This year’s dramatic events in North Africa and the Middle East inspired people around the globe.
Let us help make the Arab Spring a true season of hope for all.
In Libya, we are deploying a new UN support mission to assist the country’s transitional authorities in establishing a new government and legal order, consistent with the aspirations of the Libyan people.
Syria is a special concern.
For six months we have seen escalating violence and repression.
The government has repeatedly pledged to undertake reforms and listen to its people.
It has not done so.
The moment to act is now.
The violence must stop.
Last but not least is the imperative of working with and for women and young people.  
Women hold up more than half the sky and represent much of the world’s unrealized potential.
We need their full engagement – in government, business, and civil society.
The UN has placed a high priority on promoting women at all levels of the Organization and this year, for the first time, UN Women is operating to promote the interests and rights of women all over the world.
Seven billion people now look toward the United Nations for solutions to the world’s great global challenges.
They hold different religions and backgrounds but common dreams and aspirations.
Our global future depends on bringing these individual talents and universal rights together in common cause.
Let our common agenda begin.
Mention the United Nations and the first reaction is likely to be the ongoing oil-for-food scandal and what it will mean for Secretary-General Kofi Annan’s ability to lead the organization for the remaining year and a half of his tenure.
But there is much more going on at the UN than investigations.
Reform is in the air – in part because of the scandal, but also because of the UN’s inability to deal effectively with challenges ranging from Rwanda and Kosovo to Iraq and, most recently, Sudan.
Even the UN’s most ardent supporters now recognize that change is called for if the organization is to make a significant contribution to international peace and security.
Some of the reform talk concerns the UN Security Council’s composition.
The Security Council represents what the World War II Allies believed the post-war world would look like and how it should be run.
This helps to explain why a much-weakened France was made a permanent member of the Council – and why Germany and Japan (and a not-yet independent India) were not.
Defending the Security Council’s current make-up is impossible; the need for change is beyond debate.
But coming up with an approach that gains broad international support will prove extremely difficult.
Great Britain and France will resist being replaced by a single EU seat, while making Germany a permanent member would only exacerbate the problem of Europe’s relative over-representation.
Pakistan would object to adding India to the Security Council; Argentina, Chile, and Mexico to adding Brazil; Nigeria to South Africa (and vice-versa); and several countries, including China, Indonesia, and South Korea, might resist creating a permanent seat for Japan.
Clearly, fixing the Security Council will require considerable time and political effort.
In the meantime, there is important work to be done.
One productive avenue would be to follow up on one of the recommendations of the High Level Panel that was endorsed by Annan; namely, that all UN members go on record declaring that terrorism has no place in today’s world.
This will prove more difficult than it first sounds.
For too long, the international community has tolerated terrorism – the intentional killing of civilians and noncombatants by non-state actors for political purposes – on the grounds that, on occasion, “one man’s terrorist is another man’s freedom fighter.”
Historians have the luxury of debating whether terrorism may have been justified in certain situations in the past.
We do not.
Modern terrorism is too destructive to be tolerated, much less supported.
Weapons of mass destruction – nuclear, biological, and chemical weapons – are just that, and no cause can excuse their use.
Moreover, as the terrorist attacks on America of 2001 showed, weapons as basic as box-cutters can become weapons of mass destruction if they are used to exploit the vulnerabilities of modern, global life.
Terrorism is even less justified given that political avenues exist nowadays for pursuing political aims.
Palestinians can negotiate their future relationship with Israel and can count on American, Russian, European, and UN assistance.
Iraqis have elected their own representatives and are poised to write their constitution.
No one pursuing reasonable goals and who is prepared to compromise can argue that terrorism is his or his group’s only option.
The world has already taken some important steps against terrorism.
A dozen international conventions and numerous UN resolutions commit governments to oppose hostage taking, the hijacking of civilian aircraft, and terrorism more broadly.
Similarly, the mandate of the Financial Action Task Force, created in 1989 to curb money laundering, has grown and become focused mainly on curbing terrorist financing.
UN Security Council Resolution 1373, passed after the September 11 attacks, calls on states to deny safe haven to terrorists, bring to justice anyone associated with terrorism, suppress recruitment by terrorist groups, block terrorists’ efforts to acquire weapons, and cooperate with other governments and international organizations in tracking suspects and boosting security.
What is missing is a new, 13th convention that closes the loophole that seems to permit governments to decide what constitutes terrorism and what does not.
Broad agreement is needed that any intentional killing of civilians and noncombatants is unacceptable, and that its perpetrators and supporters must be punished.
Of course, such a convention will not prevent all future acts of terrorism.
But ideas matter.
Terrorism needs to be de-legitimized in the way that slavery has been.
Doing so will make governments and individuals think twice before becoming a party to terrorism; it should also make it less difficult to garner support for international action against those who nevertheless carry it out.
We are taught early on in our lives that the end cannot justify the means.
It is time to put this principle into effect before many more innocent lives are lost.
NAIROBI – With unemployment soaring, bankruptcies climbing, and stock markets in free-fall, it may at first glance seem sensible to ditch the fight against climate change and put environmental investments on hold.
But this would be a devastating mistake of immediate, as well as inter-generational, proportions.
Far from burdening an already over-stressed, over-stretched global economy, environmental investments are exactly what is needed to get people back to work, get order books flowing, and assist in powering economies back to health.
In the past, concern for the environment was viewed as a luxury; today, it is a necessity – a point grasped by some, but by no means all, economic architects yet.
A big slice of President Barack Obama’s $825 billion stimulus package for the United States includes a boost to renewable energy, “weatherizing” a million homes, and upgrading the country’s inefficient electricity grid.
Such investments could generate an estimated five million “green-collar” jobs, provide a shot in the arm for the construction and engineering industries, and get America back into the equally serious business of combating climate change and achieving energy security.
The Republic of Korea, which is losing jobs for the first time in more than five years, has also spotted the green lining to grim economic times.
President Lee Myung-Bak’s government plans to invest $38 billion employing people to clean up four major rivers and reduce disaster risks by building embankments and water-treatment facilities.
Other elements of Lee’s plan include construction of eco-friendly transportation networks, such as high-speed railways and hundreds of kilometers of bicycle tracks, and generating energy using waste methane from landfills.
The package also counts on investments in hybrid vehicle technologies.
Similar pro-employment “Green New Deal” packages have been lined up in China, Japan, and the United Kingdom.
They are equally relevant to developing economies in terms of jobs, fighting poverty, and creating new opportunities at a time of increasingly uncertain commodity prices and exports.
In South Africa, the government-backedWorking for Water initiative – which employs more than 30,000 people, including women, youth, and the disabled – also sees opportunity in crisis.
The country spends roughly $60 million annually fighting invasive alien plants that threaten native wildlife, water supplies, important tourism destinations, and farmland.
This work is set to expand as more than 40 million tons of invasive alien plants are harvested for power-station fuel.
As a result, an estimated 500 megawatts of electricity, equal to 2% of the country’s electricity needs, will be generated, along with more than 5,000 jobs.
So it is clear that some countries now view environmental investments in infrastructure, energy systems, and ecosystems as among the best bets for recovery.
Others may be unsure about the potential returns from investing in ecosystem services such as forest carbon storage or in renewable energy for the 80% of Africans who have no access to electricity.
Still others may simply be unaware of how to precisely follow suit.
In early February, the United Nations Environment Program will convene some of the world’s leading economists at the UN’s headquarters in New York.
A strategy for a Global Green New Deal, tailored to different national challenges, will be fleshed out in order to assist world leaders and ministers craft stimulus packages that work on multiple fronts.
The Global Green New Deal, which UNEP launched as a concept in October 2008, responds to the current economic malaise.
Spent wisely, however, these stimulus packages could trigger far-reaching and transformational trends, setting the stage for a more sustainable, urgently needed Green Economy for the twenty-first century.
The trillions of dollars that have been mobilized to address current woes, together with the trillions of investors’ dollars waiting in the wings, represent an opportunity that was unthinkable only 12 months ago: the chance to steer a more resource-efficient and intelligent course that can address problems ranging from climate change and natural-resource scarcity to water shortages and biodiversity loss.
Blindly pumping the current bail-out billions into old industries and exhausted economic models will be throwing good money after bad while mortgaging our children’s future.
Instead, political leaders must use these windfalls to invest in innovation, promote sustainable businesses, and encourage new patterns of decent, long-lasting employment.
CAMBRIDGE: The rich countries meeting in June at the G-7 Economic Summit in Cologne had some interesting things to declare about their relations with the poor countries.
First, they acknowledged -- without ever quite admitting it -- that their earlier attempts to reduce developing-country debt had failed.
Therefore they signaled the start of a new program, immediately dubbed the Cologne Initiative, to reduce further the debt burden of the so-called Highly Indebted Poor Countries (HIPCs).
Second, they instructed the IMF and the World Bank to re-think their development strategies, in order to put more focus on social problems, particularly health and education.
One could of course be quite cynical about both announcements.
After all, it has been clear to most objective observers for many years that the rich countries had no realistic strategy for reducing the unpayable debts of the poor countries, yet such critics were told to be patient, that everything was okay.
Moreover, only the finance ministers of the G-7 could possibly have believed that the IMF and World Bank were doing a good job in the poorest countries.
In truth, their record is often disastrous, or simply irrelevant.
The IMF in particular doesn't have a strategy for long-term economic development, even though the United States has assigned the IMF the lead role in economic development in dozens of poor countries.
Another reason for cynicism is that the G-7 didn't move mainly on their own initiative, but rather in response to a growing cry of international civil society for action on behalf of the world's poorest.
The credit for the Cologne Initiative goes strongly to the worldwide movement known as Jubilee 2000, a grass-roots movement based on the biblical concept of Jubilee, in which unpayable debts should be forgiven in order to allow a debtor to have a fresh start in life.
The Jubilee 2000 movement has adherents in all parts of the world, including Pope John Paul II, rock stars such as Bono of the Irish group U2, and non-governmental organizations representing many religions and professions.
We should move beyond cynicism, however, in embracing the new Cologne Initiative, especially to push the G-7 countries to do all that needs to be done to make the Initiative successful.
The details of the Initiative announced in Cologne were disappointing, but these details can still be changed under international public pressure.
At least the Initiative pointed in the right direction.
The motivation for urgent action on behalf of the poorest nations is clear.
The 42 countries that are part of the HIPC initiative have a combined population of around 700 million.
Around three-fourths of these people live in Africa.
The combined HIPC population has a life expectancy of around 50 years, compared with 78 years in the rich countries.
Around one-third of the children are malnourished, and will consequently suffer a lifetime of physical and cognitive disabilities.
Many will never finish even primary school, or be able to play an effective role in modern society.
Diseases are rampant, including an AIDs epidemic that killed around 2 million people in Africa last year, and malaria, which took more than 1 million lives.
A successful Cologne Initiative would build on the following concepts.
First, the debts of the countries suffering from extreme poverty and illness would be forgiven entirely.
Around 25 countries out of the 42 HIPC countries probably need complete debt cancellation.
Second, the United Nations Development Program (UNDP) and the World Bank, rather than the International Monetary Fund, should take the lead in helping these countries.
Both the UNDP and the World Bank would help to ensure that debt forgiveness opens the way to new and ambitious programs of social improvement -- with the focuses on health and education.
The UNDP should turn its annual Human Development Reports into concrete guidelines for social action, to help ensure that each impoverished country has the adequate resources to provide effective programs for children's vaccines, AIDS prevention, meals for impoverished children, improved access to clean water, and mother-and-infant medical care.
The UNDP should also have the task of coordinating the specialized agencies of the United Nations on behalf of the world's poorest, to ensure that key organizations such as United Nations Children's Fund (UNICEF) and the World Health Organization (WHO) have the access and financial resources to fulfill their missions.
The Cologne Summit announcements so far fall short of these objectives.
The debt relief proposals are still too small.
The role of the IMF remains too large.
Public health goals are still too far down the list of priorities.
But we should maintain hope and pressure on the international organizations and the rich countries.
Already, international actions have pushed the G-7 in a new and hopeful direction.
With a continued worldwide movement on behalf of global justice and economic development, a much more ambitious program for the world's poorest can still be reached.
Two wrongs don’t make a right.
Just because European governments have failed to put bread on their constituents’ tables doesn’t mean that the European Central Bank should likewise fail in its job of promoting price stability in the euro zone.
That may sound obvious, but abandoning price stability is exactly what some European politicians are advocating.
For example, Italian politicians, who, given Italy’s recent dismal economic performance, would seem the least qualified to offer the ECB advice on monetary policy, are nonetheless advocating interest-rate cuts.
Echoing comments by Italian Prime Minister Silvio Berlusconi, Deputy Economics Minister Mario Baldassarri said in Il Sole 24 Ore last week that all efforts to boost growth are in vain “if someone is pushing on the brake pedal.”
Who’s he kidding?
If anyone is “pushing down on the Italian growth brake” it is Berlusconi himself.
He has made no efforts at economic reform during his term and now seeks to blame the ECB for Italy’s lame economic performance.
But it is precisely the lack of economic reform at home that has made Italy one of the least competitive states in the euro-zone economy.
More than the usual “blame game” is at work here.
Pressures are mounting on the ECB to raise interest rates – and Berlusconi and Co.’s attacks are as much as an attempt to forestall future rate hikes as to get the ECB to loosen its monetary policy.
Soaring energy prices, for example, have become a leading inflation risk.
But higher energy prices, by themselves, will not cause the ECB to pull the interest-rate trigger.
The key will be so-called “second-round effects” – whether growing crude prices lead to higher wage demands from trade unions.
So far, the “social partners,” as ECB president Jean-Claude Trichet likes to call the unions, have been quiet.
Should this change, the ECB will have to raise rates even if Europe’s economic growth remains slack.
The good news is that economic growth in the euro-zone economy appears to be picking up (even in Italy).
Though second-quarter GDP growth was weak — the euro-zone average was only 0.3% year on year – third-quarter data are indicating a sustained economic pick-up in the second half of the year.
Only consumption is lagging.
How will the ECB react to better economic news?
Some on the Governing Council have grown uncomfortable that euro-zone interest rates have stayed so low, at 2%, for so long (more than two years).
True, there is no inflation problem in the short run, but the ECB’s monetary policy focuses on the medium term.
One particular worry is that euro-zone money supply is well above the ECB’s benchmark level, indicating an excess supply of liquidity.
It is doubtful that the ECB would raise interest rates to curb excess liquidity so long as economic recovery remains in question.
Slow growth has silenced the monetarists on the ECB’s Governing Council.
This will change, however, once the economic pick-up is confirmed.
Interest-rate hikes may be coming sooner rather than later, which is why Berlusconi and French President Jacques Chirac are talking up interest-rate cuts now.
Meanwhile, in Germany, the elections this September may have surprising consequences for ECB monetary policy.
Angela Merkel, the Christian Democrats’ candidate, is a reformer, holding out hope for Germany’s future – and that of Europe.
Unfortunately, Merkel’s campaign is off to a rocky start, and the recent entry of Oskar Lafontaine’s extreme left-wing party into the fray may necessitate the formation of a grand coalition between the Christian Democrats and the Social Democrats.
This would be bad news for the German economy, which could delay possible ECB interest rate hikes.
Because the expected gridlock in parliament would make reforms less likely, companies might hold off on investment, while consumers would be more likely to keep their wallets closed, because official policy would be even less clear than it is now.
On the other hand, a center-right coalition between the Christian Democrats and the Free Democrats could spark the ECB into action.
This raises an interesting point.
The public should be relieved if the ECB raises rates, because this would most likely signal that the long-awaited economic recovery is well under way, and that inflationary repercussions are being addressed.
A hike, in other words, would indicate that good things are happening.
But the public often views interest-rate increases as negative events that increase unemployment and stifle growth.
Blame-game politicians like Berlusconi, who have failed to put bread on the table, their minions in the media, and Keynesian economic professors who don’t understand and misrepresent Keynes sustain this distorted view.
Europe would be a lot better off if someone told the public the truth.
The specter of a nuclear Iran haunts Arabs and Israelis alike, but it is the United States and Israel that are the driving force behind efforts to curtail Iran’s nuclear ambitions.
The America-Iran-Israel triangle is where the clue to the problem and its possible solution lie.
Economists believe that market forces drive prices to fundamentals.
But we are not careful enough to distinguish situations in which equilibrium-restoring forces are strong from those in which such forces are weak.
The dollar will fall and US long-term interest rates will rise, but only when traders on Wall Street and elsewhere decide that holding dollars and long-term US bonds is more risky in the short run.
When that happens, the long-run future will be now.
BERKELEY – It is hard right now to write about American political economy.
Nobody knows whether the debt-ceiling tripwire will be evaded; if so, how; or what will happen if it is not.
If no deal to raise the debt ceiling is reached by August 3, interest rates on United States Treasury bonds could spike, or they could remain stable, as investors decide they have other problems to worry about.
Or the US Federal Reserve, the Peoples Bank of China (PBC), or both – or even some other body – could support the market.
Or interest rates could rise if people expect a much weaker global economy – and, in a weaker global economy with no inflation, investors should be holding more US Treasuries, not fewer.
Frankly, no one knows what legislative deal will be struck to raise the debt ceiling.
All we know as of this writing is that a deal would probably involve cuts in near-term spending, meaning weaker growth and higher unemployment over the next 18 months.
And we can assume that it would be repealed and replaced by something else come January 2013, either by a re-elected President Barack Obama, or by a new, Republican president.
So, rather than talking about the US debt ceiling, let us think instead about all of the things that the debt-ceiling impasse has prevented the US government from doing during the past six months – all of the useful policies that might have been debated and enacted, but were not.
The risks imposed by global warming, for example, have not gone away.
The sooner the world starts preparing to deal with those threats, the better.
Another six months should not be lost.
The employment-to-population ratio in the US remains flat – mired at the very low levels to which it fell during the recession.
With households desperately trying to rebuild their balance sheets, and with capital investment remarkably healthy, the only places to boost spending to restore capacity utilization and unemployment to normal levels are exports, government purchases, and construction investment.
But opportunities to pursue the necessary policies have not been grasped.
Here, too, another six months should not be lost.
Likewise, the US could have fulfilled its normal role as the conductor of the international economic orchestra.
It has not, even as the European Union continues to respond inadequately to its own slow-moving solvency crises. The mandarins of northern Europe continue to measure out a drip-feed of support with coffee spoons.
Another six months have been lost.
America faces long-run and short-run problems: decaying infrastructure, weakening educational systems, and a dysfunctional health-care system that produces sub-standard outcomes at twice the cost of any other industrial country.
Solving any of these three problems would go a long way toward resolving the long-run financing imbalance between current tax rates and America’s long-run social-insurance promises that the debt-ceiling debate’s instigators supposedly want to address.
But the US government won’t address them.
Six months that could have been spent boosting the long-run growth potential of the American economy through infrastructure investment, educational reform, or an overhaul of health-care financing – greatly easing America's long-run deficit and debt dilemmas in the process – have been lost.
During the run-up to World War II, Winston Churchill, speaking in Parliament, lamented “the years that the locusts hath eaten” – the period during which preparatory action to face the great crisis of his day (the rise of Continental fascism) could have been taken, but was not.
Over the past century – with the notable exception of the Great Depression – the US political system has been remarkably good at foreseeing crises long before they have happened, and at least setting the foundation for dealing with them when they have occurred.
But so far in the third millennium, this skill – or simply run of luck – has deserted the US.
My view is that the problem would fix itself easily if only the Republican Party of Dwight D. Eisenhower could stage a comeback (though without Richard Nixon and Joseph McCarthy).
It is becoming increasingly clear, however, that the problem is one not only for the US, but for the rest of the world as well.
Since December 7, 1941, the world has in large part been able to rely on global governance by a somewhat-competent hyperpower.
That America may be gone for good.
If it is, the world needs to develop other institutions for global management – and quickly.
A debate on immigration is beginning in the United States Senate, which will take up several proposals.
These include a hateful bill – which the House of Representatives has already approved – that provides for the construction of a wall along the US-Mexican border and makes unauthorized entry into the US a felony.
The US Senate will also consider a bill co-authored by Senator Edward Kennedy and Senator John McCain, which proposes stronger border enforcement, a temporary workers program with a path to residency and citizenship, and legalization for people already in the US without papers.
Another idea is to require anyone in the US wanting to regularize their immigration status to go home and wait in line there.
This last component is largely rhetoric; it is hard to imagine any Mexican already in the US voluntarily returning to, say, Zacatecas to wait patiently in line for a new visa.
President George W. Bush has been skirting the question ever since he committed himself to an immigration agreement with Mexico when he visited President Vicente Fox in Guanajuato almost exactly five years ago.
Finally, and perhaps most importantly, there is Senate Judiciary Committee Chairman Arlen Specter’s compromise proposal.
Specter’s proposal also provides for reinforced security at the border, as well as a six-year non-renewable Temporary Workers Program without a path to residency, although it would allow unauthorized immigrants to remain in the US with a new, non-immigrant status.
The latter status may or may not include a path to residency and citizenship; fudging the issue may be a negotiating tactic to avoid debate over whether this is a form of disguised amnesty (which, fortunately, to a certain extent, it is).
What’s missing in the debate is the Latin American context.
There was a time when north-south migratory flows in the western hemisphere were limited to Mexico and the Caribbean.
That changed in the 1980’s, when Central America’s civil wars sent hundreds of thousands of migrants thru Mexico to the US, and then in the 1990’s, when people fleeing violence in Colombia, Venezuela, Peru, and Ecuador also began searching for opportunity.
Today, even Brazil, traditionally a country of immigration, has become one of emigration.
Moreover, these migrants are no longer exclusively of rural origin, nor do they travel only to traditional areas in the US; they are, literally, everywhere.
Their remittances contribute immensely to the economic welfare of their families, communities, and home countries’ economies.
Thus, whatever immigration policy emerges in the US will have an enormous impact south of the Rio Grande well beyond Mexico.
This will occur precisely at a time when Latin America is swerving left, with country after country drifting back to anti-American, populist stances: Venezuela in 1999, Bolivia last year, perhaps Mexico, Peru, and Nicaragua later this year.
If the perception of further US hostility toward Latin America persists, the tilt toward an irresponsible, demagogic left will harden.
The responsible left in Chile, Brazil, and Uruguay are an exception to the emerging rule set by Venezuela’s President Hugo Chávez.
The best way to accentuate the region’s growing anti-American sentiment is to try to close the US-Mexican border (which will be futile).
Instead, the US should establish humane, secure, and legal mechanisms of temporary or permanent entry for people the American economy needs and wants, and it should work with, not against, governments in Latin America.
Five years ago, Mexico’s President Vicente Fox tried to convince Bush that something had to be done before a nativist backlash in the US complicated its relations with Latin America and made goals such as a Free Trade Agreement of the Americas (FTAA) impossible.
But matters have gotten worse: border tensions between the US and Mexico have grown, the proposed wall has rightly provoked indignation, more unauthorized immigrants than ever are entering the US, and the FTAA has collapsed.
Bush must begin to use what political capital he has left to support enlightened immigration reform, along the lines of the Kennedy-McCain bill.
He will never get a guest-worker program without Democratic support, which in turn is unlikely unless the White House supports access to a program for unauthorized immigrants already in the US that includes some type of path to residence and citizenship.
Mexico and the US must be sensitive to domestic political concerns in both countries.
No immigration deal is feasible north of the border without addressing security matters; south of the border, there is no conceivable Mexican cooperation on border security or on a Temporary Workers Program if immigration reform ignores the nearly five million Mexican citizens without papers currently living in the US.
Mexico must act on what Fox has called “shared responsibility.”
The best imaginable deal between the US and Mexico, or the best imaginable US immigration reform, will not eliminate the flow of undocumented migrants from Mexico and South America overnight.
Mexico has to assume responsibility for regulating this traffic, which means more than sealing off its southern border.
The government could, for example, double welfare payments to households whose male heads stay home, threaten to revoke land reform rights after years of absence in rural communities, and establish choke points on highways at the Tehuantepec Isthmus.
Fox has said that he is willing to break with old Mexican taboos, but the Bush administration has never taken him up on it.
That is unfortunate, because Fox will not be around forever.
Immigration has always been an immensely complex and delicate issue inside the US, and now for Latin America as well.
A window of opportunity opened at the beginning of Bush’s first term, and closed shut after the terrorist attacks of September 2001.
It is opening again and should be taken advantage of before it is too late.
As the current “development round” of trade talks moves into its final stages, it is becoming increasingly clear that the goal of promoting development will not be served, and that the multilateral trade system will be undermined.
Nowhere is this clearer than in a provision that issupposed to give the least developed countriesalmost duty-free access to developed countries’ markets.
A year ago, the leaders of the world’s richest countries committed themselves to alleviating the plight of the poorest.
At Doha in November 2001, they pledged to give something more valuable than money: the opportunity for poor countries to sell their goods and earn their way out of poverty.
With great fanfare, developed countriesseemed for a while to be making good on their promise, as Europe extended the “Everything but Arms” initiative (EBA), under which it was unilaterally to open its markets to the poorest countries of the world.
The opening was less than it seemed.
The devil is in the details, as many less developed countries discovered that EBA’s complicated rules of origin, together with supply-side constraints, meant that there was little chance for poor countries to export their newly liberalized products.
But thecoup de grace was delivered by the world’s richest country, the United States, which once again decided to demonstrate its hypocrisy.
The US ostensibly agreed to a 97% opening of its markets to the poorest countries.
The developing countries were disappointed with the results of Europe’s EBA initiative, and Europe has responded by committing itself to dealing with at least part of the problem that arises from the rules of origin tests.
America’s intention was, to the contrary, toseem to be opening up its markets, while doing nothing of the sort, for it appears to allow the US to select adifferent 3% for each country.
The result is what is mockingly coming to be called the EBP initiative: developing countries will be allowed freely to export everything but what they produce.
They can export jet engines, supercomputers, airplanes, computer chips of all kinds—just not textiles, agricultural products, or processed foods, the goods they can and do produce.
Consider Bangladesh.
If we go by the most widely used six-digit tariff lines, Bangladesh exported 409 tariff lines to the US in 2004, from which it earned about $2.3 billion.
But its top 12 tariff lines – 3% of all tariff lines – accounted for 59.7% of the total value of its exports to the US.
This means that the US could erect barriers to almost three-fifths of Bangladeshi exports.
For Cambodia, the figure would be about 62%.
The situation is no better if the 3% rule applies to the tariff lines that the US imports from the rest of the world (rather than to the lines individual poor countries export to the US), for then the US can exclude roughly 300 tariff lines from duty-free and quota-free treatment.
For Bangladesh, this implies that 75% of the tariff lines, accounting for more than 90% of the value of its exports to the US, could be excluded from duty-free treatment.
Exclusion from duty-free treatment could reach 100% for Cambodia, which exported only 277 tariff lines to the US in 2004.
The official argument for the 3% exclusion is that it affects “sensitive products.”
In other words, while the US lectures developing countries on the need to face the pain of rapid adjustment to liberalization, it refuses to do the same.
(Indeed, it has already had more than 11 years to adjust to liberalization of textiles.)
But the real problem is far worse because the 3% exclusion raises the specter of an odious policy of divide and conquer, as developing countries are invited to vie with each other to make sure that America does not excludetheir vital products under the 3%.
The whole exclusion simply undermines the multilateral trading system.
Indeed, there may be a further hidden agenda behind the 97% proposal.
At the World Trade Organization’s meeting Cancun in 2003, the developing countries stood together and blocked efforts to forge a trade agreement that was almost as unfair as the previous Uruguay round, under which the poorest countries actually became worse off.
It was imperative that such unity be destroyed.
America’s strategy of bilateral trade agreements was aimed at precisely that, but it enlisted only a few countries, representing a fraction of global trade.
The 97% formula holds open the possibility of extending that fragmentationinto the WTO itself.
The US has already had some success in pitting the poor against each other.
Preferential access for African countries, under the African Growth and Opportunity Act (AGOA) and more recent initiatives, seems to be largely a matter of trade diversion – taking trade from some poor countries and giving it to others.
For example, Bangladesh’s share in US clothing markets declined from 4.6% in 2001 to 3.9% in 2004.
During the same period, AGOA countries’ market share in the US clothing sector increased from 1.6% to 2.6%, and it is likely to increase further when AGOA countries start to take full advantage of duty-free access.
AGOA had a sunset clause, but if the duty-free access becomes permanent for less developed countries in Africa – as stipulated in Hong Kong – then poor countries in Asia will continue to lose US market share.
The WTO is supposed to prevent these trade-diversionary agreements, but so far no case has been successfully brought.
Even if America succeeds in dividing the developing countries, however, it may inspire a degree of unity elsewhere.
Both those committed to trade liberalization within a multilateral system and those committed to helping developing countries will look at America’s new strategy with abhorrence.
I recently learned something interesting: American international finance economists and American domestically oriented macroeconomists have very different – indeed, opposing – views of the likely consequences of America’s huge current-account deficit.
International finance economists see a financial crisis as likely, followed by a painful and perhaps prolonged recession in the United States.
Domestically oriented macroeconomists, by contrast, see a forthcoming fall in the value of the dollar not as a crisis, but as an opportunity to accelerate growth.
Domestically oriented macroeconomists look at the situation roughly like this: at some point in the future, foreign central banks will become less willing to continue buying massive amounts of dollar-denominated securities in order to prop up the greenback.
When they cease their large-scale dollar-purchase programs, the value of the dollar will fall – and it will fall hard.
But, according to this view, as the dollar’s value declines, US exports will become more attractive to foreigners and American employment will rise, with labor re-allocated to the newly-vibrant export sector.
It will be like what happened in Britain after it abandoned its exchange-rate peg and allowed the pound to depreciate relative to the Deutschmark , or what happened in the US in the late 1980’s, when the dollar depreciated against the pound, the Deutschmark , and – most importantly – the Japanese yen.
International finance economists see a far bleaker future.
They see the end of large-scale dollar-purchase programs by central banks leading not only to a decline in the dollar, but also to a spike in US long-term interest rates, which will curb consumption spending immediately and throttle investment spending after only a short lag.
To be sure, international finance economists also see US exports benefiting as the value of the dollar declines, but the lags in demand are such that the export boost will come a year or two after the decline in consumption and investment spending.
Eight to ten million people will have to shift employment from services and construction into exports and import-competing goods, implying that structural unemployment will rise.
Moreover, there may be a financial panic: large financial institutions with short-term liabilities and long-term assets will have a difficult time weathering a large rise in long-term dollar-denominated interest rates.
This mismatch can cause financial stress and bankruptcy just as easily as banks’ local-currency assets and dollar liabilities caused stress and bankruptcy in the Mexican and East Asian crises of the 1990’s and in the Argentinean crisis of this decade.
When international finance economists sketch this scenario, domestically oriented macroeconomists respond that it sounds like a case of incompetent monetary policy.
Why should the Federal Reserve allow long-term interest rates to spike just because other central banks have ceased their dollar-purchase programs?
Should not the Fed step in and replace them with its own purchases of long-term US Treasury bonds, thereby keeping long-term interest rates at a level conducive to full employment?
To this, international finance economists respond that the Fed does not have the power to do so.
When forced to choose between full employment and price stability, the international finance economists say that the Fed will choose price stability, because its institutional memory of the 1970’s, when inflation ran rampant, remains very strong.
Therefore, since a fall in the value of the dollar raises import prices, and thus functions as a negative shock to the supply side of the economy, the Fed will have to raise, not lower, interest rates, and sell, not buy, bonds.
Serious economists whom I respect enormously find themselves taking strong positions on opposite sides of this debate.
I’m not wise enough to say which side is right, but I certainly know which side I hope is wrong.
Has the United States transcended the laws of economics?
As the New Year begins, the US continues to race ahead of its rich-country counterparts.
The gargantuan US trade deficit?
No problem.
In 2005, it widened further, and the dollar only strengthened.
Low investment and a deteriorating primary education system?
Not to worry.
The super-flexible US economy keeps managing to produce more with less.
Nor are there any signs of America’s economic hegemony starting to fold under the weight of maintaining its unilateral military dominance.
Instead of feeling the pinch of wartime privations, like in any ordinary country, American consumers are binging as if it were Christmas all year round.
There are those who truly believe in the idea that America is exceptional.
Those true believers argue that America’s consumers can long pursue their spendthrift ways because their country’s economy is better than everyone else’s.
The US labor market is more flexible than Europe’s, enabling it to react more nimbly to the ever shifting sands of globalization.
And, unlike most countries, especially in Latin America and Asia, the US system ruthlessly prunes weak corporate leadership.
Moreover, the true believers cite America’s better-funded and hyper-competitive university system, which sucks in a disproportionate share of the world’s top students and researchers.
Many ultimately choose to immigrate to America permanently, and it is relatively easy for them to do so, thanks to a society that still welcomes outsiders with open arms (even if things have become more difficult since 2001).
On top of all this, the US military, rather than being a burden, feeds the country’s technological superiority by subsidizing basic research.
By contrast, skeptics hold that the US economy already contains the seeds of its own socio-economic decline.
They point to worsening income inequality, as images beamed worldwide from post-hurricane New Orleans illustrated all too clearly.
Poor children do not have reasonable access to health care.
Nor are the non-poor faring particularly well, as wage growth has remained virtually flat for a very long time, even as corporate profits are booming.
Indeed, this disconnect may explain why polls do not give President Bush the credit for economic management that his strong record would seem to merit.
Nor does it help Americans’ mood that they spend far more of their lives working than do citizens in Europe or, these days, even Japan.
All of these factors place deep stresses on the social fabric which, so the skeptics argue, will ultimately play out in the political arena.
Interestingly, both sides cite America’s gaping trade deficit – believe it or not, the US is soaking up two-thirds of global excess saving – to support their arguments.
The true believers view the deficits as evidence that the world recognizes how special the US is and wants to buy in.
Skeptics see an empire living on borrowed money and borrowed time.
So which is it?
In my view, those who think that America is about to collapse are likely to be disappointed.
Nevertheless, I suspect that the age of American exceptionalism is near an end, and soon per capita income in Europe and Japan will approach that of the US, rather than falling farther behind.
Though the next few years are likely to underscore some of the weaknesses that the skeptics highlight, the end will come mainly because other countries will find creative ways to mimic the most effective US institutions, albeit within their own legal, political, and social frameworks.
We would do well to recall how, at the beginning of the 1990’s, book after book was still being written urging US and European corporations to imitate Japan or face certain doom.
The last 15 years have of course revealed deep flaws in Japan’s financial system.
But another major factor contributing to Japan’s decline was that firms elsewhere began adopting Japanese methods, such as just-in-time supply chains.
Surely, imitation will someday impinge on superior US growth performance as well.
Perhaps the biggest weakness in the true believers’ argument is the trade deficit.
For the moment, America’s ability to borrow vast sums at low interest rates acts like a huge dose of steroids on the economy.
It artificially props up consumption growth and allows the government to defer hard choices between taxes and military expenditures.
At some point, the party is going to end.
The unwinding of the US economy might even begin in 2006, particularly if Japan continues to grow out of its doldrums, the US housing market softens dramatically, and Europe’s economic recovery accelerates.
Individually, these are each highly plausible scenarios, and collectively they would hit the US trade deficit like a perfect storm.
Perhaps the end will come in a different way, but it is difficult to imagine the age of US exceptionalism lasting indefinitely.
Can the end come abruptly in 2006?
This is not the most likely scenario, but it is not unthinkable.
NEW YORK – America is on a collision course with itself.
This month’s deal between President Barack Obama and the Republicans in Congress to extend the tax cuts initiated a decade ago by President George W. Bush is being hailed as the start of a new bipartisan consensus.
I believe, instead, that it is a false truce in what will become a pitched battle for the soul of American politics.
As in many countries, conflicts over public morality and national strategy come down to questions of money.
In the United States, this is truer than ever.
The US is running an annual budget deficit of around $1 trillion, which may widen further as a result of the new tax agreement.
This level of annual borrowing is far too high for comfort.
It must be cut, but how?
The problem is America’s corrupted politics and loss of civic morality.
One political party, the Republicans, stands for little except tax cuts, which they place above any other goal.
The Democrats have a bit wider set of interests, including support for health care, education, training, and infrastructure.
But, like the Republicans, the Democrats, too, are keen to shower tax cuts on their major campaign contributors, predominantly rich Americans.
The result is a dangerous paradox.
The US budget deficit is enormous and unsustainable.
The poor are squeezed by cuts in social programs and a weak job market.
One in eight Americans depends on Food Stamps to eat.
Yet, despite these circumstances, one political party wants to gut tax revenues altogether, and the other is easily dragged along, against its better instincts, out of concern for keeping its rich contributors happy.
This tax-cutting frenzy comes, incredibly, after three decades of elite fiscal rule in the US that has favored the rich and powerful.
Since Ronald Reagan became President in 1981, America’s budget system has been geared to supporting the accumulation of vast wealth at the top of the income distribution.
Amazingly, the richest 1% of American households now has a higher net worth than the bottom 90%.
The annual income of the richest 12,000 households is greater than that of the poorest 24 million households.
The Republican Party’s real game is to try to lock that income and wealth advantage into place.
They fear, rightly, that sooner or later everyone else will begin demanding that the budget deficit be closed in part by raising taxes on the rich.
After all, the rich are living better than ever, while the rest of American society is suffering.
It makes sense to tax them more.
The Republicans are out to prevent that by any means.
This month, they succeeded, at least for now.
But they want to follow up their tactical victory – which postpones the restoration of pre-Bush tax rates for a couple of years – with a longer-term victory next spring.
Their leaders in Congress are already declaring that they will slash public spending in order to begin reducing the deficit.
Ironically, there is one area in which large budget cuts are certainly warranted: the military.
But that is the one item most Republicans won’t touch.
They want to slash the budget not by ending the useless war in Afghanistan, and by eliminating unnecessary weapons systems, but by cutting education, health, and other benefits for the poor and working class.
In the end, I don’t think they will succeed.
For the moment, most Americans seem to be going along with Republican arguments that it is better to close the budget deficit through spending cuts rather than tax increases.
Yet when the actual budget proposals are made, there will be a growing backlash.
With their backs against the wall, I predict, poor and working-class Americans will begin to agitate for social justice.
This may take time.
The level of political corruption in America is staggering.
Everything now is about money to run electoral campaigns, which have become incredibly expensive.
The mid-term elections cost an estimated $4.5 billion, with most of the contributions coming from big corporations and rich contributors.
These powerful forces, many of which operate anonymously under US law, are working relentlessly to defend those at the top of the income distribution.
But make no mistake: both parties are implicated.
There is already talk that Obama will raise $1 billion or more for his re-election campaign.
That sum will not come from the poor.
The problem for the rich is that, other than military spending, there is no place to cut the budget other than in areas of core support for the poor and working class.
Is America really going to cut health benefits and retirement income?  Will it really balance the budget by slashing education spending at a time when US students already are being out-performed by their Asian counterparts?
Will America really let its public infrastructure continue to deteriorate?
The rich will try to push such an agenda, but ultimately they will fail.
Obama swept to power on the promise of change.
So far there has been none.
His administration is filled with Wall Street bankers.
His top officials leave to join the banks, as his budget director Peter Orszag recently did.
He is always ready to serve the interests of the rich and powerful, with no line in the sand, no limit to “compromise.”
If this continues, a third party will emerge, committed to cleaning up American politics and restoring a measure of decency and fairness.
This, too, will take time. The political system is deeply skewed against challenges to the two incumbent parties.
Yet the time for change will come.
The Republicans believe that they have the upper hand and can pervert the system further in favor of the rich.
I believe that they will be proved wrong.
CAMBRIDGE – With less than two months remaining before America’s presidential election, much attention is focused on the state of the American economy and the challenges that it will present to the next president.
We are in the midst of a financial crisis caused by the serious mispricing of all kinds of risks and by the collapse of the housing bubble that developed in the first half of this decade.
What started as a problem with sub-prime mortgages has now spread to houses more generally, as well as to other asset classes.
The housing problem is contributing to the financial crisis, which in turn is reducing the supply of credit needed to sustain economic activity.          
Indeed, the financial crisis has worsened in recent weeks, reflected in the US Federal Reserve’s takeover of quasi-government mortgage lenders Fannie Mae and Freddie Mac – which may cost American taxpayers hundreds of billions of dollars – as well as the bankruptcy of Lehman Brothers and the sale of Merrill Lynch.
Ultimately, these financial failures reflect the downward spiral of house prices and the increasing number of homes with negative equity, i.e., with substantial mortgage debt in excess of market values.
Negative equity is significant because mortgages in the United States are generally “no recourse” loans.
If a homeowner defaults, creditors can take the house, but they cannot take other property or income to make up any unpaid balance.
Even in those states where mortgages are not “no recourse” loans, creditors generally do not pursue the assets or income of individuals who default.
We cannot be sure about how much further house prices will fall.
Experts say another 15% decline is required just to return to the pre-bubble price path.
But there is nothing to stop the decline from continuing once it reaches that point.
The growing gap between mortgage debts and house prices will continue to increase the rate of defaults.
Many homeowners who can afford to make their mortgage payments will choose to default, move to rental housing, and wait to purchase until house prices have declined further.
As homeowners with large negative equity default, the foreclosed homes contribute to the excess supply that drives prices down further.
And the lower prices lead to more negative equity and therefore to more defaults and foreclosures.
It is not clear what will stop this self-reinforcing process.
Declining house prices are key to the financial crisis and the outlook for the economy, because mortgage-backed securities, and the derivatives based on them, are the primary assets that are weakening financial institutions.
Until house prices stabilize, these securities cannot be valued with any confidence.
And that means that the financial institutions that own them cannot have confidence in the liquidity or solvency of potential counterparties – or even in the value of their own capital.
Without this confidence, credit will not flow and economic activity will be constrained.
Moreover, because financial institutions’ assets were bought mainly with borrowed money, the shortage of credit is exacerbated by their need to deleverage.
Since raising capital is difficult and costly, they deleverage by lending less.
But the macroeconomic weakness in the US now goes beyond the decreased supply of credit.  Falling house prices reduce household wealth and therefore consumer spending.
Falling employment lowers wage and salary incomes.
The higher prices of food and energy depress real incomes further.
And declining economic activity in the rest of the world is lowering demand for US exports.
The US Federal Reserve has, in my judgment, responded appropriately by reducing the federal funds interest rate sharply and creating a variety of new credit facilities.
The low interest rate helped by making the dollar more competitive, but otherwise monetary policy appears to have lost traction because of the condition of the housing sector and the dysfunctional state of the credit markets.
The US Congress and the Bush administration enacted a $100 billion tax rebate in an attempt to stimulate consumer spending.
Those of us who supported this policy generally knew that history and economic theory implied that such one-time fiscal transfers have little effect, but we thought that this time might be different.
Our support was, in the words of Samuel Johnson, a triumph of hope over experience.
In the end, our hopes were frustrated.
The official national income accounting data for the second quarter are now available, and they show that the rebates did very little to stimulate spending.
More than 80% of the rebate dollars were saved or used to pay down debt.
Very little was added to current spending.
So that is where the US is now: in the middle of a financial crisis, with the economy sliding into recession, monetary policy already at maximum easing, and fiscal transfers impotent.
That is an unenviable situation, to say the least, for any incoming president.
CAMBRIDGE – The saving rate of American households has risen sharply since the beginning of the year, reaching 6.9% of after-tax personal income in May, the highest rate since 1992.
In today’s economy, that is equivalent to annual savings of $750 billion.
While a 6.9% saving rate is not high in comparison to that of many other countries, it is a dramatic shift from the household-saving rate of less than 1% that the United States experienced in 2005, 2006, and 2007.
Before it began rising last year, the US household saving rate had been declining for more than 20 years in response to the increasing level of household wealth.
The rising stock market and the higher value of homes induced individuals to consume more of their incomes and to save less.
As a result, most working individuals reduced the amount that they saved for their retirement, and retirees were able to increase their spending.
The net saving rate fell to near zero.
The sharp drop in household wealth over the past two years, however, put an end to that.
Dramatically lower share prices and a 35% fall in home prices reduced household wealth by $14 trillion, a loss equal to 140% of annual disposable income.
Individuals now have to save more to prepare for retirement, and retirees have less wealth to spend.
Looking ahead, the saving rate may rise even further, and will, in any case, remain high for many years.
The increase in the household saving rate reduces America’s need for foreign funds to finance its business investment and residential construction.
Taken by itself, today’s $750 billion annual rate of household saving could replace that amount in capital inflows from the rest of the world.
Since the peak annual rate of capital inflow was $803 billion (in 2006), the increased household saving has the potential to eliminate almost all of America’s dependence on foreign capital.
The annual capital inflow is equal each year to the US current-account deficit – the sum of the trade deficit plus the net interest and dividends that America’s government and businesses owe to the rest of the world.
The fall in the capital inflow would therefore bring with it a fall in the trade deficit.
Since reducing the trade deficit requires increasing exports and shrinking imports, the international value of the dollar must decline to make US products more attractive to foreign buyers and US goods and services more attractive to American consumers.
Without a fall in the dollar and the resulting rise in net exports, a higher saving rate and reduced consumer spending could push the US economy into a deep recession.
By contrast, the lower dollar makes reduced consumption consistent with full employment by shifting consumer spending from imports to domestic goods and services, and by supplementing this rise in domestic demand with increased exports.
But this direct link between higher household saving and a lower dollar will only be forged if higher household saving is not outweighed by a rise in government dis-saving, i.e., by a larger government deficit.
A large fiscal deficit increases the need for foreign funds to avoid crowding out private investment.
Put differently, the value of the dollar reflects total national saving, not just savings in the household sector.
Unfortunately, the US fiscal deficit is projected to remain high for many years.
The Congressional Budget Office projects that the US government’s budget deficit will average 5.2% of GDP over the next decade, and be 5.5% of GDP a decade from now.
If that high level of government borrowing occurs, it will absorb all of the available household savings even at the current elevated level.
That would mean that the US would continue to need substantial inflows of foreign capital to fund business investment and housing construction.
So the dollar would have to stay at its current level to continue to create the large trade deficit and resulting capital inflow.
It is, of course, possible – I would say likely – that China and other foreign lenders will not be willing to continue to provide the current volume of lending to the US.
Their reduced demand for dollars will cause the dollar to decline and the trade deficit to shrink.  That reduced trade deficit and the resulting decline in capital inflows will lead to higher real interest rates in the US.
The higher interest rate will reduce the level of business investment and residential construction until they can be financed with the smaller volume of national saving plus the reduced capital inflows.
Although the higher level of household saving will limit the rise in US interest rates, it will not change the fact that the combination of large future fiscal deficits and foreign lenders’ reduced willingness to buy US securities will lead to both a lower dollar and higher US interest rates.
The news about America's economy that dribbled out over the first half of March painted - once again - a picture that only a schizophrenic could create.
Real investment (investment adjusted for the declining prices of high-tech and information-related capital goods) continued to roar ahead.
Production and sales were consistent with the consensus forecast of real GDP growth at an annual rate of 4% or more.
Yet, despite all this, employment remained stagnant: net job creation in the United States continues to stall.
This does not mean that employment in America cannot grow.
Roughly 300,000 more Americans are employed in education and health care than a year ago - an annual rate of employment growth of 1.7%.
A quarter of a million more Americans are employed in business and professional services than a year ago - a 1.6% annual rate of employment growth.
The logic of stagnant employment is not that adding jobs to the American economy is impossible, but that demand growth is insufficient to create more jobs than are lost.
This is easy to demonstrate.
Total nominal spending in America grows at 5.5% per year.
Inflation is 1.5% per year.
And overall productivity growth is 3.5% per year.
So the equation is simple: 5.5%-1.5%-3.5% = 0.5%.
That 0.5% is all that is left for job growth, because that's all the job growth required to meet demand given the remarkably strong rate of growth of productivity.
Where America's productivity growth is coming from is clear.
A relatively small part of it is coming from simple speed-up: in an economy where the amount of time it takes for the unemployed to find new jobs is close to a post-WWII record high, demands for speeding-up the pace of work will be met with a "Yes, boss!" rather than a "Take this job and shove it!"
A bigger part of this increased productivity comes from the extraordinary technological revolutions in computers and communications that have led to dramatic increases in the usefulness - and decreases in the cost - of high-tech capital.
The boost to wealth provided by the "new economy" is exceeding even its most avid boosters' wildest dreams.
What is unexpected is that the new wealth is flowing not to the shareholders of dot-com companies, but to purchasers and users of high-tech capital and the consumers they serve.
But why does this seem so surprising?
At the end of the nineteenth century the huge amount of investment and technological progress in America's railroads appeared to benefit everyone but the stockholders and bondholders of railroad companies, as bust followed boom and ramming worthless securities down the throats of investors became Wall Street's favorite sport.
Yet another part of US productivity growth due to the fact that high-tech capital gives America's firms enormous incentives to make massive but hard to see - and even harder to measure - investments in organization and business processes that are complementary to computerization and networking.
For the US to have a rate of productivity growth of 3.5% per annum rather than the pre-1995 rate of 1.2% is amazing.
That means an annual increment to world income of $250 billion from this source alone.
That's the equivalent of adding productive power equal to a quarter of the economy of India - and adding it every year.
This persistent acceleration in American productivity growth has, however, created a massive political problem for President George W. Bush.
Demand growth at a pace that in any previous decade would have been seen as highly satisfactory is suddenly desperately insufficient, and Bush is being blamed (with some justice) for the slack labor market that has resulted.
But for everyone except Bush - and those left unemployed by the lag in demand - it is an extraordinary opportunity.
The remarkable boosts to productivity that have been within America's grasp will ultimately lead to accelerating growth of real profits and real wages, if only US policy makers resist the temptation to pursue politically expedient, but economically damaging, measures to "protect" output and employment.
As the world's leading-edge economy, America faces the hardest work in ensuring growth, for it must create - not only copy and adapt - new technologies, better forms of capital, and more productive business organizations.
If America can grow as fast as it is now, that is very good news for other, less-developed economies, especially since one powerful effect of ongoing technological revolutions in computers and communications is to make it much easier to participate in the global division of labor now centered in the US.
So the schizophrenic American economy is a sign that the world is entering an economic era of truly wonderful things - if only we properly, and patiently, grasp them.
Signs of the American economy’s perilous condition are everywhere – from yawning fiscal and current-account deficits to plummeting home prices and a feeble dollar.
But something that shows up in none of the economic indicators may be driving many of them: the deterioration of American management, which is undermining not only many of America’s great enterprises, but also its legendary spirit of enterprise.
Paradoxically, one indicator that has been improving steadily in the US – productivity – may be the clearest sign of the problem.
When it comes to productivity, managers either invest in employee training, more efficient manufacturing processes, and the like, or they take steps that appear to boost productivity in the short run but that erode it in the long run.
Productivity is a measure of output per hour worked.
So a company that fires all its workers and then ships from stock can look very productive – until it runs outs of stock.
Of course, no company can do that, but many US companies have been shedding workers and middle managers in great numbers – the figures for January 2008 were up 19% from a year earlier.
Meanwhile, those employees left behind must work that much harder, often without increased compensation.
Workers’ wages, adjusted for inflation, fell in 2007, continuing a trend throughout this decade.
That, too, is “productive” – until these overworked people quit or burn out.
A sustainable company is not a collection of “human resources.”
It is a community of human beings.
Its strength resides in its people, its culture, and the goodwill it has built up among its customers and suppliers.
So, as workers and middle managers have been departing these companies, they have taken with them not only much critical information, but often also the hearts and souls of their enterprises, with profound effects on American competitiveness.
Consider high technology, where America is supposed to excel.
According to a November 2006 report by The Task Force on the Future of American Innovation, made up of prominent universities, think tanks, industry trade associations, and corporations, the high-tech trade deficit widened in 2005, for the third consecutive year.
This is not clothing or cars, but America’s largest, and most renowned, export sector.
This deficit reflects an underlying research deficit.
Of the 25 companies granted the most US patents in 2006, only eight were American; 12 were Japanese.
Perhaps this helps to explain why, in a survey of more than 60,000 people in 29 countries conducted in 2007 by the New York-based Reputation Institute to rank the “world’s most respected companies,” the first US company on the list appeared in 15th place; the second was in 25th place.
No one can determine how much of America’s productivity gains in recent years have resulted from squeezing human capital, because such things are not measured.
But there has clearly been a great deal of reliance on this strategy, with companies shedding employees not only because they must, but often because they have not met Wall Street analysts’ financial expectations.
Managers’ increased focus on maximizing shareholder value won many adherents when the idea was introduced in the 1980’s: the impersonal discipline of financial markets would force companies to become more productive and innovative.
And, in fact, much of the US productivity increase in the 1980’s and 1990’s can likely be attributed to large-scale investment in information and communications technology.
But, as the marginal productivity gains from such investment began to fall, senior managers’ survival and compensation continued to be tied to stock-market performance.
As a result, many simply learned to manage their companies’ short-term share price at the expense of attention to their products and customers.
Moreover, because maximizing shareholder value is a poor incentive for workers and middle managers, companies’ boards have increasingly centralized power around chief executives, thereby encouraging a “heroic” form of leadership that is detached from the rest of the enterprise.
Indeed, in many cases, the CEO – frequently a Wall Street-endorsed “superstar” parachuted in to “shake things up” – nowis the company, despite having little knowledge of its products, customers, and competitors.
This shift to “heroic” leadership can be seen in ballooning CEO compensation.
According to a January 2008 report by the Hay Group, the CEO’s of the 50 largest US companies are now paid almost three times what their European counterparts receive ­– which is many hundreds of times more than their own workers.
Until recently, the US asset-price bubble ­– first in the stock market, then in real estate – masked the underlying depreciation of American enterprises.
But the bubble itself resulted from the same management pathologies as those afflicting the real economy.
After all, managing for the short run encouraged mortgage lenders to offer artificially low “teaser” interest rates to lure potential homeowners.
And then those who bought these mortgages never bothered to investigate their underlying value – a spectacular abdication of managerial responsibility.
Now that the bubble has burst, America’s current economic downturn is likely to be far worse than previous ones, because US enterprises will have to be rebuilt, slowly and carefully.
The dramatic weakening of the US dollar may help America to narrow its massive trade deficit, but we should not expect any sustained improvement without drastic changes in American management.
Fortunately, it may be possible to minimize the fallout for the rest of the world.
While American economists, politicians, and business leaders have for years sought to sell their model of management abroad, many companies elsewhere have not been buying it.
As a result, other key economies remain healthier than America’s.
Make no mistake: this problem was made in America, and that is where it will have to be solved.
The richest Congressional district in the US is the so-called "silk-stocking" district of New York City's Upper East Side, with a per-capita income of $41,151 per year.
The poorest Congressional district is a largely Hispanic-immigrant district in Los Angeles, with a per-capita income of $6,997 a year.
In 1973 the poorest fifth of America's families had incomes that averaged $13,240 a year (in today's dollars); in 2000 the average incomes of the poorest fifth were the same: $13,320.
By contrast, the richest 5% of America's families in 1973 had an average income of $149,150, and in 2000 the richest 5% had an average income of $254,840.
The increase in inequality was large enough to give a 2/3 income boost to the well-off over a time when incomes in the middle grew by only 10% and incomes at the bottom not at all.
To outsiders, the most peculiar thing about America's rising inequality is that so few Americans object.
Surely a society with a skewed income distribution is worse off than one in which incomes are more equal.
An extra $10,000 a year does little to raise the well-being of a multi-millionaire, while a deficiency of $10,000 a year makes a huge impact on how a middle-class family lives.
If you follow Nobel Prize-winner James Buchanan's utilitarian principle that you should evaluate a society's social welfare by imagining that you have an equal chance of being poor and rich, it is easy to judge that the more equal society has a better set of social and economic arrangements.
From there it is easy to make the leap to the position that - so long as redistributive taxes don't slow economic growth - when inequality rises, it is the government's duty to tax the rich and transfer money to the poor to offset the rise.
Yet there are no calls in mainstream politics to sharply increase the progressiveness of the income tax.
Indeed, even at the left end of mainstream discourse, the boldest call is for the well-off merely to contribute their "fair share" to paying for the costs of government.
One candidate for the Senate in the recent US elections, Erskine Bowles of North Carolina (a former chief of staff to President Clinton) was judged bold and foolhardy not for proposing redistributive tax increases, but simply for placing a higher priority on the federal government paying for prescription medicines than on a further cut in the highest marginal tax rate.
What happened?
Bowles lost.
Virtually no mainstream American politician seems opposed to eliminating the estate tax - a policy move that will further concentrate wealth for no countervailing supply-side gain.
As Clinton's Assistant to the President for Economic Policy Gene Sperling once wrote, staff aides who tell Congressmen that estate tax repeal "...costing tens of billions of dollars... will benefit only a few thousand families" are answered "maybe so, but I think I met every one of them at my last fundraiser."
It's not the case that the striking increase in income inequality was necessary to deliver rapid economic growth.
Most of the increase took place, after all, between 1973 and 1995 - a period during which American economic growth was slower than in any other period since the Great Depression.
It's not the case that income gains in the middle have been large enough to make mainstream voters feel generous about what is happening among their merchant princes: save for the past half-decade, income gains away from the top have been so meager that it's hard to argue that people are living much better than their parents did.
So why don't Americans feel more alarm at their country's rising income inequality?
Part of the reason that they don't is that most Americans do not recognize what is going on.
One poll found that 19% of Americans think their incomes put them in the top 1% of income distribution - and that 20% more hope to reach the top 1% someday.
Deep in the core of American ideology and culture is a constellation of beliefs and attitudes: belief that the future will be brighter than the present; that what you accomplish you make with your own hands; that individuals should rely on themselves, not the state; that people can cross oceans and mountains to make for themselves a better life; and that those who succeed do so not through luck and corruption but through preparation and industry.
These are not beliefs conducive to social democracy.
For two generations starting in 1933 America did look a lot like a west European-style social democracy.
The shock of the Great Depression and the response of Roosevelt's New Deal probably accounts for the shockingly "un-American" attitude toward redistribution of that era.
But somebody ten years old when Franklin Roosevelt was elected is now eighty.
Memories of the Great Depression are dying out.
So what now seems likely is that the older and more enduring - call it the Gilded Age - pattern of American ideology, culture, and political economy is reasserting itself.
Inequality, it seems, is as American as apple pie.
When I wrote about the “end of history” almost twenty years ago, one thing that I did not anticipate was the degree to which American behavior and misjudgments would make anti-Americanism one of the chief fault-lines of global politics.
And yet, particularly since the terrorist attacks of September 11, 2001, that is precisely what has happened, owing to four key mistakes made by the Bush administration.
First, the doctrine of “preemption,” which was devised in response to the 2001 attacks, was inappropriately broadened to include Iraq and other so-called “rogue states” that threatened to develop weapons of mass destruction.
To be sure, preemption is fully justified vis-à-vis stateless terrorists wielding such weapons.
But it cannot be the core of a general non-proliferation policy, whereby the United States intervenes militarily everywhere to prevent the development of nuclear weapons.
The cost of executing such a policy simply would be too high (several hundred billion dollars and tens of thousands of casualties in Iraq and still counting).
This is why the Bush administration has shied away from military confrontations with North Korea and Iran, despite its veneration of Israel’s air strike on Iraq’s Osirak reactor in 1981, which set back Saddam Hussein’s nuclear program by several years.
After all, the very success of that attack meant that such limited intervention could never be repeated, because would-be proliferators learned to bury, hide, or duplicate their nascent weapons programs.
The second important miscalculation concerned the likely global reaction to America’s exercise of its hegemonic power.
Many people within the Bush administration believed that even without approval by the UN Security Council or NATO, American power would be legitimized by its successful use.
This had been the pattern for many US initiatives during the Cold War, and in the Balkans during the 1990’s; back then, it was known as “leadership” rather than “unilateralism.”
But, by the time of the Iraq war, conditions had changed: the US had grown so powerful relative to the rest of the world that the lack of reciprocity became an intense source of irritation even to America’s closest allies.
The structural anti-Americanism arising from the global distribution of power was evident well before the Iraq war, in the opposition to American-led globalization during the Clinton years.
But it was exacerbated by the Bush administration’s “in-your-face disregard for a variety of international institutions as soon it came into office – a pattern that continued through the onset of the Iraq war.
America’s third mistake was to overestimate how effective conventional military power would be in dealing with the weak states and networked transnational organizations that characterize international politics, at least in the broader Middle East.
It is worth pondering why a country with more military power than any other in human history, and that spends as much on its military as virtually the rest of the world combined, cannot bring security to a small country of 24 million people after more than three years of occupation.
At least part of the problem is that it is dealing with complex social forces that are not organized into centralized hierarchies that can enforce rules, and thus be deterred, coerced, or otherwise manipulated through conventional power.
Israel made a similar mistake in thinking that it could use its enormous margin of conventional military power to destroy Hezbollah in last summer’s Lebanon War.
Both Israel and the US are nostalgic for a twentieth-century world of nation-states, which is understandable, since that is the world to which the kind of conventional power they possess is best suited.
But nostalgia has led both states to misinterpret the challenges they now face, whether by linking al-Qaeda to Saddam Hussein’s Iraq, or Hezbollah to Iran and Syria.
This linkage does exist in the case of Hezbollah, but the networked actors have their own social roots and are not simply pawns used by regional powers.
This is why the exercise of conventional power has become frustrating.
Finally, the Bush administration’s use of power has lacked not only a compelling strategy or doctrine, but also simple competence.
In Iraq alone, the administration misestimated the threat of WMD, failed to plan adequately for the occupation, and then proved unable to adjust quickly when things went wrong.
To this day, it has dropped the ball on very straightforward operational issues in Iraq, such as funding democracy promotion efforts.
Incompetence in implementation has strategic consequences.
Many of the voices that called for, and then bungled, military intervention in Iraq are now calling for war with Iran.
Why should the rest of the world think that conflict with a larger and more resolute enemy would be handled any more capably?
But the fundamental problem remains the lopsided distribution of power in the international system.
Any country in the same position as the US, even a democracy, would be tempted to exercise its hegemonic power with less and less restraint.
America’s founding fathers were motivated by a similar belief that unchecked power, even when democratically legitimated, could be dangerous, which is why they created a constitutional system of internally separated powers to limit the executive.
Such a system does not exist on a global scale today, which may explain how America got into such trouble.
A smoother international distribution of power, even in a global system that is less than fully democratic, would pose fewer temptations to abandon the prudent exercise of power.
MELBOURNE – If the broad post-World War II prosperity that has endured for six decades comes to an end, both the United States and Europe will be responsible.
With rare exceptions, politics has become a discredited profession throughout the West.
Tomorrow is always treated as more important than next week, and next week prevails over next year, with no one seeking to secure the long-term future.
Now the West is paying the price.
President Barack Obama’s instincts may be an exception here, but he is fighting powerful hidebound forces in the United States, as well as a demagogic populism, in the form of the Tea Party, that is far worse – and that might defeat him in 2012, seriously damaging America in the process.
America’s friends around the world watched with dismay the recent brawl in over raising the federal government’s debt ceiling, and the US Congress’s inability to come to anything like a balanced and forward-looking compromise.
On the contrary, the outcome represents a significant victory for the Tea Party’s minions, whose purpose seems to be to reduce government obligations and expenditures to a bare minimum (some object even to having a central bank), and to maintain President George W. Bush’s outrageous tax breaks for the wealthy.
America’s current fiscal problems are rooted in a long period of unfunded spending.
Bush’s wars in Afghanistan and Iraq, and the manner in which he conducted the “global war on terror” made matters much worse, contributing to a totally unsustainable situation.
Indeed, Obama inherited an almost impossible legacy.
In the weeks since the debt ceiling agreement, it has become increasingly clear that good government might be impossible in the US.
The coming months of campaigning for the US presidency will be spent in petty brawling over what should be cut.
The example of recent weeks gives us no cause for optimism that US legislators will rise above partisan politics and ask themselves what is best for America.
In these circumstances, it is not surprising that financial markets have returned to extreme volatility.
The expenditure cuts mandated by the outcome of the debt-ceiling debate will reduce economic activity, thereby undermining growth and making debt reduction even more difficult.
Providing further fiscal stimulus to boost economic growth would carry its own risks, owing to the debt ceiling and another, more ominous factor: America is already overly indebted, and there are signs that major holders of US government securities are finally tired of being repaid in depreciated currency.
Most importantly, China’s call for the introduction of a new reserve currency stems from its frustration with the failure of major governments – whether in the US or Europe – to govern their economic affairs with realism and good sense.
China recognizes that America is in great difficulty (indeed, it recognizes this more clearly than the US itself), and that, given the poisonous political atmosphere prevailing in Washington, there will be no easy return to good government, economic stability, and strong growth.
America’s leadership in world affairs began to weaken with the unilateralism of Bush, and today’s economic problems are reinforcing this tendency.
To reverse America’s decline, Obama needs bipartisan support for his (quite mainstream) policies, but so far the US Congress has shown no stomach for a principled approach to its legislative duties.
If Germany’s half-hearted efforts to stabilize Europe somehow turn out to be successful, America’s position will be further eroded, and central banks around the world will begin to regard the euro once again as a reliable alternative to the dollar as a reserve currency.
The alternative, as China has suggested, would be to develop a new reserve currency.
These realities represent a power shift of a kind that we have not experienced in our lifetimes.
China’s economic power over the US is now substantial, and will limit not only America’s influence in the financial markets, but also its capacity to use military power.
If this forces America back towards what the international-relations scholar Joseph Nye calls “soft power and multilateral diplomacy,” it may well be a good thing.
But such approaches are anathema to the US Republican Party, and to its Tea Party faction in particular, and they might unnerve the many Asians who are nervous at China’s growing military might.
The counter-argument – that any sell-off or failure by China to continue to buy US government securities would hurt China as much as America – is not valid.
As each year passes, China’s markets expand worldwide, and its domestic market comes to represent a greater percentage of its own GDP.
As a result, China will not need a strong dollar in the long term.
Americans need to get their economic house in order before China loses its incentive to support the dollar.
On several occasions in the post-WWII period, the US has learned with great pain that there are limits to the effective use of military power.
American objectives could not be achieved in Vietnam.
The outcome in Iraq will not be determined until the last American troops have been withdrawn.
In Afghanistan, where withdrawal dates have already been set, it is difficult to believe that a cohesive unified state can be established.
As the efficacy of military power is reduced, so the importance of economic power grows.
Recognition of these central realities – and bipartisanship in addressing them – is critical for America’s future, and that of the West.
I want to deviate from my usual economic theme this month and focus instead on the system by which the press – mostly the American press – covers government nowadays.
But perhaps this is not too great a deviation, for the behavior of the press affects not only politics, but economics as well.
Consider an editorial written in March by the Washington Post’s editorial director, Fred Hiatt, in which he makes a very small and limited apology for the newspaper’s coverage and evaluation of the Bush administration. According to Hiatt, “We raised such issues” as whether the Bush administration had properly thought its proposed adventure in Iraq through, “but with insufficient force.”
In other words, Hiatt finds fault with himself and his organization for saying the right thing, but not loudly enough.
Next, consider a comment by the former editor of the New York Times, Max Frankel, about how the Washington ecology of media leaks is healthy, because “most reporters do not just lazily regurgitate...leaks.” Instead, “they use them as wedges to pry out other secrets” and so oversee the government.
The system may be “sloppy and breed confusion,” but “tolerating abusive leaks by government [that misinform] is the price that society has to pay for the benefit of receiving essential leaks about government.”
So, where Hiatt sees a press corps that was a little too cowardly about overseeing the Bush administration, Frankel sees a press corps where a sloppy and confusing process is nevertheless doing a reasonable job.
I see a very different picture.
It was the summer of 2000 when I began asking Republicans I know – generally people who might be natural candidates for various sub-cabinet policy positions in a Republican administration – how worried they were that the Republican presidential candidate, George W. Bush, was clearly not up to the job.
They were not worried, they told me, that Bush was inadequately briefed and strangely incurious for a man who sought the most powerful office in the world.
One of President Clinton’s problems, they said, was that the ceremonial portions of the job bored him – and thus he got himself into big trouble.
Look at how Bush had operated as president of the Texas Rangers baseball club, they said.
Bush let the managers manage the team and the financial guys run the business.
He spent his time making sure the political coalition to support the Texas Rangers in the style to which it wanted to be accustomed remained stable.
Bush knows his strengths and weaknesses, they told me.
He will focus on being America’s Queen Elizabeth II, and will let people like Colin Powell and Paul O’Neill be America’s Tony Blair and Gordon Brown.
By the summer of 2001, it had become clear that something had gone very wrong.
By that point, Bush had rejected O’Neill’s and Christine Todd Whitman’s advice on environmental policy, just as he had rejected Alan Greenspan’s and O’Neill’s advice on fiscal policy, Powell’s and Condoleezza Rice’s advice on the importance of pushing forward on negotiations between Israel and Palestine, and – as we learned later – George Tenet’s and Richard Clarke’s advice about the importance of counterterrorism.
A strange picture of Bush emerged from conversations with sub-cabinet administration appointees, their friends, and their friends of friends.
He was not just under-briefed, but also lazy: he insisted on remaining under-briefed.
He was not just incurious, but also arrogant: he insisted on making uninformed decisions, and hence made decisions that were essentially random.
And he was stubborn: once he had made a decision – even, or rather especially, if it was glaringly wrong and stupid – he would never revisit it.
So, by the summer of 2001, a pattern was set that would lead British observer Daniel Davies to ask if there was a Bush administration policy on anything of even moderate importance that had not been completely bollixed up.
But if you relied on either the Washington Post or the New York Times, you would have had a very hard time seeing it.
Today, it is an accepted fact that the kindest thing you can say about the Bush administration is that it is completely incompetent, which is the line now taken by hard-line Bush supporters like the National Review and the commentator Robert Novak.
Why didn’t the American press corps cover the Bush administration properly for its first five years?
I really do not know.
I do know that the world cannot afford to rely again on America’s press for its information: fool me once, shame on you; fool me twice, shame on me.
So I appeal to all of you working for newspapers, radio, and television stations outside the United States: it is to you that we – including those of us in America – must look to discover what our own government is doing.
With all the talk of “green shoots” of economic recovery, America’s banks are pushing back on efforts to regulate them.
While politicians talk about their commitment to regulatory reform to prevent a recurrence of the crisis, this is one area where the devil really is in the details – and the banks will muster what muscle they have left to ensure that they have ample room to continue as they have in the past.
The old system worked well for the bankers (if not for their shareholders), so why should they embrace change?
Indeed, the efforts to rescue them devoted so little thought to the kind of post-crisis financial system we want that we will end up with a banking system that is less competitive, with the large banks that were too big too fail even larger.
It has long been recognized that those America’s banks that are too big to fail are also too big to be managed. That is one reason that the performance of several of them has been so dismal.
Because government provides deposit insurance, it plays a large role in restructuring (unlike other sectors).&nbsp; Normally, when a bank fails, the government engineers a financial restructuring; if it has to put in money, it, of course, gains a stake in the future.
Officials know that if they wait too long, zombie or near zombie banks –&nbsp;with little or no net worth, but treated as if they were viable institutions – are likely to “gamble on resurrection.”
If they take big bets and win, they walk away with the proceeds; if they fail, the government picks up the tab.
This is not just theory; it is a lesson we learned, at great expense, during the Savings &amp; Loan crisis of the 1980’s.
When the ATM machine says, “insufficient funds,” the government doesn’t want this to mean that the bank, rather than your account, is out of money, so it intervenes before the till is empty.
In a financial restructuring, shareholders typically get wiped out, and bondholders become the new shareholders.
Sometimes, the government must provide additional funds; sometimes it looks for a new investor to take over the failed bank.
The Obama administration has, however, introduced a new concept: too big to be financially restructured.
The administration argues that all hell would break loose if we tried to play by the usual rules with these big banks.
Markets would panic.
So, not only can’t we touch the bondholders, we can’t even touch the shareholders – even if most of the shares’ existing value merely reflects a bet on a government bailout.
I think this judgment is wrong.
I think the Obama administration has succumbed to political pressure and scare-mongering by the big banks.
As a result, the administration has confused bailing out the bankers and their shareholders with bailing out the banks.
Restructuring gives banks a chance for a new start: new potential investors (whether in equity or debt instruments) will have more confidence, other banks will be more willing to lend to them, and they will be more willing to lend to others.
The bondholders will gain from an orderly restructuring, and if the value of the assets is truly greater than the market (and outside analysts) believe, they will eventually reap the gains.
But what is clear is that the Obama strategy’s current and future costs are very high – and so far, it has not achieved its limited objective of restarting lending.
The taxpayer has had to pony up billions, and has provided billions more in guarantees – bills that are likely to come due in the future.
Rewriting the rules of the market economy – in a way that has benefited those that have caused so much pain to the entire global economy – is worse than financially costly.
Most Americans view it as grossly unjust, especially after they saw the banks divert the billions intended to enable them to revive lending to payments of outsized bonuses and dividends.
Tearing up the social contract is something that should not be done lightly.
But this new form of ersatz capitalism, in which losses are socialized and profits privatized, is doomed to failure.
Incentives are distorted.
There is no market discipline.
The too-big-to-be-restructured banks know that they can gamble with impunity – and, with the Federal Reserve making funds available at near-zero interest rates, there are ample funds to do so.
Some have called this new economic regime “socialism with American characteristics.”
But socialism is concerned about ordinary individuals.
By contrast, the United States has provided little help for the millions of Americans who are losing their homes.
Workers who lose their jobs receive only 39 weeks of limited unemployment benefits, and are then left on their own.
And, when they lose their jobs, most lose their health insurance, too.
America has expanded its corporate safety net in unprecedented ways, from commercial banks to investment banks, then to insurance, and now to automobiles, with no end in sight.
In truth, this is not socialism, but an extension of long standing corporate welfarism.
The rich and powerful turn to the government to help them whenever they can, while needy individuals get little social protection.
We need to break up the too-big-to-fail banks; there is no evidence that these behemoths deliver societal benefits that are commensurate with the costs they have imposed on others.
And, if we don’t break them up, then we have to severely limit what they do.
They can’t be allowed to do what they did in the past – gamble at others’ expenses.
This raises another problem with America’s too-big-to-fail, too-big-to-be-restructured banks: they are too politically powerful.
Their lobbying efforts worked well, first to deregulate, and then to have taxpayers pay for the cleanup.
Their hope is that it will work once again to keep them free to do as they please, regardless of the risks for taxpayers and the economy.
We cannot afford to let that happen.
NEW YORK – August 8, 2008, may someday be remembered as the first day of the post-American era.
Or it could be remembered as another “Sputnik moment,” when, as with the Soviet foray into outer space in 1957, the American people realized that the country had lost its footing and decided it was time for the United States to get its act together.
There was no mistaking the power and symbolism of the opening ceremonies for the Beijing Olympic Games on August 8.
That multimedia spectacular did far more than trace China’s 5,000-year history; it was a statement that China is a major civilization that demands and deserves its rightful place in the global hierarchy.
There was also no mistaking the symbolism of seeing President Bush, waving cheerfully from his spot in the bleachers while Chinese President Hu Jintao sat behind what looked more like a throne.
It is hard to imagine that China’s government, which obsesses over every minute issue of diplomatic protocol, had not orchestrated this stark image of America’s decline relative to the country to which it owes $1.4 trillion.
It would be hard to imagine Franklin Roosevelt or Ronald Reagan accepting a similar relative position.
At the very same time that Bush was waving from the stands, Russia was invading Georgia, America’s closest partner in the Caucasus.
Russia’s message to other West-leaning countries in the former Soviet world was clear: America cannot protect you.
Frighteningly, the Russians were likely correct.
While the Iraq quagmire has made it difficult for America to project force around the world, America’s growing debt, conflicts with friends and enemies alike, absence of any perceivable strategy for changing times, and its political system’s seeming inability to take action to address these challenges have combined to turn America into a struggling giant.
Today, from Iran to Darfur to Zimbabwe to Georgia, the world is witnessing the effects of a budding post-American world, and the picture does not look pretty.
As much as we all value the rise of new powers like China and India, it remains to be seen whether these countries will become as benevolent a power as America, however flawed, has been over the past half-century.
Neo-colonialism is returning to Africa, the global project of human rights is in retreat, and the world trade system is becoming far less open.
Brutal dictators go unpunished because their interests are protected by large powers with stakes in their natural resources.
Reversing this trend is not only in America’s interest, but also in the world’s interest.
To do so, Americans must identify and address the great challenges the United States faces, starting from the ground up.
Fixing America’s campaign finance structure, which leads to massive misallocations of government funds, resuscitating America’s wildly uneven and often moribund education system, building an immigration system that actively recruits the most talented people from around the world via a fast track to US citizenship, and developing a national energy policy that moves the US far more quickly toward energy independence would all be important steps in this direction.
Working to rebuild the traditional bipartisan foreign-policy consensus would also make the US a far more predictable partner to friends and allies around the world.
And America must be a respectful partner in order to encourage rising powers like India and China to play more constructive roles in international affairs.
The world is not ready for the post-American era, and countries like China and India must play a far greater role in strengthening the existing institutions of world peace and, where appropriate, building new ones that can promote a positive agenda of security, dignity, rights, and prosperity across the globe.
The world community is not there yet, and until it is, the world needs a new kind of American leader – a leader able to inspire Americans to fix their problems at home and work with partners across the globe in promoting a common agenda as bold and progressive as the order built from the ashes of World War II 60 years ago.
The Beijing Olympics could be remembered as a new “Sputnik moment” for the US, inspiring the country to meaningfully face the music of a changing world.
But America can make it so only by recognizing the great challenges it faces and taking bold steps towards addressing them, at home and with allies abroad.
Since its victory in the Cold War, America’s global hegemony has rested on three pillars: economic power, military might, and a vast capacity to export its popular culture.
The recent emergence of additional powers – the European Union, China, India, and a Russia driven to recover its lost status – has eroded America’s capacity to shape events unilaterally.
Even so, America remains by far the world’s most powerful country; its decline has more to do with its incompetent use of power than with the emergence of competitors.
It is American leaders’ “suicidal statecraft,” to use Arnold Toynbee’s pithy phrase for what he considered the ultimate cause of imperial collapse, that is to blame for America’s plight.
Consider the Middle East.
Nothing reveals the decline of the United States in the region better than the contrast between America’s sober use of power in the first Gulf War in 1991 and the hubris and deceit of today’s Iraq war.
In 1991, America forged the most formidable international coalition since World War II, and led it in a fully legitimate war aimed at restoring regional balance after Saddam Hussein’s invasion of Kuwait.
In 2003, America went to war without its trans-Atlantic allies after manipulating false assertions.
In doing so, the US embarked on a preposterous grand strategy that aimed no less at simultaneously dismantling Iraq’s tyrannical regime, restructuring the entire Middle East, destroying al-Qaeda, and helping democracy to take root throughout the Arab world.
The result has been utter failure: military defeat and a severe degradation of America’s moral standing.
Rather than undermining radical Islam, the US has legitimized it, in Iraq and beyond.
Indeed, what will now shape the future of the region is not democracy, but the violent divide between Shiites and Sunnis that the Iraq war precipitated.
It is this Muslim civil war that is allowing al-Qaeda to gain a larger pool of recruits.
With Iraq probably becoming the first Arab country to be ruled by Shiites, and hence integrated into an expanding Shiite Iranian empire, America’s Sunni allies in the region now view the US as unreliable.
Indeed, the US is seen as practically complicit in inciting a monumental reversal of Islam’s fortunes, the Shia revival.
Nor is the gospel of democracy especially dear to America’s Arab allies, for the call to democratize has only emboldened the Islamists to challenge the incumbent elites for power.
Admittedly, violent Islamic fundamentalism has deeper roots in the fading promise of Arab nationalism.
But America’s misbegotten democratic message has ended up alienating both its conservative regional allies, as it gave a new lease on life to political Islam, which can use the ballot box as a route to power, and the Islamists, whose electoral gains are then rejected by the US.
America’s biggest strategic blunder in the Middle East arguably concerns the emergence of Iranian power.
By destroying Iraq as a counterbalancing regional force, the US dealt a major blow to its traditional Gulf allies, for whom Iraq served as a barrier against Iran’s ambitions.
America offered Iran on a silver platter strategic assets that Khomeini’s revolution failed to acquire either in eight years of war against Saddam or in its abortive attempts to export the Islamic revolution throughout the region.
Likewise, Iran’s nuclear program gained momentum thanks to its sense of impunity following the colossal failure in Iraq of America’s concept of “preventive war.”
The calamitous US military experience in Iraq has left it strategically diminished.
Iraq has now become God’s playground, and America can hope to achieve a modicum of stability there only with the help of other regional powers.
Nevertheless, the US will remain the most influential external actor in the Middle East, for its failure is one of leadership, not of actual power.
Humbled by military defeat, America can recover its regional relevance only by avoiding the sin of hubris, and learning to lead without attempting to dominate.
This requires engaging revolutionary forces like Iran and Syria; respecting, rather than ostracizing, those Islamist movements that have opted out from jihadism in favor of political participation; and leading an international alliance for an Arab-Israeli peace based on the Arab League initiative.
Indeed, the paradox of America’s pernicious policies in Iraq is that they have created favorable conditions for an Arab-Israeli peace, as the emergence of Iran and the threat of a fundamentalist tsunami have focused Arab minds on the urgency of a settlement with Israel.
The Palestinian issue is not the source of all the Middle East’s ills, but its resolution would dramatically improve America’s standing among Arabs.
More importantly, it would deny Iran the ability to link popular Islamic and Arab causes with its own hegemonic ambitions.
BERKELEY – This year began with a series of reports providing tantalizing evidence that economic recovery in the United States is strengthening.
The pace of job creation has increased, indicators for manufacturing and services have improved, and consumption spending has been stronger than anticipated.
But it is too early to celebrate.
Output growth in the US remains anemic, and the economy continues to face three significant deficits: a jobs deficit, an investment deficit, and a long-run fiscal deficit, none of which is likely to be addressed in an election year.
Although output is now higher than it was in the fourth quarter of 2007, it remains far below what could be produced if labor and capacity were fully utilized.
That gap – between actual and potential output – is estimated at more than 7% of GDP (more than $1 trillion).
The output gap reflects a deficit of more than 12 million jobs – the number of jobs needed to return to the economy’s peak 2007 employment level and absorb the 125,000 people who enter the labor force each month.
Even if the economy grows at 2.5% in 2012, as most forecasts anticipate, the jobs deficit will remain – and will not be closed until 2024.
America’s jobs deficit is primarily the result of inadequate aggregate demand.
Consumption, which accounts for about 70% of total spending, is constrained by high unemployment, weak wage gains, and a steep decline in home values and consumer wealth.
The uptick in consumption in the last months of 2011 was financed by a decline in the household saving rate and a large increase in consumer credit.
Neither of these trends is healthy or sustainable.
With an unemployment rate of 8.5%, a labor-force participation rate of only 64%, and stagnant real wages, labor income has fallen to an historic low of 44% of national income.
And labor income is the most important component of household earnings, the major driver of consumption spending.
Even before the Great Recession, American workers and households were in trouble.
The rate of job growth between 2000 and 2007 slowed to only half its level in the three preceding decades.
Productivity growth was strong, but far outpaced wage growth, and workers’ real hourly compensation declined, on average, even for those with a university education.
Indeed, the 2002-2007 period was the only recovery on record during which the median family’s real income declined.
Moreover, job opportunities continued to polarize, with employment growing in high-wage professional, technical, and managerial occupations, as well as in low-wage food-service, personal-care, and protective-service occupations.
By contrast, employment in middle-skill, white-collar, and blue-collar occupations fell, particularly in manufacturing.
Hard-pressed American households slashed their savings rates, borrowed against their home equity, and increased their debt to maintain consumption, contributing to the housing and credit bubbles that burst in 2008, requiring painful deleveraging ever since.
Three forces have driven the US labor market’s adverse structural changes:
·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Skill-biased technological change, which has automated routine work while boosting demand for highly educated workers with at least a college degree.
·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Global competition and the integration of labor markets through trade and outsourcing, which have eliminated jobs and depressed wages.
·&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; America’s declining competitiveness as an attractive place to locate production and employment.
Technological change and globalization have created similar labor-market challenges in other developed countries.
But US policy choices are responsible for the erosion of America’s competitiveness.
In particular, the US is underinvesting in three major areas that help countries to create and retain high-wage jobs: skills and training, infrastructure, and research and development.
Spending in these areas accounts for less than 10% of US government spending, and this share has been declining over time.
The federal government can currently borrow at record-low interest rates, and there are many projects in education, infrastructure, and research that would earn a higher return, create jobs now, and bolster US competitiveness in attracting high-wage jobs.
President Barack Obama has offered numerous proposals to invest in the foundations of national competitiveness, but Congressional Republicans have rebuffed them, claiming that the US faces an impending fiscal crisis.
In fact, the federal deficit as a share of GDP will shrink significantly over the next several years, even without further deficit-reduction measures, before rising to unsustainable levels by 2030.
The US does indeed face a long-run fiscal deficit, largely the result of rising health-care costs and an aging population.
But the current fiscal deficit mainly reflects weak tax revenues, owing to slow growth and high unemployment, and temporary stimulus measures that are fading away at a time when aggregate demand remains weak and additional fiscal stimulus is warranted.
At the very least, to keep the economy on course for 2.5% growth this year, the payroll tax cut and unemployment benefits proposed by Obama should be extended through the end of the year.
These measures would provide insurance to the fragile recovery and add nothing to the long-run fiscal gap.
So, how should the US economy’s jobs deficit, investment deficit, and long-run fiscal deficit be addressed?
Policymakers should pair fiscal measures to ameliorate the jobs and investment deficits now with a multi-year plan to reduce the long-run fiscal deficit gradually.
This long-run plan should increase spending on education, infrastructure, and research, while curbing future growth in health-care spending through the cost-containment mechanisms contained in Obama’s health-reform legislation.
Approving a long-run deficit-reduction plan now but deferring its starting date until the economy is near full employment would prevent premature fiscal contraction from tipping the economy back into recession.
Indeed, enactment of such a package could bolster output and employment growth by easing investor concerns about future deficits and strengthening consumer and business confidence.
Painful choices about how to close the long-run fiscal gap should be decided now and implemented promptly once the economy has recovered.
But, for the next few years, the priorities of fiscal policy should be jobs, investment, and growth.
NEW YORK – The heart of any government is found in its budget.
Politicians can make endless promises, but if the budget doesn’t add up, politics is little more than mere words.
The United States is now caught in such a bind.
In his recent State of the Union address, President Barack Obama painted a convincing picture of modern, twenty-first-century government.
His Republican Party opponents complained that Obama’s proposals would bust the budget.
But the truth is that both parties are hiding from the reality: without more taxes, a modern, competitive US economy is not possible.
Obama rightly emphasized that competitiveness in the world today depends on an educated workforce and modern infrastructure.
That is true for any country, but it is especially relevant for rich countries.
The US and Europe are in direct competition with Brazil, China, India, and other emerging economies, where wage levels are sometimes one-quarter those in high-income countries (if not even lower).
America and Europe will keep their high living standards only by basing their competitiveness on advanced skills, cutting-edge technologies, and modern infrastructure.
That is why Obama called for an increase in US public investment in three areas: education, science and technology, and infrastructure (including broadband Internet, fast rail, and clean energy).
He spelled out a vision of future growth in which public and private investment would be complementary, mutually supportive pillars.
Obama emphasized these themes for good reason.
Unemployment in the US now stands at nearly 10% of the labor force, in part because more new jobs are being created in the emerging economies, and many of the jobs now being created in the US pay less than in the past, owing to greater global competition.
Unless the US steps up its investment in education, science, technology, and infrastructure, these adverse trends will continue.
But Obama’s message lost touch with reality when he turned his attention to the budget deficit.
Acknowledging that recent fiscal policies had put the US on an unsustainable trajectory of rising public debt, Obama said that moving towards budget balance was now essential for fiscal stability.
So he called for a five-year freeze on what the US government calls “discretionary” civilian spending.
The problem is that more than half of such spending is on education, science and technology, and infrastructure – the areas that Obama had just argued should be strengthened.
After telling Americans how important government investment is for modern growth, he promised to freeze that spending for the next five years!
Politicians often change their message from one speech to the next, but rarely contradict it so glaringly in the same speech.
That contradiction highlights the sad and self-defeating nature of US budget policies over the past 25 years, and most likely in the years to come.
On the one hand, the US government must invest more to promote economic competitiveness.
On the other hand, US taxes are chronically too low to support the level of government investment that is needed.
America’s fiscal reality was made painfully clear two days after Obama’s speech, in a new study from the Congressional Budget Office, which revealed that the budget deficit this year will reach nearly $1.5 trillion – a sum almost unimaginable even for an economy the size of the US.
At nearly 10% of GDP, the deficit is resulting in a mountain of debt that threatens America’s future.
The CBO study also made clear that December’s tax-cut agreement between Obama and the Republican opposition willfully and deliberately increased the budget deficit sharply.
Various tax cuts initiated by George W. Bush were set to expire at the end of 2010.
Obama and the Republicans agreed to continue those tax cuts for at least two years (they will now probably continue beyond that), thereby lowering tax revenue by $350 billion this year and again in 2012.
Tax cuts for the richest Americans were part of the package.
The truth of US politics today is simple.
The key policy for the leaders of both political parties is tax cuts, especially for the rich.
Both political parties, and the White House, would rather cut taxes than spend more on education, science and technology, and infrastructure.
And the explanation is straightforward: the richest households fund political campaigns.
Both parties therefore cater to their wishes.
As a result, America’s total tax revenues as a share of national income are among the lowest of all high-income countries, roughly 30%, compared to around 40% in Europe.  But 30% of GDP is not enough to cover the needs of health, education, science and technology, social security, infrastructure, and other vital government responsibilities.
One budget area can and should be cut: military spending.
But even if America’s wildly excessive military budget is cut sharply (and politicians in both parties are resisting that), there will still be a need for new taxes.
The economic and social consequences of a generation of tax cutting are clear.
America is losing its international competitiveness, neglecting its poor – one in five American children is trapped in poverty – and leaving a mountain of debt to its young.
For all of the Obama administration’s lofty rhetoric, his fiscal-policy proposals make no serious attempt to address these problems.
To do so would require calling for higher taxes, and that – as George H. W. Bush learned in 1992 – is no way to get re-elected.

NEW YORK – Some say there are two issues in the coming American elections: the Iraq war and the economy.
On days when the war seems to be going better than expected, and the economy worse, the economy eclipses the war; but neither is faring well.
In some sense, there is only one issue, and that is the war, which has exacerbated America’s economic problems.
And when the world’s largest economy is sick – and it is now very sick – the entire world suffers.
It used to be thought that wars were good for the economy.
After all, World War II is widely thought to have helped lift the global economy out of the Great Depression.
But, at least since Keynes, we know how to stimulate the economy more effectively, and in ways that increase long-term productivity and enhance living standards.
This war, in particular, has not been good for the economy, for three reasons.
First, it has contributed to rising oil prices.
When the United States went to war, oil cost less than $25 a barrel, and futures markets expected it to remain there for a decade.
Futures traders knew about the growth of China and other emerging markets; but they expected supply – mainly from low-cost Middle East providers – to increase in tandem with demand.
The war changed that equation.
Higher oil prices mean that Americans (and Europeans and Japanese) are paying hundreds of millions of dollars to Middle East oil dictators and oil exporters elsewhere in the world rather than spending it at home. 
Moreover, money spent on the Iraq war does not stimulate the economy today as much as money spent at home on roads, hospitals, or schools, and it doesn’t contribute as much to long-term growth.
Economists talk about “bang for the buck” – how much economic stimulus is provided by each dollar of spending.
It’s hard to imagine less bang than from bucks spent on a Nepalese contractor working in Iraq.
With so many dollars going abroad, the American economy should have been in a much weaker shape than it appeared.
But, much as the Bush administration tried to hide the true costs of the war by incomplete and misleading accounting, the economy’s flaws were covered up by a flood of liquidity from the Federal Reserve and by lax financial regulation.
So much money was pumped into the economy and so lax were regulators that one leading American bank advertised its loans with the slogan “qualified at birth” – a clear indication that there were, in effect, no credit standards.
In a sense, the strategy worked: a housing bubble fed a consumption boom, as savings rates plummeted to zero.  The economic weaknesses were simply being postponed to some future date; the Bush administration hoped that the day of reckoning would come after November 2008.  Instead, things began to unravel in August 2007.

Now it has responded, with a stimulus package that is too little, too late, and badly designed.
To see the inadequacy of that package, compare it with the more than $1.5 trillion that was borrowed in home equity loans in recent years, most of it spent on consumption.
That game – based on a belief in ever-spiraling home prices – is over. 
With home prices falling (and set to continue to fall), and with banks uncertain of their financial position, lenders will not lend and households will not borrow.
So, while the additional liquidity injected into the financial system by the Fed may have prevented a meltdown, it won’t stimulate much consumption or investment.
Instead, much of it will find its way abroad.
China, for example, is worried that the Fed’s stimulus will increase its domestic inflation. 
There is a third reason that this war is economically bad for America.
Not only has America already spent a great deal on this war – $12 billion a month, and counting – but much of the bill remains to be paid, such as compensation and health care for the 40% of veterans who are returning with disabilities, many of which are very serious.
Moreover, this war has been funded differently from any other war in America’s history –perhaps in any country’s recent history.
Normally, countries ask for shared sacrifice, as they ask their young men and women to risk their lives.
Taxes are raised.
There is a discussion of how much of the burden to pass on to future generations.  In this war, there was no such discussion.
When America went to war, there was a deficit.
Yet remarkably, Bush asked for, and got, a reckless tax cut for the rich.
That means that every dollar of war spending has in effect been borrowed.
For the first time since the Revolutionary War, two centuries ago, America has had to turn to foreigners for financing, because US households have been saving nothing .
The numbers are hard to believe.
The national debt has increased by 50% in eight years, with almost $1 trillion of this increase due to the war – an amount likely to more than double within ten years. 
Who would have believed that one administration could do so much damage so quickly?
America, and the world, will be paying to repair it for decades to come.
One of the casualties of the war against terrorism--or, rather, of the way the United States is conducting the war--is the US influence in promoting human rights worldwide.
For the international human rights movement, this is a severe setback.
For more than a quarter of a century, ever since advancing human rights internationally became an explicit and avowed goal of US foreign policy under President Jimmy Carter, American influence played a leading role in mitigating abuses.
The consequences were most profound in what were the countries of the Soviet empire, but they extended to other regions as well.
Even where the US supported regimes that committed grave violations of rights--or served as an apologist for them because other national interests took precedence--it was often possible for the human rights movement to embarrass Washington by making it the surrogate villain for its clients' abuses.
In the 1980's, this approach focused attention on abuses in conflict-ridden Central America and in Saddam Hussein's Iraq, which the Reagan Administration favored in its struggle with America's enemy, Ayatollah Khomeini's Iran.
It thus sometimes achieved indirectly what could not be done directly: the leveraging of American influence to promote human rights.
But America's capacity to promote human rights in other countries has never been weaker than now.
One reason is the tremendous increase in anti-Americanism since the terrorist attacks of September 11, 2001.
This is largely due to a widespread perception of American arrogance.
Despite (or because of) its insistence that all who are not with America are against it, the Bush administration alienated many who previously counted themselves either as friends of the US or did not take sides.
At the same time, rising anti-Americanism preceded the US response to the terrorist attacks.
The Bush team was outspoken in its hostility to a range of international agreements, from the Kyoto Treaty to reduce global warming to the establishment of the International Criminal Court.
Whatever goodwill towards the US prevailed after September 11 was quickly squandered.
The Bush administration proclaimed a national security policy that insists that America provides the only sustainable model for national success, and asserted its right to engage in unilateral, preemptive military strikes.
It treated the UN Security Council with disdain in its rush to war in Iraq, invoking justifications that have not stood up to scrutiny.
Since then, it has continued to insist that its arguments for invading Iraq are beyond criticism, while making a mess of the postwar administration by refusing to share authority.
The other major reason that America is losing its effectiveness as a promoter of human rights is a widespread perception of hypocrisy.
Even before the terrorist attacks on New York and Washington, America's image as a rights proponent had been tarnished, particularly in Europe, by its continued practice of capital punishment and, to a lesser degree, by its high incarceration rate--approximately seven times the average in the European Union's fifteen member countries.
Since September 2001, the cause for concern has grown dramatically.
Much international attention has focused on the USA Patriot Act's sanctioning of grave violations of civil liberties, and on the subsequent treatment of thousands of immigrants--particularly south Asian Muslims--who have faced secret detention and deportation.
Above all, the rest of the world has looked on with alarm as the US holds more than 600 men at Guantanamo Bay in Cuba without access to family or counsel, and without prospect of an impartial hearing or trial.
In some instances, reports of rights violations in the US are exaggerated.
But this is an inevitable consequence of the Bush administration's own haughty manner, with leading spokespersons, such as Attorney General John Ashcroft, proclaiming their own righteousness in leading the effort to abrogate rights. Ashcroft is much less known internationally than Secretary of Defense Donald Rumsfeld, but he is an even match in arousing dislike for the US among those who do know him.
Unfortunately, there is no ready substitute for the US as a force for advancing human rights internationally.
The UN has been useful as a forum for adopting standards, but its machinery for seeking compliance with those standards is weak and has been badly compromised over the years by its failure to address grotesque abuses. The choice of Libya to chair the UN Human Rights Commission adds insult to injury.
Some European governments have evolved strong human rights polices but, for a variety of reasons, they have been unable, individually or collectively, to exert the influence of the US.
Fortunately, while this is likely to remain true for the foreseeable future, the international human rights movement is not completely without resources.
Its own prestige is high: groups such as Amnesty International and Human Rights Watch are respected voices, to whom many governments feel obliged to pay attention.
There is also the promise of new institutions.
In cases of extreme rights abuses, the chance that an international criminal tribunal will ultimately sit in judgment of those principally responsible is growing, thereby becoming a deterrent to would-be tyrants elsewhere.
America should take note.
President Bush has pushed stopping the spread of nuclear weapons to the top of the international agenda. Ironic, then, that America's nuclear weapons development program may promote the very proliferation it seeks to prevent, as US Senator Dianne Feinstein explains.
With the world's focus on the debate over Iraq, the war on terror, and the Bush administration's doctrine of unilateral preemption, the American government's new emphasis on the utility of nuclear weapons has not received the attention it deserves.
This is unfortunate, as this exploration of new uses for nuclear weapons represents a revolutionary shift in US national security policy.
Today, the world faces unprecedented challenges at the nexus of terror and weapons of mass destruction.
With both North Korea and Iran openly pursuing nuclear ambitions and a potential nuclear arms race in South Asia, it is critical that America provide leadership, in both word and in deed, to reduce the risks and the role of nuclear weapons throughout the world.
Instead, the Bush administration seems intent on doing just the opposite.
Many of the actions of the American administration, and much of the US government's rhetoric, may actually be increasing the threat from nuclear weapons rather than making the world safer.
The Bush administration's January 2002 Nuclear Posture Review signaled a major change in US nuclear policy by advancing a new triad that integrates nuclear weapons with conventional strike options and blurring the line between the use of conventional and nuclear weapons.
It also specified scenarios in which the US might use nuclear weapons first, even against non-nuclear states, and called for a new generation of US nuclear warheads, including low yield or so-called "mini-nukes."
The US has never had a no-first-strike policy, but it has likewise never had a policy such as that embodied in the Nuclear Policy Review.
Today, under the terms of the ideas set out in that review, the US contemplates the first use of nuclear weapons, and seeks to integrate tactical battlefield nuclear weapons alongside conventional munitions.
Despite efforts to downplay the significance of the Nuclear Posture Review since its publication, it remains, in my view, extremely provocative and dangerous.
Earlier this year, at a hearing of the US Senate's Committee on Energy and Natural Resources, I asked Energy Secretary Spencer Abraham, whose Department oversees America's research and development of nuclear weapons, whether the Bush administration wanted to develop new low-yield nuclear weapons.
Secretary Abraham said it did not; that his department was only studying adaptations of existing weapons.
Yet, there should be no doubt that the Bush administration is beginning the research and development of new nuclear weapons.
Just this year, a 10-year-old ban on the research and development of nuclear weapons below five kilotons--the bomb at Hiroshima was 15 kilotons--was eliminated.
Pushed by the Bush administration, Congress authorized $21 million for the study and development of new nuclear weapons, including a 100-kiloton bunker buster, as well as tactical battlefield nuclear weapons.
Moreover, the time to test readiness of the Nevada test site has been moved up from three years to two years, and funding has been provided to produce additional fissile material for new nuclear weapons.
I argued and voted against these new nuclear initiatives in the US Senate earlier this year.
Clearly, the nuclear door is being reopened.
For, by taking the steps called for in the Nuclear Posture Review--specifically, developing "new capabilities...to defeat emerging threats," including "extensive research and timely fielding ofnew systems to address these challenges"--the Bush administration is lowering the threshold for the possible use of nuclear weapons by the US or other countries.
This approach is not in America's national interest, nor is it consistent with American traditions and values.
A first-use of nuclear weapons by the US should be unthinkable, and responding to a non-nuclear attack with nuclear weapons violates a central tenet of just war and US military tradition.
Indeed, nuclear options should not be considered as an extension of conventional options.
Why?
Because this inevitably lowers the threshold for use.
So, if the US develops nuclear weapons that blur the distinction between conventional and nuclear forces, the message this sends to the rest of the world must be considered.
I believe it is critical that the US set a very high international standard for nuclear restraint.
If America does not, it may very likely encourage others to develop their own standards and their own nuclear arsenals.
That seems to be happening.
Both India and Pakistan are nuclear powers, and the history of bloody warfare between them presents a major and ongoing security threat to South Asia.
If either country adhered to the thinking embodied in the Bush administration's new nuclear policy, there would be little reason for each not to seek to integrate nuclear weapons even more deeply into their own contingency plans--and possibly use them.
At a time when the US brands as "evil" certain countries based, in part, on their pursuit of nuclear arms and weapons of mass destruction, it must be especially careful in how it considers its own options and contingencies regarding nuclear weapons.
If the US is not careful, our own new nuclear posture could provoke the very nuclear-proliferation activities we are seeking to prevent.
In commemorating the 230th anniversary of America’s independence last July, President George W. Bush noted that the patriots of the Revolutionary War believed that all men are created equal, and with inalienable rights.
Because of these ideals, he proclaimed, the United States “remains a beacon of hope for all who dream of liberty and a shining example to the world of what a free people can achieve.”
But, at the same time, his administration was holding approximately 400 prisoners at the US Naval Base at Guantánamo Bay in Cuba.
Some of them have now been there for more than five years.
None of them has ever been put on trial.
Last month, a highly reputable source confirmed that the Guantánamo prisoners are suffering from more than indefinite detention.
The US Federal Bureau of Investigation released documents showing that an FBI agent witnessed “on several occasions” detainees who were “chained hand and foot in [a] fetal position to [the] floor,” without a chair, or food or water.
In these conditions, “most urinated or defecated on [them]selves.”
They were left there for 18 or 24 hours, or more.
On one of these occasions, the agent reported, “the air conditioning was turned up so low that the barefooted detainee was shaking with cold.”
On another occasion the room was unventilated, the temperature over 100 degrees Fahrenheit, and the detainee was almost unconscious on the floor with a pile of hair next to him – “he had apparently been pulling it out throughout the night.”
Another FBI agent was laughingly told by a civilian contractor, “[Y]ou have to see this.” He was then taken to an interrogation room where he saw a longhaired man with a full beard who was gagged with duct tape that “covered much of his head.”
When the agent asked how the tape would be removed, he was not given any answer.
Other FBI agents reported seeing prisoners left in shackles for 12 hours or more, again in cold conditions, being subjected to strobe lights and loud rap music for many hours, or being forced to wrap themselves in an Israeli flag.
The FBI report noted these incidents with the comment: “doesn’t seem excessive given Department of Defense policy.”
Several of the detainees told the FBI agents that they had no connection with terrorism and had no idea why they had been abducted and taken to Guantánamo.
Many prisoners were not captured fighting in Afghanistan.
Some were picked up in Bosnia, Indonesia, Thailand, Mauritania, and Pakistan.
The Bush administration says that the detainees are “enemy combatants” in the global war against terror – a war that is being waged around the world, and that could last for decades.
The commander of the Guantánamo task force, Rear Admiral Harry B. Harris, Jr., recently defended harsh treatment of his prisoners, claiming, “They’re all terrorists; they’re all enemy combatants.”
But the CIA has made mistakes before.
For example, Murat Kurnaz, a German-born Turkish man, was held in Guantánamo for four years before being released last August.
The case of Khaled el-Masri, a German citizen of Lebanese descent, appears to be another of these errors.
Seized by the CIA in Macedonia, he was taken to Afghanistan and interrogated for five months before being released without charge.
A German court has now issued arrest warrants for those involved in his abduction.
If there are any human rights at all, the right not to be locked up indefinitely without trial is surely one of them.
The US Constitution’s Bill of Rights puts considerable emphasis on that right, specifying in the Sixth Amendment that in all criminal prosecutions, “the accused shall enjoy the right to a speedy and public trial, by an impartial jury” and “to be informed of the nature and cause of the accusation; to be confronted with the witnesses against him.”
None of the Guantánamo inmates has been granted these rights.
So it has never been proved, by the standards laid down in the US Constitution that any of them really are terrorists.
But the Sixth Amendment does not apply to the Guantánamo prisoners, because they are not US citizens and are in a facility that, technically, is not part of US territory, although it is under the full control of the US government.
Whatever US courts say about it, abducting people all over the world, locking them up for years without establishing that they are guilty of anything, and subjecting them to harsh and abusive treatment is a flagrant violation of international law.
By any standard of justice, it is also just plain wrong.
Tom Paine, the great American revolutionary and author ofThe Rights of Man,wrote: “He that would make his own liberty secure must guard even his enemy from oppression; for if he violates this duty he establishes a precedent that will reach himself.” If America would only follow that advice, it might really be a beacon of hope and a shining example.
But as long as it continues to hold and abuse prisoners without giving them a fair trial, America’s professed ideals will continue to sound to the rest of the world like the deepest hypocrisy.
After years of debate in the United States, and opposition to action by the Bush administration, America is finally waking up to the reality of global climate change.
Leadership is still not coming from the president, but the private sector has begun to act.
Leaders of major US companies have decided that global man-made climate change is real, must be controlled, and that business must play a constructive part in the process.
Thus, even as the Bush administration and some scientific contrarians pretend that there is no problem, US corporate leaders are seeking practical solutions.
The basic situation has been clear for years.
Global use of fossil fuels is contributing to a sharp rise in atmospheric carbon dioxide, which is causing the Earth to warm.
Rainfall patterns are changing.
Deserts and dry regions are becoming drier.
Extreme weather events such as hurricanes and typhoons are likely to increase.
Flooding in Europe is likely to intensify, a process that may already have begun.
Sea levels are rising, and could climb sharply if global warming leads to a destabilization of the Greenland and Antarctic ice sheets.
In short, the scientific evidence is strong and growing that the planet is at grave risk, with many ill effects already being felt and more to come.
The proper responses are also increasingly understood.
We must move to a sustainable energy system, one that does not mean a huge increase of carbon in the atmosphere.
This will require a shift to renewable energy sources such as solar power, and perhaps nuclear power, as well as new technologies to capture carbon dioxide at power plants and then to dispose of the carbon dioxide in safe underground deposits.
Society will have to pay a price for these investments in new energy technologies, but the benefits will be vastly greater than the price.
The US is the world’s major emitter of carbon dioxide from energy use, but it has done the least among all major economies to confront the global challenge.
The Bush administration claims that more research is needed before any action is taken.
Yet real action in the US is starting, thanks to leadership in other parts of the world, and thanks to the enlightened understanding of some major American businesses.
First, the rest of the world ratified the Kyoto Protocol to control emissions of carbon dioxide.
At the beginning of this year, Europe introduced a new Greenhouse Gas Emissions Trading Scheme that uses market-based incentives to control carbon emissions.
American companies operating in Europe are part of that system for their European-based emissions, so that US companies are being pulled into climate control even if their own government avoids the issue.
Second, major US investors, such as pension fund managers, are realizing that US companies that fail to control their emissions may be vulnerable to financial losses in the future.
They know that, sooner or later, the US will have to join the rest of the world in controlling climate change.
At that point, power companies that use antiquated technologies that emit massive amounts of greenhouse gases may face serious financial losses.
So investors are telling companies to report their carbon emissions today in order to assess future liabilities.
Similarly, many company bosses know that pretending that climate problems do not exist is bad for shareholders, because reality will one day strike.
They know that investing today in clean technologies can give them a long-term competitive advantage.
As a result, many companies are taking steps now to limit their emissions to avoid future financial liabilities and a lack of investor confidence.
The most dramatic breakthrough of this kind occurred when General Electric, one of the world’s most important, innovative, and respected companies, announced that it was going “green” with a major new corporate focus on environmentally sound technologies and a commitment to limit its own greenhouse gas emissions.
With GE’s leadership, which it termed “ecomagination” (combining ecology with imagination), many US businesses are sure to follow.
It is too early to count on success in engaging the US on climate change.
The Bush administration continues to delay and to avoid sound science.
Yet it is reasonably clear that a tipping point has been reached.
Reality is catching up with the US, as it already has elsewhere in the world.
As US citizens and businesses continue to suffer the results of climate change – heat waves, droughts, hurricanes, and floods – more and more Americans, including an increasing number of business leaders, will press America’s political leaders for real action.
The solutions will not be easy, and the effort must last over many decades in all parts of the world.
But the effort needs to start now.
As with Europe’s new carbon trading, all producers and consumers around the globe will need to face market incentives to adopt technologies and consumption patterns that slow (and eventually stop) the increase of greenhouse gases in the atmosphere.
We will all need to pay a “market price” when we contribute to global climate change, so that we give true economic incentives to sustainable energy systems and new public investments – for example, mass transit – that reduce greenhouse gas emissions and thereby head off future climatic disasters.
What comes after Iraq?
If President George W. Bush’s current troop “surge” fails to produce an outcome that can be called “victory,” what lessons will the United States draw for its future foreign policy?
Will it turn inward, as it did after its defeat in Vietnam three decades ago?
Will it turn from promoting democracy to a narrow realist view of its interests?
Even while discussion in Washington is fixated on Iraq, a number of thoughtful foreign observers are asking these longer-term questions.
Analysts and pundits have often been mistaken about America’s position in the world.
For example, two decades ago, the conventional wisdom was that the US was in decline.
A decade later, with the Cold War’s end, the new conventional wisdom was that the world was a unipolar American hegemony.
Some neo-conservative pundits drew the conclusion that the US was so powerful that it could decide what it thought was right, and others would have to follow.
Charles Krauthammer celebrated this view as “the new unilateralism,” and it heavily influenced the Bush administration even before the attacks on September 11, 2001.
But the new unilateralism was based on a profound misunderstanding of the nature of power in world politics.
Power is the ability to get the outcomes one wants.
Whether the possession of resources will produce such outcomes depends upon the context.
For example, a large, modern tank army is a powerful resource if a war is fought in a desert, but not if it is fought in a swamp – as America discovered in Vietnam.
In the past, it was assumed that military power dominated most issues, but in today’s world, the contexts of power differ greatly.
I have likened the distribution of power in politics today as analogous to a three-dimensional chess game.
On the top board – military relations among states – the world is, indeed, unipolar, and likely to remain that way for decades.
But on the middle board of economic relations, the world is already multipolar, and the US cannot obtain the outcomes it wants without the cooperation of Europe, Japan, China, and others.
And, on the bottom board of transnational issues outside the control of governments – including everything from climate change to pandemics to transnational terrorism – power is chaotically distributed, and it makes no sense at all to claim American hegemony.
Yet it is on this bottom board that we find most of the greatest challenges we face today.
The only way to grapple with these problems is through cooperation with others, and that requires the “soft” power of attraction as well as the hard power of coercion.
There is no simple military solution that will produce the outcomes we want.
The new unilateralists who dominated Bush’s first administration made the mistake of thinking that the unipolar distribution of power in the military context was sufficient to guide foreign policy.
They were like a young boy with a hammer who thinks that every problem resembles a nail.
The danger of their approach is now obvious.
Whoever plays a three-dimensional game by focusing on only one board is bound to lose in the long run.
Fortunately, the pendulum has begun to swing back toward cooperation.
In Bush’s second term, some of the most extreme unilateralists have departed from the government, and the president has approached difficult problems like North Korea or Iran with a more multilateral approach than during his first term.
Likewise, for all the complaints about the United Nations, the US and others turned to UN peacekeepers to sort out the mess after the Lebanon War last summer.
The Iraq War, in particular, increased public awareness of the mistakes in Bush’s first term, but other issues are changing as well.
Americans now view cooperative action on global climate change more favorably.
Similarly, the threat of pandemics means that Americans may come to recognize the importance of a stronger World Health Organization, just as the problem of nuclear proliferation is increasing awareness of the importance of the International Atomic Energy Agency.
The nature of these problems means that the US does not have the luxury of turning inward no matter what the outcome in Iraq.
These are not problems you can leave overseas.
They follow you home.
It also is unlikely that American foreign policy will return to a narrow realism and drop all emphasis on democracy and human rights.
While the Iraq War discredited the idea of coercive democratization, both Republicans and Democrats have a strong strand of idealism in their foreign policy orientations.
The problem for whoever is elected president in 2008 will be to find appropriate realistic means to advance democratic values and adjust official rhetoric accordingly.
When rhetoric greatly outstrips reality, others view it as hypocrisy.
Americans will need to find ways to assert their narrative of democracy, freedom, and rights in a manner that respects diversity and the views of others.
What Iraq has taught is the importance of developing civil society and the rule of law before trying to hold broad-based elections.
Democracy is more than voting, for it requires large investments in education, institutions, and promotion of non-governmental organizations.
It must be rooted in the indigenous society and bear its characteristics, not be imposed from abroad.
It is highly unlikely that the US will react after Iraq as it did after Vietnam.
The paradox of American power is that the world’s only military superpower cannot protect its citizens by acting alone.
NEW YORK – Few Americans cast their ballot in the recent mid-term elections on the basis of foreign policy.
While it may be difficult for people around the world to comprehend this, given the global reach of the United States, it is an undeniable fact.
Most Americans are, after all, preoccupied with the US economy’s sluggish growth and persistent high unemployment.
The world’s challenges seem far removed from their day-to-day lives.
The Cold War ended a generation ago; the terror attacks of September 11, 2001, are nearly a decade in the past.
Most Americans do not feel the sacrifices associated with the large troop presence and ongoing conflicts in Afghanistan and Iraq.
But the fact that foreign policy did not materially affect the November elections does not mean that the results will not affect US foreign policy.
They will, but in ways that are inconsistent and even surprising.
One relationship sure to be influenced by Republican gains will be that between the US and Russia.
Quick or easy Senate approval of the New START arms-control treaty is highly unlikely, given stated concerns about verification and the protection of US missile-defense programs; instead, we can expect delays and, possibly, attempts to amend what the two governments already agreed upon.
Congress may also prove less willing to remove hurdles to Russia’s admission to the World Trade Organization, given what is widely judged to be its leaders’ anti-democratic behavior.
China, too, will feel the results of the new balance in Congress.
Pressure was already growing to introduce trade sanctions in response to China’s refusal to allow its currency to rise to a natural level against the dollar.
Such pressure will likely grow, given concerns over Chinese behavior both at home and abroad.
Moreover, Congress will resist rolling back any of the long-standing economic sanctions against Cuba.
President Barack Obama has the authority to take some small steps on his own to normalize ties, but substantial change to US policy requires Congress to act – and Congress wants to see fundamental change in Cuba before it does so.
There will be other consequences stemming from the election.
What little chance there was of the US backing any global plan to limit or tax carbon emissions has disappeared.
Improvement in US performance on climate change will have to come from innovation and increased energy efficiency.
One can anticipate the Republicans, now in control of the House of Representatives, exploiting their ability to convene hearings to question and review foreign policy.
Depending on how this power is used (or abused), it can be beneficial (exercising needed oversight and increasing the transparency of policy and policy-making) or destructive (if, for example, hearings degenerate into politically motivated attacks on administration officials and policies).
In many other areas, continuity can be expected to trump change.
This comes as little surprise, as America’s Constitution and political system delegate most of the initiative on foreign policy and defense to the president.
Yes, Congress must declare war, approve spending, agree to most senior appointments, and (in the case of the Senate) ratify treaties, but the president has enormous latitude when it comes to carrying out diplomacy and using military force in situations other than war, which tend to be most situations.
One area of probable continuity is the Middle East, where Obama will continue to try to broker a deal between Israelis and Palestinians and press Iran not to develop nuclear weapons.
(Republicans, however will argue for putting less pressure on Israel to compromise and more pressure on Iran.)  But he can expect considerable backing from Republicans if he wants to maintain a sizeable US military presence in Afghanistan beyond this July, or a modest military presence in Iraq beyond the end of 2011.
Questions abound when it comes to foreign economic policy, however.
Three completed trade agreements (with South Korea, Panama, and Colombia) have been languishing for years, mostly because of deep opposition to free trade from labor unions and the Democratic Party.
Republicans have historically been more supportive of such bilateral free-trade agreements.
But will the new generation of Republicans continue this tradition?
There is a fair chance that one or more of these bilateral accords will be approved (in part because the Obama administration seems finally to have recognized that trade can generate good jobs), but it is far less certain that the president will gain the authority needed to negotiate a new global trade deal.
An even bigger question mark hovers over what might be the greatest national security concern of all: the federal budget deficit.
Failure to address the deficit (and the mounting debt) will create pressures to reduce what the US spends on foreign aid, intelligence, and defense – although Republicans are more likely than Democrats to protect such spending (except for foreign aid).
Mounting debt also leaves the US vulnerable to the decisions of those who lend it money – or to the vagaries of the market.
A dollar crisis could weaken the foundations of American power.
But averting such a crisis requires that the White House and Congress, Democrats and Republicans, agree on a plan for moving the US budget toward balance.
Alas, the election makes such agreement more distant than ever.
NEW YORK – The eccentric Bengali intellectual Nirad C. Chaudhuri once explained the end of the British Raj in India as a case of “funk,” or loss of nerve.
The British had stopped believing in their own empire.
They simply lost the will, in Rudyard Kipling’s famous words, to fight “the savage wars of peace.”
In fact, Kipling’s poem, “The White Man’s Burden,” which exhorted the white race to spread its values to the “new-caught sullen peoples, half devil and half child,” was not about the British Empire at all, but about the United States.
Subtitled “The United States and the Philippine Islands,” it was published in 1899, just as the US was waging a “savage war of peace” of its own.
Chaudhuri had a point.
It is difficult to sustain an empire without the will to use force when necessary.
Much political rhetoric, and a spate of new books, would have us believe that the US is now in a dangerous state of funk.
For example, Republican presidential candidate Mitt Romney likes to castigate President Barack Obama for “apologizing for America’s international power,” for daring to suggest that the US is not “the greatest country on earth,” and for being “pessimistic.”
By contrast, Romney promises to “restore” America’s greatness and international power, which he proposes to do by boosting American military force.
Romney’s Kipling is the neo-conservative intellectual Robert Kagan, whose new book, The World America Made, argues against “the myth of American decline.”
Yes, he admits, China is growing in strength, but US dominance is still overwhelming; American military might can still “make right” against any challenger.
The only real danger to US power is “declinism”: the loss of self-belief, the temptation to “escape from the moral and material burdens that have weighed on [Americans] since World War II.”
In a word, funk.
Like Chaudhuri, Kagan is an engaging writer.
His arguments sound reasonable.
And his assessment of US firepower is no doubt correct.
True, he has little time for domestic problems like antiquated infrastructure, failing public schools, an appalling health care system, and grotesque disparities in income and wealth.
But he is surely right to observe that no other power is threatening to usurp America’s role as the world’s military policeman.
Less certain, however, is the premise that the world order would collapse without “American leadership.”
France’s King Louis XV allegedly declared on his deathbed: “Après moi, le déluge” (After me, the flood). This is the conceit of all great powers.
Even as the British were dismantling their empire after World War II, the French and Dutch still believed that parting with their Asian possessions would result in chaos.
And it is still common to hear autocratic leaders who inherited parts of the Western empires claim that democracy is all well and good, but the people are not yet ready for it.
Those who monopolize power cannot imagine a world released from their grip as anything but a catastrophe.
In Europe after World War II, Pax Americana, guaranteed by US military power, was designed “to keep the Russians out and Germany down.”
In Asia, it was meant to contain communism, while allowing allies, from Japan to Indonesia, to build up economic strength.
Spreading democracy was not the main concern; stopping communism – in Asia, Europe, Africa, the Middle East, and the Americas – was.
In this respect, it succeeded, though at great human cost.
But, now that the specter of global communist domination has joined other fears – real and imagined – in the dustbin of history, it is surely time for countries to start handling their own affairs.
Japan, in alliance with other Asian democracies, should be able to counterbalance China’s growing power.
Similarly, Europeans are rich enough to manage their own security.
But neither Japan nor the European Union seems ready to pull its own weight, owing in part to decades of dependency on US security.
As long as Uncle Sam continues to police the world, his children won’t grow up.
In any case, as we have seen in Iraq and Afghanistan, “savage wars of peace” are not always the most effective way to conduct foreign policy.
Old-fashioned military dominance is no longer adequate to promote American interests.
The Chinese are steadily gaining influence in Africa, not with bombers, but with money.
Meanwhile, propping up secular dictators in the Middle East with US arms has helped to create Islamist extremism, which cannot be defeated by simplysending more drones.
The notion promoted by Romney and his boosters that only US military power can preserve world order is deeply reactionary.
It is a form of Cold War nostalgia – a dream of returning to a time when much of the globe was recovering from a ruinous world war and living in fear of communism.
Obama’s recognition of America’s limitations is not a sign of cowardly pessimism, but of realistic wisdom.
His relative discretion in the Middle East has allowed people there to act for themselves.
We do not yet know what the outcome there will be, but “the greatest country on earth” cannot impose a solution.
Nor should it.
Recently, the United States achieved the dubious honor of boasting the largest prison and jail population on earth.
It reached this zenith by surpassing cash-strapped Russia - long its only rival as a mass imprisonment society - after Russia released thousands of inmates so as to save money.
A few years earlier, as America rushed to lock up ever more of its population for ever-pettier offenses, the absolute size of its incarcerated population surpassed that of China - despite China's population being more than four times that of America.
According to research conducted by the British Home Office, America now incarcerates over one fifth of the world's total prisoners.
There is something bitterly ironic in this.
For America really is a land of liberty, a place where lives, often scarred by injustice elsewhere, can be remade.
How tragic, therefore, that over the past twenty years, the country's political leaders have so often decided to deal with many of the most noxious side-effects of poverty - from chronic drug use and the establishment of street drug markets, to hustling, to gang membership and the spraying of graffiti on public buildings - through a vast over-reliance on incarceration.
How doubly tragic that this has occurred in tandem with a political assault on the Great Society anti-poverty programs put in place during the 1960s; that the investments in infrastructure, public education, public healthcare and job training which might curtail crime more effectively are, instead, being replaced by massive public expenditures on building new prisons to incarcerate hundreds of thousands of low-level offenders.
With such vicious cycles of crime, punishment and dis-investment in poor communities it is no surprise that the prison population has expanded to such an extent.
The numbers buttressing this sprawling prison system are extraordinary.
Approximately two million Americans are now serving either prison or jail time, over one million of them for non-violent offenses (a preponderance of these either for drug use or low-level drug sales).
Per hundred thousand residents, the US has an incarceration rate over five times that of England, six times that of Canada, and seven times that of Germany.
Somewhere in the region of 10% of African American men in their twenties live behind bars.
In some states, where a single felony conviction is enough to bar the offender from ever being able to vote again, over one quarter of African American males are disenfranchised. High levels of disenfranchisement in Florida likely played a critical role in the much-disputed electoral victory of President Bush.
Since 1980, a virtual ``prison industrial complex'' has arisen, with phenomenal rates of new-prison construction abetted by lucrative construction and prison-guard union lobbies.
Several states, including California, now spend more on prisons than they do on higher education.
Despite dramatically falling crime rates over the last ten years (which most criminologists attribute more to demography - there have simply been fewer young men of late - than incarceration), prison populations have continued to soar.
Much of that increase has more to do with public perceptions about supposed crime waves and ham-handed public and political responses to occasional headline-capturing murders, than any actual underlying crime rate.
As the actual number of truly heinous crimes has in fact fallen, increasingly it is small-time hoodlums, drug users, and mentally ill people who have been drawing long spells behind bars.
America today has five times as many prisoners as it did in 1980.
One of the most dismaying developments is the spread of so-called ``three-strikes-and-you're out'' laws.
California's version, passed by citizen referendum in 1993 and ratcheted into place by state legislators in 1994, provides for the life imprisonment of any criminal with two previous serious convictions who is found guilty of any third felony.
By the end of last year there were about 7,000 people serving life sentences in California under this law.
Many thousands of them are serving life for small-time ``Third Strikes'': minor drug crimes, car theft, petty fraud, burglary, and drunk driving (even graffiti spraying, to the tune of $400 damage, which has now been reclassified as a felony).
One such man is fifty-eight year old heroin addict Billy Ochoa, who is serving a staggering 326 years in a supermax (super maximum security) prison for $2,100 of welfare fraud.
Because he had been convicted of several burglaries over the previous decades, when Ochoa was caught making fraudulent applications for food stamps and emergency housing vouchers in Los Angeles, he was tried under the Three Strikes law and given sentences on thirteen separate counts to be served in one of the toughest, most secure prisons in America.
Ochoa's sentence, apart from its extravagant cruelty, may ultimately cost taxpayers as much as a million dollars.
In many high security American prisons, inmates are routinely kept in virtual isolation, fed in their cells, allowed out for only half an hour of exercise a day, sometimes denied a TV, a radio, or even decorations for their concrete walls - conditions which have been documented to drive many of them into states of serious psychosis.
How can things have come to this America?
Now is the time - with the world watching America fight to defend its values - for the worst excesses of its criminal justice system to be addressed.
It is a tragedy that a great democracy should have so ugly and vast a prison system corroding both its reputation and its polity.
OXFORD – When one state is preponderant in power resources, observers often refer to the situation as hegemonic.
Today, many pundits argue that other countries’ rising power and the loss of American influence in a revolutionary Middle East point to the decline of “American hegemony.”
But the term is confusing.
For one thing, possession of power resources does not always imply that one can get the outcomes one prefers.
Even the recent death of Osama bin Laden at the hands of United States special forces does not indicate anything about American power one way or the other.
To see why, consider the situation after World War II.
The US accounted for more than one-third of global product and had an overwhelming preponderance in nuclear weapons.
Many considered it a global hegemon.
Nonetheless, the US was unable to prevent the “loss” of China, “roll back” communism in Eastern Europe, prevent stalemate in the Korean War, defeat Vietnam’s National Liberation Front, or dislodge the Castro regime in Cuba.
Even in the era of alleged American hegemony, studies show that only one-fifth of America’s efforts to compel change in other countries through military threats were successful, while economic sanctions worked in only half of all cases.
Yet many believe that America’s current preponderance in power resources is hegemonic, and that it will decline, like that of Britain before it.
Some Americans react emotionally to that prospect, though it would be ahistorical to believe that the US will have a preponderant share of power resources forever.
But the term “decline” conflates two different dimensions of power: absolute decline, in the sense of decay or loss of ability to use one’s resources effectively, and relative decline, in which the other states’ power resources become greater or are used more effectively.
For example, in the seventeenth century, the Netherlands flourished domestically but declined in relative power as other states grew in strength.
Conversely, the Western Roman Empire did not succumb to another state, but instead to internal decay and swarms of barbarians.
Rome was an agrarian society with low economic productivity and a high level of internecine strife.
While the US has problems, it hardly fits the description of absolute decline in ancient Rome, and the analogy to British decline, however popular, is similarly misleading.
Britain had an empire on which the sun never set, ruled more than a quarter of humankind, and enjoyed naval supremacy.
But there are major differences in the relative power resources of imperial Britain and contemporary America.
By World War I, Britain ranked only fourth among the great powers in terms of military personnel, fourth in GDP, and third in military spending.
The costs of defense averaged 2.5-3.4% of GDP, and the empire was ruled in large part with local troops.
In 1914, Britain’s net export of capital gave it an important financial kitty to draw upon (though some historians consider that it would have been better to have invested the money in domestic industry).
Of the 8.6 million British forces in WWI, nearly one-third were provided by the overseas empire.
With the rise of nationalism, however, it became increasingly difficult for London to declare war on behalf of the empire, the defense of which became a heavier burden.
By contrast, America has had a continental-scale economy immune from nationalist disintegration since 1865.
For all the loose talk of American empire, the US is less tethered and has more degrees of freedom than Britain ever had.
Indeed, America’s geopolitical position differs profoundly from that of imperial Britain: while Britain faced rising neighbors in Germany and Russia, America benefits from two oceans and weaker neighbors.
Despite these differences, Americans are prone to cycles of belief in decline.
The Founding Fathers worried about comparisons to the decline of the Roman republic.
Moreover, cultural pessimism is very American, extending back to the country’s Puritan roots.
As Charles Dickens observed a century and a half ago, “if its individual citizens, to a man, are to be believed, [America] always is depressed, and always is stagnated, and always is in an alarming crisis, and never was otherwise.”
More recently, polls showed widespread belief in decline after the Soviet Union launched Sputnik in 1957, then again during the Nixon-era economic shocks in the 1970’s, and after Ronald Reagan’s budget deficits in the 1980’s.
At the end of that decade, American’s believed the country was in decline; yet, within a decade, they believed that the US was the sole superpower.
Now many have gone back to believing in decline.
Cycles of declinism tell us more about American psychology than about underlying shifts in power resources.
Some observers, such as the Harvard historian Niall Ferguson, believe that “debating the stages of decline may be a waste of time – it is a precipitous and unexpected fall that should most concern policy makers and citizens.”
Ferguson believes that a doubling of public debt in the coming decade cannot erode US strength on its own, but that it could weaken a long-assumed faith in America’s ability to weather any crisis.
Ferguson is correct that the US will have to come to terms with its budget deficit to maintain international confidence, but, as I show in my book The Future of Power, doing so is within the range of possible outcomes.
America enjoyed a budget surplus only a decade ago, before George W. Bush’s tax cuts, two wars, and recession created fiscal instability.
The US economy is still ranked near the top in competitiveness by the World Economic Forum, and the political system, in its own messy way, has slowly begun to wrestle with the necessary changes.
Some believe a political compromise between Republicans and Democrats can be reached before the 2012 election; others suggest an agreement is more likely after the election.
Either way, fuzzy statements about hegemonic decline would again prove misleading.
CAMBRIDGE – The United States government’s National Intelligence Council projects that American dominance will be “much diminished” by 2025, and that the one key area of continued American superiority – military power – will be less significant in the increasingly competitive world of the future.
Russian President Dmitri Medvedev has called the 2008 financial crisis a sign that America’s global leadership is coming to an end.
The leader of Canada’s opposition Liberal Party, Michael Ignatieff, suggests that US power has passed its mid-day.
How can we know if these predictions are correct?
One should beware of misleading metaphors of organic decline.
Countries are not like humans with predictable life spans.
For example, after Britain lost its American colonies at the end of the eighteenth century, Horace Walpole lamented Britain’s reduction to “as insignificant a country as Denmark or Sardinia.”
He failed to foresee that the industrial revolution would give Britain a second century of even greater ascendency.
Rome remained dominant for more than three centuries after the apogee of Roman power.
Even then, Rome did not succumb to another state, but suffered a death of a thousand cuts inflicted by various barbarian tribes.
Indeed, for all the fashionable predictions of China, India, or Brazil surpassing the US in the coming decades, the classical transition of power among great states may be less of a problem than the rise of modern barbarians – non-state actors.
In an information-based world of cyber-insecurity, power diffusion may be a greater threat than power transition.
So, what will it mean to wield power in the global information age of the twenty-first century?
What resources will produce power?
In the sixteenth century, control of colonies and gold bullion gave Spain the edge; seventeenth-century Holland profited from trade and finance; eighteenth-century France gained from its larger population and armies; and nineteenth-century British power rested on its industrial primacy and its navy.
Conventional wisdom has always held that the state with the largest military prevails, but in an information age it may be the state (or non-state) with the best story that wins.
Today, it is far from clear how the balance of power is measured, much less how to develop successful survival strategies.
In his inaugural address in 2009, President Barack Obama stated that “our power grows through its prudent use; our security emanates from the justness of our cause, the force of our example, the tempering qualities of humility and restraint.”
Shortly thereafter, Secretary of State Hillary Clinton said, “America cannot solve the most pressing problems on our own, and the world cannot solve them without America.
We must use what has been called ‘smart power,’ the full range of tools at our disposal.” Smart power means the combination of the hard power of command and the soft power of attraction.
Power always depends on context.
The child who dominates on the playground may become a laggard when the context changes to a disciplined classroom.
In the middle of the twentieth century, Josef Stalin scornfully asked how many divisions the Pope had, but four decades later, the Papacy was still intact while Stalin’s empire had collapsed.
In today’s world, the distribution of power varies with the context.
It is distributed in a pattern that resembles a three-dimensional chess game.
On the top chessboard, military power is largely unipolar, and the US is likely to remain the only superpower for some time.
But on the middle chessboard, economic power has already been multi-polar for more than a decade, with the US, Europe, Japan, and China as the major players, and others gaining in importance.
The bottom chessboard is the realm of cross-border transactions that occur outside of government control.
It includes diverse non-state actors, such as bankers electronically transferring sums larger than most national budgets, and, at the other extreme, terrorists transferring weapons or hackers threatening cyber-security.
It also includes new challenges like pandemics and climate change.
On this bottom board, power is widely dispersed, and it makes no sense to speak of unipolarity, multipolarity, hegemony, or any other cliché.
Even in the aftermath of the financial crisis, the giddy pace of technological change is likely to continue to drive globalization and transnational challenges.
The problem for American power in the twenty-first century is that there are more and more things outside the control of even the most powerful state.
Although the US does well on military measures, there is much going on that those measures fail to capture.
Under the influence of the information revolution and globalization, world politics is changing in a way that prevents America from achieving all its international goals acting alone.
For example, international financial stability is vital to Americans’ prosperity, but the US needs the cooperation of others to ensure it.
Global climate change, too, will affect Americans’ quality of life, but the US cannot manage the problem alone.
In a world where borders are more porous than ever to everything from drugs to infectious diseases to terrorism, America must help build international coalitions and institutions to address shared threats and challenges.
In this sense, power becomes a positive sum game.
It is not enough to think in terms of powerover others.
One must also think in terms of powerto accomplish goals.
On many transnational issues, empowering others can help to accomplish one’s own goals.
In this world, networks and connectedness become an important source of relevant power.
The problem of American power in the twenty-first century is not one of decline, but of recognizing that even the most powerful country cannot achieve its aims without the help of others.
Los Angeles – As Barack Obama’s incoming administration debates the pace and consequences of withdrawal from Iraq, it would do well to examine the strategic impact of other American exits in the final decades of the twentieth century.
Although American commitments to Lebanon, Somalia, Vietnam, and Cambodia differed mightily, history reveals that despite immediate costs to America’s reputation, disengagement ultimately redounded to America’s advantage. 
In all of these cases, regional stability of sorts emerged after an American military withdrawal, albeit at the cost of a significant loss of life.
America’s former adversaries either became preoccupied with consolidating or sharing power, suffered domestic defeat, or confronted neighboring states.
Ultimately, America’s vital interests prevailed.
The evidence today suggests that this pattern can be repeated when the United States departs Mesopotamia and leaves Iraqis to define their own fate.
Of the four withdrawals, arguably the 1982-1984 American intervention in Lebanon marks the closest parallel to Iraq today.
A country torn by sectarian violence beginning in 1975, Lebanon pitted an even more complex array of contestants against each other than Iraq does today.
Into this fray stepped the US and its Western allies.
Their objective was to create a military buffer between the PLO and Israeli forces that were then fighting in Beirut in order to promote the departure of both.
The massacres in Palestinian refugee camps prompted a new commitment to “restore a strong and central government” to Lebanon, to quote President Ronald Reagan.
But the result of intervention was that US forces became just one more target, culminating in the 1983 bombing of a US Marine barracks that killed 241 American soldiers.
A similar suicide bombing two days later claimed the lives of 58 French soldiers.
In February 1984, facing a quagmire, Reagan acceded to Vice President George H.W. Bush’s recommendation to get out of Lebanon.
But the withdrawal of Western forces did not stop the fighting.
The civil war continued for another six years, followed by a bumpy political aftermath: Syrian intervention and expulsion (two decades later), as the Lebanese defined their own fate with the US exercising only background influence.
In 1992, the sirens of Somalia’s political collapse lured the US into another civil war to save a country from itself.
The US humanitarian mission to that benighted country sought to salvage a failed United Nations enterprise to secure and feed Somalia’s ravaged population.
The US committed 28,000 troops, which for a time imposed a modicum of security.
But ill-equipped and poorly led UN replacement forces for the American presence put the remaining US troops in the bull’s eye as they attempted to bring to justice the Somali warlord responsible for the death of Pakistani peacekeepers.
The ensuing bloodbath of US soldiers generated images that the American public could not stomach, prompting the exit of American and then UN forces.
As unrest mounted with these military retreats, offshore US forces monitored and intercepted jihadists who sought to enter Somalia, while Kenya and Ethiopia blocked the unrest from metastasizing across the region.
In 2006, the capture of Somalia’s capital, Mogadishu, by the Islamic Courts raised the specter of a jihadist state. But Somalia soon demonstrated that quagmires can be a two-way street.
Following Ethiopia’s intervention, the Islamists found themselves out of power.
Today, Somalia remains a dysfunctional state, as rival clans, jihadists, and an interim government with Ethiopian support compete for power.
The US, now out of the quagmire, exercises limited influence from afar.
While Lebanon and Somalia remain damaged and failed states, respectively, regional and domestic factors have cauterized the consequences of America’s retreat from Vietnam and Southeast Asia.
The result is the stable region that the world sees today.
But the US saw things very differently in the 1960’s, when the ghosts of Munich hovered over Vietnam’s jungles.
As President George W. Bush argued about the war in Iraq, US President Lyndon Johnson predicted that defeat in Vietnam “would be renewed in one country and then another.”
What Johnson failed to foresee were the domestic and regional constraints that would prevent the dominos from falling in the way he predicted.
Although the US bombed northeastern Cambodia intensely throughout the Vietnam War years, it had no stomach for a ground commitment there.
Still within congressional restraints, the Nixon administration attempted to bolster Cambodia’s military government.
But, despite modest material support, the US could not sustain a government that could not sustain itself.
Rather than the dominos falling following America’s retreat from Saigon in 1975, a Vietnam-Cambodian War ensued.
This in turn stimulated China’s unsuccessful intervention in North Vietnam.
The withdrawal by all of these invading armies to the recognized international boundaries demonstrated that nationalist forces were dominant in the region, not communist solidarity.
None of these American exits was without consequence.
But, while the US suffered costs to its reputation around the world, the supposed advantages from this for America’s opponents proved illusory.
America’s departure from Mesopotamia will likewise put the burden of problem solving onto Iraqis and other regional players, leaving the US offshore to assist when and where it deems appropriate.
History suggests that, in fits and starts, Iraq, like Vietnam and Lebanon, will find itself able to sort out its own affairs.
MUNICH – The American business model has collapsed.
During recent years, the United States borrowed gigantic sums of money from the rest of the word.
Net capital imports exceeded $800 billion in 2008 alone.
The money came largely from selling mortgage-backed securities and collateralized debt obligations, claims against claims against American homeowners (or to be precise, only against the homes themselves, as the owners were protected by the non-recourse nature of loans).
The market for such securities has now vanished.
While the volume of new issues in 2006 was $1.9 trillion, the likely volume in 2009 will be just $50 billion, according to the most recent IMF estimates.
The market declined by 97%.
No number reveals the true catastrophe of the American financial system more than this one.
As the flow of funds from the world to US homeowners was disrupted, house prices collapsed by 30%, and construction of new homes by more than 70%.
The recession was inevitable.
Laid-off construction workers tightened their belts, as did homeowners.
Some did so because they felt poorer.
Others did so because the banks, shocked by the collapse of the securitization business, stopped giving them home-equity loans for consumption purposes.
In the last years before the crisis, the flow of new mortgages had been 60% higher than the value of residential construction.
Now it is 150% lower.
The first eleven months of the recession that followed were as severe as the first eleven months of the Great Depression that started in 1929.
But gigantic Keynesian recovery packages worth more than $1.4 trillion worldwide, together with bank rescue packages worth about $8 trillion, have had their effect.
They stopped the decline in the spring and early summer of this year, bringing the recession to what one hopes is more than a temporary halt.
Underutilization of capacity, however, remains huge.
It will take years for the world economy to return to trend, in particular as the growth outlook is not very promising and unemployment continues to rise in the US and Europe.
The medicine that has helped, and that remains necessary for the time being, is government debt.
Governments absorb the excess of private savings over private investment and re-inject it into the global economy, thereby stabilizing aggregate demand and the financial system.
As a result, public deficits are shooting up everywhere.
Nearly all European Union countries will violate the Stability and Growth Pact’s 3%-of-GDP cap on fiscal deficits in 2009, and some of them will have deficits at or above 10% of GDP, notably Spain (10%), the United Kingdom (14%), and Ireland (16%).
The US, the epicenter of the crisis, is in particular trouble.
By the end of this year, America’s debt-to-GDP ratio will have climbed to 87% from 73% in 2008, and, with next year’s deficit set to reach 11% of GDP, it is certain that the ratio will surpass 100% during 2011.
The country that used to be the symbol of capitalist stability and strength now shows frightening similarities to the developing countries that suffered from the world debt crisis in the early 1980’s.
Although countries can become insolvent, they have many ways to reduce their sovereign debt before this happens.
The US is considering the possibility of imposing a bequest tax on foreign holdings of US securities, and many people believe that it will try to play “the Italian card”: inflating away its public debt and devaluing the currency in order to maintain international competitiveness.
To be sure, inflation is difficult to bring about when short-term interest rates are near zero – and thus cannot be reduced any further without inducing massive hoarding of cash.
Nevertheless, investors around the world currently fear such a scenario, and this may create a self-fulfilling prophesy, because it helps to drive down the dollar, boost export demand, and make US imports more expensive.
Ironically, flexible exchange rates help the very country that caused the crisis.
There is no justice in economic mechanisms.
The opposite is true in Europe.
There the European Central Bank has also used up its gunpowder and cannot create inflation even if it wished to do so (which it cannot, because the Maastricht Treaty defines preservation of price stability as the ECB’s only goal.)
But the strengthening euro reduces both import prices and export demand, which, in itself, causes prices to fall .
In all likelihood, therefore, Europe will not be playing the Italian card; instead, it will face substantial difficulties in freeing itself from its current stagnation.
The risk for Europe is that it goes down the Japanese, rather than the Italian, path.
After its banking crisis of 1987-1989, Japan experienced two decades of stagnation and deflation with skyrocketing government debt.
Preventing a repetition of this scenario is the main challenge for European policymakers in the coming years.
Senior US officials, including Secretary of Defense Donald Rumsfeld, have recently suggested that Saddam Hussein and his top henchmen might be given an amnesty for their past crimes in exchange for leaving Iraq and averting war.
Is such an amnesty a good idea?
How should it be judged by those attempting to end the practice of exempting from punishment government officials guilty of monstrous crimes?
These are weighty questions.
In trying to answer them, two considerations seem fundamental.
First, one should consider the severity of the crimes committed by those who would escape punishment.
Second, we should consider how much death and suffering would be avoided by letting such a ruler and his henchmen go free.
A third factor that should also be taken into account is what damage would be done to the emerging international legal system for ending the impunity long enjoyed by state officials who use their power to commit atrocities.
As for the severity of Saddam Hussein's criminal behavior, there is probably no official now in power anywhere in the world with as much blood on his hands.
An incomplete list of his crimes includes:
using chemical weapons against Iranian troops during the eight-year Iran-Iraq war that he started in 1980;
murdering about 5,000 residents of the predominantly Kurdish town of Halabja in March 1988 through the use of chemical weapons, after using these weapons in previous months against Kurdish villages in the vicinity;
murdering about 100,000 Kurds during the "Anfal" campaign between February and September 1988, mainly by transporting the victims to a desert area where they were forced into trenches, machine-gunned, and then covered with sand by bulldozers;
destroying the ancient civilization of the Marsh Arabs in southeastern Iraq, followed by the forced resettlement and murder of the region's former residents;
his actions in Kuwait when Iraq invaded in 1990, including the disappearance--still unresolved--of hundreds of Kuwaiti citizens;
savage reprisals against the Shiites in southern Iraq in the aftermath of the 1991 Gulf War;
and persecution of any and all Iraqis suspected of dissent or disloyalty.
Each of these constitutes a war crime, a crime against humanity and, in the case of the Anfal campaign and its mass slaughter, and perhaps also in the case of the Marsh Arabs, the gravest crime of all, genocide.
Although we cannot know how many lives would be lost and how much misery would be inflicted in an invasion of Iraq to oust Saddam's regime, the cost would unquestionably be great.
No matter how compelling the case for punishing Saddam Hussein and such partners in crime as Ali Hassan al-Majid ("Ali Chemical" to the Kurds), Saddam's cousin and the principal organizer of the Anfal campaign, it is equaled by our duty to try to minimize harm to the living.
The apparent conflict between doing justice and preserving peace may be resolved through international law.
As matters currently stand, there is no mechanism for bringing Saddam Hussein to trial.
The International Criminal Court, which is now taking shape in The Hague with the selection of its first justices, does not have retroactive jurisdiction.
It cannot consider crimes committed prior to July 1, 2002.
So Saddam could be tried only before a newad hoc tribunal established for that purpose, such as those previously created for ex-Yugoslavia and Rwanda.
He could also be tried before a national court in a country that accepts the idea of universal jurisdiction, as happened in Spain as well as in the United Kingdom in the case of Chile's former dictator, General Augusto Pinochet.
If Saddam were granted sanctuary in a country such as Belarus or Libya, he would probably remain safe from prosecution, but only as long as he never leaves.
For example, Uganda's Idi Amin and Ethiopia's Haile Mariam Mengistu--deposed tyrants who rival Saddam in the scale of their criminality--have taken care not to stray from their shelters in Saudi Arabia and Zimbabwe, respectively.
If Saddam is ready to abdicate to preserve his life, he should get that much security, no more.
Without amnesty from a body such as the UN Security Council, the theoretical possibility that he could be prosecuted would be preserved.
He could not move freely.
His crimes would neither be forgiven nor forgotten.
Amnesty for Saddam Hussein is simply intolerable.
But condemning thousands to death in order to be able to punish him is intolerable as well.
Let him go where we can't get at him, but with no guarantee of impunity if his actions or fate bring him to a place where justice can be done.
Doctors use the word “crisis” to describe the point at which a patient either starts to recover or dies.
President George W. Bush’s Iraqi patient now seems to have reached that point.
Most commentators appear to think that Bush’s latest prescription – a surge of 20,000 additional troops to suppress the militias in Baghdad – will, at best, merely postpone the inevitable death of his dream of a democratic Iraq.
Yet as “Battle of Baghdad” begins, factors beyond Bush’s control and not of his making (at least not intentionally) may just save Iraq from its doom.
One key factor is that, for the first time since the United States and Britain invaded Iraq, Arab Sunni leaders are backing a US military plan for that country.
These Sunni leaders live in abject fear of the geopolitical earthquake that any disintegration of political authority in Baghdad would bring, believing that all-out civil war would invariably follow – a war that would not respect international borders.
Of course, America has been encouraging Sunni leaders in this belief.
Secretary of State Condoleezza Rice’s recent tour of Middle East capitals helped spread the word to Egypt, Jordan, Saudi Arabia, and the Gulf states that any US failure and sudden withdrawal would be certain to destabilize them.
Given the fragile grip that these leaders have over their societies, America’s warnings have been taken to heart.
But the truly curious factor that might bring success to Bush is that those who have opposed or resented America’s presence in Iraq, such as the Iranian-backed Shi’a parties now also appear to want Bush’s new strategy to succeed.
They are for it because they believe it will defang Moqtada al-Sadr, the rogue Shi’a cleric whose power has mushroomed over the past three years – to the point that he now dominates much of Baghdad and holds the allegiance of countless angry young Shi’a men.
Of course, attacking Moqtada al-Sadr’s Mahdi Army in the name of fighting militia death squads has the potential to draw American military forces into a level of urban warfare unseen since the Falluja assaults of 2004 and 2005.
Al-Sadr is seen as the protector of the Shi’a of Iraq and has are an estimated 60,000 fighters in his militia.
But he is deeply mistrusted by other Shi’a leaders, who fear that they may one day have to take him on by themselves.
Better to let the Americans do it, though of course these Shi’a leaders prefer a slow strangulation of al-Sadr to a direct and bloody assault.
But make no mistake: how al-Sadr is handled is the big test of Bush’s new strategy.
Should the US choose to face al-Sadr and his forces head on, they risk alienating Iraq’s largest sectarian community, the Shi’a, adding fuel to the anti-occupation resistance and thus probably dooming Bush to failure.
Iran and Syria, which have played a spoiler role in Iraq up to now, may also now be anxious to find a way to pull the country back from the brink.
Bush still refuses to talk to either of them, and has lately been having US troops arrest Iranian agents in Iraq.
Yet Iran may already see itself as victorious, with the current Iraqi government friendlier than any the Iranians have ever known.
So maintaining that government in office has now become a strategic priority for Iran, particularly as it is now clear that any US hopes of using Iraq as a permanent military base are dead. 
The “surge” also opens, perhaps for the first time, a serious possibility of pouring water on the insurgent fires in Anbar province, the heartland of the Sunni insurgency.
The US has achieved relative successes in the province through alliances with Sunni tribes.
The hope is that such realistic and pragmatic accommodations will be extended to Iraqis who are fighting under the banner of a nationalist and anti-occupation agenda.
So some of the stars have come into alignment for Bush.
But to keep them there in the long term, the Iraqi government will need to amend the constitution in a way that appeases the Sunni community.
Reassuring Iraq’s Sunnis that they have a place in the new Iraq will also reassure neighboring Sunni governments, which have mostly turned a blind eye to the support for the insurgency that has come from their lands.
Of course, should the US see failure ahead, it could seek to broaden the war beyond Iraq’s borders by attacking Iran, a policy reminiscent of “Operation Sideshow,” when US failure in Vietnam in the late 1960’s enticed President Nixon into attacking Cambodia and Laos.
But Iran has resources that Cambodia and Laos could never muster; indeed, its ability to retaliate could set the entire region ablaze.
Whereas America’s war in Indochina was a tragic mistake, the cost of a wider war precipitated by the crisis in Iraq would be incomparably greater – for both the patient and the doctor.
CAMBRIDGE – As the United States and European economies continue to struggle, there is rising concern that they face a Japanese-style “lost decade.”
Unfortunately, far too much discussion has centered on what governments can do to stimulate demand through budget deficits and monetary policy.
These are key issues in the short term, but, as every economist knows, long-run economic growth is determined mainly by improving productivity.
There is no doubt that Japan’s massive 1992 financial crisis was a hammer blow, from which it has yet to recover, and the parallels with the US and Europe today are worrisome.
Both seem set for a long period of slow credit growth, owing both to necessary stricter financial regulation and to the fact that their economies remain significantly over-leveraged.
There are no simple shortcuts in the healing process.
Yet, in assessing the Japanese experience and its relevance today, it is important to recognize that Japan’s fall to earth was due not only to its financial crisis.
Japan also suffered a number of severe productivity shocks, which had much to do with its longer-term problems.
Even if Japan had never experienced a real-estate and stock-market bubble, the meteoric rise of its giant neighbor China would have been a huge challenge.
At the dawn of the 1990’s, Japan’s dominance in export markets worldwide had already been dented somewhat by the rise of its smaller Asian neighbors, including Malaysia, Korea, Thailand, and Singapore.
But China presents an entirely different challenge, one for which adjustment will take much longer.
Moreover, even if it never had a financial crisis, Japan would have been plagued by adverse demographics, as its population is both aging and shrinking.
Last but not least, Japan’s hyper-growth years were built on a phenomenal rate of investment.
But, because productivity ultimately must be built on innovation, not just on ever more buildings and equipment, it was inevitable that returns on investment would turn south at some point.
In principle, with a healthier financial system, Japan’s economy would have had more flexibility to meet these challenges to its productivity growth.
But, one way or another, Japan’s once sky-high growth rates probably would have fallen sharply.
As is usually the case, financial crisis amplified other causes of economic meltdown, rather than igniting it directly.
The US Great Depression of the 1930’s is another case in point.
Again, a great deal of attention has been lavished on the ebbs and flow of fiscal and monetary policy.
But New Deal economic policies, by expanding the role of the state in an often chaotic and unpredictable fashion, probably also played a role in at least temporarily impeding productivity growth.
The US today seems to be moving towards a gentler and more European-style state, with higher taxes and possibly greater regulation.
Supporters of the US administration might fairly argue that it is undertaking long-deferred maintenance on issues such as income inequality.
But if the US does experience slow growth over the next decade, can it all be blamed on the financial crisis?
Likewise, Europe’s latest existential identity crisis is again creating a great deal of policy uncertainty and unpredictability.
In Europe, too, if there are adverse growth effects over the next decade, they cannot all be blamed on the financial crisis.
In the short term, it is important that monetary policy in the US and Europe vigilantly fight Japanese-style deflation, which would only exacerbate debt problems by lowering incomes relative to debts.
In fact, as I argued at the outset of the crisis, it would be far better to have two or three years of mildly elevated inflation, deflating debts across the board, especially if the political, legal, and regulatory systems remain somewhat paralyzed in achieving the necessary write-downs.
With credit markets impaired, further quantitative easing may still be needed.
As for fiscal policy, it is already in high gear and needs gradual tightening over several years, lest already troubling government-debt levels deteriorate even faster.
Those who believe – often with quasi-religious conviction – that we need even more Keynesian fiscal stimulus, and should ignore government debt, seem to me to be panicking.
Last but not least, however, it is important to try to preserve dynamism in the US and European economies through productivity-enhancing measures – for example, by being vigilant about anti-trust policy, and by streamlining and simplifying tax systems.
For better or for worse, productivity trends are very difficult to extrapolate, depending as they do on hugely complex interactions of social, economic, and political forces.
Nobel Prize winners Robert Solow and Paul Krugman famously once questioned whether the proliferation of computers and technology would lead to bottom-line growth.
(This theme underlies the title of Krugman’s classic 1990 book “The Age of Diminished Expectations.”)
In the end, policymakers must remember that whether or not the US and Europe avoid a lost decade depends on their ability to retain productive vitality in their economies, not simply on short-term demand-stimulation measures.
A recent OECD study reminds us, once again, that per capita income levels are roughly 30% lower in the euro area, as well as in the three largest Continental countries – France, Germany, and Italy – that dominate its performance, than in the United States.
That gap is likely to widen as Europe’s demographic profile darkens, and if productivity continues to grow more slowly than elsewhere in the industrial economies.
Why have the large European economies failed to catch up with US income levels?
The bulk of the shortfall is due to less intensive use of labor: employment rates for women and for the oldest and youngest age groups are lower in the euro area than in the US, working hours are far fewer, and, least significantly, unemployment rates are higher.
Some take consolation from this, viewing it as positive that Europeans prefer leisure to work.
But low levels of labor utilization are largely due to heavier income taxes and social security contributions, as well as high social benefit levels introduced at a time when the labor force was growing rapidly and the need to replace involuntary with voluntary unemployment seemed more urgent than today.
These measures will need to be revisited both to increase the supply of labor and to make public finances more sustainable.
This process is already underway, particularly in Italy and France, through cuts in social security contributions for lower-paid workers, tighter conditions for drawing unemployment benefits, and tax credits for “the working poor.”
Since the mid-1990’s, the relative decline in employment in these countries has, indeed, been slightly reversed.
But factors beyond taxes and benefits also contribute to low employment rates in all the three major euro-zone economies: high minimum wages and some features of employment protection legislation slow down the flow of workers through the job market.
Although a long agenda of reforms is beginning to be tackled, first in Germany and, more recently and cautiously, in France, the results are slow in coming and public understanding of the need for change remains limited.
Much can be learned from each country’s experience and from that of smaller EU member states, but labor market reforms inevitably have a strong national flavor.
Employment objectives have been formulated for all EU member states since 1997 in the so-called European Employment Strategy (EES), now part of the “Lisbon Agenda,” the set of goals established to boost EU productivity.
But, with the policy instruments for achieving these goals largely national and the arguments for applying them simultaneously in several member states weak, the EES has created unrealistic public expectations and triggered only limited action by governments.
Nor is the employment gap with the US the only problem for Europe.
Beginning in the mid-1990’s, the rate of growth in output per hour worked – a key factor behind the rise in per capita income – slowed in most European countries while it rose in the US, reversing a decades-long pattern.
Between 2000 and 2004, hourly labor productivity rose more than twice as fast in the US than in the large euro zone economies – 2.8% per year versus little more than 1%.
So why have the Europeans been unable to sustain improvements in both foundations of growth – employment and productivity – at the same time?
This proved possible not only in the US, but also in other advanced economies outside Europe – Australia, Canada, and New Zealand – and, unsurprisingly, in the new EU member states.
The explanation is not capital spending, which is normally linked to productivity growth.
There have been no major differences between the US and the large euro zone economies here. This leaves the “explanation” to what economists call Total Factor Productivity (TFP), a mix of several important elements, including innovation activity, a well-functioning financial system ready and willing to take risks, and organizational flexibility that facilitates rapid diffusion of new technologies.
The main lapse in TFP growth in Europe over the past decade has been in services (excluding information and communications technologies).
So deregulation and integration of services will be essential if the Euro area’s TFP is to improve, as more than two-thirds of total income in most EU economies is generated in this sector.
While product markets have held center stage in the creation of the single European market, services continue to be fragmented by national regulatory, anti-competitive practices.
Much of the explanation lies in the very heterogeneity of services and the greater difficulties that mutual recognition, or the “country-of-origin principle” – essential in the integration of product markets – implies for services.
Unfortunately, reform was derailed in 2005.
During the referendum campaign in France preceding the vote on the draft EU Constitutional Treaty, the proposed directive was vilified as undermining the rights of labor, symbolized by that dreaded bogeyman, the “Polish plumber.”
These attacks overlooked the fact that the directive makes employment conditions of workers from other EU-member states subject in most respects to host-country rules.
A revised version of the directive that reduces its sectoral scope and makes a number of compromises with the country-of-origin principle is now before the European Parliament.
Even this limited version would constitute progress; most of the gains arise from removing the red tape that complicates cross-border establishment of small and medium-size service enterprises and limits competition in broad sectors of the economy.
It is a sad reflection on the state of the EU that it seems unable to agree on the one clear productivity-advancing piece of legislation when improving productivity is held out as a shared goal.
The failure to mobilize consumer interests in favor of European integration is particularly disappointing for the new member states, which had expected to reap some of the benefits.
MADRID – The first International Forum of the Alliance of Civilizations, conceived as an antidote to the idea that the world is doomed to a “clash of civilizations,” recently met in Madrid and revealed that there is more than a grain of truth in Robert Kagan’s idea that Americans are from Mars and Europeans from Venus.
Ever since September 11, 2001, the United States has been engaged in a crusade against the forces of evil in the Muslim world.
By contrast, the March 11, 2004, terrorist attack on Spain, which left 200 dead, triggered an “anti-crusade” that seeks to disarm extremism by building bridges of understanding and reconciliation with Islam.
Co-sponsored by Spain and Turkey, the Alliance of Civilizations initiative is not devoid of political calculation.
To the Spaniards, it helps to justify their abrupt withdrawal from Iraq in 2004; for the Turks, it is yet another vehicle in their struggle, as the vital bridge between Islam and the West, for admission into the European Union.
A loose and somewhat confused project, the Alliance of Civilizations aims to heal the wounds of conflict between Islam and the West through education, viable integration policies, and a better-informed dialogue with the media.
But it suffers from the major global players’ profound skepticism, with the US, Russia, and, for that matter, the EU shown no real enthusiasm for it.
However vague, the alliance of civilizations idea certainly cannot do more harm than war against Islamic extremism.
After all, none of the Muslim world’s problems and conflicts with the West are susceptible to a military solution.
Moreover, the Alliance is not an entirely incoherent proposal if the objective is that the West disengage from the politics of hubris and establish a genuine sphere of cooperation with the Muslim world in economics, culture, and science.
Of course, the idea is held back by the inner workings of both parts of the proposed alliance.
Many in the West question whether Islam is compatible with human rights and Western concepts of liberty.
Many Muslims who have been fighting for years for  their countries’ modernization have so far failed to find a lucid response to the progressive wave of radical Islam.
To claim that Islam is incompatible with human rights is to consider it a civilization too hidebound to change.
This is a historic fallacy.
Nor is the claim that Islam is intrinsically inimical to innovation viable, because Muslim civilization has contributed mightily to science and art throughout history.
Today, Western universities are replete with distinguished Arab scholars in almost every field – the result of a brain drain that itself reflects the Islamic world’s centuries of decline.
In 2005, the 17 countries of the Arab world together produced 13,444 scientific publications, fewer than the 15,455 achieved by Harvard University alone.
Enemies of reason, however, are also to be found in the West.
We live in an age in which many people are disillusioned with secular politics, and are turning to religion instead, not only throughout the Muslim world, but in the core of Western civilization, Christian Europe and Evangelist America.
Nor is the Jewish state of Israel, where Messianic fanatics and religious nationalists have embraced a political theology that questions the very legitimacy of the democratic institutions, immune from this phenomenon.
The current crisis of Islam might not be congenital, but Islam’s predicament is acute.
The question is this: are Muslims ready to accept that Khomeini’s dictum that “Islam is politics or it is nothing” is wrong, that Islam is a religion and not a form of government, and that, as in the Christian world, there is a sphere for Caesar and a sphere for God?
Those in the Muslim world who want to embrace reform must be driven by the conviction that theocracy has never served as a vehicle for human progress.
Of course, the Alliance of Civilizations should not attempt to bridge differences by defending moral relativism.
If it is driven by a Western guilt complex that assumes that the solution simply lies in greater empathy for the Muslim predicament, then the skeptics are bound to be vindicated.
For the Alliance of Civilizations to have any chance of success, the emphasis must be on reciprocity.
Tolerance and religious freedom must be mutual.
Islam’s part in the deal must include a guarantee of human rights and civil liberties, improvement in women’s status, and realistic policies to stem the Islamic world’s demographic explosion.
Some, as usual, will claim that the Arab-Israeli conflict lies at the root of the problems that exist between Islam and the West, and that resolving the Palestinians’ plight will contribute immensely to smoother relations.
But Arabs and Muslims must stop deluding themselves that the Israel-Palestine dispute is what is holding them back.
Ending the American occupation in Iraq and imposing an Arab-Israeli peace would help, but they are no panacea.
The fight to eradicate misery, illiteracy, and corruption, and Islam’s embrace of science, do not depend on the results of the Middle East peace process.
PARIS – During NATO’s recent 60th anniversary ceremony in Strasbourg, the Alliance welcomed two new members, Albania and Croatia, bringing its total membership to 28.
This expansion is a good thing, for history has tormented these two countries.
Being welcomed within the great international family of the West will reassure them, stabilize them, and contribute to their political, cultural, and economic development.
But the good news was limited, because NATO addressed only a routine agenda.
No core problem was really tackled.
The controversy that arose in France over the country’s return to NATO’s unified military command makes this abundantly clear.
Was France losing its autonomy, perhaps even its sovereignty?
Was it capitulating to American hegemony?
These are real questions, yet at the NATO summit people spoke of them more in terms of symbols than as realities.
But what is the reality here?
NATO is a military alliance composed of 28 countries.
One of them, the United States, has a military budget that is more than three times that of all the other members combined.
Hence, the US runs most NATO civilian and military commands with the consent of the others.
Of course, there is a collective consultation and deliberative process that enables any member to be heard.
But in reality a member’s actual power is what affects common decisions.
This structure harks back to the conditions of NATO’s birth, when it was forged to thwart the Soviet threat to Western civilization.
At the time, no one ever doubted that American power – already endowed with nuclear weapons – was the only counterpart.
For this reason, the US came to preside over the alliance.
During the 41 years of the Cold War, 14 of NATO’s 16 members strictly obeyed and complied with American decisions and policies.
French President Charles de Gaulle was the only one to question whether an American president would actually ever be ready to launch a nuclear attack on the USSR in order to protect one or several Alliance members if vital US interests were not directly at stake.
Based on that doubt, France – a nuclear power since 1960 – withdrew in 1966 from the Alliance’s permanent centralized military command in order to assert its own deterrent capability.
This decision was mainly grounded on the American doctrine, adopted in 1962, of “flexible response,” which said to the Soviets: “As long as you do not use nuclear weapons, we will not use them, either.” This very doctrine left Europe exposed.
Indeed, while it is a much disputed question, de Gaulle was probably right about America’s lack of commitment to the nuclear defense of Europe.
Both Henry Kissinger and Robert McNamara left office admitting that de Gaulle had been correct.
Nevertheless, de Gaulle’s insights left a legacy that still causes some mistrust and dissent within NATO.
France was right on this key strategic point, but it was never able to explain its position to its allies.
This inability to discuss, clearly and forthrightly, this strategic doctrine continues to hamper the Alliance.
At the Strasbourg summit, confidence in the future could have been strengthened if a couple of troubling issues had been discussed.
Instead, once again, there was an extended focus on the past.
The key questions are whether NATO’s doctrine of common defense is currently directed at one country in particular, and whether nuclear force remains the Alliance’s major defensive tool.
In the current global situation, no predictable conflict will require the use of a nuclear weapon.
At the moment, there is no global threat and the Alliance only intervenes in regional conflicts, so why not have NATO admit this?
But the most important matter that went unmentioned in Strasbourg is the relationship with Russia.
NATO was founded to confront the threat that the USSR represented 60 years ago.
But the Warsaw Pact, the Soviet Union’s “anti-NATO” alliance of socialist countries, was dissolved in 1991; communism imploded the same year, with Russia caught ever since in a struggle to build a market economy and define a new global position for itself.
At a time when Russia was taking a more pacific course, NATO – unlike the Warsaw Pact – was not dismantled.
On the contrary, the Allies chose to maintain the pact and to extend it to numerous Russian neighbors.
NATO’s members essentially said: “We Western nations do not trust you.
Even if you become a democracy, we will always be suspicious.”
George Kennan, one of the greatest American diplomats of the post-war years, once wrote that the Western world was committing its biggest mistake in 50 years time by expanding NATO after Soviet communism collapsed.
The resulting humiliation and blatant mistrust that Russia’s elite has felt ever since has led them to their current policy of rearmament.
The only way to resolve this problem is for NATO to assert its pacific intentions before the world.
The most convincing way to do that is to moderate America’s excessive taste for power, which it demonstrated in Iraq.
NATO needs to shift its focus from organizing and administering a unified military command to building real confidence that every member’s voice will be heard.
To that end, all members must stand on an equal footing.
France’s decision to return to full and equal Alliance membership was a good one, and France must now work from within to advance the principles in which it believes.
Argentina's financial panic and the run on its banks that ensued, as well as Asia's financial crisis of 1997, have forced a number of countries to consider adopting deposit insurance schemes to protect their citizens' savings.
But is deposit insurance the best defense against bank panics?
Deposit insurance was a response to banking crises of the type that plagued the United States until the 1930's.
The first explicit scheme was introduced in America after the Great Depression and initially seemed an unmitigated success.
Panics no longer occurred, which stabilized the financial system and contributed to sustained post-war economic growth.
Deposit insurance did away with financial panics because bank runs are typically driven by a self-fulfilling prophecy.
They occur when a bank's clients fear that most of their fellow depositors will withdraw their funds.
Because banks service their depositors on a first-come-first-served basis, those who wait risk being left empty-handed, because the bank may be forced to liquidate its long term-assets at a loss and run out of resources.
Sofear of a panic cancreate a panic.
This is highly inefficient, because while it isindividually rational for depositors to want their money immediately, the bank might have been able to service all of them had they beencollectively patient.
Economists call such situations "coordination failures," if depositors could talk to each other and coordinate their actions, they would be able to avoid a self-defeating run on the bank.
By guaranteeing that there will be enough resources available for patient clients when they want to withdraw their funds, deposit insurance eliminates the coordination failure.
Patient depositors no longer need to worry about others withdrawing their funds because it has no effect on them.
But deposit insurance leads to other problems, which first appeared with the Savings and Loan crisis in the US during the 1980's.
Deposit insurance creates what economists call "moral hazard," people who are insured against an unpleasant event are not as careful as they would otherwise be in trying to avoid that event.
If my bicycle is insured against theft, I might buy a cheaper lock for it, making it more likely that it will be stolen.
With deposit insurance, clients who no longer risk losing their money have no incentive to monitor their bank, while banks, with no one watching, have incentives to invest in excessively risky projects.
Although many factors contributed to the Savings and Loan crisis, it is generally agreed that moral hazard was a major one.
Following that crisis, deposit insurance in the US was reformed with the objective of mitigating the moral hazard problem.
But did the reforms go far enough?
There are ways to improve the existing system, but is something altogether different and better possible?
As far back as 1873, in his classic book on central banking,Lombard Street, Walter Bagehot noted that central banks should be able to prevent financial panics by injecting liquidity into the economy.
I have studied policies of the type proposed by Bagehot in a way that allows me to compare them with deposit insurance schemes.
The main conclusion of my work is that policies aimed at ensuring liquidity can not only prevent bank panics, but also avoid the excess risk-taking that deposit insurance encourages.
In case of panic, a good policy should help banks that have enough assets to cover their deposits but that can't pay all depositors at the same time because some assets are tied up in real estate or other long-term investments.
These banks areilliquid but notinsolvent.
The central bank can help with familiar tools.
Under a repurchase agreement, for example, monetary authorities buy assets from an illiquid bank under the promise that the bank will then buy the assets back on a specified date and for a specified price.
In this way, the bank temporarily exchanges its illiquid assets for cash, pays off its depositors, and avoids doing so at a loss.
As with deposit insurance, repurchase agreements solve the coordination failure problem because depositors know that, even if they wait, the bank will be able to accommodate their withdrawals.
In contrast to deposit insurance, however, liquidity provision can avoid moral hazard by helpingonly those banks that are solvent.
Depositors still have a strong incentive to monitor their banks.
Consider a bank that has invested in risky projects and finds itself in trouble.
It can ask the central bank for help and sell some of its assets for cash.
However, under the agreement with the central bank, it must buy its assets back.
If the assets are worthless, it will ultimately be forced out of business.
If it declares bankruptcy and refuses to buy back its assets, bankruptcy laws should give the central bank the first claim on the bank's assets.
This creates a powerful incentive for depositors and investors to monitor their bank's performance.
Implementing liquidity provision policies like those advocated by Bagehot would prevent bank panics without the incentive for undue risk-taking associated with deposit insurance.
Depositors deserve strong, effective protection for their funds--and the banking system requires it in order to maintain confidence.
But neither depositors nor their banks should be given a free ride.
Now that the UN inspection teams are in Iraq, and as the December 8 deadline approaches for Iraq to declare all its weapons of mass destruction and the facilities for producing them, the world must reckon with a hard question: what is to be done if Saddam Hussein does not obey the Security Council resolution on his weapons of mass destruction?
There is a chance that the Iraqi president will comply, but the Council promised "serious consequences" if he does not.
What should these be?
We know from experience that neither political pressures nor economic sanctions hurt Saddam enough.
Only military action will do.
But the only military option so far put before us is invasion to change the regime - that is, full-scale war.
Starting a war is always a grave step, and the effects are never neatly calculable.
In this instance five key areas of uncertainty and risk exist.
First, the fighting itself may not be the cakewalk that some assert.
Churchill once wrote: "Never, never, never assume that any war will be smooth and easy."
Brainwashed Iraqi forces, and a regime complicit at every level in Saddam's crimes, would be fighting not to hang on to a conquest (as in the Gulf War of 1991) but to defend their homeland.
This raises the spectre of street fighting through Baghdad, desperate use of biological or chemical weapons, an attack to draw in Israel, numerous military and civilian deaths and the further destruction of a ravaged society.
Second, Iraq is a diverse country, distorted by over thirty years of Saddam's tyranny, and with no plausible and coherent alternative government in sight.
How would it be run?
WWII's victors had to rule Germany for four years and Japan for longer.
According tothe New York Times, Pentagon officials have said, "thousands of military specialists in civil affairs familiar with the linguistic and cultural differences within Iraq would probably be deployed throughout the country".
Where is this remarkable cohort to come from?
Next, no government in the region loves Saddam, but all fear popular reaction to a third Western onslaught on an Islamic state, this time with much less clear justification than over Kuwait and in Afghanistan.
Some hawks might welcome the destabilisation of Saudi Arabia.
Should anyone else?
Indeed, the fourth dimension of risk is that an invasion could weaken the support of key governments for action against terrorists, and provoke further outrages.
Fifth, the world economy is scarcely thriving.
Would unrest in the main oil-producing region help or hinder prosperity?
What would the whole enterprise cost?
Explicit UN support for invasion might ease some of these risks, but it would not remove them.
Necessity sometimes dictates that risks be accepted, as Britain did in 1939.
But does necessity really drive us so hard now?
Three main reasons for acting against Saddam have been offered.
We need no longer address the first - that he was behind the attacks of September 2001 on the US.
The Bush Administration makes no claim to have adequate evidence of this.
The second reason adduced is that Saddam poses a grave security threat to the US and to his region.
But his two aggressive adventures - the more recent over twelve years ago - ended in humiliating failure.
He is weaker militarily now than then, he cannot hit the US directly, and he must know that fresh aggression would bring the house down upon him.
Saddam's only option would be to provide weapons of mass destruction to terrorists.
But that would be so uncontrollable and dangerous for him as to be deeply implausible - unless we drive him to desperation.
Saddam Hussein heads a state, not a shadowy terrorist outfit.
Deterrence - which works by basic human nature, not through some arcane construct peculiar to the Cold War - can be brought to bear here.
The third reason for acting against Saddam is cogent: that his defiance of the Security Council since 1991 cannot be allowed to stand.
The Council has now made that plain.
Yet we must still ask whether a full-scale invasion is the only way, a necessary and proportionate way, to fulfil that aim.
We should not forswear that option, but we ought to consider others, not least because the Security Council - whose backing will be politically if not legally crucial - may never support invasion.
It would be odd to uphold the Council's authority by means that failed to get its approval.
The Council is more likely to accept an option of mounting a punitive program of air strikes - going well beyond what was done in 1998 - on suspected WMD sites, presidential compounds, the Republican Guard and other armed-force targets.
This would hurt and weaken Saddam, and establish unmistakably the message that defiance of the UN carries severe penalties.
The Council could also declare that any fresh aggression, or any use, threat or transfer of WMD, would trigger Saddam's removal and his pursuit as an international criminal like Slobodan Milosevic.
Such a course would not please those whose underlying desire is regime change, not disarmament or punishment.
The US has skilfully carried the international community along with it so far.
To throw away that achievement would impose costs not confined to the present episode.
The sledgehammer of invasion could easily cause far more harm than the ills it seeks to stamp out.
Dealing with Saddam does not need, and is not worth, a full-scale war.
BERLIN – For 19 years, the West (America and Europe) has been putting off answering a critical strategic question: what role should post-Soviet Russia actually play globally and in the European order?
Should it be treated as a difficult partner or a strategic adversary?
Even when this choice became critically acute during the crisis of Russia’s short war against Georgia last summer, the West didn’t provide a conclusive answer to this question.
If you follow most East Europeans, the United Kingdom and the Bush administration, the answer is “strategic adversary.”
But most West Europeans prefer “difficult partner.”
These seemingly mutually exclusive alternatives have one thing in common: neither of them has been thought through to the end.
If you see Russia as a strategic adversary – and the restoration of Great Russian power politics under Vladimir Putin, to the detriment of the rule of law in domestic and foreign policy, does indeed speak for it – then the West should fundamentally change its agenda.
While Russia is no longer the superpower it was in the Soviet era, militarily it is still a great power, at least in Europe and Asia.
To address the numerous regional conflicts (Iran, Middle East, Afghanistan/Pakistan, Central Asia, North Korea) and global challenges (climate protection, disarmament, arms control, nuclear anti-proliferation, energy security) that have high priority on the Western agenda, cooperation with Russia is necessary.
A strategic confrontation with Moscow, i.e., a new kind of “mini-Cold War,” would undermine this agenda, or at least complicate its implementation significantly.
So the question is simply whether the threat emanating from Russia is so grave that this kind of strategic reorientation on the part of the West is required?
I believe it is not.
Putin’s claim to great-power status and his great-power policies are structurally very vulnerable.
This is especially true at times where the price of oil has fallen below $40 per barrel.
And he knows that.
Demographically, Russia is in a dramatic nose-dive; it remains economically and socially backward; its infrastructure is underdeveloped, as are its investments in education and vocational training.
Economically, it mainly relies on energy and commodity exports, and in its modernization efforts, it is largely dependent on the West, particularly Europe.
Due to its geopolitical position and its potential, however, Russia will remain a permanent strategic factor in Europe and Asia that cannot be ignored.
To integrate the country into a strategic partnership is therefore in the West’s interest.
But this would require a Western policy based on long-term thinking and a self-confident and strong power position, because the Kremlin will perceive any sign of division and weakness as encouragement to return to Great Russian power politics.
A few months ago, the Russian government came up with a proposal to negotiate a new European order within the framework of the Organization for Security and Cooperation in Europe.
Russia considers the agreements from the 1990’s unjust, based as they were on its weakness at the time, and it wants to revise them.
Moscow’s main strategic objective is the weakening or even roll-back of NATO as an Ant-Russian military alliance and the re-establishment of its East European and Central Asian zones of influence.
But Putin is making a big mistake here, because all these aims are unacceptable for the West, and the Kremlin still doesn’t seem to understand that the best and most effective guarantee of NATO’s existence was, is, and will continue to be an aggressive Russian foreign policy.
In the former mother country of Marxism-Leninism, the leaders still don’t seem to understand dialectics.
After all, if Russia’s government really wanted to achieve a change in the post-Soviet status quo, it should, first and foremost, pursue a policy vis-à-vis its neighbors that reduces rather than increases fears.
But this applies similarly, if in reverse, to the West: on the one hand, the principles of a new Europe as defined by the OSCE after 1989/1990 don’t allow decisions about alliances to be subject to the veto of a large neighbor.
The same is true for free and secret elections and the inviolability of borders.
On the other hand, the missile defense systems in Poland and the Czech Republic, and the prospect of NATO accession for Georgia and Ukraine, assume confrontation where this was not at all necessary.
The West should not reject Russia’s wish for new negotiations on a European security system.
Instead, it should be viewed as an opportunity finally to answer the key question of Russia’s place within Europe.
NATO must play the central role here, because it is indispensable for the vast majority of Europeans and for America.
The possible trade-off could be that the existing principles and institutions of the post-Soviet European order, including NATO, remain unchanged and are accepted and implemented by Russia, which would get a significantly enhanced role within NATO, including the perspective of full membership.
The peripheral nature of the NATO-Russia Council was clearly not enough and did not work.
But why not think about transforming NATO into a real European security system, including Russia?
The rules of the game would be changed and a whole variety of strategic goals could be achieved – European security, neighborhood conflicts, energy security, arms reduction, anti-proliferation, etc. Yes, such a bold step would transform NATO.
But it would transform Russia even more.
If the West approaches these discussions with Russia without illusions, with a clear understanding of its own strategic interests, and with new ideas for partnership and cooperation, the worst to be feared is failure.
Of course, this approach presupposes two things that don’t exist at the moment: a common transatlantic approach to dealing with Russia, and a European Union that acts in much greater unison and is therefore stronger.
Nonetheless, the challenge posed by Russia does not allow any further procrastination.
There is simply too much at stake.
BARCELONA – The current global financial crisis has made evident the tremendous pressures to which competition policy is subject on both sides of the Atlantic.
In particular, competition policy has suffered a setback mostly because of the distortional aid measures to financial intermediaries, as well as a suspension of merger rules to save institutions.
Indeed, public provision of capital and other subsidies have made the playing field uneven, with weaker institutions ending up much better capitalized than healthier ones.
This is crucial in a sector like banking, where perceptions about the soundness of an institution are fundamental to its ability to compete.
For example, Lloyds TSB took over the troubled HBOS, Britain’s largest mortgage lender, in a merger opposed by the country’s Office of Fair Trading, whereas it was barred from taking over Abbey National bank in 2001.
In the United States, the investment banking business has been consolidated with the forced takeovers of Bear Stearns by JP Morgan and of Merrill Lynch by Bank of America.
The result is very weak competition among the players left.
Competition policy was attuned to deal with individual crises, but a systemic crisis has almost broken its back.
Not only in banking, but in other sectors as well – with automakers at the forefront – massive subsidies are keeping inefficient incumbents in place, limiting the growth of efficient firms or, perhaps even worse, preventing market entry by new firms.
In the European Union, national governments maneuver in a subsidy race to shift the costs of capacity adjustment in the car industry to neighbors, as the case of Opel shows.
But consolidation to reduce perceived excess capacity in banking and the automotive sector may create long-term anti-competitive market structures.
As long as those structures manage to keep new entrants out, market discipline will be suppressed and the consumer will suffer.
It is precisely the size and power of large financial, automotive, and other firms that have conditioned the scope of regulation and public intervention.
Indeed, the influence of the US investment-banking industry’s lobbying efforts on the relaxation of prudential standards in financial regulation is widely recognized as a factor leading to the current crisis.
And many would argue that the industry has had a substantial impact on the measures to resolve the crisis itself.
The clout of the “big three” automakers in the US is also evident, despite their relatively poor record in terms of efficiency and delivering value to consumers.
Indeed, it is remarkable that, with General Motors seemingly unresponsive to consumer demand, there is now a debate about whether it should be forced to produce more fuel-efficient cars.
If large firms can shape the playing field in their favor through their influence on the political process and regulation – thereby keeping out new entrants in their industries and shifting costs to society – a whole new perspective on competition policy follows.
Or perhaps it is not so new after all.
Antitrust policy started in the US at the end of the nineteenth century with a deep suspicion about large firms, owing to the concentration of power that largeness entails.
This somewhat populist view later gave way to a view of antitrust that focused on efficiency.
What it sought to address was market power in a particular sector, not sizeper se, because market power leads to high prices and potentially reduces variety and innovation.
In Europe, the “efficiency view” of competition policy also prevailed.
But the current crisis might pose the question of whether the populist view of antitrust – limiting the size of firms because of the excessive influence they may wield – has some merit.
The issue is not only that firms that become systemically vital may blackmail society, but also that very large firms can tilt the playing field to further their interests at society’s expense.
The saying that what is good for GM is good for the US, if it was ever valid, seems hardly tenable today.
It is, however, one thing to recognize the problem, and another to think about measures to address it.
Firms can be made to internalize the costs they impose on society with appropriate regulation (for example, capital requirements with a systemic charge for financial institutions), but it is not so obvious what to do with “excessive” influence that comes with size.
To limit the size of firms to check the concentration of power is a very blunt instrument – one that highlights the failure of other controls in the democratic process aimed at ensuring that strong lobbies do not end up imposing regulation that is not aligned with social welfare.
But if effective checks and balances are not put in place, nineteenth-century antitrust may be back in fashion sooner rather than later.
SINGAPORE − When the ongoing turmoil surrounding the Iranian elections finally ends, the West is likely to walk away with a simple black and white judgment: the bad guys won.
Of course, the West did the right thing by supporting the good guys, the street demonstrators.
Hence, the West need not bear any responsibility for the outcome.
The tragedy of such thinking is that it does not allow for any moral and political complexity or nuance, yet that is exactly what will be needed if the many problems surrounding Iran are to be resolved.
Moreover, with Mahmoud Ahmadinejad remaining as Iran’s president, the West will once again resort to its usual method of dealing with unfriendly regimes: impose more sanctions.
But this would lead to an even greater tragedy.
The only clear lesson to emerge from Iran’s disputed presidential election is that the country has a vibrant and indeed dynamic civil society.
Many brave Iranians were prepared to risk their lives to defend their beliefs.
Their ability to do so confirms that Iran is not a closed totalitarian state like North Korea.
Despite many years of rule by a theocratic establishment (or perhaps because of it), Iranian minds remain open and engaged.
So there is real hope that Iran can change, modernize, and open up as the rest of Asia has.
Indeed, the only viable long-term strategy to adopt, therefore, is to stop trying to isolate Iran and instead nudge Iranians into engaging more with modern Asia.
In the Iranian worldview, there are three great ancient Asian civilizations: Chinese, Indian, and Persian (with Persia being the greatest).
Iranians expect to perform on par with China and India.
So, while Western hectoring of Iran will not work, when Iranians see their society falling far behind China and India as those countries open up to the world, they may become motivated to reconsider their path.
The more Iranians visit China and India, the more likely that Iran will change.
Similarly, the West should find ways to re-engage with Iranian society, a major obstacle to which is the absence of diplomatic relations between the United States and Iran.
American foreign policy assumes that diplomatic relations with Iran are somehow an act of approval.
In fact, the exact opposite is true.
Diplomacy was invented precisely in order to enable relations between adversaries, not friends.
No one needs diplomatic immunity to talk to their friends.
They need it to talk to their adversaries.
Unfortunately, no US politician appears willing to explain this bit of common sense to the American public.
The US might also learn from other examples.
Many Americans applauded Egyptian President Anwar el - Sadat for his political courage in visiting Jerusalem three decades ago – a decision for which he ultimately paid with his life − even though the vast majority of Egyptians strongly disapproved.
It is useful to recall President Richard Nixon’s words when, prior to restoring diplomatic relations China, he visited Beijing: “We have at times in the past been enemies.
We have great differences today.
What brings us together is that we have common interests which transcend those differences.
As we discuss our differences, neither of us will compromise our principles.
But while we cannot close the gulf between us, we can try to bridge it so that we may be able to talk across it.”
In engaging Iran, the West should ignore the nature of its regime.
It is almost impossible for any outsider to understand Iran’s real internal political dynamics.
Just when the world reached a consensus that Ahmadinejad was merely an instrument of the Supreme Leader, Ayatollah Khamenei, Ahmadinejad appointed a Vice-President against Khamenei’s wishes (though he later retracted the appointment).
What we do know with certainty is that the regime is divided.
These divisions will allow new forces to emerge in Iranian society.
So all means should be found to reach out to Iranian society at all levels.
Iranian students should be encouraged to visit and study in Asian universities, where they would discover how confident young Chinese and Indian students are about the future − which might well cause them to reflect on why young Iranians do not share that optimism.
A final reason for the West to change course is that Western sanctions are proving increasingly useless.
Only 12% of the world’s population lives in the West, and power is slipping steadily away from it.
The July 2009 decision by the Non-Aligned Movement (comprising 118 member states) to hold its next meeting in Tehran provides a powerful demonstration of non-Western perceptions about Iran.
If the West persists with its sanctions, it will not do any good.
It will only make Western leaders feel good.
But what is ultimately more important: doing good or feeling good?
Not since Archduke Franz Ferdinand's assassination has a murder shaken Belgrade as much as the killing of Serbian Premier Zoran Djindjic.
The bullets that killed Djindjic may also have slain Serbian hopes for normalcy at the very moment that we were emerging from the nightmare of Slobodan Milosevic's long misrule.
With the bloody wars of the Yugoslav succession still etched deeply in everyone's minds, does Djindjic's assassination herald the end of an era of political violence or the dawn of a new one?
Milosevic's ouster two years ago was turbulent, but no one was killed.
Serbs were justly proud: a dictatorship was ended in a democratic, peaceful way.
Milosevic's extradition to face charges of war crimes before the Hague Tribunal--a trial that has proceeded without incident in Serbia--was also peaceful.
With relations in the region and with the West approaching something like normalcy, Serbs were beginning to feel, at long last, that they were finding peace with themselves and the world.
Of course, assassinations are nothing new in Serbia.
"Arkan," the leader of the most murderous paramilitary group in the wars in Bosnia and Kosovo, and a political power even after Milosevic's fall, was murdered in Belgrade last year.
Djindjic himself narrowly escaped a highway assassination attempt only last month.
But most Serbs were beginning to believe that the ballot and not the gun was becoming the dominant tool of politics.
Djindjic's effective leadership brought about this change.
Although the most popular politician of the uprising against Milosevic was Vojislav Kostunica, who replaced him as president, it was Djindjic who skillfully coordinated the volatile coalition that opposed the regime.
His boundless energy and quick thinking delivered success from behind the scenes.
As Serbia's prime minister after Milosevic, he resembled a corporate CEO more than the Heidelberg-educated philosophy professor that he was.
Djindjic remained pragmatic, never doctrinaire.
As a result of Serbia's predicament, he accumulated more power than prime ministers typically wield.
Milosevic's regime left behind crippled institutions, with large sections of the police and judiciary and many state-owned companies remaining under the control of Milosevic's clique.
With little trust in existing institutions to implement reforms, Djindjic often took shortcuts, using extra-legal means and improvised parliamentary majorities to push through legislation.
Only prosperity and a "European Serbia" mattered.
Did these short cuts help incite his death?
Who can say?
They certainly did little to build respect for the rule of law.
Yet the immediate consequences of Djindjic's death will be tragic.
He was seen in the West as a reformer, and reform may not proceed without him.
If it does not, urgently needed Western investment won't materialize.
Serbia will again seem a benighted and lawless land.
Although Djindjic was not popular, only extreme nationalists and die-hard Milosevic supporters are cheering.
They regard his murder as just punishment for the "traitor" Djindjic's decision to extradite Milosevic--and other Serbian "heroes"--to The Hague.
The more dangerous outcome is that the assassination may reinforce the belief in Serbia that only authoritarian rule is possible.
Given the prevalence of this belief, Djindjic's death creates a serious power vacuum precisely because his vast personal power was moving Serbia in some of the right directions.
Now, it is feared, organized crime will intimidate his less talented successors.
For now, Serbia's government has imposed a state of emergency.
But effective or quick suppression of the organized criminals who were almost certainly behind Djindjic's murder is unlikely.
The reason for this also explains why Djindjic could not rely on the Serb state to carry out his policies.
Many policemen and intelligence officers are on the crime bosses' payrolls.
The fact that a former president of Serbia, Ivan Stambolic, could disappear without a trace in 1999 is grim testimony to the power of Serbia's criminal underworld.
Indeed, Djindjic may well be a victim of his recent moves to root out organized crime.
He was initially slow in fighting organized crime, because he did not want to alienate the bulk of Milosevic's mafia-infested establishment at once.
He preferred to confront corrupt institutions one at a time as he consolidated his rule.
Sadly, he may also have needed the support of some crime bosses at the outset.
Djindjic's murder will make the fight against crime the country's main political goal.
In this, politicians will at last have something like united public support.
But crime would not be as powerful as it is, and the police and judiciary would not be as corrupt, if Serbia's economy were in better shape.
Serbia is poor and Western aid is desperately needed.
Djindjic's murder shows that the situation is so dire that aid should no longer be strictly conditional on harsh reforms.
For the moment, extreme nationalists and Milosevic supporters may feel triumphant.
But the one certain success of Djindjic's era is that they will never return to power.
Their vision of a chauvinistic, inward-looking Serbia has been discredited, while Djindjic's stance may become more popular due to his martyrdom.
Moments of defeat have always been history's turning points in Serbia.
Once again, Serbs face such a moment.
This time, however, we must resolve to remember Zoran Djindjic's cause--political and economic liberty--more than his blood sacrifice.
Saad Eddin Ibrahim is Egypt's most prominent social scientist--and the most independent-minded in a conformist society ruled by President Hosni Mubarak's authoritarian regime.
For years, Prof. Ibrahim headed the Cairo-based Ibn-Khaldun Institute, which undertook, with the European Union's encouragement, pioneering studies on women and minority rights, as well as electoral practices, in Egypt.
In a country where the President has been consistently re-elected with 97% of the vote since 1980, Ibrahim's institute is the only academic research organization that dares to ask troubling questions about the way Egypt is run.
Two years ago, Prof. Ibrahim, together with practically all of the Ibn-Khaldun Institute staff, were arrested and put on trial before a State Security Court on trumped up charges.
The allegations included financial irregularities, receiving EU funds without the proper ministerial authorization, and "tarnishing Egypt's image."
Prof. Ibrahim was sentenced to seven years imprisonment.
After diplomatic pressure was applied by the United States (through his American-born wife, Prof. Ibrahim holds US citizenship) and the EU, he was granted a re-trial.
This ended days ago with the old verdict reaffirmed: seven years in prison.
Twenty-seven of the Institute's staff members also received jail sentences, and the Institute is now practically destroyed.
Any dictator, from Saddam Hussein to Robert Mugabe, could take pride in this abuse of power.
But because Mubarak regime's is considered moderate, pro-Western, and helpful in the context of Israeli-Palestinian relations, the West's response to this and other abuses remains muted.
Indeed, the US Charge d'Affaires in Cairo expressed mere "disappointment" at the verdict--a response that gives understatement a bad name.
Since the terrorist attacks on New York and Washington last year, America and the EU recognize (or say that they do) that the lack of legitimate channels of opposition in Arab countries pushes people who might otherwise be mere critics of governments into the arms of extreme Islamic fundamentalists.
Saad Eddin Ibrahim is a liberal: he is also a staunch Egyptian and Arab nationalist.
He has vehemently condemned Israeli policies vis-à-vis the Palestinians, and is a critic of many aspects of US foreign policy.
But his has always been the voice of aresponsible opposition.
Indeed, his is the type of voice that Egyptian civil society needs if there is ever to be a chance that the country's Pharaonic authoritarian regime--symbolized by President Mubarak's high-handedness--is to be reformed.
Just because Mubarak's government persecutes Islamic terrorists, and is an ally in the war against fundamentalist extremism, is no reason to give himcarte blanche to repress every attempt to open up Egyptian society.
Western intellectuals, who were instrumental in pressuring the Soviet Union in support of Andrei Sakharov, have been singularly quiet when it comes to Ibrahim.
An Arab intellectual persecuted by an Arab regime, it seems, is nowhere near the top of their agenda.
But it is the EU that is proving most complicit.
After all, it was the EU's effort to stimulate Egyptian civil society with its grant of funds to the Ibn-Khaldun Institute that incited Ibrahim's persecution.
The EU's silence in the face of his arrest and imprisonment is shameful.
For not just Ibrahim, but the values that the EU professes to uphold, have been on trial in Egypt, and they have been mocked by the Mubarak's regime idea of justice.
Europe must work--promptly--to overturn Ibrahim's conviction.
The EU should consider blocking all its educational and cultural programs in Egypt if the verdict on Ibrahim and his associates is not overturned and the Ibn Khaldun Institute not re-opened and restored to full vigor.
Just as the fight for Andrei Sakharov was also a fight for an open society in Russia and thus helped dismantle Communist tyranny, so the fight for Ibrahim's freedom is a fight to put an end to Egypt's oppressive authoritarian regime.
George W. Bush’s disastrous war in Iraq has put Europe in a bind.
The United States long has been Europe’s protector.
Now, because of a war it wanted no part of, Europe finds its security undermined.
Chaos in Iraq has empowered Iran – a much more dangerous country for Europe than Iraq ever was.
And, with America bogged down in Iraq, Russian President Vladimir Putin has resurrected Soviet-style bullying tactics.
Would Russia otherwise have dared to threaten to re-direct its nuclear missiles at European cities?
Not only has Bush destroyed Iran’s most formidable enemy and bogged down US troops in a hopeless cause; he also has enriched energy-abundant Iran and Russia by pursuing a war that has dramatically raised energy prices.
High crude oil prices make it easier for Iran to build nuclear weapons and for Russia to use energy blackmail to threaten Europe.
But Europe can fight back.
By imposing a stiff tax on energy consumption, Europeans would reduce both consumption of energy and its price in world markets, in turn cutting the flow of funds to Russia and Iran.
Because crude oil is priced in US dollars, and the dollar has depreciated against the euro, European consumers have gotten off relatively easy from rising energy prices.
So an energy tax roughly equal to the euro’s 33% appreciation in recent years would be about right.
Europeans might be forgiven for thinking that the Americans, who pumped up oil prices in the first place with their military misadventure in Iraq, should be the ones who “pump it down” with an energy tax.
But, with a “Texas oil man” in the White House, it won’t happen.
Perhaps after 2008, the politics in America will change in favor of an energy tax, but such a tax is needed now.
Besides, given the strength of environmentalism in Europe, the issue is tailor-made for Europeans to take the lead.
Moreover, Europeans do not narrowly equate national security with military spending.
They know that confiscating the checkbooks of Russia and Iran would probably make the world a lot safer than building another submarine or aircraft carrier.
Indeed, an energy tax would not only effectively counter the argument that Europeans are “free riders” when it comes to defense; it would be tantamount to defense leadership.
Still, with the amount of real resources transferred to their governments already high, Europeans might balk at a further increase.
That is why the energy tax must be imposed as a tax substitution, with income or payroll taxes simultaneously reduced to keep real resource transfers to government at a constant level.
This would increase economic growth as well as strengthen national security.
Critics who worry about the cost of the energy tax have not thought about tax substitutions.
They also do not seem to realize that an energy tax is a much cheaper way for Europe to protect itself from Iran and Russia than alternative means, such as a defense buildup.
Europe currently lacks military muscle because it made a decision a half-century ago to be protected by the US and devote the saved resources to building up its welfare state.
This strategy – which worked well for decades – always carried the risk that at some point America’s resources might be tied up elsewhere, leaving Europe under-protected.
That risk materialized with the Iraq war.
But Europeans are showing little taste for increased defense spending, Iraq or no Iraq.
Even France’s new president, Nicolas Sarkozy – thought by many to be a pro-American foreign policy hawk – is backing away from his campaign promise to maintain defense spending at 2% of GDP.
In a recent speech to the French defense industry, Sarkozy conspicuously failed to repeat the pledge, instead warning that he soon might cut France’s defense budget.
According to a respected defense industry publication, Sarkozy changed his mind after his party’s smaller-than-anticipated victory in June’s parliamentary election.
The reason Europeans are reluctant to increase defense spending is expense.
Cutting welfare spending – where the big money is – would be painful.
Solemn promises made over the years would have to be broken (people would not get the social services that they paid for with a lifetime of high taxes), lives would be shortened (less money for hospitals and nursing homes), and overall hardship increased.
Even economic growth will not prevent a tradeoff between defense and welfare spending for Europeans.
Fifty years of defense dependence on the US has created a powerful “peace industry” in Europe whose primary business is to fight defense spending tooth and nail.
They will want to protect all social spending, regardless of the consequences for foreign policy.
A counterweight to the “peace crowd” may be new migrants from Eastern Europe, for whom cuts in social services would break no promises, and for whom job availability and wage levels are more important.
But it will take some time before the new migrants gain decisive political influence, and the problems of Iran and Russia for Europe require immediate attention.
In short, Europeans will not allow Bush’s Iraq war to become a war on their welfare state.
What makes the energy imposed as a tax substitution tax particularly attractive as a defense measure is that it leaves the welfare state intact while making Europe safer, greener, and richer.
Why wait?
Americans, like citizens in countries throughout the world, have come to accept that politics plays an important role in the appointment of certain kinds of public officials.
Few of us are surprised (though some may be disappointed) when a federal judgeship is awarded or a senior diplomat appointed because the candidate passes a litmus test of loyalty to some principle that is important to the President's or Prime Minister's party.
But science, almost everyone agrees, is different, and here the United States is beginning to stand as a cautionary example to the rest of the world.
Scientific appointments should rest on objective criteria of training, ability, and performance.
Clearly, it is legitimate to interrogate a future Secretary of Health and Human Services (HHS) about his views on abortion.
But it is entirely out of place when appointees to scientific advisory committees are subjected to tests of political loyalty.
Similarly, membership of bodies that conduct peer review of scientific proposals - a process that is fundamental to scientific progress - surely ought to be free of all barriers to entry that are unrelated to professional qualifications.
Unfortunately, scientists in the US are running up against such barriers more and more often.
During the past fall, the journalSciencepublished several news stories related to the issue.
One involved the wholesale replacement of members of the advisory committee to the National Center for Environmental Health, a part of the Centers for Disease Control and Prevention (CDC), without consulting the center's director.
Similar cases involved the CDC's Advisory Committee on Lead Poisoning and Prevention, the Advisory Committee on National Human Research Protections, and the Advisory Committee on Genetic Testing.
The current epidemic of ideology, in which advisory committees are shut down and reassembled with new members, and candidates are subjected to loyalty tests, seems old hat to some observers.
Officials at the HHS call it "fairly standard practice."
Well, it isn't standard practice in America - or at least it wasn't.
In any case, what's really worrisome is not that the Bush administration examines candidates for compatibility with its "values."
The most alarming development is how deep the ideological vetting now cuts, invading areas that once were immune to this kind of manipulation.
Indeed, perhaps the most telling case in the widening political epidemic was a membership re-shuffle of the study section at the National Institute of Occupational Safety and Health that evaluates grants for studying workplace injuries.
Advisory committees might have been vulnerable to occasional stacking of this kind in the past.
After all, they recommend the policies that politicians may or may not want to consider.
But study sections?
In October 2002,Sciencepublished an editorial by David Michaels and a group of colleagues.
Several were distinguished former public servants who had been involved with some of the committees in question, and they brought a valuable perspective to the issue, one based on their personal experience.
Their piece was a story in itself, but what followed was even more interesting.
It set off a volley of letters in which scientists told of similar experiences.
A nominee for the National Institutes of Health's Muscular Dystrophy Research Coordinating Committee told of being vetted by a White House staff member.
After being asked about her views on various Bush administration policies, none of them related to the work of the committee, she was asked whether she supports the president's policy on embryonic stem cells.
Another letter writer, a distinguished professor of psychiatry and psychology, reported receiving a call from the White House about his nomination to serve on the National Council on Drug Abuse.
The caller declared that he must vet him to "determine whether he held any views that might be embarrassing to the president."
According to the professor, a series of questions followed, with the White House official keeping a running score.
One example: "You're two for three; the president opposes needle exchange [for intravenous drug users] on moral grounds, regardless of the outcome."
Then the exchange took an even more chilling turn.
The official asked the nominee whether he had voted for Bush, and, on being informed that he had not, asked: "Why didn't you support the president?"
This is the stuff of dictatorship, not democracy.
The purpose of scientific advisory committees is to provide balanced, thoughtful advice to the policy process.
Nothing is gained - and much is lost - when a desired policy outcome is put first.
This is why deciding which research projects to support has always been a matter for objective peer review, not politicians.
In fact, the applicable statute for all this - the Federal Advisory Committee Act - specificallyrequires that committees be balanced and "not inappropriately influenced by the appointing authority."
US Health and Human Services Secretary Tommy Thompson and the White House Personnel Office ought to set an example to the rest of the world.
They can do so very easily: by following the law.
BERLIN – The current economic crisis has exposed two fundamental problems in the design of the European Monetary Union.
The first concerns the sustainability of public finances in a number of euro-zone member states.
Second, inadequate macroeconomic policy coordination has resulted in divergences in the international competitiveness of euro-zone members, threatening the very existence of the euro.
Countries whose public finances seemed fundamentally sound as late as last year have come under severe fiscal pressure.
Ireland’s government debt is expected to rise to almost 80% of GDP by 2010, whereas just a year ago the European Commission projected that Ireland’s government debt would be below 30% of GDP.
Likewise, whereas Spain was expected to decrease its debt ratio, its debt-to-GDP ratio is now likely to double between 2007 and 2010, to more than 60%.
The EU’s fiscal surveillance mechanisms failed to predict these developments because they neglect a crucial variable: the dynamics of private-sector debt.
Given the high economic costs of a banking crisis, governments are likely to take on the liabilities of their financial sector when a crisis hits – as recently occurred in the United Kingdom and Ireland, and in financial crises in Latin America and Asia in the 1990’s.
The same is probably true when key business sectors near insolvency.
A country with sound public finances can thus become a fiscal basket case practically overnight.
Given the increasingly close financial and economic linkages between euro-zone members, rising government debt in even one EMU country can have serious consequences for all members, because no member state will allow another to default.
Thus, EMU members indirectly share the liability for fellow countries’ private-sector debt, which for this reason should be monitored within the EMU’s surveillance framework.
Another apparent problem is that EMU member states – at least until now – do not coordinate their economic policies effectively.
Even before the crisis, this resulted in divergences in competitiveness and in the business cycle.
The persistent loss in competitiveness over the past decade is one reason why the crisis is hitting some southern European EMU countries such as Spain and Italy so hard.
The inefficiency of fiscal-policy control and the lack of economic convergence are a matter of increasing concern to both the European Central Bank and euro-zone finance ministers.
While no initiative for coping with these problems has been tabled so far, the issue is certain to become a matter of debate within the EMU.
One way to tackle the problems associated with government debt, as well as to improve economic policy coordination, is through a simple extension of existing rules: an “External Stability Pact” could be introduced to complement current EMU regulations.
This pact would monitor current-account imbalances and penalize excessive deficits or surpluses in the external account.
Monitoring external balances can be an effective tool to measure future default risks, since sustained current-account deficits lead to a growth in net foreign debt.
Moreover, there is a direct relationship between the EMU countries’ private-sector debt dynamics and their current-account imbalances within the euro zone.
So long as a national government is not running more than a modest deficit, a current-account deficit reflects the private sector’s borrowing from abroad (or the sale of previously accumulated foreign assets).
If the current-account balance is assessed together with the fiscal position, it becomes possible to draw conclusions about risky debt trends within the private sector.
The mathematics of debt dynamics suggest that no euro-zone country should have a current-account imbalance, whether a deficit or a surplus, of more than 3% of GDP.
Exceptions could be granted for countries with large inflows of foreign direct investment in greenfield projects.
The rule should apply both to debtor and creditor countries.
After all, payment imbalances always have two sides, and the burden of adjustment should not be borne only by deficit countries.
Such a pact would oblige governments to use fiscal and wage policies as well as overall economic policy to achieve external balance.
It would also lead to broader economic-policy coordination, particularly with respect to wage-setting, because governments would be compelled to use national legislation and public-sector wage settlements to influence wage policy in such a way that imbalances among euro-zone countries are reduced.
Furthermore, an External Stability Pact would oblige governments to take into account the consequences for other member states when designing national economic reforms.
If a “surplus country” such as Germany wanted to lower non-wage labor costs and increase value-added tax in order to boost its competitiveness, it would simultaneously have to adopt an expansive fiscal policy to compensate for the negative effects on its partners’ foreign trade.
Within the framework of these rules, individual countries would retain the authority to design their policies.
The Spanish government, for example, could have met Spain’s building boom and foreign-trade deficit with tax increases or by urging domestic wage restraint.
Alternatively, it could have intervened by instituting planning regulations or imposing limits on mortgage loans.
An External Stability Pact would not only detect risks to fiscal stability early on; it would also help make a reality of a fundamental principle of EU law, namely that member states finally treat economic policy as a “common interest.”
In his gushing account of President George W. Bush, the former presidential speechwriter David Frum tells us that his boss "scorned the petty untruths of the politician."
We learn, for example, that when asked to prepare a radio broadcast for the following day, he would begin reading, "Today I am in California" and quickly break off, saying with exasperation, "But I'm not in California." Frum thought this a bit pedantic, but concluded that it was emblematic of the President's character and that "the country could trust the Bush administration not to cheat and not to lie."
How wrong Frum now seems.
Bush may naively consider it lying, and therefore wrong, to say that he is in California when he is recording a speech in Washington.
But he fails to see anything gravely wrong about misleading his country and the world concerning Iraq's weapons of mass destruction.
As we have seen, the White House built its case for war on a highly selective dossier of evidence, and Bush made statements about Iraq's attempt to purchase uranium from Africa that he and his staff knew to be highly doubtful, if not false.
When questions were raised about how the statement about uranium was allowed to remain in Bush's State of the Union address, both National Security Advisor Condoleeza Rice and Secretary of Defense Donald Rumsfeld argued that it was not a lie.
Their reasoning indicates that they, like the President, have a childishly literal notion of what it is to lie.
Bush's actual words were these: "The British government has learned that Saddam Hussein recently sought significant quantities of uranium from Africa." Bush's statement took this form because the CIA objected to the original version, which flatly stated that Saddam Hussein had sought to buy uranium from Africa.
The White House staff member who discussed it with the CIA then suggested changing the sentence so that it stated that the British reported that Saddam Hussein hadsought to buy uranium from Africa.
This was literally true, because the British had reported that.
It was nevertheless misleading, for the CIA had informed the British that their information was not reliable.
The fact that Bush only referred to a British statement is the basis for Rice and Rumsfeld's defense of it.
Rice said that "the statement that [Bush] made was indeed accurate.
The British government did say that." Rumsfeld said that Bush's statement was "technically accurate."
In fact, even on the most literal interpretation, Bush's statement was not accurate.
Bush did not say merely that the British had "reported" that Iraq had sought to buy uranium from Africa, but that the British had ``learned'' this.
To say that someone has learned something is to endorse what they say they have learned as true.
Imagine that the British had said that Saddam Hussein was a peace-loving man about to bring democracy to his country.
Would Bush have said that the British hadlearned that?
Quite apart from these weak attempts to justify Bush's statement as "technically accurate," the more serious charge is that even if what Bush said really were technically accurate, it still would have been designed to mislead the world into thinking that Iraq had been trying to buy uranium in Africa.
Bush and his staff had good reason to believe that this was not true.
Bush's response to the issue after it became public shows him to be focused on the trivial and morally reckless about the essential.
A person who is morally sensitive to the seriousness of starting a war on the basis of misleading information would take appropriate steps.
He would ensure that the American public knew how the error occurred, and that whoever was responsible for it suffered the usual consequences that befall senior officials who make what was--to put the best possible interpretation on it--a grave error of judgment.
But Bush did nothing of the sort.
When the issue became public, Bush's response was to condemn his critics as "revisionist historians" and to evade questions about the credibility of the information he had provided by asserting that the removal of Saddam was a good outcome.
Then he said that the CIA had cleared his speech, as if that absolved him of all responsibility.
After CIA Director George Tenet took responsibility for the inclusion of the misleading material, Bush said that he "absolutely" had confidence in Tenet and the CIA, and that he considered the matter closed.
Belief in Bush's honesty led many voters to prefer him to Albert Gore in the 2000 presidential election.
Among voters who rated "honesty" as an important factor influencing their choice of candidate, 80% said that they voted for Bush.
These voters were disgusted with Clinton, not only for his sexual relationship with White House intern Monica Lewinsky, but for lying about it.
That Clinton did lie about his sexual activities is clear, and he was wrong to do so.
But his lies did not lead his country into a war that has cost thousands of lives.
Bush's excessively literal interpretation of the requirements of honesty conceals a deeper dishonesty whose consequences have been far more morally serious.
CAMBRIDGE – What a difference the crisis has made for the International Monetary Fund.
It was just a few months ago that this important but unloved institution, a landmark of post-war global economic arrangements, seemed destined to irrelevance.
The IMF has long been a whipping boy for both left and right – the former because of the Fund’s emphasis on fiscal rectitude and economic orthodoxy, and the latter because of its role in bailing out indebted nations.
Developing nations grudgingly took its advice, while advanced nations, not needing the money, ignored it.
In a world where private capital flows dwarf the resources at its disposal, the IMF had come to seem an anachronism.
And, when some of the IMF’s largest debtors (Brazil and Argentina) began to prepay their debts a few years ago with no new borrowers in sight, it looked like the final nail in the coffin had been struck.
The IMF seemed condemned to run out of income, in addition to losing itsraison d’être.
It shrank its budgets and began to downsize, and, while it was handed some new responsibilities in the meantime – surveillance over “currency manipulation,” in particular – its deliberations proved largely irrelevant.
But the crisis has invigorated the IMF.
Under its capable managing director, Dominique Strauss-Kahn, the Fund has been one of the few official agencies ahead of – instead of behind – the curve.
It moved quickly to establish a fast-disbursing emergency line of credit for countries with “reasonable” policies.
It ardently championed global fiscal stimulus on the order of 2% of world GNP – a position that is all the more remarkable in view of its traditional conservatism on all fiscal matters.
And, in the run-up to the G-20 summit in London, it thoroughly overhauled its lending policies, de-emphasizing traditional conditionality and making it easier for countries to qualify for loans.
Even more significantly, the IMF has emerged from the London meeting with substantially greater resources, as well as new responsibilities.
The G-20 promised to triple the Fund’s lending capacity (from $250 billion to $750 billion), issue $250 billion of new Special Drawing Rights (a reserve asset made up of a basket of major currencies), and permit the Fund to borrow in capital markets (which it has never done) if necessary.
The IMF was also designated as one of two lead agencies – along with an expanded Financial Stability Forum (now renamed the Financial Stability Board) – charged with providing early warning of macroeconomic and financial risks and issuing the requisite policy recommendations. 
Another piece of good news is that the Europeans have now given up their claim on naming the IMF’s managing director (as have the Americans their corresponding claim on the World Bank presidency).
These senior officials are henceforth to be selected “through an open, transparent, and merit-based selection process.”
This will provide for better governance (although Strauss-Kahn’s leadership has been exemplary), and will enhance both institutions’ legitimacy in the eyes of developing nations.
So the IMF now finds itself at the center of the economic universe once again.
How will it choose to deploy its newfound power?
The greatest risk is that it will once again over-reach and over-play its hand.
That is what happened in the second half of the 1990’s, as the IMF began to preach capital-account liberalization, applied over-stringent fiscal remedies during the Asian financial crisis, and single-handedly tried to reshape Asian economies.
The institution has since acknowledged its errors in all these areas.
But it remains to be seen if the lessons have been fully internalized, and whether we will have a kinder, gentler IMF in lieu of a rigid, doctrinaire one.
One encouraging fact is that developing countries will almost certainly get a larger say in how the Fund is run.
This will ensure that poorer nations’ views receive a more sympathetic hearing in the future.
But simply giving developing nations greater voting power will make little difference if the IMF’s organizational culture is not changed as well.
The Fund is staffed by a large number of smart economists, who lack much connection to (and appreciation for) the institutional realities of the countries on which they work.
Their professional expertise is validated by the quality of their advanced degrees, rather than by their achievements in practical policymaking.
This breeds arrogance and a sense of smug superiority over their counterparts – policymakers who must balance multiple, complicated agendas.
Countering this will require proactive efforts by the IMF’s top leadership in recruitment, staffing, and promotion.
One option would be to increase substantially the number of mid-career recruits with actual practical experience in developing countries.
This would make the IMF staff more cognizant of the value of local knowledge relative to theoretical expertise.
Another strategy would be to relocate some of the staff, including those in functional departments, to “regional offices” in the field.
This move would likely face considerable resistance from staff who have gotten used to the perks of Washington, DC.
But there is no better way to appreciate the role of context than to live in it.
The World Bank, which engaged in a similar decentralization a while back, has become better at serving its clients as a result (without facing difficulties in recruiting top talent).
This is an important moment for the IMF.
The international community is putting great store in the Fund’s judgment and performance.
The Fund will require internal reforms to earn that trust fully.
This year’s Nobel Peace Prize justly rewards the thousands of scientists of the United Nations Climate Change Panel (the IPCC).
These scientists are engaged in excellent, painstaking work that establishes exactly what the world should expect from climate change.
The other award winner, former US Vice President Al Gore, has spent much more time telling us what to fear.
While the IPCC’s estimates and conclusions are grounded in careful study, Gore doesn’t seem to be similarly restrained.
Gore told the world in his Academy Award-winning movie (recently labeled “one-sided” and containing “scientific errors” by a British judge) to expect 20-foot sea-level rises over this century.
He ignores the findings of his Nobel co-winners, the IPCC, who conclude that sea levels will rise between only a half-foot and two feet over this century, with their best expectation being about one foot.
That’s similar to what the world experienced over the past 150 years.
Likewise, Gore agonizes over the accelerated melting of ice in Greenland and what it means for the planet, but overlooks the IPCC’s conclusion that, if sustained, the current rate of melting would add just three inches to the sea level rise by the end of the century.
Gore also takes no notice of research showing that Greenland’s temperatures were higher in 1941 than they are today.
Gore also frets about the future of polar bears.
He claims they are drowning as their icy habitat disappears.
However, the only scientific study showing any such thing indicates that four polar bears drowned because of a storm.
The politician-turned-movie maker loses sleep over a predicted rise in heat-related deaths.
There’s another side of the story that’s inconvenient to mention: rising temperatures will reduce the number of cold spells, which are a much bigger killer than heat.
The best study shows that by 2050, heat will claim 400,000 more lives, but 1.8 million fewer will die because of cold.
Indeed, according to the first complete survey of the economic effects of climate change for the world, global warming will actually save lives.
The IPCC has magnanimously declared that it would have been happy if Gore had received the Nobel Peace prize alone.
I am glad that he did not, and that the IPCC’s work has rightfully been acknowledged.
Gore has helped the world to worry.
Unfortunately, our attention is diverted from where it matters.
Climate change is not the only problem facing the globe.
Our blinkered focus on it – to the detriment of other planetary challenges – will only be heightened by the attention generated by Gore’s Nobel Peace Prize.
Gore concentrates above all else on his call for world leaders to cut CO2 emissions, yet there are other policies that would do much more for the planet.
Over the coming century, developing nations will be increasingly dependent on food imports from developed countries.
This is not primarily a result of global warming, but a consequence of more people and less arable land in the developing world.
The number of hungry people depends much less on climate than on demographics and income.
Extremely expensive cuts in carbon emissions could mean more malnourished people.
If our goal is to fight malnutrition, policies like getting nutrients to those who need them are 5,000 times more effective at saving lives than spending billions of dollars cutting carbon emissions.
Likewise, global warming will probably slightly increase malaria, but CO2 reductions will be far less effective at fighting this disease than mosquito nets and medication, which can cheaply save 850,000 lives every year.
By contrast, the expensive Kyoto Protocol will prevent just 1,400 deaths from malaria each year.
While we worry about the far-off effects of climate change, we do nothing to deal with issues facing the planet today.
This year, malnutrition will kill almost four million people.
Three million lives will be lost to HIV/AIDS.
Two and a half million people will die because of indoor and outdoor air pollution.
A lack of micronutrients and clean drinking water will claim two million lives each.
With attention and money in scarce supply, what matters is that we first tackle the problems with the best solutions, doing the most good throughout the century.
If we focus on solving today’s problems, we will leave communities strengthened, economies more vibrant, and infrastructures more robust.
This will enable these societies to deal much better with future problems – including global warming.
Committing to massive cuts in carbon emissions will leave future generations poorer and less able to adapt to challenges.
Gore has an unshakable faith that climate change is the biggest challenge facing the world.
To be fair, he deserves some form of recognition for his resolute passion.
However, the contrast between this year’s Nobel winners could not be sharper.
The IPCC engages in meticulous research where facts rule over everything else.
Gore has a very different approach.
The economic booms in China and India have helped to reduce global inequality.
Over the two last decades, masses of Indians and Chinese have closed the gap (in relative terms) with the rich world.
But, at the same time, many of the world’s truly poor countries have fallen further behind (particularly in Africa, where developments are often described as catastrophic), and inequality within most countries has risen.
Widening inequality has been recorded in the United States (starting with Ronald Reagan’s administration), the United Kingdom (starting with Margaret Thatcher), Russia during its privatization, and more recently in China and India.
These developments seem to add to global inequality.
So, on balance, it seems that global inequality has been relatively stable during the last two decades.
Should anything be done about this?
Many think that no global action to fight economic inequality is necessary.
They argue that only poverty reduction matters.
In the words of Anne Krueger, the Deputy Managing Director of the IMF, “Poor people are desperate to improve their material conditions…rather than to march up the income distribution [ladder].”
Thus, even if the absolute income gap between an average American and an average African increases, why worry?
After all, such people argue, the average African would be a bit less poor.
But this assumes that our income relative to the income of others does not matter.
On the contrary, psychological studies invariably show that people care not only about their absolute income, but also about where they stand in the social pyramid and whether their position is fair.
In the past, a poor African might have looked at his compatriots and resented their wealth; now, both he and his better-off compatriots look at the rich world and resent the huge income gaps they see.
The gaps are most obvious where people from different countries work together, as in many multinational companies. An “expatriate” may be paid ten times more than local staff for the same job.
A wage premium based solely on citizenship is grating.
But even when people do not work together, globalization, by bringing the world to everyone’s living room (or hut), enables them to make much wider comparisons of their living standards.
It erodes the relative security in which the rich world could shelter itself, as in a cocoon.
Now, all can see these income differences.
This is why international action to address both global poverty and global inequality is needed.
Global redistribution through taxes that would be levied by an international body may seem far-fetched today, but the logic of development that we are witnessing – particularly the move away from nation-states as the locus of sovereignty – suggests that it may eventually come to pass.
One such opportunity was missed in the early 1990’s.
When Russia faced its worst crisis, aid was given to the corrupt Yeltsin regime.
But it should have been disbursed directly in cash to the most needy Russians: pensioners whose earnings plummeted due to inflation and economic contraction.
An international organization could have simply used the existing infrastructure of the Russian state to distribute cash grants to some 20 million pensioners – money that would have been much better targeted and spent than by giving the same amount to the government.
If this had been done, Russians would have fondly remembered receiving cash aid from the international community rather than blaming it for transferring funds to corrupt leaders.
But the same or a similar approach could be taken in many countries today, from Angola to Zimbabwe.
The approach is simple and powerful.
It involves three steps: raise money from the globally rich, do not deal with governments, and transfers funds in cash to the poor.
Those who advocate leaving globalization exclusively in the hands of the private sector may resent the idea of vesting tax-raising authority in a global agency.
But they cannot fail to notice that the processes they support undercut their own position by rendering the wealth gap more obvious and the fairness of the actual global distribution more questionable.
They will ultimately realize that their self-interest lies in supporting some form of global action to deal with both poverty and inequality.
CAMBRIDGE – As inflation continues to soar everywhere, maybe the world’s central bankers need a jolt to awaken them from complacency.
How about holding one of their bi-monthly meetings in hyperinflationary Zimbabwe?
It might not be comfortable, but it would be educational.
According to Zimbabwe’s official statistical agency, inflation topped 66,000% in 2007, which looks more like Weimar Germany than modern-day Africa.
While no one is quite certain how the government managed to estimate prices, given that there is virtually nothing for sale in the shops, most indicators suggest that Zimbabwe does have a good shot at breaking world records for inflation.
Of course, curious as they might be, central bankers could decide that meeting in Harare would be too inconvenient and politically unpalatable.
Fortunately, there are lots of other nice – albeit less spectacular – inflation destinations.
Inflation in Russia, Vietnam, Argentina, and Venezuela is solidly in double digits, to name just a few possibilities.
Indeed, except for deflation-ridden Japan, central bankers could meet just about anywhere and see high and rising inflation.
Chinese authorities are so worried by their country’s 7% inflation they are copying India and imposing price controls on food.
Even the United States had inflation at 4% last year, though the Federal Reserve is somehow convinced that most people won’t notice.
Many central bankers and economists argue that today’s rising global inflation is just a temporary aberration, driven by soaring prices for food, fuel, and other commodities.
True, prices for many key commodities are up 25% to 50% since the start of the year.
But if central bankers think that today’s inflation is simply the product of short-term resource scarcities as opposed to lax monetary policy, they are mistaken.
The fact is that around most of the world, inflation – and eventually inflation expectations – will keep climbing unless central banks start tightening their monetary policies.
The US is now ground zero for global inflation.
Faced with a vicious combination of collapsing housing prices and imploding credit markets, the Fed has been aggressively cutting interest rates to try to stave off a recession.
But even if the Fed does not admit it in its forecasts, the price of this “insurance policy” will almost certainly be higher inflation down the road, and perhaps for several years.
America’s inflation would be contained but for the fact that so many countries, from the Middle East to Asia, effectively tie their currencies to the dollar.
Others, such as Russia and Argentina, do not literally peg to the dollar but nevertheless try to smooth movements.
As a result, whenever the Fed cuts interest rates, it puts pressure on the whole “dollar bloc” to follow suit, lest their currencies appreciate as investors seek higher yields.
Looser US monetary policy has thus set the tempo for inflation in a significant chunk – perhaps as much as 60% – of the global economy.
But, with most economies in the Middle East and Asia in much stronger shape than the US and inflation already climbing sharply in most emerging-market countries, aggressive monetary stimulus is the last thing they need right now.
The European Central Bank is staying calm for the moment, but it, too, is probably holding back on interest-rate hikes partly out of fear of driving the euro, already at record levels, even higher.
And the ECB worries that if the US recession proves contagious, it may have to turn around and start slashing rates anyway.
So what happens next?
If the US tips from mild recession into deep recession, the global deflationary implications will cancel out some of the inflationary pressures the world is facing.
Global commodity prices will collapse, and prices for many goods and services will stop rising so quickly as unemployment and excess capacity grow.
Of course, a US recession will also bring further Fed interest-rate cuts, which will exacerbate problems later.
But inflation pressures will be even worse if the US recession remains mild and global growth remains solid.
In that case, inflation could easily rise to 1980’s (if not quite 1970’s) levels throughout much of the world.
Until now, most investors have thought that they would rather risk high inflation for a couple of years than accept even a short and shallow recession.
But they too easily forget the costs of high inflation, and how difficult it is to squeeze it out of the system.
Maybe they, too, should try holding a few conferences in Zimbabwe, and get a reality check of their own.
Terrorism is an existential threat.
In our European Security Strategy, it was deemed one of the key strategic threats facing the European Union, and to fight it we are using all instruments at our disposal, particularly in the intelligence area.
The first objective of intelligence is to find terrorists, prevent them from acting, and track them after they do attack.
This is the kind of operational intelligence that is best done at the national level.
Many arrests and disruptions of terrorist operations in Europe result from cooperation between EU members' intelligence services.
I was recently asked by journalists whether inter-agency cooperation is sufficient and whether European mechanisms for sharing operational intelligence should be created.
Later that very day, a joint operation resulted in simultaneous arrests in five European countries.
The operation's success was no accident.
Last year, the Union concluded two Europol agreements, as well as an Extradition and Mutual Legal Assistance Agreement.
Europe's security services are working closely together within the Counter-Terrorist Group, and Europol's Counter-Terrorist Task Force has been re-established.
A high-level group on border and transport security is at work, and links between member states' police chiefs are strengthening.
But widespread sharing is not always needed or appropriate.
Member states also need intelligence derived from ongoing casework, not to inform policy, at least not directly, but to disrupt and dismantle networks and prevent attacks.
This information is in many ways more sensitive, and services share it on a "need to know" basis, not for the sake of promoting cooperation.
I see another role for intelligence: to inform political action.
Intelligence services can educate the public, explaining the origins of the alienation that underpins terrorism, how radicalization and recruitment occur, and highlight terrorists' goals, methods, and targeting strategies.
Only when we understand this can we develop appropriate and concrete policies.
For this we need good strategic assessments of intelligence.
The EU's members have structures to provide this, and with their support and input we are building structures at a Europe-wide level, to bring this information to EU policymakers.
Europol is performing a similar function with material derived from police work, and we are working to ensure synergy between these two efforts.
This is a different level of intelligence, more analytical, where close collaboration adds significant value.
In the aftermath of the Madrid bombings, the EU focused on internal aspects of the fight against terrorism.
But this does not mean that the Union has become introverted.
On the contrary, the EU regards international cooperation as fundamental in the fight against terrorism.
Generally, counter-terrorism is very high on our international agenda and is becoming better integrated into the Union's political dialogue with other countries.
We are better targeting our external assistance and capacity building programs, and we are ready to use our trade and economic muscle, when necessary, by demanding counter-terrorism clauses in bilateral treaties.
There has also been a sea change in transatlantic cooperation between the EU and the US.
Deeds speak louder than words, and deeds on the transatlantic level have been swift and decisive - for example, joint efforts aimed at choking off terrorist financing - even when we had strong divergences over Iraq.
Still, I am not complacent.
To facilitate the extremely complex task of counter-terrorism policymaking in the EU, we now have a Plan of Action, approved by the European Council, which clearly specifies who does what, and by when.
This will also help national parliaments understand EU objectives and facilitate their legislative planning.
I have recently appointed a counter-terrorism coordinator to assist me in following through on the Plan of Action.
We also have a considerable number of new instruments in the area of justice and home affairs.
The European Arrest Warrant is already producing concrete results, and we are moving towards the "free movement of judicial decisions" in the EU, through which judicial decisions - such as arrest and surrender of suspects, confiscation, and freezing of assets - will be mutually recognized.
Furthermore, the European Border Agency will become operational in 2005.
As requested by the European Council, I am developing, in cooperation with the European Commission, a strategy to shut down terrorist financing.
This is where the real test of cooperation lies, for our success will rely on securing the appropriate interaction and flow of intelligence between the relevant services and the financial and banking communities.
I firmly believe that the military option alone cannot defeat terror.
Judicial, police, and intelligence cooperation should be the focal point for action.
This does not mean that we are not working on how European Security and Defense Policy (ESDP) can offer a meaningful contribution.
But ESDP is not at the core of our efforts.
Aside from security and intelligence efforts, we must also work to deny "oxygen" to the terrorists.
This means addressing the factors that contribute to support for and recruitment by terrorist groups.
Regional conflicts cause anger and resentment.
The unresolved Arab-Israeli problem leads to the rise of radicalism and extremism.
There is entirely too much fuel for terrorist propaganda.
The EU will be tough on terrorism.
But it must also be tough on the causes of terrorism.
These are not two fights, but one.
NEW DELHI – Among the many international consequences of Barack Obama’s stunning victory in the United States is worldwide introspection about whether such a breakthrough could happen elsewhere.
Could a person of color win power in other white-majority countries?
Could a member of a beleaguered minority transcend the circumstances of his birth to lead his or her country?
While many analysts in a wide variety of nations, especially in Europe, have concluded that such an event could not occur there in the foreseeable future, India is an exception.
Minority politicians have long wielded authority, if not power, in its various high offices.
Indeed, India’s last general election, in 2004, was won by a woman of Italian heritage and Roman Catholic faith (Sonia Gandhi) who made way for a Sikh (Manmohan Singh) to be sworn in as Prime Minister by a Muslim (President Abdul Kalam) in a country that is 81% Hindu.
Not only could it happen here, Indians say, it already has.
Such complacency is premature.
The closest Indian analogy to the position of black Americans is that of the Dalits – formerly called “Untouchables,” the outcastes who for millennia suffered humiliating discrimination and oppression.
Like blacks in the US, Dalits account for about 15% of the population; they are found disproportionately in low-status, low-income jobs; their levels of educational attainment are lower than the upper castes; and they still face daily incidents of discrimination for no reason other than their identity at birth.
Only when a Dalit rules India can the country truly be said to have attained its own “Obama moment.”
In theory, this already has happened: K. R. Narayanan, born into a poor Dalit family, served as India’s president, the highest office in the land, from 1997 to 2002.
But the Indian Presidency is a largely ceremonial position: real power is vested in the office of prime minister, and no Dalit has come close to holding that post.
Since independence in 1947, a majority of India’s prime ministers have been Brahmins, the highest Hindu caste.
Yet the next national elections, due before May 2009, may produce a plausible Dalit contender for the job of prime minister – Kumari Mayawati, the female chief minister of India’s largest state, Uttar Pradesh.
Since 1991, no Indian governing party has enjoyed a secure parliamentary majority on its own, necessitating multi-party coalition governments.
The current Congress Party-led government of Manmohan Singh comprises 20 parties; it succeeded a 23-party coalition headed by the Bharatiya Janata Party’s Atal Bihari Vajpayee.
When the election results are declared next year, no one doubts that the first challenge will be to cobble together another coalition.
Both the Congress and the BJP will seek to make alliances with the dozens of smaller parties likely to be represented in parliament.
But this time they are likely to face a third alternative: Mayawati, whose Bahujan Samaj Party (BSP) may command a bloc of at least 50 seats.
She has publicly expressed her disdain for both large national parties; she would much rather lead a coalition than join one.
And if the electoral numbers break down right, she could conceivably assemble a collection of regional and left-wing parties and stake a claim to rule India.
This is a remarkable development: the idea that a Dalit woman could lead India has been inconceivable for 3,000 years.
But India’s democracy has opened new pathways to empowerment for its underclasses.
The poor and the oppressed may not have much, but they do have the numbers, which is what matters at the ballot box.
Dalits and India’s aboriginals (listed in the Constitution as “Scheduled Castes and Tribes”) are entitled to 85 seats in India’s 543-member parliament that are “reserved” for candidates from their communities.
Mayawati’s shrewd alliances, including with some members of the upper castes, which propelled her to power in Uttar Pradesh, give her party a fighting chance to win a number of other seats as well.
In a coalition-dependent parliamentary system, that could be all she needs to become prime minister.
The daughter of a government clerk, Mayawati studied law and worked as a teacher before being spotted by the BSP’s founder, the late Kanshi Ram, and groomed for political leadership.
Her ascent has been marked by a heavy emphasis on symbolism – her rule in Uttar Pradesh has featured the construction of numerous statues of Dalit leaders, notably herself – and a taste for lavish celebrations.
Mayawati’s weakness for “bling” has been demonstrated at her extravagant birthday parties, which she presides over laden with diamonds, saying (rather like Evita Peron) that her luster brings glamour and dignity to her people.
She takes pride in being the Indian politician who pays the highest income taxes – about $6 million last year – though the sources of her income are shrouded in controversy.
She has been accused, but not convicted, of corruption several times, with one notable case involving the construction of an elaborate shopping complex near the Taj Mahal, in violation of zoning laws.
Critics argue that Mayawati’s promotion of Dalit welfare seems to start with herself.
But there is no denying that her rise to power in India’s largest state, which sends 80 members to parliament, has given her a vital platform to bid for India’s most powerful job.
With her diamonds and her statues, and a reputation for dealing imperiously with her subordinates, she’s clearly no Obama.
But if she succeeds, she will have overcome a far longer legacy of discrimination.
WARSAW – Had the August 1991 putsch against Mikhail Gorbachev not failed, the riots and death recently seen in Xinjiang could have been taking place in Russia.
Instead of hearing about a crackdown in Urumqi, Xinjiang’s capital, we might be reading about hundreds killed on the streets of Almaty, and columnists would be making comparisons to the bloody crushing of Ukrainian independence demonstrations in Lvov the previous year.
As with China today, there would have been some feeble international condemnation, and some speculation about possible links between Kazakh militants and exile groups, or Islamic fundamentalists.
Experts would remind us that Kazakhstan had never been a country, and that Ukrainian claims to independence are historically dubious.
Substitute Xinjiang for Kazakhstan and Tibet for Ukraine and you get the picture.
But that putsch, thankfully, ended as a farce.
The decaying Soviet regime was unable to crush Russia’s growing democratic movement – it would take Vladimir Putin to do that a decade later.
By opting for the Tiananmen Square massacre in 1989, the Chinese Communist leadership set their country on a road starkly different from the one on which Russia subsequently embarked.
Though China’s policies have brought about Pinochet-style economic growth, if on the scale of a country that is almost a continent unto itself, they have also ensured that there is in no freedom for anyone, including the Han majority.
This, in turn, means that, while Kazakhstan and Ukraine are independent, Tibet and Xinjiang alternate between phases of violent agitation and bloody repression.
Though Russia today is autocratically governed, the introduction of a Chinese-style dictatorship seems hardly plausible, while GDP per capita was $15,800 last year, or almost three times that of China.
Yet a majority of the Chinese population seems to support its’ government’s policies, including its brutal suppression of minorities and denial of democratic freedoms.
In fact, the latter seems to be the price paid for the success of the former.
This is not a novel phenomenon.
In 1863, the Russian democratic émigré thinker Alexander Herzen, commenting on the brutal crushing of the Polish uprising by the Tsarist army, wrote in his publicationKolokol that acceptance of violence on the streets of Warsaw meant the acceptance of violence on the streets of St. Petersburg.
Oppression is a package deal.
His comments cost him his Russian readership, andKolokol had to close down.
When Herzen was writing his words, Moscow was not only busy successfully putting down the Poles, reasserting its rule there for another half-century, but also, together with China, carving up Central Asia, known then as Turkestan.
The eastern part of the region fell under Chinese rule, and was renamed Xinjiang, or New Frontier.
Each time Chinese rule weakened, as in the 1930’s and 1940’s, short-lived East Turkestan Republics were established, with Russian support, only to flounder when Russia and China struck new deals.
The leadership of the second East Turkestan Republic was presumably murdered on Stalin’s orders, when the plane carrying it to Beijing for talks allegedly crashed in Soviet airspace.
Since then, East Turkestan has existed solely on paper, as a member of the Unrepresented Nations and Peoples Organization (UNPO), a would-be competitor of the United Nations set up in 1991.
In Xinjiang itself, the current agitation is more social than nationalist in character, and targets cultural oppression (Han Chinese by now make up half of the region’s population) rather than expressing aspirations for independence.
Yet the recent bloodbath there is almost sure to change that, as violence unavoidably breeds radicalization.
In the short and medium term, China’s rule in Xinjiang and Tibet seems secure: the international community will not challenge a Security Council member state.
Only its own citizens could do that, but Herzen’s package deal seems to prevent that: just like the Tibetans, the Uighurs elicit not Han solidarity, but a braying for their blood – somewhat understandable, given that ordinary Han in Lhasa and Urumqi were made to pay with their own for China’s misdeeds.
In the longer term, however, the Chinese authorities have every reason to be worried: Xinjiang will grow to be a problem like Tibet.
Indeed, though the UNPO, to which both belong – alongside Assyria and the Buffalo River Dene Nation – has a vaguely Marx Brothers’ air to it (one expects Freedonia, the mythical country of which Groucho Marx was prime minister, to be on the roster), six member states already have left it to join the UN, and Kosovo, now independent if lacking UN recognition, will eventually follow.
Political maps are never carved in stone.
It is therefore safe to assume that not only obscure academics and correspondents, but officials in Beijing as well, are now busy studying the history of the Ghulja uprising and of Osman Batur’s guerillas.
Come to think of it: whatever happened to the Poles, whom Russia so successfully put down in 1863?
Dear Mr. Olmert,
I am writing you in the hope that you will take time from your busy schedule as Israel’s acting Prime Minister to hear one Palestinian’s hopes.
Even though your ascension to the position of Prime Minister came in an awkward way because of Ariel Sharon’s stroke, I believe that you have an opportunity to be part of a historic reconciliation.
While I am sure you will insist that you are going to follow in the political legacy of Sharon, you have some important advantages with Palestinians that Sharon did not have.
The first advantage is that you’re not burdened with Ariel Sharon’s negative image among Palestinians and Arabs.
Having been the mayor of Jerusalem for 10 years, you know the situation of Palestinians close up.
I believe that the chances for a political breakthrough in our region have never been better.
On the Israeli side, your faith in the political process was demonstrated recently when you and Sharon decided unilaterally to go against your own ideology and take on the powerful settler movement.
The two of you also went against conventional Israeli thinking by breaking away from your Likud party, greatly weakening the ideological stranglehold that Likud’s far-right central committee held on Israeli politics.
The realization that withdrawal from populated areas, and thus an end to holding another people under permanent occupation, was necessary to preserve the Jewish nature of Israel clearly brought the two of you to the center of Israeli thinking.
On a much smaller scale, significant change has been taking place on the Palestinian side as well.
While I believe that the occupation, rather than the reaction to it, is the main cause of our conflict, the unilateral tahdia (“declared calm”) decision by Palestinian militant groups has reduced anti-Israeli attacks mightily, which shows that Palestinians also realize the limits of their military actions.
The decision by Hamas to join the political process by participating in the upcoming legislative elections shows that even this hardline Islamic movement has concluded that our conflict needs to be addressed by political rather than military means.
While I understand that you are an Israeli patriot, I believe that much can be done to reduce the tensions between our two peoples, eventually leading to genuine reconciliation and peace.
As a start, priority must be given to face-to-face negotiations.
Sharon and you might have felt that unilateral action was needed in Gaza, but the withdrawal from Gaza could have produced many more benefits for both sides had it been done bilaterally.
Direct talks should concentrate on two parallel tracks.
They should attempt to produce an immediate cessation of violence from both sides while simultaneously focusing on a permanent settlement of our conflict.
Contrary to territorial withdrawal, cessation of violence can be achieved only bilaterally.
Both sides should commit to an end to assassinations, shelling, bombings, and any other form of attacks on the other side’s military targets and citizens.
To be effective, such a cease-fire must contain a monitoring mechanism.
Neutral foreign observers should be asked to be deployed in major hot spots and be asked to identify anyone on either side who violates any of the agreement’s clauses.
Alongside this effort, vigorous negotiations on a permanent settlement should start immediately.
Historically, cease-fires have survived only when they are backed by talks that both parties believe are genuine and serious.
At the same time, the atmosphere among Palestinians and their attitude towards Israel must be improved, so that we can have a political environment that supports negotiations.
Improving the daily conditions of life, particularly increasing Palestinians’ freedom of travel both between Gaza and the West Bank and within the West Bank, will also go a long way in helping to create a positive atmosphere.
I truly wish you success in your responsibilities as acting Prime Minister and acting head of Kadima.
Your efforts to move forward towards resolving the Palestinian-Israeli conflict will generate significant improvement in the political atmosphere in the entire Middle East.
But, whatever you do in the next few months to win the forthcoming parliamentary elections, please remember that the support that Kadima has received from the Israeli public derives precisely from the fact that it has taken a moderate centrist position.
So please don’t allow yourself to be drawn into pandering to Israel’s radicals and hawks.
The support that you and your colleagues will get from Israelis and Arabs will depend on the resolve that you show in making serious progress in the peace process.
That process, now as before, must culminate in an independent and democratic Palestine alongside a safe and secure Israel.
STANFORD – Well, America is involved at last.
President Barack Obama has dispatched Senator John Kerry to Sudan with a proposal for peace between the country’s North and South.
It’s a giant step toward avoiding the kind of bloodshed that killed more than two million people in Sudan’s previous 20-year North-South civil war, which ended only in 2005 – and is threatening to erupt once again.
In recent months, Obama has stepped up his own involvement and that of senior figures in his administration in support of a peace strategy for Sudan.
On his behalf, Kerry has delivered a package of proposals designed to break the logjam that has brought the North and South to a dangerous crossroads.
We have written a memo that spells out some of the essential elements of what a grand bargain for peace in Sudan could look like.
If you’re interested in the specifics of a possible peace deal – and in actions that you can take to support it – go to www.sudanactionnow.org.
There is little time to waste.
On January 9, 2011, the people of Southern Sudan will vote for independence from the North, taking with them up to three-quarters of the country’s known oil reserves and placing millions of civilians in the direct path of war.
The government in Khartoum (the capital in the North) is led by Omar al-Bashir, whose accomplishments, which include overseeing war crimes during the previous North-South war and engineering the atrocities in Darfur, have brought him arrest warrants for war crimes and genocide from the International Criminal Court.
And yet renewed war in Sudan is not inevitable.
A complex but workable peace can be brokered if all interested parties become more deeply involved.
The current moment requires robust diplomacy – the kind that can leave a bad taste in your mouth, but that gets the job done.
We believe that Kerry is a skilled emissary and can help the parties find the compromises necessary for peace.
Any agreement preventing a return to war would necessarily involve the National Congress Party, representing the North, and the Sudan People’s Liberation Movement, representing the South.
But it would also involve the United States, whose post-referendum relationship with the two parties will have enormous influence over whether a deal gets done.
We believe that a grand bargain to lay the foundation for lasting peace between the North and South would oblige the parties to:
·        hold the Southern Sudan referendum on time and fully respect and implement the results;
·        reach a mutually satisfactory agreement concerning the territory of Abyei, a key disputed border area;
·        craft a multi-year revenue-sharing arrangement in which the oil wealth of Abyei and key border areas could be divided equitably between the North and South, with a small percentage going to the Arab Misseriya border populations for development purposes;
·        demarcate the uncontested 80% of the border and refer the remaining 20% to binding international arbitration;
·        create serious protections for minority groups, with consideration of joint citizenship for certain populations, backed by significant international consequences for attacks on southerners in the North or northerners in the South.
The US role as the invisible third party to the agreement involves a series of incentives offered to the regime in Khartoum to ensure agreement and implementation of a peace deal.
In exchange for action on the North-South and Darfur peace efforts, the US would implement a clear, sequenced, and binding path to normalization of relations.
This would involve – in order – removal of Sudan from the State Sponsors of Terrorism list, exchange of ambassadors, lifting of unilateral sanctions, and support for bilateral and multilateral debt relief, together with other economic measures by international financial institutions.
Conversely, the US must be prepared to lead international efforts to impose severe consequences on any party that plunges the country back into war.
Peace and security in Darfur should be an essential benchmark for normalized relations between the US and Sudan.
The Obama administration should hold firm on this through the coming rounds of negotiation, and should appoint a senior official to help coordinate US policy on Darfur in order to ensure that peace efforts there receive the same level of attention as the North-South efforts.
What is needed now is political will – and not only in the US – to sustain this diplomacy.
The European Union and Sudan’s neighbors – in particular Egypt, Ethiopia, Kenya, and Uganda – will also need to play a robust role.
And China’s diplomacy in Sudan, where it has invested massively in developing the country’s oil resources, will be a test of whether or not it intends to be a responsible stakeholder in Africa and the wider world.
Ensuring that governments work toward peace is where you come in.
Keep the pressure on them.
Support the peace process.
Your voice can prevent a war.
Not guns.
Not money.
Just our voices.
The way to peace in Sudan is not simple, but it is achievable.
There are hard choices to be made.
We can make those choices now, or we can persuade ourselves that peace is too hard or too complex, and then look on resignedly from the sidelines as hundreds of thousands of innocent men, women, and children needlessly die.
It’s up to us.
Why did high_tech stock market values fall so far in the last year-and-a-half?
What does the crash of the NASDAQ (and of smaller IT exchanges around the world) tell us about the future of the "new economy"?
As we move away from those events, a clearer assessment is possible.
Conventional wisdom holds that the NASDAQ crash exposed the "new economy" as a conjuring trick of smoke and mirrors.
It incarnated the irrational exuberance that often breaks out as a boom peaks and did not deliver deeper permanent changes in the economy.
A more likely explanation, however, is that the NASDAQ crashed because it became clear that dominant market positions in high tech_based businesses were not sources of profits unless accompanied by substantial barriers to entry for new potential competitors--and that such barriers to entry were becoming remarkably hard to create.
Over a wide range of activities, the dominant effect of the "new economy" has been to make competition more effective, not to create new advantages based upon economies of scale.
The high-tech crash was thus the result of a realization by investors that the "new economy" was, in most sectors and for most firms, unlikely to lead to large quasi_rent type profits from established market positions, but rather to heightened competition and reduced margins.
The exuberance that pushed the NASDAQ so high in 1999 and early 2000 rested on the belief that a technological leap forward in data processing and data communications technologies had created a host of "winner_take_all" markets in which increasing returns to scale were the dominant feature.
An information good--a computer program, a piece of online entertainment, or a source of information--needs to be produced only once and can then be distributed to a potentially unlimited number of consumers at very little (if any) additional cost.
The larger the market, the larger the cost advantage.
Moreover, information goods produced at larger scale are also more valuable to consumers.
The version with the largest market share becomes the standard; it is the easiest to figure out how to use, the easiest to find support for, and the one that works best with other products (which are, of course, designed to work best with it).
In the section of the "new economy" dominated by producers' economies of scale and consumers' economies of scope, a firm that establishes a lead in market share gains a nearly overwhelming advantage.
Unless its competitors take extraordinary and extraordinarily costly steps--like those taken by Microsoft against Netscape, its rival in the Internet browser market, by pouring a fortune into creating its Internet Explorer and then distributing it for free--the first firm to establish a dominant market position will reap high profits as long as its sector of the industry lasts.
But increasing returns to scale and winner_take_all markets are not the only, or even the primary, consequence of the IT revolution.
It is at least as likely that innovations in computer and communications technologies are competition's friends because they eliminate the frictions that in the past gave nearly every producer a little bit of monopoly power.
In the past you could comparison_shop only by trudging from store to store.
Today you can use the World Wide Web to conduct instant searches that can reveal the prices and qualities of every single producer.
Firms must adjust instantaneously or perish in the process.
Thus the "new economy" makes most markets more, not less, contestable.
A competitive edge based on past reputation, brand loyalty, or advertising footprints will fade away.
As they do, profit margins will fall: competition will become swifter, stronger, more pervasive, and more nearly perfect.
Consumers will gain and shareholders will lose.
Those products that can be competitively supplied will be supplied at very low margins.
The future of technology is bright; the future of the profit margins of businesses--save for those few that truly are able to use economies of scale to create mammoth cost advantages--is dim.
Is it really possible to acquire significant economies of scale by writing a single suite of software that will cover the heterogeneous purchasing requirements of millions of businesses seeking to streamline their operations by using the Internet?
Is it really possible to obtain significant economies of scale by using the Internet to distribute information about groceries?
The NASDAQ crash was the result of realization by marginal investors that the odds were heavily against this.
But the NASDAQ crash tells us next to nothing about the future of the underlying technologies, or about their true value.
Perhaps the best analogy is an old puzzle posed by the classical economists three centuries ago: why is there such a difference between the price of water and the price of diamonds?
Water is absolutely essential to sustain life, and thus immensely valuable to every consumer.
Yet water is cheap.
Diamonds, by contrast, have been and remain expensive.
The gap in price does not tell us that diamonds are useful and valuable and water is not, but that it has so far proved easier to maintain market power and high margins in the diamond business than in the water business.
The analogy to the Internet, the "new economy," and the crash of the NASDAQ is straightforward.
Even Internet Explorer, which today has as dominant a position in the browser market as anyone could wish to have, is not (or is not yet) a source of profits, and will not be, barring the creation of some essential function that Internet Explorer can serve and competing browsers cannot.
Our modern computer and communications technologies simply make it too cheap and too easy to distribute a competing product.
So, what NASDAQ's crash tells us is that the new economy is more likely to be a source of downward pressure on profit margins than of large, durable quasi_rents.
BERKELEY – Getting out of our current financial mess requires understanding how we got into it in the first place.
The fundamental cause, according to the likes of John McCain, was greed and corruption on Wall Street.
Though not one to deny the existence of such base motives, I would insist that the crisis has its roots in key policy decisions stretching back over decades. 
In the United States, there were two key decisions.
The first, in the 1970’s, deregulated commissions paid to stockbrokers.
The second, in the 1990’s, removed the Glass-Steagall Act’s restrictions on mixing commercial and investment banking.
In the days of fixed commissions, investment banks could make a comfortable living booking stock trades.
Deregulation meant competition and thinner margins.
Elimination of Glass-Steagall then allowed commercial banks to encroach on the investment banks’ other traditional preserves.
In response, investment banks branched into new businesses like originating and distributing complex derivative securities.
They borrowed money and put it to work to sustain their profitability.
This gave rise to the first causes of the crisis: the originate-and-distribute model of securitization and the extensive use of leverage.
It is important to note that these were unintended consequences of basically sensible policy decisions.
Other things being equal, deregulation allowed small investors to trade stocks more cheaply, which made them better off.
But other things were not equal.
In particular, the fact that investment banks, which were propelled into riskier activities by these policy changes, were entirely outside the regulatory net was a recipe for disaster.
Similarly, eliminating Glass-Steagall was fundamentally sensible.
Conglomerates allow financial institutions to diversify their business, and combining with commercial banks allows investment banks to fund their operations using relatively stable deposits instead of fickle money markets.
This model has proven its viability in Europe over a period of centuries, and its advantages are evident in the US even now with Bank of America’s purchase of Merrill Lynch.
But conglomeratization takes time.
In the short run, Merrill, like the other investment banks, was allowed to double up its bets.
It remained entirely outside the purview of the regulators.
As a stand-alone entity, it was then vulnerable to market swings.
A crisis sufficient to threaten the entire financial system was required to precipitate the inevitable conglomeratization.
The other element in the crisis was the set of policies that gave rise to global imbalances.
The Bush administration cut taxes.
The Fed cut interest rates in response to the 2001 recession.
Financial innovation, meanwhile, worked to make credit even cheaper and more widely available.
This, of course, is just the story of subprime mortgages in another guise.
The result was increased US spending and the descent of measured household savings into negative territory.
Of equal importance were the rise of China and the decline of investment in Asia following the 1997-1998 financial crisis.
With China saving nearly 50% of its GNP, all that money had to go somewhere.
Much of it went into US treasuries and the obligations of Fannie Mae and Freddie Mac.
This propped up the dollar and reduced the cost of borrowing for US households, encouraging them to live beyond their means.
It also created a more buoyant market for the securities of Freddie and Fannie, feeding the originate-and-distribute machine.
Again, these were not outright policy mistakes.
Lifting a billion Chinese out of poverty is arguably the single most important event in our lifetimes.
The fact that the Fed responded quickly prevented the 2001 recession from worsening.
But there were unintended consequences.  The failure of US regulators to tighten capital and lending standards when abundant capital inflows combined with loose Fed policies ignited a furious credit boom.
The failure of China to move more quickly to encourage higher domestic spending commensurate with its higher incomes added fuel to the fire.
Now, a bloated financial sector is being forced to retrench.
Some outcomes, like the marriage of Bank of America and Merrill Lynch, are happier than others, like the bankruptcy of Lehman Brothers.
But, either way, there will be downsizing.
Foreign central banks are suffering capital losses on their unthinking investments.
As they absorb their losses on US treasury and agency securities, capital flows toward the US will diminish.
The US current-account deficit and the Asian surplus will shrink. US households will have to start saving again.
The one anomaly is that the dollar has strengthened in recent weeks.
With the US no longer viewed as a supplier of high-quality financial assets, one would expect the dollar to have weakened.
The dollar’s strength reflects the knee-jerk reaction of investors rushing into US treasuries as a safe haven.
It is worth remembering that the same thing happened in August 2007, when the sub-prime crisis erupted.
But once investors realized the extent of US financial problems, the rush into treasuries subsided, and the dollar resumed its decline.
Now, as investors recall the extent of US financial problems, we will again see the dollar resume its decline.
Emphasizing greed and corruption as causes of the crisis leads to a bleak prognosis.
We are not going to change human nature.
We cannot make investors less greedy.
But an emphasis on policy decisions suggests a more optimistic outlook.
Unintended consequences cannot always be prevented. Policy mistakes may not always be avoidable.
But they at least can be corrected.  That, however, requires first looking more deeply into the root causes of the problem.
NEW YORK – A vicious circle is currently underway in the United States, and its reach could broaden to the global economy.
America’s financial crisis has triggered a severe credit crunch that is making the US recession worse, while the deepening recession is leading to larger losses in financial markets – thus undermining the wider economy.
There is now a serious risk of a systemic meltdown in US financial markets as huge credit and asset bubbles collapse.
The problem is no longer merely sub-prime mortgages, but rather a “sub-prime” financial system.
The housing recession – the worst in US history and worsening every day – will eventually see house prices fall by more than 20%, with millions of Americans losing their homes.
Delinquencies, defaults, and foreclosures are now spreading from sub-prime to near-prime and prime mortgages.
Thus, total losses on mortgage-related instruments – include exotic credit derivatives such as collateralized debt obligations (CDOs) – will add up to more than $400 billion.
Moreover, commercial real estate is beginning to follow the downward trend in residential real estate.
After all, who wants to build offices, stores, and shopping centers in the empty ghost towns that litter the American West?
In addition to the downturn in real estate, a broader bubble in consumer credit is now collapsing: as the US economy slips into recession, defaults on credit cards, auto loans, and student loans will increase sharply.
US consumers are shopped-out, savings-less, and debt-burdened.
With private consumption representing more than 70% of aggregate US demand, cutbacks in household spending will deepen the recession.
We can also add to these financial risks the massive problems of bond insurers that guaranteed many of the risky securitization products such as CDOs.
A very likely downgrade of these insurers’ credit ratings will force banks and financial institutions that hold these risky assets to write them down, adding another $150 billion to the financial system’s mounting losses.
Then there is the exposure of banks and other financial institutions to rising losses on loans that financed reckless leveraged buy-outs (LBOs).
With a worsening recession, many LBOs that were loaded with too much debt and not enough equity will fail as firms with lower profits or higher losses become unable to service their loans.
Given all this, the recession will lead to a sharp increase in corporate defaults, which had been very low over the last two years, averaging 0.6% per year, compared to an historic average of 3.8%.
During a typical recession, the default rate among corporations may rise to 10-15%, threatening massive losses for those holding risky corporate bonds.
As a result, the market for credit default swaps (CDS) ­– where protection against corporate defaults is bought and sold – may also experience massive losses.
In that case, there will also be a serious risk that some firms that sold protection will go bankrupt, triggering further losses for buyers of protection when their counterparties cannot pay.
On top of all this, there is a shadow financial system of non-bank financial institutions that, like banks, borrow short and liquid and lend to or invest in longer-term and illiquid assets.
This shadow system includes structured investment vehicles (SIVs), conduits, money market funds, hedge funds, and investment banks.
Like banks, all these financial institutions are subject to liquidity or rollover risk – the risk of going belly up if their creditors do not rollover their short-term credit lines.
But, unlike banks, they do not have the safety net implied by central banks’ role as lender of last resort.
Now that a recession is underway, US and global stock markets are beginning to fall: in a typical US recession, the S&amp;P 500 index falls by an average of 28% as corporate revenues and profits sink.
Losses in stock markets have a double effect: they reduce households’ wealth and lead them to spend less; and they cause massive losses to investors who borrowed to invest in stock, thus triggering margin calls and asset fire sales.
There is thus a broader risk that many leveraged investors in both equity and credit markets will be forced to sell illiquid assets in illiquid markets, leading to a cascading fall in asset prices to below their fundamental values.
The ensuing losses will aggravate the financial turmoil and economic contraction.
Indeed, adding up all these losses in financial markets, the sum will hit a staggering $1 trillion.
Tighter credit rationing will then further hamper the ability of households and firms to borrow, spend, invest, and sustain economic growth.
The risk that a systemic financial crisis will drive a more pronounced US and global recession has quickly gone from being a theoretical possibility to becoming an increasingly plausible scenario.
The ongoing conflict between Iran’s rulers and the Iranian public is the result of a head-on collision between two contradictory forces.
In recent years, public attitudes in Iran have become more liberal.
At the same time, power has shifted from conservative pragmatism toward a much more militant fundamentalism.  The call by the most important group of Iran’s clerics for the election results to be thrown out is but the latest sign of the fight back of both the reformist and pragmatic conservative factions.
Thirty years after the Islamic revolution, Iranians are growing demonstrably less religious and more liberal.
Two face-to-face surveys of more than 2,500 Iranian adults, conducted in 2000 and 2005, clearly show the trend.
The percentage of those who “strongly agree” that democracy is the best form of government increased from 20% to 31%.
Similarly, on a number of questions concerning gender equality – including political leadership, equal access to higher education, and wifely obedience – the numbers continued a downward trend.
Those who considered love as the basis for marriage increased from 49% to 69%, while those who depended on parental approval fell from 41% to 24%.
In 2005, a much higher percentage than in 2000 defined themselves as “Iranian, above all” rather than “Muslim, above all.”
This trend is not hard to understand.
The imposition of a monolithic religious discourse on society has made liberal values attractive to Iranians.
But, while this was reflected in reformist trends in the country’s wider political life, a movement toward militant fundamentalism took shape within the regime’s power structure.
Reform-minded politicians were partly to blame for this change.
Far from opposing absolutist power as an impediment to religious democracy, they tried to persuade the Supreme Leader, Ayatollah Ali Khamenei, of the value of reform.
But Khamenei had no interest in reform, as he made plain in dismantling the reform movement.
The presidency of Mohammad Khatami, an avowed reformer, who served eight years, beginning in 1997, convinced the Supreme Leader that his authority would be assured only if the presidency was held by a subservient fundamentalist such as the current president, Mahmoud Ahmadinejad.
In this, Khamenei was following the lead of the late Shah, who kept Amir Abbas Hoveyda, a loyal retainer, as prime minister from 1965 until the Shah was overthrown in 1979.
The problem with the Supreme Leader’s calculation, however, is that Ahmadinejad is a loose cannon.
His populist rhetoric and religious fundamentalism have alienated a large section of conservative-pragmatist clerics and their supporters.
Many members of this group honor the institution of private property, and Ahmadinejad’s talk of redistributing wealth is not to their liking.
More disturbing to them is his apocalyptic conviction regarding the imminent advent of the Hidden Imam, the Mahdi, whose appearance is believed to lead to the destruction of the world and the end of time.
Generally, Ahmadinejad begins his public speeches with prayers for the Mahdi’s immediate return.
For the Shia religious hierarchy, long accustomed to relegating the advent of the Mahdi to a distant future, Ahmadinejad’s insistent millenarianism is troublesome.
They have often dismissed as unorthodox, if not heretical, any claim of personal contact with the Imam or speculation about his arrival.
Several ayatollahs opined that such talk about the Mahdi is unbecoming of a president or, worse, indicative of an unstable leader.
These concerns were reflected in the fact that the Society of Combatant Clergy, a conservative body, was unable to endorse Ahmadinejad’s candidacy.
Defiance of the Supreme Leader by millions of Iranians just a day after he firmly endorsed Ahmadinejad threw the country into a political crisis.
Worldwide broadcasts of the beating and killing of protesters have undermined the regime’s religious credentials.
Seeking a way out of this difficult situation, the Supreme Leader declared that the electoral disputes must be settled in through legal channels, not on the street.
Given his role in justifying electoral fraud, this argument seems like an effort to buy time to clear the streets of demonstrators, put opposition leaders under severe physical and psychological stress, and isolate Mir Hossein Mousavi, the presumed winner of the real vote.
Nonetheless, Khamenei’s invocation of the law echoes the demands of many conservative-pragmatists who lean toward Mousavi, who is not in a position to challenge Khamenei’s authority directly.
Mousavi must carefully continue his legal campaign, without compromising the trust he has gained from the majority of Iranians.
He must stand by his two principal demands: nullification of the election and establishment of an impartial committee to rule on the government’s violations of the electoral law.
Should Mousavi persuade Khamenei to reconsider his position, the Supreme Leader’s hold on power will be shaken.
If Khamenei holds fast, Mousavi cannot gain the presidency, but he will continue to represent the hopes of the majority of Iranians who differ dramatically with their government.
For now, what will happen depends on Mousavi’s perseverance.
How does your brain form its most significant memories?
Studies of fear in rats have helped us learn much here.
Although people and rats fear different things, the manner in which the rat and human brain and body respond to danger is similar.
Because fear is at the core of many human pathologies, from panic attacks to posttraumatic stress disorder, breakthroughs in understanding the brain's fear system may lead to new ways to treat these disorders.
The core of the brain's fear system is found in a region called the "amygdala".
This region receives information from all the senses and in turn controls the various networks that inspire the speeding heart, sweaty palms, wrenching stomach, muscle tension and hormonal floods that characterize being afraid.
A rat's amygdala responds to natural dangers (rats fear cats without having to learn to do so) and learns about new dangers (sounds, sights and smells that occur in anticipation of cats and other threats).
It is through studies of the way the brain learns about stimuli, such as the sounds that precede danger, that our systems for learning about fear, and memory as a whole, have been elucidated through rat studies.
There is also evidence that amygdala of reptiles and birds have similar functions.
Studies of humans with damage to the amygdala, due to neurological disease or as a consequence of surgery to control epilepsy, show that our brains also work in this same basic way.
The implication of these findings is that early on (perhaps since dinosaurs ruled the earth, or even before) evolution hit upon a way of wiring the brain to produce responses likely to keep an organism alive in dangerous situations.
The solution was so effective that it has not changed much over the ages.
Obviously, this is not the whole story.
Once the fear system detects and starts responding to danger, a brain such as the human brain, with its enormous capacity for thinking, reasoning, and musing, begins to assess what is going on and tries to determine what to do.
This is when feelings of fear arise.
But in order to be consciously fearful you have to have a sufficiently complex kind of brain, one aware of its own activities.
While this is undoubtedly true of the human brain, it is not at all clear which (if any) other animals have this capacity.
So, in evolutionary terms, the fear system of the brain is very old.
It is likely that it was designed before the brain was capable of experiencing what we humans refer to as "fear" in our own lives.
If true, then the best way to understand how the fear system works is not to chase the elusive brain mechanisms of feelings of fear, but to study the underlying neural systems that evolved as behavioral solutions to problems of survival.
In order to understand feelings, we need to step back from their superficial expression in our conscious experiences and dig deeper into how the brain works when we have these experiences.
A fundamental discovery has been that the brain has multiple memory systems, each devoted to different kinds of memory functions.
For memories of fear arousing experiences, two systems are particularly important.
Take this example: if you return to the scene of a recent accident, you are likely to have a physical reaction that reflects activation of memories stored in the amygdala.
At the same time, you will be reminded of the accident, will remember where you were going, who you were with, and other details.
These are explicit (conscious) memories mediated by another system, the "hippocampus".
In contrast, memories mediated by the amygdala are unconscious.
These are memories in the sense that they cause your body to respond in a particular way as a result of past experiences.
The conscious memory of the past experience and the physiological responses elicited thus reflect the operation of two separate memory systems that operate in parallel.
Only by taking these systems apart in the brain have neuro-scientists been able to figure out that these are different kinds of memory, rather than one memory with multiple forms of expression.
Many of the most common psychiatric disorders that afflict humans are emotional disorders; many of these are related to the brain's fear system.
According to America's Public Health Service, about 50% of mental problems reported in the US (other than those related to substance abuse) are accounted for by anxiety disorders, including phobias, panic attacks, post-traumatic stress disorder, obsessive compulsive disorder, and generalized anxiety.
Research into the brain mechanisms of fear helps us to understand why these emotional conditions are so hard to control.
Neuro-anatomists have shown that the pathways that connect the amygdala with the thinking brain, the neocortex, are not symmetrical - the connections from the cortex to the amygdala are considerably weaker than those from the amygdala to the cortex.
This may explain why, once an emotion is aroused, it is so hard for us to turn it off at will.
The asymmetry of these connections may also help us understand why psychotherapy is often such a difficult and prolonged process, for it relies on imperfect channels of communication between brain systems involved in cognition and emotion.
Studies of the basic biology of the fear system are likely to continue to reveal important information both about where our emotions come from and what goes wrong in emotional disorders.
As we learn more, we may begin to figure out how to better treat - and even prevent - these conditions.
London – Thirty years ago this month, Margaret Thatcher came to power.
Although precipitated by local conditions, the Thatcher (or more broadly the Thatcher-Reagan) revolution became an instantly recognizable global brand for a set of ideas that inspired policies to free markets from government interference.
Three decades later, the world is in a slump, and many people attribute the global crisis to these very ideas.  
Indeed, even beyond the political left, the Anglo-American model of capitalism is deemed to have failed.
It is held culpable for the near financial meltdown.
But 30 years of hindsight enable us to judge which elements of the Thatcher revolution should be preserved, and which should be amended in the light of today’s global economic downturn.
Most obviously in need of amendment is the view that minimally managed and regulated markets are both more stable and more dynamic than those subject to extensive government intervention.
The Thatcherite assumption, in other words, was that government failure is far more menacing to prosperity than market failure.
This was always bad history.
The record shows that the period 1950-1973, when government intervention in market economies was at its peacetime height, was uniquely successful economically, with no global recessions and faster rates of GDP growth – and growth of GDP per capita – than in any comparable period before or since.
One can argue that economic performance would have been even better with less government intervention.
But perfect markets are no more available than perfect governments.
All we have are comparisons between what happened at different times.
What these comparisons show is that markets plus government have done better than markets minus government.
Nevertheless, by the 1970’s the pre-Thatcher political economy was in crisis.
The most notorious symptom of this was the emergence of “stagflation” – simultaneously rising inflation and unemployment.
Something had gone wrong with the system of economic management bequeathed by John Maynard Keynes.
In addition, government spending was on the rise, labor unions were becoming more militant, policies to control pay kept breaking down, and profit expectations were falling.
It seemed to many as though government’s reach had come to exceed its grasp, and that either its grasp had to be strengthened or its reach had to be reduced.
Thatcherism emerged as the most plausible alternative to state socialism.
Nigel Lawson was Thatcher’s second Chancellor of the Exchequer, or finance minister.
Out of the government’s anti-inflationary efforts emerged the “Lawson doctrine,” first stated in 1984 and broadly accepted by governments and central banks ever since. “The conquest of inflation,” Lawson said, “should...be the objective of macroeconomic policy.
And the creation of conditions conducive to growth and employment should be...the objective of microeconomic policy.”
This proposition overturned the previous Keynesian orthodoxy that macroeconomic policy should aim at full employment, with the control of inflation left to wage policy.
Yet, despite all the “supply side” reforms introduced by Thatcherite governments, unemployment has been much higher since 1980 than in the 1950’s and 1960’s – 7.4% on average in the United Kingdom, compared to 1.6% in the earlier decades.
What about inflation targeting?
Here, too, the record since 1980 has been patchy, despite the huge deflationary pressure exerted by low-wage competition from Asia.
Inflation in 1950-1973 and 1980-2007 was about the same – just over 3% – while inflation targeting has failed to prevent a succession of asset bubbles that have brought recessions in their wake.
Nor has Thatcherite policy succeeded in one of its chief aims – to reduce the share of government spending in national income.
The most one can say is that it halted the rise for a time.
Now public spending is on the increase again, and record peacetime deficits of 10% or more of GDP stretch ahead for years.
In de-regulating financial markets worldwide, the Thatcher-Reagan revolution brought about the corruption of money, without improving on the previous growth of wealth – except for the very wealthy.
The average world citizen would have been 20% richer had world GDP per capita grown at the same rate between 1980 and 2007 as it did between 1950 and 1973 – and this despite China’s high growth rates in the past 20 years.
Furthermore, in unleashing the power of money, the Thatcherites, for all their moralizing, contributed to the moral decay of the West.
Against these formidable minuses are three pluses.
The first is privatization.
By returning most state-owned industries to private ownership, the Thatcher revolution killed off state socialism.
The British privatization program’s greatest influence was in the former communist states, to which it gave the ideas and techniques needed to dismantle grossly inefficient command economies.
This gain must be preserved in the face of the current clamor to “nationalize” banks.
Thatcherism’s second success was to weaken trade unions.
Set up to protect the weak against the strong, labor unions had become, by the 1970’s, enemies of economic progress, a massive force of social conservatism.
It was right to encourage a new economy to grow outside these congealed structures.
Finally, Thatcherism put paid to the policy of fixing prices and wages by central diktat or by tripartite “bargains” between governments, employers, and trade unions.
These were the methods of fascism and communism, and they would, in the end, have destroyed not just economic, but political, liberty.
Political pendulums often swing too far.
In rebuilding the shattered post-Thatcherite economy, we should be careful not to revive the failed policies of the past.
I still find fruitful Keynes’s distinction between the agenda and the non-agenda of politics.
As long as central government takes responsibility for maintaining a high and stable level of employment, Keynes thought, most of the rest of economic life can be left free of official interference.
Building a proper division of responsibility between state and market from this insight is today’s main task.
More than anything else, Vladimir Putin understands power: how to get it; how to consolidate it.
His predecessor, Boris Yeltsin, knew how to seize power but not how to consolidate it, which partly explains why power seeped away throughout his presidency.
President Putin's success, however, has bred its own problem: he consolidated power at the center so well that opposition is brewing in Russia's regions.
Yeltsin's biggest failing was in not creating a viable, non-ideological party - a "party of power" - to buttress his regime.
He tried to do so in 1995, but the Chechen War drove Russia's democrats away from him.
Moreover, his efforts here were amazingly clumsy.
Yeltsin once spoke about his scheme to link two centrists. With "Ivan Rybkin (then Duma's speaker)," Yelstin said on TV, "leading the left flank, and Viktor Chernomyrdin (then prime minister) leading the right, we will encircle everyone."
But by linking both parties to his very unpopular self, Yeltsin damaged both.
Perhaps if both wings had united, that single party would have appeared as an unbeatable juggernaut.
Such unity, however, was impossible, for an obvious Russian reason: the faction leaders hated each other too much to get together, even for their own good.
Indeed, Rybkin was told to pretend to be opposed to Yeltsin's policies, but when he did object, Chernomyrdin summoned Rybkin to his office for "clarifications."
When businessmen learned about this "dressing down," they became afraid to finance Rybkin's party.
In the end, Rybkin went unelected and Chernomyrdin's `Our Home Is Russia' (NDR) came third.
Yeltsin failed to consolidate political support for other reasons as well, the most important being his unwillingness (or inability) to forcefully manipulate the media.
Of course, transformation of the presidential administration into a public relations machine began under Yeltsin when Anatoli Chubais directed the 1996 election campaign.
Before that, the Kremlin had little idea about how to manipulate the new media outlets that Russia's infant democracy had produced.
Today's Kremlin, however, is full of clever ideas about how to control and intimidate newspapers, radio, and television.
In the 1995 election, Yeltsin would have been happy if the NDR secured 25% to 30% of the vote.
Putin is far more ambitious.
He will be displeased if `United Russia' - the "party of power" he has built - wins less than 50% of the seats in the next Duma.
But are the results of the parliamentary elections due this coming January truly a foregone conclusion? Or are surprises in store for Putin?
Surprises seem likely because Russia's political dividing line has shifted, but the President's political strategy hasn't recognized that fact.
Indeed, he appears set to be waging battles against the communists that are already won.
Putin's re-consolidation of power within the Kremlin, after much of it escaped to the regions during the Yeltsin years, dramatically shifted Russia's political dividing line.
In the past, that dividing line separated right and left, but the line at the forthcoming elections will run between the federal center and the regions.
The loss of political power in the regions (regional governors, for example, were evicted from the Duma's upper house) has incited serious discontent that is spilling over into the public sphere.
That discontent will likely gather momentum as elections near, which may be enough to stop the federal authorities from meeting their strategic goal of winning an unchallengeable majority of seats in the new Duma.
Vast administrative resources are being used to secure the desired result.
But Russia's bureaucracy is no disciplined machine, and the lower reaches of the state's `vertical' power structure may well ally themselves - quietly - with regional authorities to prevent the center from gaining too many votes.
Regional administrations also possess their own instruments of obstruction, including propaganda outlets in the regional media, as well as the ability to manipulate ballot papers.
Indeed, President Putin's failure to "reconquer" his home city of St. Petersburg, now controlled by a bitter political opponent of the President, Vladimir Yakovlev, demonstrates the bureaucratic powers that local leaders retain.
So the real issue in the forthcoming Duma elections will be how powerfully regional elites confront Putin.
Their ability to defy the president may be aided by the fact that the Kremlin is failing to recognize the potential of their challenge.
So far, the main target of its campaign is the communists, whom Kremlin political operatives hope to destroy in the way they destroyed Moscow Mayor Yuri Luzhkov and former Prime Minister Yevgeny Primakov, head of the Fatherland party, who were the leading non-communist challengers during Putin's first presidential campaign.
That focus on the battle with the communists may allow other forces to sneak into the Duma by the back door.
The Boris Nemtsov/Sergei Kiriyenko `Union of Right Forces' (SPS) is one party that seems certain to benefit in this way. Indeed, the SPS electorate is growing faster than that of other parties.
In principle, all of Russia's political elites appear to have - or pretend to have - resigned themselves to a political landscape with Putin alone on the mountaintop and everyone else consigned to the valley below.
The upcoming elections won't knock the president off that mountain, but his `party of power' is not omnipotent enough to silence the dissenting echoes rising from below.
NEW DELHI – For 18 days, during the ebb and flow of protest, it did not seem possible that the end of the Egyptian Revolution would come so suddenly, in a terse announcement that lasted no more than a half-minute: “President Hosni Mubarak has relinquished office….” With that, amidst roars of victory, an era was ended, reaffirming the old saying that “the graveyards of the world are full of those who considered themselves indispensable to their nations.”
In the days and weeks ahead, there could arise occasions when the news from Cairo is not uplifting, but let us never forget that Egypt has taken a giant step, which in reality is a giant step for all Arabs.
After all, Egypt is the heart, brain, and nerve center of the Arab world.
True, it once spawned the radical Muslim Brotherhood, but it also gave birth to Islamic socialism and anti-colonialism, Arab unity, and now a democratic affirmation of the people’s will.
Pernicious talk that Arabs do not want democracy has been exposed as the big lie it is.
Egypt, in the great Bengali poet Rabindranath Tagore’s memorable words, is the land “where the head is (now) held high and the mind is (now) without fear…” The consequences will be vast.
Ancient Arab lands are bestirred.
Decades-old, apparently immovable autocracies are finding their hold on power unhinged; change is invading their static environs.
Yesterday’s treaties, particularly those with the United States and Israel, will no longer inspire the same type of confidence they have long had as instruments of state policy.
Memory of these 18 days is so crowded that it is difficult to separate one event from another, one phase from the next: the dramatic, the moving, the bizarre, and the unreal from the bathetic.
But the thread that united all, the theme that remained unerringly constant, was the yearning for “change” – immediate, real, and tangible, not a promise or a tantalizing, unreachable mirage.
Will this yearning travel beyond the Nile, as it did from Tunis to Cairo?
This question haunts other Arab portals of power.
And not just Arab; globally, foreign policies are being hurriedly – and somewhat confusedly – revised and rewritten.
This is why US policy oscillated so disconcertingly from Secretary of State Hillary Clinton’s “Do not rush the pace or else the pro-democracy movement could well be hijacked” to President Barack Obama’s emphatic call for “change now.”
Of course, a grave question arises about the now-ruling Supreme Council of the Military High Command in Egypt: How can the enforcers of the status quo become the agents of change?
But, then, military rule is only a temporary measure, or so we reason.
The great Tunisian poet Abul-Qasim Al Shabi has captured poignantly the spirit of Egypt’s saga: “If one day the people want life, then fate will arise…night fade away, chains broken…” That, in essence, is what the young in Egypt have done.
Their idiom is current; their instruments of change are today’s electronic media.
They – and we – are very far from the world that Mubarak, or the great Gamal Abdel Nasser, knew and understood.
The Egyptian revolution now faces the exacting task that confronts all successful revolutions: how to define the future.
Like the Ottoman Empire’s fragmentation in 1922 or Nasser’s overthrow of King Farouk’s regime in 1952, the current transformation, too, must be shaped.
And how that future is shaped will determine whether or not Mubarak’s end marks the beginning of political transformation throughout the Middle East.
That is the possibility that is shaking governments from Washington to Beijing.
It is not just the reliability of the Suez Canal and oil exports that are now in doubt; decades of fixed strategic certainties must now be reexamined.
Consider Israel, which has watched the events in Cairo with a degree of worry unfelt since January 1979, when Ayatollah Ruhollah Khomeini unseated the Shah of Iran.
That strategic nightmare cost Israel and the US their closest ally in the region, one that was soon transformed into an implacable enemy.
Israel’s two most recent wars – against Hezbollah in Lebanon in 2006, and against Hamas in Gaza in 2009 – were fought against groups sponsored, supplied, and trained by Iran.
Clearly, Israeli-Palestinian negotiations will also now lie unattended as Israel concentrates on developments in Egypt.
Above all, Israel must wonder if the peace treaty with Egypt will hold, and, if not, how to carry out the massive restructuring of its defense posture that will be required.
But it is not only the fate of Israel that has now shocked US policy, in particular, to its core.
Egypt, after all, has been the cornerstone of America’s balancing act in the Middle East – and the Islamic world – for three decades.
The Egypt-Israel peace treaty has kept Egypt comfortably neutralized, freeing the US to commit its strategic resources elsewhere.
In turn, Egypt, propped up by massive US aid, has secured the region from a larger conflagration, even though the Israel-Palestine conflict has continued to smolder.
Herein lies the core of the dilemma for the US: it wants Egypt’s basic state apparatus to survive, so that the levers of power do not fall into the wrong hands.
This requires the US to be seen as siding with the public’s demand for change, yet to avoid being identified with political immobility.
There is reason to feel reassured by Obama’s reactions.
He termed Mubarak’s departure a display of “the power of human dignity,” adding that “the people of Egypt have spoken, their voices have been heard, and Egypt will never be the same.”
But nothing that Obama, or anyone else, says can answer the question now occupying the attention of senior US officials: Will the coming of popular sovereignty to Egypt inevitably lead to anti-Americanism?
At long last, Angela Merkel is Germany’s new – and first woman – Chancellor.
Although continuity will remain the hallmark of foreign policy, Germany’s international engagement under Merkel will sound and feel different from that under Gerhard Schroeder’s leadership.
Schroeder came to power seven years ago representing a new generation whose formative experience was not the Cold War, European integration, and transatlantic friendship, but German unification and the restoration of national sovereignty.
For him and the team that took over after Helmut Kohl’s 16-year reign, Germany had become a normal country, no different from other European heavyweights like France or Britain.
Indeed, one of Schroeder’s first major foreign-policy experiences was the EU summit of 1999, where the leaders of France and Britain played rough with the newcomer from Berlin.
The lesson that Schroeder drew was to insist that Germany could no longer be taken for granted and would demand a role commensurate to its size and weight.
Self-assertion became the watchword of German foreign policy.
Thus, when Schroeder claimed special circumstances for Germany’s failure to meet the budgetary ceilings of the European Union’s Stability and Growth Pact, he seemed to be arguing that the restrictions should apply only to smaller countries, not to the big players.
When he rightly opposed America’s war against Iraq, the pride of standing up to the world's only superpower was palpable.
When he established a close personal and political relationship with Russian President Vladimir Putin, he signaled to the world – and to the EU’s sensitive new Eastern European members – that Germany’s foreign policy would no longer be constrained by the past.
In fairness, it should be acknowledged that it was under Schroeder that Germany shed hesitations to deploy soldiers abroad.
His support for international crisis missions in Kosovo, Bosnia, or Afghanistan required considerable political courage and made Germany one of the major contributors to international stability efforts.
To have removed the issue from domestic ideological controversy ranks as a major achievement of Schroeder’s tenure.
But it was also meant to convey that Germany had grown up into a proper international power.
With Merkel, the substance of Germany’s foreign policy will change little, but the assertive style will be muted.
American leaders will welcome her election as proof that the estrangement in bilateral relations is over.
But that alienation already largely ended earlier this year, when the Bush administration realized that allies are good to have and that Germany is an important one.
Merkel will reintroduce the warmth that has been missing under Schroeder, but she will not become America’s yes-woman.
Nor will she abandon special relations with Russia, to which every German chancellor since Adenauer has attached major importance.
But she has already made clear that Germany’s neighbors to the East will have no reason not feel bypassed.
She may even want to confirm that message by making her first official trip abroad not to Paris but to Warsaw or Vilnius.
On the European project, she is as committed to integration as her predecessors have been.
She will continue to emphasize close relations with France because there is no alternative; Britain, absent from the euro zone and the Schengen border regime, remains the odd man-in of the EU.
But there will be no new initiatives on integration until leaders in the countries that rejected the Constitutional Treaty are ready for a new try.
Then Merkel will be in a key position to add weight to a new effort for moving the EU forward.
She will continue to favor the eventual admission of the Balkan states, but she has left no doubt of her opposition to full membership for Turkey, which is the major substantive change from the Schroeder era (although her government will not block the start of negotiations in early October).
In fact, there is very little Merkel has to do after her election to make her mark on foreign policy; the visible change of style will suffice, at least at first.
In any case, she will have her hands full pushing through the economic reforms for which she will be elected and which are her top priority.
There are indications that Germany is finally emerging from years of economic stagnation, not least thanks to the reforms started under Schroeder.
At home, Merkel can hope to reap the rewards.
Abroad, Merkel has no need to demonstrate that Germany is a big country in Europe; her partners are fully aware of this.
But it is also more than just a normal country: Germany remains central to holding together the two international institutions that will continue to assure its well-being, the European Union and the Atlantic alliance.
There are some indications that Merkel is more aware of this then Schroeder was.
One can only hope that this recognition will serve as her guidepost when tough decisions must be made and changes in style alone will not be enough.
CAMBRIDGE – As Europe struggles to save the euro, the chorus of complaints about weak leadership in the world’s major economies grows louder.
Many have singled out German Chancellor Angela Merkel for failing to promote a vision of Europe similar to that of her predecessor and mentor, Helmut Kohl.
Are the critics right?
Part of what effective leaders do is communicate a vision that gives meaning to policies and inspires others to support these policies (and those who propose them).
It is one of the ways in which leaders help to create shared objectives and energize common action.
Usually, such a vision provides a scenario for the future that is meant to encourage change, though it may also portray the status quo – or the past – as attractive, thereby encouraging resistance to change.
Either way, without a vision, it is difficult to lead others anywhere.
Frederick Smith, CEO of Federal Express, has argued that “the primary task of leadership is to communicate the vision and values of an organization.”
But one must be cautious about visions.
Sometimes leaders think that vision can solve most of their problems, but the wrong vision – or an overly ambitious vision – can do damage.
George H.W. Bush was faulted (and faulted himself) for not having what he called “the vision thing.”
When pressed by his staff to speak more boldly and expansively, he replied, “It’s just not me.”
After the shock of the September 2001 terrorist attacks, his son, George W. Bush, developed a far more ambitious vision.
As one former adviser put it, he was “irresistibly drawn to Big Ideas like bringing democracy to the Middle East, Big Ideas that stood in sharp contrast to the prudent small ball played by his father.”
Yet the elder Bush turned out to have had the better foreign policy.
Some aspiring leaders think that they must proclaim a vision that overawes their followers.
In practice, however, a successful vision often arises from the needs of the group, which are then formulated and articulated by the leader.
The vision that Martin Luther King, Jr., expressed in his “I Have a Dream” speech, for example, was deeply rooted not only in America’s professed values of equality and inclusion, but also in African-Americans’ experience of subordination and exclusion.
At the same time, the pressure to articulate a vision can get a leader into difficulty.
As one university president put it: “Everyone asks, ‘What’s your vision?’ But you offend many people and get into trouble by answering too quickly.
The smart response at the beginning is, ‘What do you think?’ and then listen before you articulate your vision.”
A successful vision has to be attractive to various circles of followers and stakeholders.
What plays well with one group may not sit well with another.
And, to be sustainable, a successful vision must also be an effective diagnosis of the situation that a group faces.
Leaders must get the question right before proposing answers.
To choose goals and articulate them in a vision, they need not only to solicit input from their followers, but also to understand the context of their choices.
They must be able to assess reality accurately.
The boldness of a vision varies with the type of leadership involved.
Leaders of social movements can call forth larger visions than public officials can.
A movement leader can promote a vision that is miles ahead of his followers, while a prime minister with multiple objectives and responsibilities must maintain a continuous dialogue with the public, which keeps him or her from moving too far ahead of citizens.
After former US Vice President Al Gore lost his bid for the presidency in 2000, he became a leader of the social movement to combat global climate change, and his style changed from pragmatic to inspirational and prophetic.
Analysts judge a government leader’s vision in terms of whether it creates a sensible balance between realism and risk, and whether it balances objectives with capabilities.
Anyone can produce a wish list, but effective visions combine inspiration with feasibility.
Critics of former British Prime Minister Tony Blair, for example, acknowledged that his ability to articulate a vision was one of his great strengths as a leader, but complained about his lack of attention to detail.
Similarly, two twentieth-century US presidents, Woodrow Wilson and George W. Bush, were good at articulating an ambitious foreign-policy vision, but were poor at refining and reshaping their vision when they encountered implementation challenges.
Both promoted democracy, but both did so in a manner that generated a backlash against democracy promotion.
Of course, prudence is not enough.
Sometimes leaders need to stretch the boundaries of realism to inspire their followers and call forth extra effort, as Winston Churchill did in Great Britain in 1940.
But, without a degree of prudence based upon comprehension of the context, visions turn from grand to grandiose and undercut the values that they seek to promote.
Like Franklin Roosevelt, who acted very cautiously in trying to persuade American opinion to abandon isolationism in the 1930’s, Merkel has proceeded cautiously on saving the euro.
She faced public skepticism about using German funds to bail out the Greek economy.
Her coalition was divided on the issue, and her party lost state elections.
If she had acted more boldly, she might have lost even more support, but the steps that she agreed to remained insufficient to reassure markets.
At the end of October, however, she finally articulated a vision of the future of Europe that persuaded the German Bundestag to agree to a package of measures to save the euro.
Whether she waited too long – and whether her vision will prove convincing – will be determined in the coming months.
With the world focused on Iraq, North Korea, and a possible clash with Iran over nuclear weapons, Kosovo has fallen off the radar screen.
That inattention will end soon; a decision about the province’s fate is looming.
The United States and its European friends have repeatedly stated their intent to make the difficult decision before the end of the year on whether to separate Kosovo from Serbia.
This decision – crucial to the future of an unstable region – will test Western determination and unity.
Negotiations this year in Vienna, brokered by the United Nations, showed that an agreed settlement between Serbia and Kosovo on “final status” will not happen.
Talks continue, but, as UN negotiator and former Finnish President Martti Ahtisaari diplomatically told the Security Council, they are effectively dead.
No Serbian leader will agree to Kosovo’s independence, because nationalism remains the dominant political force in the country.
Indeed, Prime Minister Vojislav Kostunica, the apostle of Serbian nationalism, has been trying in every way to undermine Kosovo’s interim government.
He is rushing to hold a national referendum this month on a new constitution without serious parliamentary debate or the usual public education.
The main purpose of his new constitution is its preamble, which enshrines Kosovo as an inalienable part of Serbia.
Kosovo’s ethnic Albanians have proclaimed that they will not accept any tie to Serbia, no matter how tenuous.
Throughout the 1990’s, they virtually opted out of Serbian-run Kosovo by creating parallel institutions.
Their forced mass exodus in 1999 and NATO’s subsequent intervention, which ended Serbia’s rule and established a quasi-state under UN administration, has made anything other than independence intolerable.
Some time over the next month or two, the Balkan Contact Group — the US, UK, France, Germany, Italy, and Russia – will consider Ahtisaari’s recommendations on Kosovo’s final status and possibly propose a solution to the Security Council, which must make the final decision.
In public, all Contact Group members have tried to leave the question of Kosovo’s final status open, but informally the US and some of its allies have told the two parties that they will propose independence this year.
Some members of the Security Council – particularly Russia and China – are opposed to or skeptical of an imposed settlement, and few governments favor dividing up another country’s territory, however compelling the circumstances.
Whether the Security Council will approve independence largely depends on averting a Russian veto, which will require considerable diplomatic effort.
The nature of the independence bestowed is also important.
An independent Kosovo must be secured and its minorities protected.
Northern Kosovo, now largely under Belgrade’s control, must not be partitioned off in all but name.
In the interest of reducing the blow to Serbia, the Security Council must avoid granting independence in ways that are so contorted that the new state cannot effectively function.
If the Security Council fails to reach a decision on final status, it will produce a GRAVE situation: Kosovo would declare independence unilaterally, and all nations would have to make up their mind whether or not to recognize the new state.
If that happens, it is likely that the Serbs of North Kosovo would declare their own independence.
At a minimum, Serbia would campaign strongly against recognition.
In fact, Serbia’s government is already trying to persuade the West to postpone a decision until mid-2007.
It claims that if Kosovo is granted independence, the ultranationalist Radical Party will come to power in the next elections, and believes that holding elections as early as this year will cause the Contact Group to delay a proposal to the Security Council.
Moreover, the government has encouraged the leaders of Bosnia’s Republika Srpska to threaten to hold their own referendum on separation from a still fragile Bosnia.
And they continue to push &#45;&#45; unsuccessfully &#45;&#45; for Ahtisaari’s removal in order to prolong the Vienna talks.
The timing of the constitutional referendum appears to be a part of this delaying strategy.
Some hope that postponement will stimulate violence in Kosovo and further encourage Western reconsideration of independence.
That tactic may be working.
Many European Union countries are worried about the implications of taking away a country’s territory, as well as the impact of Kosovo’s independence on Serbian democracy.
Given Serbia’s political instability, they question the harm of a short-term postponement – albeit mostly self-inflicted.
But delay only offers more room for Kostunica to find ways to make a Security Council decision more difficult.
The West must ignore Belgrade’s siren song.
Serbian politics will be chaotic and unstable for the foreseeable future, and Serbian politicians will attempt to present this as an excuse to avoid facing the loss of Kosovo.
Likewise, there will be problems establishing ties between Serbia and Kosovo under any circumstances.
But failure to proceed definitively now on Kosovo’s final status will produce a worse Balkan situation, one that blocks Serbia’s move toward the West and ultimate membership in the EU, condemns Kosovo’s ethnic minorities to dangerous ambiguity, and imperils fragile states like Bosnia and Macedonia.
No realistic solution exists for Kosovo but independence.
If Serbia wants to join the West, it must not forsake that opportunity by trapping itself in its nationalist past.
NEW YORK – Conventional wisdom rarely survives a good stress test, and few tests have been as stressful as that which the global economy has endured over the past 24 months.
A healthy season of reappraisal has dawned, shining a new light on boom-time notions like the value of opaque markets, the untouchable status of the American consumer, or the wisdom of deregulation.
One piece of bubble wisdom that has escaped relatively unscathed, however, is the assumption that the “BRIC” countries – Brazil, Russia, India, and China – will increasingly call the economic tune in years to come.
The BRIC notion, coined in a 2003 Goldman Sachs report, is not all bad: at 75% correct, it scores a good deal better than most economic prognostications of the day.
Yet the economic crisis that began in 2008 exposed one of the four as an impostor.
Set the vital statistics of the BRIC economies side-by-side and it becomes painfully obvious that, in the words of the old Sesame Street game, “One of these things is not like the other.”  
The weakness of the Russian economy and its highly leveraged banks and corporations, in particular, which was masked in recent years by the windfall brought by spiking oil and gas prices, burst into full view as the global economy tumbled.
Saddled with a rust-belt infrastructure, Russia further disqualifies itself with dysfunctional and revanchist politics and a demographic trend in near-terminal decline.
Even with the modest recovery in commodity prices over the past six months, Russia’s energy sector has experienced declining production in recent years, due in part to fears among foreign investors of expropriation.
Russia’s sovereign wealth fund, integral in propping up an increasingly re-centralized economy, is being depleted fast.
If negative trends continue, Russia’s reserve fund could eventually be exhausted.
Russia’s fall back to earth, meanwhile, spawned a kind of parlor game among academics, foreign-policy wonks, and educated investors, aimed at replacing the country in the club of major emerging-market economies.
A variety of acronyms has been suggested, from the cutesy BRICET (adding Eastern Europe and Turkey) to BRICKETs (the former plus South Korea) and – an even greater stretch – BRIMC, which shoehorns Mexico into the mix.
In all of these revisions, Russia survives, despite the writing on its economic wall.
While Russia retains the world’s largest (if somewhat aging) arsenal of nuclear weapons, as well as a permanent seat (and thus veto power) on the UN Security Council, it is more sick than BRIC.
Purely from the standpoint of economic potential and fundamentals, the case is far stronger for South Korea, a sophisticated economic power whose primary liability is the danger that the regime of its evil twin to the north will collapse and inundate it with hungry refugees.
The same is true of Turkey, with its robust banking sector, thriving domestic market, growing importance to Middle East and energy politics, NATO membership, European Union membership bid, and ties to ethnic cousins across Central Asia.
Perhaps the most compelling case of all is that of Indonesia, the world’s largest Muslim state, with a rapidly expanding middle class, relatively stable democratic politics, and an economy that has been a star performer in Asia despite the global recession.
From an American perspective, Indonesia is an attractive alternative to Russia, which recently has vied with Venezuela for leadership of the “America in decline” cheering section.
Indonesia, moreover, has shown resilience not only economically, but also as a nation.
In spite of its diverse ethnic makeup and far-flung island territory, the country has made a quick transition from military dictatorship and has recovered from myriad challenges and setbacks, including the 1997 Asian financial crisis, the tsunami in 2004, the emergence of radical Islam, and domestic unrest.
While Indonesia’s per capita GDP remains low, it is a country’s potential that matters in economic affairs, and here Indonesia shines.
Indonesia depends less on exports than its Asian peers (let alone Russia), and its asset markets (timber, palm oil, and coal, in particular) have attracted major foreign investment.
The government in Jakarta, meanwhile, has taken a strong stand against corruption and moved to address structural problems.
Even demographic trends favor Indonesia, which, with 230 million people, is already the fourth largest country in the world by population – a full Germany (80-plus million) larger than Russia.
But catchy ideas die hard, and Russia has moved to cement the current concept of the BRICs into an irreversible reality.
The ossification of the BRICs into ade facto global institution move forward dramatically in June, when the four countries’ leaders met (in Russia, of course) for the first “BRIC Summit.”
That meeting produced a notable broadside against the United States, as each member declared its desire to unseat the dollar as the global reserve currency.
A few months earlier, the four were moved to issue a joint communiqué ahead of the G-20 Summit in April noting their shared determination to change the rules of the global economic system.
In the private sector, BRIC index funds have proliferated, though Goldman Sachs has radically hedged its own BRIC bet by introducing a second term – the “Next 11,” or N-11 – to the debate.
This grouping addsBangladesh,Egypt,Indonesia,Iran,Mexico,Nigeria,Pakistan, thePhilippines,South Korea,Turkey, andVietnam to the economic radar, and, together with the four BRIC countries, probably comprises a more logical and defensible “first tier” of emerging economies.
Russia sniffs at the idea of demotion, and American officials appear to have decided to steer clear of the semantic debate.
Still, it should surprise no one that Russia lobbied hard for the Yekaterinburg BRIC summit, and footed the bill for much of it as well.
Why risk exposure too soon?
JERUSALEM: The European Union has failed once again.
Its total impotence to prevent war near the heart of Europe was amply proved in Bosnia and Kosovo over the last decade.
Now the European Union has once again failed to respond to the challenge posed by the Haider phenomenon in Austria.
By lifting the half-hearted sanctions imposed by the 14 members of the EU on Austria in February, any talk about Europe standing for a community of values sounds even more hollow than ever before.
In the case of Bosnia and Kosovo, Brussels proved itself to be totally irrelevant and impotent when the use of force – or the threat of the use of force – was concerned.
Fine words and mellifluous phrases filled many documents – but when Vukovar was destroyed, Dubrovnik shelled, Sarajevo besieged for years and then the horrible mass murders in Srebrenica occurred – all that the European Union was able to muster were more words and self-righteous indignation.
But then one could argue that the European Union was not a military alliance.
In the end, it proved that – of all people – Machiavelli was right when he argued that even prophets need to be armed in order to be effective: the moral imperative not to allow another genocide-like development in Europe needed the NATO’s armaments to be effective.
The European Union continued to produce words.
When it came to Austria, however, there was a feeling that since this was not a military, but a purely political and moral situation, Brussels – and the Continent-wide political clout signified by it – would be able to prove efficient.
Alas, it failed as dismally as the League of Nations failed in the l930's.
Let us revisit what the issue was and still is: in the heart of Europe – and in a country burdened by the political ideologies which gave rise to Hitler, himself an Austrian – Jörg Haider and his party revived the political discourse of xenophobia, racism and visceral anti-foreign sentiment.
It is true that democracies always find it difficult to balance their commitment to human rights with their commitment to free speech: it is a delicate path to tread, and there is no easy answer on a legal and constitutional level.
Yet the issue is not legal or constitutional – it is political.
To preserve democracy and human rights, democratic parties have realized that the most effective ways to confront racist and xenophobic parties is to marginalize and exclude them – to treat them as beyond the pale as potential partners for government.
The Austrians are right that Haider-like parties exist in many European countries – in Britain, France, even in some Scandinavian countries.
But in all these countries, the political discourse of all democratic parties ostracized these racist groups and parties: British Conservatives have never entered into an alliance with the British National Front; the same goes for France, where French conservatives have expelled from their own party local leaders who fashioned municipal alliances with Le Pen's representatives.
This is exactly what the Austrian conservative People's Party under Wolfgang Schuessel did not do.
Confronted with an election outcome of whether to rejoin the Social Democrats or Haider's Freedom Party, they made a Faustian pact with Haider.
There may be good political reasons why another alliance with the Social Democrats was not appealing to Schuessel's party (for one, he would not be Chancellor in such a coalition).
But there are basic values which should have overruled such purely tactical considerations and have prevented Schuessel's party from joining with Haider.
It is the moral blindness of Schuessel and his party that triggered the response of the 14 members of the EU.
One could argue that the bilateral sanctions imposed by the 14 on Austria were inadequate and even ineffective.
This is besides the point: the point is, what is the European Union, committed to democracy and human rights, going to do now?
Let us put it bluntly: the continued participation of Haider's party in a governing coalition in a European country is totally unacceptable.
The language Haider and many leaders of his party have used over the years is informed by the same racist and anti-Semitic discourse that gave birth to Nazism: in the specific Austrian context, it is violently anti-Slav as well as anti-Turkish.
While Haider is careful not to say anything which can be construed as anti-Semitic, his praise for the valor and honor of Waffen-SS veterans as well as comments on Nazi concentration camps clearly suggest where his ideological home is.
Haider and his party deserve to be politically isolated and ostracized.
The EU countries have failed twice in their attempt to respond to this challenge – once by half-hearted sanctions; now by lifting them.
What is Brussels to do?
Continue with business-as-usual, churning out document upon document of bureaucratic mumbo-jumbo, perhaps even continue to give free advice to Israelis and Palestinians about how to work out their differences?
One wonders what a good European word for chutzpa would be.
Charity begins at home.
At a time when the EU is on the verge of an ambitious project of enlargement to include many Slav and other Eastern European nations, to allow a racist and xenophobic party to be in power in Austria – or anywhere else within the EU – is a continued reminder of the moral bankruptcy of the idea of European unification.
After the l930's and l940's one would have hoped that European countries would take threats emanating from a kind of language and sentiment expressed by Haider and his party more seriously.
This is the challenge for European leaders now, and one would hope that under the French Presidency, and with the traditions of the Enlightenment being so central to French and European discourse, a vigorous, efficient response will be found.
ROME – A game of smoke and mirrors: this is how Italy’s current electoral campaign appears – both to Italians and the wider world.
Of course, there is nothing new in this: Italy’s political dynamics have always baffled participants and observers alike.
That a small centrist party may now get the courts to postpone the election merely adds to the usual confusion.
But one thing that seems certain this time is the likely result.
Silvio Berlusconi, the leader of the right-wing alliance, will win his third election (he has also lost twice), while the vote for the Senate is expected to produce a draw.
In this case, Berlusconi’s forces could ally themselves with Pier Ferdinando Casini’s centrist Catholic party, or work to form a coalition with their center-left adversary, the Democratic Party, led by Walter Veltroni. 
The latter option, once unthinkable, is possible because Berlusconi is not running the type of inflammatory electoral campaign that he has in the past.
The sharp tone and fierce partisanship of the past 13 years have been cast aside.
Berlusconi seems to be fully aware of the difficulty of governing Italy.
He needs to be.
With public debt expected to stand at 102% of GDP in 2009, rising inflation, and growth of just 0.2%, it will be difficult to keep electoral promises.
Sagging public infrastructure and an inability to attract foreign capital have made the economic outlook even worse.
In addition, while the state-owned companies Telecom, Autostrade, and Alitalia were subject to an extremely interventionist policy by Romano Prodi’s outgoing government, they have little to show for it.
Plans to build a high-speed train connecting Italy with northern Europe continue to experience delays. The garbage crisis in Naples remains unresolved putting the international reputation of one of Italy’s most famous products, mozzarella, at risk.
With global financial markets in crisis and Europe’s economy softening, the challenges for the new Italian government will only become greater.
Foreign policy, too, may prove difficult to manage.
New activism on the part of France and the United Kingdom, along with Germany’s emergence as a central player in EU affairs, risk marginalizing Italy’s influence even more.
If Berlusconi returns to office, he will again seek strong cooperation with the United States, the path now being followed by French President Nicolas Sarkozy and British Prime Minister Gordon Brown.
If he succeeds, something like a six-nation “contact group” (France, the UK, Germany, Spain, Poland, and Italy) will have formed to determine EU relations with the US.
This leadership will be needed, because, regardless of who wins the US presidential election, the next American administration is bound to ask for greater EU participation in addressing international conflicts. 
But Italy, unlike France, is in no position to substitute the beauty of Carla Bruni, Sarkozy’s new wife, for real prestige.
To achieve that, the country must promote itself as a motor of serious European reform, without neglecting the debate on the member states’ role in the EU’s economic choices.
Here Italy could join the more nationally minded economic policies now being pursued by France and the UK, to the detriment of EU technocrats in Brussels.
The one thing that seems certain from the upcoming vote is that – barring any last-minute surprises – the billionaire Berlusconi will re-assert his hold over Italian politics.
In fact, he has been Italy’s true ruler for the past 13 years.
Born as a “plastic party” to unite a gamut of political forces following the implosion of the Christian Democrats in 1994, Berlusconi’s Forza Italia showed itself to be a very cunningly structured movement, with a strong and stable consensus among its members on core doctrine.
In this election, Berlusconi decided to open the door to Gianfranco Fini’s right-wing National Alliance, with which he founded a new group, People of Freedom – the only party allied with Umberto Bossi’s Northern League – in an effort to ensure that the government is backed by an even stronger and more cohesive core party.
The Catholics of the Union of Christian and Center Democrats and the post-fascist right of Francesco Storace have left the coalition. 
A similar choice was made on the left by Veltroni, whose Democratic Party is now allied with Antonio Di Pietro’s Italy of Values Party.
The Communist Party and the Socialists have left the coalition that Prodi forged to gain his parliamentary majority.
The purpose of this realignment was to create more stable large parties, but further changes are likely.
Strong pan-European center-right and center-left political parties are likely to contest the European Parliament elections in the spring of 2009.
As Europe presses ahead with reform, the question for Italy is whether smoke and mirrors is all its politics have to offer.
The Middle East conflict - Palestine versus Israel now, Iraq to come - creates serious risks for growth and financial stability.
To understand the severity of these risks, let's work backwards from what is unlikely to happen.
All grandstanding notwithstanding, neither Iraq nor Iran will mount an effective oil embargo on the US.
First, their commitment to oppose America does not include a pre-emptive sacrificing of essential oil sales that keep their run-down economies churning.
Both countries recognize that if they refuse to sell America oil, other countries (Russia and Mexico) will take up the slack.
So an Iran/Iraq oil embargo is bound to be ineffective.
All that will happen is that they will lose money.
Even Saddam is smart enough to avoid this trap, so he and Iran's ayatollahs will posture and grandstand and thus move oil prices up a bit.
Nothing more serious than that.
To their Arab spectators, grandstanding is almost as good a proof of leadership as actually doing something.
But the real risk to oil is open hostilities or sabotage of oil installations.
What matters here are not oilfields, but pipelines, refineries, and oil ports - they influence spot price because they govern the immediate availability of oil.
As we saw in the Gulf War, the risk of damage to oil refineries raised spot prices dramatically: $40 back then.
This time around the price would certainly go higher because the risks including sabotage are much more widespread.
This would almost certainly happen if and when the US takes on Iraq.
In principle Saudi Arabia could offset a price rise by hiking its production.
But it is one thing for Saudi Arabia not to join an embargo, and it is another to undercut oil politics by flooding the market in a pro-US move.
Saudi Arabia is unstable, so it will keep trying to straddle both sides.
Use of America's vast strategic oil reserve will dampen world oil prices for a time, but when all is said and done, once hostilities with Iraq start, oil prices will shoot up.
When may any of this happen?
America demands that Iraq meet three criteria - promoting regional stability, ending its pursuit of weapons of mass destruction, and ending suppression of its own people - to which Saddam will never assent.
Saddam is, thus, doomed and it does not matter whether Europe cooperates with the US or not.
The problem, as in 1991, is the absence of a suitable government to fill the vacuum, one acceptable to the region and to the US.
That issue and the unresolved Palestine-Israel debacle are holding off immediate action.
This means that oil prices will remain high (possibly higher) for some time to come.
Consumers in the US, but also in Europe and Asia, will be hit by an oil shock.
They will have less spending power, demand will fall and growth will slow, as during the Gulf War.
A slowdown of the US and world economy, in turn, is bad news for asset markets and will put central banks in the awkward position to having to decide between fighting recession through easier money or fighting the inflation caused by rising oil prices by raising interest rates.
If tightening is the rule, say sayonara to a rising stock market.
True, oil is far less important to the industrial economies nowadays than in the past, but an extra $10 dollars per barrel in costs is a huge shock that will hit hard.
Suppose all this happens, what will happen to the dollar?
So far, the dollar remains strong relative to Europe--not very strong, a rate of $1.10 for the Euro was never an equilibrium rate--but it was sustained by US relative growth performance and by the image of a US as the world's economic superstar.
The superstar role is enforced by military prowess but it becomes seriously damaged when it gets bogged down in worldwide disapproval, from greens, anti-globalizers and peaceniks, European cynicism, and the angry "Arab Street".
With an economy that will not better Europe in such adverse circumstances, and with a tarnished US image, the dollar will be at risk of a serious fall.
The only thing that might hold the dollar at near to present levels is a bad economic performance in Europe.
After all, blaming the US is predominantly a way of shifting light from Europe's failed leadership to another country's struggles for a safer world (including the continued existence of Israel) and a stronger world economy.
After all, the problems that beset Mr. Schroeder, or Mr. Berlusconi, and Messieurs Chirac and Jospin, aren't the stuff that shapes the world.
CAMBRIDGE – 2008 has been an exceptionally tumultuous year for exchange rates.
The American dollar soared, the Japanese yen went into orbit, the euro fell to earth, and the British pound crashed, leaving a giant crater.
Emerging-market currencies were hammered, as were “commodity currencies” such as the Canadian, Australian, and New Zealand dollars, and the South African rand.
Indeed, the currency of any country that is significantly dependent on commodity exports has suffered.
So, what will the New Year bring for exchange rates?
While the only safe bet is continuing high volatility, we are at an unusual juncture where the short- and long-term trends appear to be very different.
In the short run, the yen and the dollar continue to benefit from a flight to safety, as panicked investors seek a place to hide.
The yen and dollar are also being bolstered as central banks elsewhere continue to cut interest rates towards zero, territory that the yen and dollar policy rates already occupy.
Thus, even though the United States and Japan will not be raising interest rates anytime soon, lower foreign rates still make the dollar and yen relatively more attractive.
Commodity prices will continue to be soft, pulling down commodity currencies, and bolstering the yen especially, since resource-poor Japan is so reliant on commodity imports.
Normally, short-run and long-run exchange-rate trends point in the same direction.
Indeed, a huge body of research shows that for most major currencies, the best forecast of next week’s exchange rate, next month’s exchange rate, or even next year’s exchange rate is simply today’s exchange rate.
But times are hardly normal.
The continuing financial crisis is putting steady upward pressure on the dollar thanks to its safe haven status.
Commodity prices are plumbing new depths.
Yet the financial crisis will eventually end, as will the global recession.
Neither will end soon, mind you, perhaps not for another seven or eight months, if not longer.
But, when more normal growth does resume, the recent trends underpinning dollar and yen appreciation will disappear.
Perhaps international investors will be grateful to the US for its aggressive monetary and fiscal stimulus, which will accelerate sharply when President-elect Barack Obama takes office on January 20.
But investors will still worry about what happens when the bills come due.
Many emerging markets will also want to engage in countercyclical macroeconomic policy, but they are hemmed in by concerns of fiscal sustainability and fear of rampant inflation.
European fiscal policy is constrained by the Maastricht Treaty, while European monetary policy is rather single-mindedly devoted to price stability.ampnbsp; 
True, China, with its vast foreign exchange reserves, has the wherewithal to spend as much on countercyclical macroeconomic policy as anyone.
But China’s rulers know that their highly repressed banking system is vulnerable as the country continues to pursue gradual financial liberalization, and that foreign currency reserves may be needed for recapitalization.
Thus perhaps no region will be as expansionary as the US.
For the moment, global investors cannot get enough of US treasury bills, as collapsing interest rates for short-term US securities demonstrates.
But a lot of this demand is driven by short-term, crisis-fueled fear.
As markets normalize, surely investors will look around and realize that the US has vastly increased its debt in fighting the downturn, possibly by several trillion dollars.
At the same time, today’s falling prices (or “deflation”) will eventually morph into inflation as aggressive monetary easing takes its toll on price stability.
Admittedly, some of the major currency’s movements during the past year can be regarded as normalizing.
On a purchasing power basis (a crude measure of what different currencies can buy in terms of real goods), the euro was absurdly overvalued at $1.60, just as the yen was absurdly undervalued at over ¥120 to the dollar.
Commodity currencies had to come off their meteoric highs.
Thus, the past year’s currency alignments have, to some extent, simply brought relative domestic price levels and exchange rates into better balance.
But by now, emerging-market countries’ exchange rates, and even more so commodity currencies, have probably overshot on the downside.ampnbsp; 
Over the long run, globalization and economic convergence will resume, and emerging market and commodity currencies will have to strengthen.
At the same time, the prospect of higher US inflation and massively higher US public debt levels must eventually weigh on the dollar, as does the still worrisome US trade deficit.
As for the yen, it, too, will suffer from the continuing rise in Japan’s public debt levels, which are already among the highest in the world.
Continuing weakness in the Japanese economy will eventually hit the yen.
If today’s constellation of exchange rates represents some excessive dollar and yen appreciation, especially against emerging-market currencies, when it will unwind?
That depends on when you think the financial crisis will abate, and the timing of that is as hard to predict as exchange rates.
But come it will.
Then watch for the dollar and yen to boomerang.
PARIS: Brazil's currency devaluation earlier this year, and its difficulties since in stabilizing the real as well as its stock market, have demonstrated the importance, if any new proof was needed, of financial markets and their volatile mood swings.
There can no longer be any doubt that investor panic can provoke economic meltdown, as it did in Asia and Russia last year, still threatens to do in Brazil and across Latin America, and may yet stage an encore in Asia over worries about a devaluation in China and the spiral of competitive devaluations that could follow.
Now in its eighth year, the almost obscene economic growth in the United States could be used to illustrate the inverse proposition.
On at least two occasions in 1998, bad news could have set off a crash in American stock prices and an economic recession.
After all, the majority of observers (analysts, too) had concluded that Wall Street was overvalued, even before the onset of the Asian crisis.
Stock prices did, of course, decrease as a result of the Asian panic and its financial ramifications, but America's stock markets have since then recouped all of their initial losses and even moved on to new record highs.
The impeachment trial in the US Senate of President Clinton and the political crisis that could have amplified both political and economic uncertainty, leading to another sharp fall in prices on Wall Street, also had absolutely no effect on Americans and how they spend and save their money.
Investors and consumers did not lose their optimism.
Nothing seems able to shake them.
Could the American public's faith in Alan Greenspan, chairman of the Federal Reserve Board, America's central bank, be a satisfactory explanation?
He's done a solid job, but I doubt that this can be the only cause of American buoyancy.
So what factors get economies going and keep them humming?
In Europe, the advent of the Euro has certainly not invigorated economic growth, and does not look likely to do so anytime soon.
The best news of the year is that, at long last, the Continent's consumers seem to be emerging from their long depression.
In contrast to the United States, however, the boost in consumer demand has not become an engine of growth.
Why not?
Probably because the macroeconomic policies of Europe's governments were, and remain, overly cautious and have not dared provide the necessary kick-start.
Having satisfied the Maastricht criteria, fiscal policies have been geared to putting on brakes.
Across "euroland" monetary policy was focused on the harmonization of interest rates, not on their level.
So there is little reason to be terribly optimistic for the near future, neither for growth nor job creation.
Still, there is an upside here.
Europe's relatively newfound fiscal discipline probably was a blessing in maintaining market confidence, and thus in immunizing the Continent, during the Asian, Russian, and Brazilian financial panics.
In Japan, sad to say, that sort of fiscal austerity remains something of a curse.
Sad to say, Japan continues to teach us that some of history's most painful episodes do repeat themselves.
A series of vicious cycles that one had hoped had vanished with the end of the Great Depression have shown themselves to be relevant today.
Deflation increased real interest rates and curbed economic activity, thereby setting off another round of deflation, and so on.
With interest rates reaching almost zero, this liquidity trap has paralyzed Japan's monetary policy.
Keynesian remedies (now being tardily applied) and an expansionary fiscal policy have not been able to jump-start the Japanese economy and bring about a return of optimism.
Is it because the Japanese government delayed action for too long before accepting budget deficits?
No one really knows.
Is it possible to discern a common thread to all of these developments?
I see two of them.
The first one is the importance of what Keynes called "animal spirits."
In all cases, they have been at the center of today's economic successes and failures.
The second one is that it is quite difficult to tame those animal spirits.
Why did international investors panic in South East Asia?
Why has, say, Poland been relatively immune to the panic caused by Russia while the rest of Eastern Europe caught cold?
Why do American consumers seem to be immunized against pessimism?
Is there a macroeconomic policy that could boost the still shaky optimism of consumers?
How can Japan restore optimism and jump-start its economic engine with no macroeconomic tools left to use?
These are the questions on which governments must now focus.
On the answers will depend the health of the global economy.
NEW YORK – We know quite a bit about Iran’s nuclear program, and what we know is not encouraging.
Iran is reported to be enriching uranium at two sites – some of it to levels of 20%, far beyond what is required for civilian purposes.
The International Atomic Energy Agency also reports that Iran is carrying out research to develop designs for nuclear warheads.
In short, Iranian officials’ claims that their nuclear program is aimed solely at power generation or medical research lacks all plausibility.
Yet there is still much that the world does not know.
For example, we do not know whether Iran is conducting secret activities at undisclosed sites, or when Iran could develop a crude nuclear weapon, with estimates ranging from several months to several years.
We also do not know whether Iran’s divided leadership has decided to develop nuclear weapons, or to stop just short, calculating that the country could derive many of the benefits of possessing nuclear weapons without running the risks or incurring the costs of actually doing so.
Either way, Iran’s activities confront the world with difficult choices.
None is costless or risk-free.
Moreover, neither the costs nor the risks are possible to calculate with precision.
One option would be to accept and live with a nuclear or near-nuclear Iran.
This assumes that Iran could be deterred from using its weapons, much as the Soviet Union was during the Cold War.
Missile defenses could be expanded; the United States could extend security guarantees so that Iran would understand that the threat or use of nuclear weapons would be met with a decisive American response.
But there are significant drawbacks to acquiescing to a nuclear-armed Iran.
Given its use of subversion and terrorism against its adversaries, a nuclear-armed Iran might be even more assertive.
It might also transfer nuclear-related material, technology, or weapons to allies (Hugo Chávez’s Venezuela, for example) or radical organizations such as Hezbollah and Hamas.
And, rather than promoting caution and stability in the region, Iran or Israel could be tempted to strike first in a crisis.
Nor can it be assumed that Iran’s divided and radical leadership would always act rationally, or that proliferation would stop with the Islamic Republic.
If Iran develops its nuclear weapons, countries such as Saudi Arabia, Turkey, and Egypt would be tempted to purchase or develop nuclear weapons of their own.
A Middle East with multiple fingers on multiple triggers is as good a definition of a nightmare as there is.
At the opposite end of the spectrum of policy choices is a preventive attack: a military strike (most likely by Israel, the US, or both) against sites in Iran associated with its nuclear program.
The core objective would be to interrupt the emergence of a threat that is still gathering.
Here, again, there are considerable drawbacks.
Even a successful preventive attack would at most set back Iran’s nuclear program a few years.
It would almost certainly be rebuilt, presumably in underground, fortified sites that would make future attacks far more difficult to carry out.
Moreover, Iran could well retaliate immediately against targets that could include Saudi Arabia, Iraq, Afghanistan, and other US interests worldwide – as well as sites on American territory.
Hezbollah could attack Israel.
If all of this happened, the price of oil would skyrocket owing to shortages and fears, possibly driving much of the world economy, already in a precarious position, into recession.
An armed attack could also cause the Iranian public to rally around the government, reducing the chances that a more responsible leadership might emerge.
It thus comes as little surprise that the US and much of the world have explored alternatives, including regime change in Iran.
But, however desirable that might be, no policy can assuredly bring it about.
As a result, the principal policy toward Iran centers on the imposition of increasingly painful economic sanctions.
The rationale underlying this policy is that Iran’s leaders, fearful of losing political control as popular discontent increases over the sanctions’ effects, will recalculate the costs and benefits of their nuclear activities and become receptive to negotiated constraints in exchange for removal of sanctions.
That could happen.
International support for sanctions is considerable and increasing.
It is becoming more difficult for Iran (whose economy depends to a large extent on oil exports of more than two million barrels a day) to find customers – and especially customers willing to pay full price.
Meanwhile, Iran’s currency is weakening, pricing imported goods out of many Iranians’ reach.
Additional elements of current policy that seem to be having an effect are clandestine efforts aimed at impeding Iran’s ability to import sensitive technologies.
Viruses have infiltrated computers in Iran, reducing the efficiency of the centrifuges central to enriching uranium.
It is also possible that the assassination of selected individuals has slowed the advance of Iranian nuclear efforts.
But slowing Iran’s efforts is not the same as stopping them.
So one question is whether existing sanctions can be extended and tightened; here, China and Russia must determine their priorities.
Another question is whether any sanctions will be enough to persuade Iran’s leaders to accept verifiable limits on their nuclear program.
And a third unsettled issue is how long Israel or the US will tolerate Iranian efforts before striking militarily.
Indeed, the only certainty may be that Iran’s nuclear program will be a major international issue in 2012 – quite possibly the most important one.
The question of how the international community should deal with Saddam Hussein, Iraq's ruthless dictator, is rightly the year's dominant theme.
In one sense it has been answered: the United Nations is and will continue to be involved, and the United States has and will continue to play the leading role.
Containment of Iraq by intervention is the method that now seems most likely.
In the process of reaching this decision, however, several long simmering issues have come to the fore.
One, of course, concerns the supposed "clash of civilisations": how do we keep a focused and limited conflict between the UN and Iraq distinct from the need to maintain a relationship of dialogue between world religions?
Another question may seem more parochial to some but is of equal significance globally: what are we to make of the differences between Europe and America that have become so manifest in the Iraq debate?
Is this its own form of "clashing civilizations."
No doubt, the differences that now exist between America and Europe are profound, and are not confined to a temporary cooling of German-American relations or to a half-serious exchange of invectives about "gun-slinging America" and "old Europe."
Indeed, even intellectuals are caught up in the emotional undertones.
When the British historian Timothy Garton Ash, writing in theNew York Review of Books, distinguished the US and Europe by paraphrasing the title of a bestselling book, saying that "Americans are from Mars, Europeans are from Venus," some American readers objected to the sexual portrayal of an effiminate Europe and a macho America.
Yet Garton Ash is among the most pro-American Europeans, whose views of a united Europe are closer to those of his many friends in the "new", postcommunist Europe than to those of France or Germany.
But views about what Europe is and should be are actually at the heart of today's anti-Americanism.
The countries of Europe are moving inexorably towards the "ever closer union" that the founding Treaty of Rome demands.
There is a single market, crowned--at least for most EU members--by a single currency; there is a constitutional convention that will propose a new basic treaty, perhaps by mid-June; there are ambitious plans for a common foreign and security policy and other common policies.
So what is the problem?
One problem--probably the most fundamental--is that European integration no longer fires the imagination of Europeans.
There are still Euro-enthusiasts, but among the peoples of Europe indifference and, in some places, mild hostility, prevails.
Even the common currency has so far not really caught on; it is useful, but somehow "foreign."
Underneath all this is the niggling question: why are we doing all this?
What is the compelling reason that provides the driving force behind "ever closer union"?
In the 1950s, the answer was simple: Europeans should never go to war against each other again. On the contrary, they need to stand together against the Communist threat.
Fifty years later, these goals are no longer relevant.
Economic union has benefited many; but it is not the type of driving force that inspires.
More recently, the idea of a "European identity" has been in vogue.
The EU supposedly expresses it.
But how is this identity to be defined?
This is the point at which many begin to use language that defines Europe by distinction, indeed by contrast, to the US--Europe as the anti-America. Throughout the Cold War, what was then the Soviet Union provided araison d'être for European union; in the era of globalization, it is the US.
Comparing and contrasting the two sides of the Atlantic has a long pedigree, of course.
European culture and American commerce, European profundity and American materialism--these are ancient and tired themes.
Most would today use more subtle language.
They point to what they regard as America's unfettered capitalism and hold up Europe's social market economies against it.
Internationally, Europe likes multilateral arrangements, whereas America prefers to go it alone.
From the other stereotypical point-of-view, Europe wallows in the complexity of issues whereas America likes simple lines of conflict--you are either for us or against us.
It is easy to see how the belief in such differences affects the Iraq debate.
The result is that many leading Europeans begin to define their intentions for the Union by contrasting it to the USA.
The euro must hold its own against the dollar--and hurrah!--it is now above parity.
European foreign policy must provide a counterweight to that of the hyperpower across the Atlantic.
On closer scrutiny, such facile phrases are deeply disturbing.
The eight (and now nine or more) governments that signed the Aznar/Berlusconi/Blair statement supporting the US realized this.
They insisted on undivided Western values, the values of enlightenment and liberty.
These values are shared between Europe and America--and some others--and they are worth defending in an alliance.
When it comes to values, any attempt to divide the American and the European traditions is misguided.
It may be that these shared values make it more difficult to find the much-desired European identity.
But feeding anti-American sentiment, however unintentionally, into the European construction would be intellectually dishonest, morally suspect, and politically dangerous for all freedom-loving Europeans.
When Brazil's Supreme Court ruled in the case of Sigfried Ellwanger ­- an editor, author, and notorious Nazi sympathizer - it entered the perilous field where free speech and efforts to contain racism meet.
For years, Ellwanger published anti-Semitic books, such asThe Protocols of the Elders of Zion, as well as books of Holocaust denial, such as his ownJewish or German Holocaust: Behind the Lie of the Century.
By a vote of eight to three, the Court upheld his conviction on charges of racism.
Of course, the enormity of the Holocaust ought to have eradicated anti-Semitism for all time.
Shamefully, it did not.
In many places, hatred of Jews thrives.
Elsewhere - including Europe and the United States - anti-Semitism survives among a fringe of neo-Nazis and renegades like Ellwanger, but also, more widely, in milder forms of prejudice.
But punishing someone criminally for being an anti-Semite and a racist propagandist raises troublesome issues that different countries approach in different ways.
To be sure, every country places some limits on speech.
As Oliver Wendell Holmes famously put it in a 1919 US Supreme Court decision, "Even the most stringent protection of free speech would not protect a man in falsely shouting 'fire' in a crowded theater and causing a panic."
Banning someone from shouting "Fire!" in a crowded theater is not the same, however, as convicting him for holding and propagating an opinion, even a despicable one, such as anti-Semitism.
In a democracy, standard restrictions regulate the time, place, and manner of speech in order to prevent imminent violence and civil disorder.
They bar threats against, and harassment of, individuals.
They forbid libel and fraud.
Some countries, such as the US, refuse to go further and regulate speech because of itscontent.
The reason, as US Supreme Court Justice Louis Brandeis put it, is that "If there be time to expose through discussion the falsehood and fallacies, to avert the evil by the processes of education, the remedy to be applied is more speech, not enforced silence."
Why, then, do many countries prosecute the hate speech of racists?
Why do International Human Rights Conventions stipulate that the law should prohibit speech that supports national, racial, or religious hatred?
Is any form of race-related speech that anybody finds offensive to be prosecuted?
Will such prosecutions actually deter hard-core racists?
No court should convict someone lightly because of the views he espouses in the public sphere.
But Ellwanger's appeal, which took almost a year for Brazil's Supreme Court to hear and decide, put Brazil squarely on the side of those who believe that inciting hatred against even a small minority - such as Jews in Brazil - cannot be allowed in the name of freedom of speech.
The Ellwanger case arose because many believe that anti-racism laws can be effective in reassuring minorities of their safety and place in the community.
Brazil is a large, pluralist, multi-ethnic country.
Its social fabric, like that of many other countries around the world, depends on mutual trust among citizens.
Constitutional and legal provisions that make practicing racism a crime punishable by imprisonment have great symbolic significance and help insure - indeed, create and secure - social peace.
Defining the offensive racist views proscribed by the Constitution was the first challenge in the Ellwanger case, because the defense denied that anti-Semitism constitutes racism at all.
The Jews, the defense claimed, do not constitute a race.
In fact, the Jews are, of course,not a race, but then neither are whites, blacks, mulattos, Indians, gypsies, Arabs, or any other subgroup of human beings.
The recently completed sequencing of the human genome proved the existence of but a single race: the human race.
The Court made short shrift of Ellwanger's claim, becauseall human beings can be the victims of racism.
The practices of racism are historical, political, and cultural phenomena.
Their systematic dissemination endangers minorities, threatening them with invidious discrimination.
The truth of a racist belief is not the issue.
The second issue the Court considered was the conflict between constitutional principles: the clash between freedom to express one's thoughts and condemnation of Ellwanger for the crime of racism.
The court ruled that, ultimately, freedom to express one's thoughts, however generously conceived in a democracy, must be balanced against other values, such as reputation, honor, privacy, dignity, and equality.
Ellwanger crossed the line separating free expression from hate speech.
As in the Ellwanger case, restrictions on free expression should be defined narrowly.
But by opting for a balanced concept of free speech, Brazil's Supreme Court followed precedents in a number of European countries condemning Holocaust deniers, as well the opinion of the committee charged with monitoring compliance with the UN Convention on the Elimination of all Forms of Racial Discrimination and the European Court of Human Rights.
In a world where anti-Semitism and racism fester, where prejudice on national, religious, colored-based, or ethnic grounds foster discrimination, that is the view that best nurtures the rights of all.
We were taken aback and dismayed by reports of actions directed against ethnic Georgians in Russia.
These include accounts in the international media that Moscow police have asked schools to draw up lists of pupils with Georgian surnames as part of their search for illegal immigrants, and verifiable cases where Georgian businesses in Russia have been closed.
Knowing the importance to poor families of remittance to Georgia, we are also concerned at reports of measures to block bank transfers.
We feel obliged to emphasize that disputes between governments are not grounds for actions against the civilian population.
We would hope that the leadership of the Russian Federation will affirm the rights of ethnic minorities; refrain from hostile rhetoric and actions against Georgians; and ensure that our common democratic values and respectful relations between neighbours are upheld.
André Glucksmann
Vartan Gregorian
Frederik Willem de Klerk
Václav Havel
Mike Moore
Michael Novak
Yohei Sasakawa
Karel Schwarzenberg
This month has been a bad one for the cause of human rights in Europe, as Serbia was allowed to begin its six-month presidency of the Council of Europe, the Continent’s oldest political body.
With Serbia at the helm, the Council, which aims to promote human rights and the rule of law, is now overseen by a state that thumbs its nose at the Genocide Convention and harbors an indicted war crimes suspect, former Bosnian Serb army chief Ratko Mladic.
Moreover, the European Commission has indicated that it is ready to resume talks aimed at bringing Serbia closer to the European Union as soon as a reform-oriented government is formed in Belgrade.
Earlier this year, the International Court of Justice (ICJ) found Serbia guilty of failing to prevent the massacre of more than 7,000 Bosnian Muslim men in Srebrenica.
The Court also declared that Serbia will remain in violation of the Genocide Convention until it transfers Mladic—who is believed responsible for some of the worst crimes in Europe since the Second World War—to the International Criminal Tribunal for Former Yugoslavia (ICTY) in The Hague.
But the EU seems ready to ignore Serbia’s disdain for international law.
The EU is understandably eager to support a pro-European government in Serbia, for this might pave the way for Serbia to swallow the prospect of Kosovo’s independence.
That explains why some EU member states are keen to resume the negotiations on a Stabilization and Association Agreement, which were suspended a year ago due to Serbia’s failure to cooperate fully with the ICTY.
The proposed u-turn by the EU means that Mladic’s arrest and transfer to The Hague is no longer a condition for restarting talks.
Of course, Europe needs to sweeten the Kosovo deal for Serbia.
But an immediate resumption of negotiations amounts to an approach that is all carrot and no stick, damaging the EU’s own credibility.
Indeed, the West has already tried this approach before, with paltry results.
In December 2006, NATO allowed Serbia to join its Partnership for Peace, even though there were still war criminals at large in the country.
This softer approach will prove counterproductive, as it will not strengthen democratic forces in Serbia.
Just last week, caretaker Prime Minister Vojislav Kostunica, once hailed by Europe as a great democrat, showed his true colors.
He went so far as to support the election of an extreme nationalist, Tomislav Nikolic, who was an old ally of Milosevic’s, as the Speaker of the Serbian Parliament.
The head of Nikolic’s party, Vojislav Seselj, is in the dock in The Hague facing trial for war crimes.
Although Nikolic soon resigned after a new Serbian government was formed, the cabinet’s composition suggests that the EU might be foolish to expect greater cooperation with the ICTY.
By effectively abandoning conditionality, the EU will be rewarding the most intransigent hard-liners in Serbia – that is, the very people who have opposed the arrest of Mladic for years.
With the ICTY’s closure just one year away, there is a risk that Mladic will never be held accountable.
The effect that the resumption of talks might have on the system of international law is no less chilling.
Serbia’s leadership of the Council of Europe is a done deal.
But the EU must insist on Serbia’s compliance with the ICTY, the ICJ decision, and its own Copenhagen political criteria.
Mladic must be arrested before talks start, not after.
As a signal of their seriousness, European governments should think twice before they accept Serbia’s invitation to attend the Council of Europe’s festive 1,000th meeting in June.
A minute of silence for the victims of unarrested war criminals might be a more appropriate way to pay tribute to the Council’s core values of human rights and justice than attending the party now being planned in Belgrade.
The deaths of Yasir Arafat and of Sheikh Zayd, the long-standing ruler of the United Arab Emirates, continues the generational change that began in 1999-2000, when the leaders of Jordan, Morocco, Bahrain, and Syria died in quick succession.
Across the Middle East people are younger, and their political leaders older, than the world average.
The gradual replacement of one generation of elites by another may be one of the key factors in determining whether or not effective reform takes place in the Arab world.
At present, four political generations co-exist on the region’s socio-political map.
The outgoing leadership generation – that of Arafat, King Hussein or Hafiz al-Assad, King Fahd and President Mubarak – was born before 1935 and has determined events in the Middle East since the 1970’s.
These leaders came of age and began their careers during the era of decolonization.
They were weaned on Gamal Abdel-Nasser’s pan-Arab nationalism, and the crucial political event for them was the Arab defeat in the 1967 Arab-Israeli war.
Members of this generation sought a strong Arab leadership that would create a balance of power with Israel.
They also believed in – or at least toyed with – forms of socialism and étatism, and did not consider democracy or civil rights to be priorities.
The next generation was born between 1935 and 1955, and in many respects represents a generation “in between.”
Most benefited from the economic growth and expanded educational opportunities associated with the oil boom of the 1970’s.
At the same time, political participation remained blocked by the previous generation, which never intended to give up power voluntarily.
Unsurprisingly, many in this generation grew dissatisfied, and not a few began to look for Islamic alternatives to the prevailing political systems.
Rather than determining events in the coming two or three decades, this generation is likely to be sidelined by the next cohort, born between 1955 and 1975.
This is the generation of Syria’s President Bashar al-Assad, Jordan’s King Abdullah and Morocco’s King Muhammad VI.
Some call this the “generation of sons” – sons of leaders who led their states for decades.
This age cohort was not much influenced by the Arab-Israeli wars or the East-West conflict.
Instead, their political education included the Gulf War of 1991 and the Arab-Israeli peace process of the 1990’s, with its crises and breakdown.
Jailed West Bank Fatah leader Marwan Barghouti is as representative of this group as the leaders of Syria and Jordan.
Members of this generation are better acquainted with notions of globalization and economic reform than with socialism and revolution.
Except for the Palestinians, they have never known their countries other than as independent and comparatively stable states.
In the Palestinian territories, the jil al-intifada , the generation of the (first and second) Palestinian uprising, will likely become the founding generation.
But it is the fourth group that underscores the relevance of generational issues in the Arab world.
Even when combined, the first three generations make up barely one-third of the entire Arab population.
Almost 60% of all Arabs are younger than 20, with roughly 70% below the age of 30.
This raises a key question: what happens to these Arab “baby boomers” if the generation now coming to power clings to it as tenaciously as the generation of Mubarak, Assad, and Hussein?
The political generation of Bashar al-Assad, King Abdullah, and Gamal Mubarak – son of Egypt’s ailing president – forms a less coherent picture than that of the outgoing leadership.
In that elder generation, many had pursued military careers, and many of their aides and collaborators were engineers and civil servants.
The socio-professional profile of the new elite is broader.
Economists, bankers, and entrepreneurs as well as of technology or communication experts are common.
There are also more traditional politicians: personalities who see themselves as representatives of particular social or economic interests, not as apolitical technocrats.
This new leadership elite is in many ways more cosmopolitan than its predecessors; their average level of education is higher; a few have foreign degrees.
Women also play a somewhat greater role.
Developments in Morocco, Bahrain, and Jordan certainly seem to suggest that this changing of the guard can help soften rigid political structures and allow for broader participation.
But generational change need not be accompanied by economic reform and steps towards political liberalization – witness North Korea under Kim Il Sung’s son, Kim Jong Il.
Indeed, experience gives little reason to presume that a modern way of speaking, willingness to liberalize the economy, and an urge for technological development automatically translates into a democratic opening.
It is more realistic to expect that the new Arab elites will make use of their states’ authoritarian institutions, both to overcome resistance to their economic agendas and to consolidate their newly acquired power.
This is anything but a risk-free path.
Without a significant increase in opportunities for political participation, including genuinely competitive elections, the chasm between a predominantly young population and a ruling elite with a narrow generational base will widen.
Such continuing political inertia leaves an increasingly young Arab population prey to the appeal of extremist ideologies, while driving the best and brightest to seek their fortune elsewhere.
The problem of succession in the Arab secular republics highlights their predicament in the transition to a post-revolutionary phase, for succession in regimes that fail to build strong institutions always risks triggering a systemic crisis.
While the decision by some in favor of dynastic succession may be lacking in democracy, it is not entirely devoid of merit.
Arguably, it is a choice for economic modernization, for an end to the politics of conflict, and for positive political change further down the road.
Years of Western-backed repressive authoritarianism nipped in the bud any potential growth of a liberal alternative to the incumbent Arab regimes, and turned any abrupt move to free elections into a dangerous exercise in Islamic democracy.
A democracy that produces governments led by Hamas, Hezbollah, or the Muslim Brotherhood is inevitably bound to be anti-Western and opposed to an American-inspired “peace process” with Israel.
Syria has already sought to assure regime continuity through quasi-monarchic hereditary succession with the move from Hafez al-Assad to his son Bashar.
There are indications that Egypt might follow suit, with Hosni Mubarak’s son, Gamal, taking over.
Likewise, Libya’s Muammar Khaddafi may be succeeded by his son, Seif el Islam.
As products of revolutionary military takeovers, these secular nationalist regimes failed to produce genuine popular legitimacy and have had to fall back on the dynastic succession practiced by the regimes they toppled.
The centrality of hereditary succession in the quest for peace and stability was shown by Hafez al-Assad when he agreed to unprecedented good will gestures aimed at drawing Ehud Barak’s Israeli government into a peace deal.
An old and sick man who was to die a few months later, he acted with a sense of urgency to reach a deal that would relieve his inexperienced son of the burden of struggling for the recovery of the Golan Heights.
Bashar Assad remains essentially loyal to his father’s legacy.
Not unlike North Korea’s and Iran’s defiant nuclear policies, Bashar’s membership in the region’s “axis of evil” is a call for dialogue with America, not an invitation to an invasion, and for a settlement with Israel, not a drive to wage war on it.  
In Egypt, Mubarak turned his back on the lofty rhetoric of Gamal Abdel-Nasser’s revolution and its grand strategic designs.
Stability is at the heart of his thinking.
Hence, he could not accept America’s awkward pro-democracy agenda.
But he was more than willing to occupy center stage in Arab diplomacy’s support of the Annapolis peace conference.
After all, the passion that the Palestinians’ plight evokes among ordinary Egyptians is a dangerous source of instability.
Mubarak’s succession is being conducted in an especially sophisticated manner.
His son’s ascension, unlike that of Bashar on the eve of his father’s death, is anything but settled.
But, by being allowed to acquire popular legitimacy and a high degree of acceptance within the political establishment as the driving force behind the ruling party’s preparations for the post-Mubarak era, Gamal is being positioned strategically to compete effectively for the presidency.
He is widely credited for setting the country’s agenda, and for being the motor behind the liberal economic reforms that since 2004 have meant a qualitative leap in the Egyptian economy.
It may be, as President Mubarak’s critics argue, that the faltering progress of democratization reflects the attempt to block all potential challengers to Gamal.
But, with the decline of secular nationalism and Islamism’s rise, the hidden electoral power of the Muslim Brotherhood poses a mortal threat to the regime and its strategic alliance with the West.
As a result, the regime refuses to take any chances.
Nor was Muammar Khaddafi’s decision to stop being an international pariah entirely unrelated to his concern to bequeath to his son a state that lives in peace with the world.
His abysmal human rights record remains, but the flamboyant “Guide of the Revolution” ceased flirting with weapons of mass destruction and global terrorism in exchange for the end of sanctions and international rehabilitation.
A sick man whose rule at home is being challenged by Islamist opponents, he decided that international ostracism and domestic troubles is too explosive a combination for his son, a spoiled playboy, to handle.
Algeria is an especially difficult case.
The last of the revolutionary generation, President Abdulaziz Buteflika must still conceive a succession that ends his country’s civil war.
Fully-fledged democracy might lead to victory for Islamists, as it did in 1991.
A transition to democracy in the old revolutionary Arab regimes will not correspond to a Western model, nor can it be imposed by American F-16’s.
But, as countries like Egypt, Syria, and Lybia might be indicating, hereditary succession is not an inherently reactionary move.
Rather, it means opting for a controlled transition to a post-revolutionary phase in which economic modernization and international integration might usher in greater political change in the future.
WASHINGTON, DC – With Hosni Mubarak’s ouster in Egypt – widely considered to have one of the region’s most stable regimes until only recently – and Colonel Muammar Qaddafi clinging to power in Libya, there is no clear end in sight to the turmoil sweeping across the Arab world.
Protests have already toppled governments in Tunisia and Egypt, leaving other Arab countries faced with widespread discontent.
The unrest caught most people by surprise – both inside and outside the region – and has fundamentally upended at least five conventional beliefs about the Arab world.
Arabs don’t go into the street.
Before the protests began in Egypt and Tunisia, many people argued that there was no real urgency to political reform, and that those who were calling for change did not understand the public mood – things weren’t as bad as the dissidents made them out to be.
This line of thinking led governments to believe that Arabs would not demonstrate in large numbers and demand change.
In each country, rapid reform was seen as detrimental to national interests.
This argument clearly is no longer tenable.
No one predicted what happened in Egypt and Tunisia, which means that no Arab country is immune.
Governments don’t have the luxury of waiting forever, and they can no longer use the myth of popular quiescence to avoid initiating the necessary reforms that will address the public’s underlying grievances.
Economic liberalization should precede political reform.
Arab governments – and many Westerners – claimed that privatization and other economic reforms should be given priority over political change.
But, while it is easy to argue that citizens want bread before freedom, economic liberalization came without a system of checks and balances, and thus largely resulted in neither bread nor freedom.
Instead, the benefits of privatization and other initiatives went largely to political and business elites.
As a result, Arabs have come to view liberalization and globalization negatively.
It is clear by now that economic reform must be coupled with political reform, so that institutional mechanisms of accountability are developed to monitor any excesses and ensure that benefits are made available to all.
Governments have been quick to believe that the protests are fundamentally about high prices and unemployment, but the issue that unites Arab discontent is inadequate governance.
Closed systems are necessary to prevent Islamists from taking power.
The West is often afraid that democracy will give Islamists the opening they need to gain control – a fear that Arab regimes exploit to justify maintaining closed political systems.
But Islamists did not play a big role in Egypt or Tunisia, and they are not expected to lead any of the new governments that are formed – though they are an important part of Arab societies and should play a role in their emerging regimes.
So it is untrue that the only viable alternative to unrelenting absolutist rule must be Islamist.
The protests are clearly the result of ordinary citizens becoming fed up with corruption, the lack of any semblance of rule of law, and arbitrary treatment.
There is an opportunity here to start developing pluralistic systems where not only Islamists, but also other parties and discourses can play a role.
Elections equal democracy.
No one is fooled by this claim anymore.
In order to maintain their dominance, Arab governments have relied on flawed laws and elections that don’t produce strong parliaments or lead to real change.
Indeed, in countries like Egypt and Tunisia, government and parliament alike were unpopular.
Throughout the region, elections have been used to create a façade of democracy aimed at impressing citizens and the outside world while insulating the regimes from pressure for genuine reform.
The Arab public, however, will no longer accept the status quo.
People will not be satisfied with economic handouts or cosmetic changes in governance; they are demanding real change that puts their country on a clear path toward democracy.
The international community has no role to play.
While the reform process should certainly be homegrown, the United States and the rest of the international community can encourage democratic development without imposing it from afar.
President Barack Obama rejected many of the policies of the George W. Bush administration that were seen as trying to force democracy on Arab countries.
But the subsequent silence on democratization aggravated – though it certainly did not cause – the unraveling of the Arab reform process in the last few years.
The US and the West can discuss with Arab countries how political reform should be carried out in a way that would contribute to greater openness and opportunities for power-sharing.
The West should not sacrifice these objectives for others; if allies ultimately lose power in popular revolts, such a tradeoff would not have furthered the West’s interests, to say the least.
The unfolding events grabbing headlines around the world have shattered key myths about the Arab world.
These countries’ people need to start gradual, sustained, and serious political reform now.
At the dawn of a new Arab era, it is up to them to build new, open political systems that can head off the looming threat of escalating crises.
History gave Yasir Arafat far more time than most leaders to achieve his mission.
After all, at the time of his death he had been leader of the Palestinians for 35 years.
Yet he left his people in a terrible situation, with no state, in the midst of a losing war, and with a bankrupt economy.
Whether his successors can revive and complete the Palestinians' historic mission depends on how they define their goal.
Looking back at his career, Arafat never really veered from the belief that his life's mission was to destroy Israel by any means necessary and replace it with a Palestinian Arab state.
An independent Palestinian state that did not include all of Israel held no appeal to him.
He was equally indifferent to his people's material welfare and anything particular about the design of a viable political and economic system.
Now, in the post-Arafat era, Palestinians must choose one of several strategies.
Unfortunately, most of the alternatives call for the continued use of violence and terrorism.
Themoderate strategy seeks an independent Palestine state as quickly as possible, on the assumption that once there is no more Israeli presence or violence, the Palestinians can concentrate on constructive pursuits, including resettling refugees and improving living standards.
But this is the view of only a small minority of leaders, notably former Prime Minister Abu Mazin and Muhammad Dahlan, who heads his own militia in the Gaza Strip.
If Arafat had taken this road - accepting Israel's existence, ending terrorism, and confronting Palestinian extremists - the conflict would have ended long ago.
But, with no single all-powerful leader, it will be hard for any successor to force through the difficult decisions required by such an orientation.
Thehard-line strategy is the traditional ideological approach championed by many Fatah and PLO veterans who returned from exile to the West Bank and Gaza Strip, including Arafat.
Their current leaders include men like Palestine National Council head Salim al-Zanun and Fatah ideological chief Sakr Habash, who favor continuing to battle Israel until it is destroyed, at which point they will rule Palestine with a relatively secular nationalist regime.
They look down at younger challengers and view the Islamists as a threat.
The younger generation of indigenous West Bank Palestinians, whose leaders began political activity in the uprising of the late 1970's, embraces amilitant strategy that views the hardliners as burned-out old fogies, enervated by corruption.
Unlike the hard-line secularists, the militants, whose best-known leader is Marwan Barghuti, the head of the Tanzim grassroots grouping in Fatah, are willing to work with the Islamists.
The militants argue that a two-stage strategy is needed to defeat Israel.
First, long-term continuation of violence will force Israel to withdraw from the occupied territories.
Then, with Palestinians gaining the upper hand, they can advance to a second stage in which all of Israel is conquered, implying armed struggle - which often takes the form of anti-civilian terrorism - for many more years.
Finally, there is therevolutionary Islamist vision espoused by Hamas, which seeks to continue fighting and using terrorism, regardless of how much time it takes and lives it costs, until it defeats both Israel and Palestinian secular nationalists.
Palestine will then be an Islamist state in which moderates would be shot and the old nationalist leadership forcibly retired or jailed for corruption.
In the meantime, however, Hamas is willing to form alliances with the nationalists, particularly the militant faction of Fatah.
The problem for Palestinian moderates is clear: any leader willing to agree a peace treaty with Israel would be opposed - passionately and even violently - by roughly 80% of the movement.
A key question is whether the Palestinian masses, fed up with their leadership's bickering, corruption, and incompetence, could make their wishes known to find an end to a conflict that has cost them so much.
But none of the main leadership factions are proposing that the masses be consulted very much.
Nor did Arafat leave in place any institutional mechanisms for doing so.
Moreover, the popular appeal of radical religion, ideology, and misinformation should not be underestimated.
Few Palestinians are even aware that four years ago Arafat turned down an independent state equal in size to the entire West Bank and Gaza Strip, in addition to more than $20 billion in refugee compensation.
The main problem left by Arafat is the lack of any leadership at all.
Rarely in history has a political movement been so deliberately set by its founder on a course toward chaos.
Arafat not only left no successor, but no order.
Over the decades, the movement has developed a political culture of indiscipline.
Arafat presided over a sort of anarchy, encouraging rivalries, undermining other potential leaders, and ensuring that all authority (and money) ran through his hands.
Only if the post-Arafat movement decides that it really wants a Palestinian state in exchange for ending the conflict with Israel in every respect will there be a real chance of peace.
Arafat's death may well mark the beginning of that process, but the transition to a new Palestinian leadership could take years, and there is no assurance that it will be a moderate one.
In his protracted moment of death, Yasir Arafat performed his last act of duty to the Palestinian cause to which he devoted his entire life.
Everything about the man was, indeed, protracted.
He carried out a protracted war of national liberation.
He withstood a series of protracted sieges – in Amman (1970), Beirut (1982), and in Ramallah (2002-2004).
Arafat’s leadership was the most protracted among his counterparts in the Arab World, as he outlived three Egyptian Presidents (Naguib, Nasser, Sadat and spanned all of Mubarak’s quarter of a century), five Lebanese Presidents, three Iraqis, five Algerians, three Syrians, three Saudi Monarchs, and two in Morocco, not to mention other world leaders, from Eisenhower to Bush in the US, from de Gaulle to Chirac in France, and from Maó to three successors in China.
Probably no other political figure alive today met and endured as many world leaders as Arafat.
But there is much more to Arafat’s legacy than endurance.
It has been correctly said over and again that Arafat was a mixed blessing for his people.
Their fate and destiny have been inextricably linked, to the near demise of both at times.
For several decades after the usurpation of their homeland, Palestinians were reduced to aggregates of refugees, some remaining in the newly-created state of Israel as second-class citizens, with others scattered over the Arab World and far beyond.
It was Yasir Arafat, through the Palestinian Liberation Organization (PLO) he founded, that gave them a sense of identity as a people.
Regardless of its effectiveness, the armed struggle waged by the PLO did empower the Palestinians and internalize a sense of collective dignity and self respect within them.
Their cause could no longer be ignored.
No other modern issue has appropriated as many UN resolutions or as much international diplomacy.
If politics is defined as the art of compromise, Arafat was a master of it at the Palestinian and Arab levels.
He managed to stay at the helm for over forty years with no serious challengers.
Internationally, however, he was out of step with the post Cold War era.
Whether or not he was solely to blame, a true opportunity for historical compromise was missed at Camp David in August 2000, and he himself acknowledged it a year later.
By that time it was too late, as the leadership in both the US and Israel had changed and there was no interest to engage him.
During the last four years of his life, Arafat’s public space was literally and metaphorically diminishing.
He was unable to re-engage his Israeli adversaries or control his suicide-bound Palestinian militants.
Nor was he able to contain let alone combat rampant corruption in the Palestinian Authority.
Nor was Arafat helped by world events that shifted the spotlight to Bush’s wars on terrorism in Afghanistan and Iraq.
If anything, they had adverse effects for him and his life-long cause.
Like his own body, Arafat’s familiar world was steadily fading away with irreversible loss of control.
Ironically however, as he was dying, world leaders and the media were rediscovering the importance of Arafat’s leadership if not his persona.
The sustained focus of the media on him, to the point of near saturation, focused world attention on the Palestinian Question once again.
Statements by Tony Blair, Jacques Chirac, Kofi Annan and others on the occasion of Arafat’s death have been forceful in demanding a speedy and long overdue resolution of the conflict.
It is as if in death, Arafat has given his people a chance to achieve what he could not achieve in life –the dream of an independent democratic Palestinian state.
It is Arafat’s last hurrah.
STOCKHOLM – The idea of a “bad bank” appears to grow more popular by the day in countries where toxic assets have paralyzed lending.
The Swedish bank cleanup in the early 1990’s is often cited as an example of how successful this idea can be.
But the lessons that are sometimes derived from Sweden’s experience are based on misunderstandings of what we actually did, and of how our system worked.
The initiative to set up a “bad bank” in Sweden was taken not by politicians, but by the management of Nordbanken.
Following years of mismanagement and reckless lending, the bank was the first big victim of the commercial property market’s decline in 1990.
Nordbanken had become fully state-owned and a new management was put in place to restore the bank to viability.
But it soon turned out that the managers had little time to spend on Nordbanken’s core banking business, because they had to focus disproportionately on handling an enormous variety of assets.
And every quarter brought new write-offs that ruined efforts to rebuild the bank’s reputation and its employees’ morale.
The radical solution was to separate all the assets that were alien to the bank’s core business, mainly real estate companies, but also firms in the manufacturing, construction, and service industries.
The “bad bank” that was established for this purpose, Securum, needed an enormous injection of capital from the owner, the Swedish government.
But Securum was then able to recruit skilled staff members who could maximize the assets’ value when markets recovered, and to be in a financial position to await that recovery.
The rest of Nordbanken, now known as Nordea, proceeded to become the largest bank in Scandinavia.
In contrast to today’s situation, the bad assets were usually entire companies, not complex securities.
But, as with today’s toxic assets, there was no market, and rapid disinvestment would have triggered fire-sale prices, depressing all asset values in the economy and resulting in more bank failures.
Furthermore, the point was not to help private banks get rid of their troubled assets.
When most other Swedish banks followed Nordbanken’s example and established their own bad banks, they did so without state participation.
But this was possible only because the Swedish government already owned all the assets, thereby circumventing the hopelessly difficult issue of pricing them.
With a private owner, huge public subsidies would have been politically unacceptable.
The assets either would have to be priced at far above their market value, with taxpayers thereby subsidizing the previous, failed owners, or the private bank would not have been helped at all.
A government-sponsored bad bank for private assets is thus a very bad idea.
In 1994, when I became State Secretary for Financial Affairs in Sweden’s Ministry of Finance, recovery appeared to be on the horizon, following the abolition of the fixed exchange rate, the ensuing sharp depreciation of the Krona, and lower interest rates.
The new government implemented an effective and very big program to close a budget deficit of roughly 12% of GDP.
Gradually, confidence grew, and financial markets began to function again.
As opportunities appeared, we began to re-privatize assets, and within a few years Securum was closed.
With hindsight, I believe we sold its assets too quickly.
Taxpayers could have recovered more of their losses if we had been more patient, as prices continued to rise for a long time.
But the stigma of socialism was stronger than the instinct to make a profit.
The following lessons of Sweden’s experience seem relevant today:
·        A bad bank can be an effective instrument in the recovery of losses and the revival of banks.
·        Although Sweden’s experience concerned shares in companies used as collateral for credit, rather than bonds or similar financial instruments, this situation will likely arise in many countries today as the crisis continues, more companies go bankrupt, and banks recall their collateral and take possession of shares in indebted companies.
·        Government subsidies for private bad banks, or public bad banks to clean up private banks’ toxic assets, are a bad way for taxpayers to transfer money to troubled banks compared to normal capital injections.
All subsidies should be transparent, and public/private bad banks are not.
·        It is vital to staff bad banks with professional and experienced managers who are untainted by previous scandals.
Here, Sweden’s experience is encouraging.
It was easier than we expected to recruit good people for Securum, because working in the public interest for this pioneering state-owned bad bank was perceived as a unique challenge.
·        Maximizing taxpayers’ economic interests, not ideology or political considerations, must be the guiding principle.
The public should be in no doubt about this, for their trust is essential.
LONDON – Are financial sector workers paid too much?
Not all of them are, of course, for there are poorly paid bank clerks and cleaners who count in this category.  But is it possible to justify the enormous rewards earned – or should we say received – by investment bankers, hedge fund managers and private equity partners?
Most people would easily and quickly answer “no.”
Certainly that is what Congressmen in the US, and Members of Parliament in the UK think.
They are trying to cook up ways to discipline financial firms, albeit without conspicuous success so far, as demonstrated by the large sums stashed away for employee compensation by Goldman Sachs after its most recent profitable quarter.
But what does it mean to say that financial folk are paid too much?
By what measure, and in relation to whom are they overpaid?
Like many other people, I tend to believe that anyone paid more than me is prima facie over-rewarded, but I know this is not the most rigorous test I could apply.
Economists have been trying to produce more robust answers to those questions.
Thomas Philippon and Ariell Reshef, for the National Bureau of Economic Research, have looked at a hundred years of data in the US, for pay in finance, and in other occupations.
Their conclusions are fascinating.
They find that if you control for educational attainment and skills, financial jobs were highly paid until the Great Depression of the 1930s, higher than the quality of the people who held the jobs would imply.
Then from the Depression, and the introduction of new and tighter regulation, financial sector pay reverted to the norm, and remained there until around 1990.
But from that date up to 2006 it raced ahead and, on average, employees in financial firms were paid between a third and a half more than similarly qualified counterparts elsewhere.
We just don’t know yet whether the crisis will cause another reversion to the mean, but some downward adjustment looks likely.
So there is some basis for saying they are overpaid, but why?
Philippon and Reshef argue that regulation, or deregulation is a big part of the story.
Deregulation increased the opportunities for innovation and trading, and for profit.
There is also evidence to support that proposition from the observable fact that rewards in the less regulated parts of the asset management sector- hedge funds etc- are typically higher than in Security and Exchange Commission regulated competitors.
But is this a good enough explanation?  As rewards went up, why did new competitors, prepared to undercut, fail to come into the market?
In other parts of the economy, where we see excess returns, we usually look for some weakness in competition, or perhaps for the exploitation of insider information, which excludes new entrants.
That may be part of the story, but competition for talent and for customers seems intense between investment banks and others, yet they have collectively been extravagantly rewarded at the expense of those customers.
An alternative hypothesis, which seems to fit the facts, recently emerged from the Paul Woolley Centre for the Study of Dysfunctionality in Capital Markets, at the London School of Economics.
Researchers there argue that in fragile speculative industries (and finance has certainly been in that category in recent years) it is hard for investors to monitor those who manage their money.
They can see short-term returns, but they do not understand very well how those returns are generated.
Managers can demand higher and higher returns in the upturn.
But eventually these high returns reduce the payouts to investors (Bernie Madoff may be the reductionad absurdum of this phenomenon) and slow the growth of the sector.
Managers take more risks in search of higher returns to justify their pay, which at some point will lead to risk mispricing, and a crisis.
We have seen the last part of this cycle over the last two years.
If this explanation is broadly correct (and it incorporates the deregulation point as well, as you can see) then what can be done about it?
Politicians and regulators are exploring a number of options, from higher tax rates, through fines for certain types of bonus arrangements, to variable capital requirements.
Higher taxes may be justified for other reasons, but are unlikely to solve the problem described.
Regulators have struggled with the problem for years without finding a solution. 
The Bank of England has described the way in which remuneration policy can create risks for banks and said that, as a result, “it is of increasing interest and concern to supervisors and regulators.”
But that was written in 1997, and progress since then has been very slow, on both sides of the Atlantic.
Shouldn’t shareholders take more of an interest?
After all, it is their money which is at stake.
They have earned low returns from financial sector investments, indeed those returns have been very strongly negative in the last two years.
Shareholders seem to take little interests in pay policy.
The arrival of “say on pay” provisions in the US – whereby boards will need to put their compensation policies to a shareholder vote in future– may focus minds, though the impact of similar provisions in the UK has been modest.
Yet without shareholder pressure, all the signs are that the problem will persist.
World flows of foreign direct investment (FDI) have soared over the past two decades, from $40 billion in the early 1980’s to $900 billion last year.
The cumulative stock of FDI has reached close to $10 trillion, making it the most important mechanism for delivery of goods and services to foreign markets: sales by foreign affiliates total roughly $19 trillion, compared to world exports of $11 trillion.
At the same time, the liberalization of FDI regimes by virtually all countries has been a driving force of intra-firm trade – the lifeblood of the emerging system of integrated international production and already around one-third of world trade.
But are the good times coming to an end?
FDI can bring a range of benefits, but it also can have costs.
During the 1970’s, when the transnational corporations (TNC’s) undertaking such investment caught the public eye, many governments believed that the costs of FDI outweighed its benefits, so they controlled it.
Led by the developed countries, the pendulum began to swing in the 1980’s.
Once viewed as part of the problem, FDI became part of the solution to economic growth and development.
Nothing exemplifies this more than changes in national FDI regimes.
As the United Nations Conference on Trade and Development reports, of the 2,156 changes that took place between 1991 and 2004, 93% were in the direction of creating a more hospitable environment for TNC’s.
But there is a real danger that the pendulum is beginning to swing back, leading to a reversal of that liberalization process.
FDI in developed countries (and increasingly in emerging markets) often takes the form of cross-border mergers and acquisitions (M&amp;A’s).
Resistance to such M&amp;A’s is becoming more frequent when they involve domestic firms that are regarded by politicians as “national champions” or important for national security, economic development, or cultural identity.
The growing involvement of private equity groups in M&amp;A activity implies additional controversy, as such transactions are typically regarded as being purely speculative.
In the name of “economic patriotism,” security, and other considerations, resistance to M&amp;A’s is being codified in an increasing number of countries.
For example, a United States Senate committee recently sought to block the planned liberalization of foreign takeover rules for airlines, while Europe has enacted more restrictive takeover laws.
Moreover, governments are applying more strictly existing regulatory provisions concerning the vetting of takeovers by foreign firms.
This response is intertwined with a defensive reaction to the growing role of TNC’s from emerging markets, the “new kids on the block.”
Established TNC’s, and their home countries, will need to adjust to this new constellation of forces and its implications for the world market.
As we know from other contexts, adjustment to newcomers is not easy: compare, say, the reaction to the tie-up between France’s Alcatel and America’s Lucent to the bids by the China National Offshore Oil Corporation for Chevron or Mittal for Acelor.
Another type of defensive reaction – this time to outward FDI – may well arise once the offshoring of services gathers more speed.
All indications are that offshoring has reached the tipping point, and more of it will take place through FDI.
If home countries do not put in place the adjustment mechanisms to deal with the rapidly unfolding revolution in making service industry jobs tradable, a backlash against such outward FDI will become inevitable.
The growing unease with FDI is so far largely confined to developed countries.
But there are signs that it is spreading to emerging markets.
In the case of large-scale projects, some host countries are raising questions about the contracts that define their relationship with TNC’s, and governments are reviewing such contracts because they believe (rightly or wrongly) that they did not get a fair deal.
Of the 219 known international arbitration cases concerning investment projects, some two-thirds were initiated during the past three years.
Approaches to FDI have changed in the past, and they can change again in the future, depending on how governments view the balance of costs and benefits.
This balance involves not only economic factors, but also such considerations as security and the desire to control one’s own economic development.
The concept of “twenty-first-century nationalization,” introduced by Peruvian presidential candidate Ollanta Humala, mirrors in this respect the “economic patriotism” of French Prime Minister Dominique de Villepin.
Reservations against FDI (as against anything foreign) can be found in all groups of countries, and politicians can bring them to the surface, resulting in protectionism.
It would be ironic, though, if developed countries – which led the FDI liberalization wave of the past two decades – now led a backlash against FDI.
Let us hope that the de-liberalization seen in developed countries can be checked before it spreads to other parts of the world and ultimately brings undesirable consequences for all.
The first big city to boom was London, starting around 1996.
Boom mentality spread to Los Angeles, New York, and Sydney around 1997, to Paris in 1998, to Miami, Moscow, and Shanghai in 2001, and Vancouver around 2002.
These and other cities have been booming pretty much ever since; prices in most are up at least 50% in real terms since 2000.
This has been a big windfall to homeowners, but has hurt anyone planning to buy.
Now growth in home prices is weakening in some of these cities.
The rate of price growth in London and New York slowed sharply over the past year, to only about a 1% real increase in the second quarter of 2004.
In Sydney, home prices actually fell in the second quarter.
Has the boom ended?
Will no other cities benefit?
Worse still, could the mood in housing markets soon lead prices in downward?
No one predicted this boom, so predicting its end is risky.
Housing prices have shown tremendous upward momentum in the face of previous warnings that the party is over.
Any prediction concerning the boom's end requires understanding why it occurred in so many places.
Surprisingly, there is no well-received explanation, because this boom's ultimate causes are mostly psychological.
Economists would rather talk about interest rates or unemployment statistics - factors that are concrete and knowable.
Of course, these indicators do have a legitimate role to play in explaining housing markets, but they are simply not adequate to account for the recent booms.
Three psychological causes stand out: first, a change in people's perceptions about the source of value in a changing world economy; second, increasing public faith in "glamour" cities with international name recognition; and third, the plain giddy dynamics of speculative bubbles.
Each factor deserves greater attention if we are to understand current housing market conditions and discern future price trends.
First, the world economy does look more chaotic than it did a decade ago.
The crash in equity prices since 2000 in most countries has made financial assets look less secure, spurring a "flight to quality" - in this case, housing.
Moreover, terrorism is now viewed as a problem for everyone, with major tragedies in Indonesia, Spain, and Russia.
People feel safest investing in their homes, and there is little reason to expect imminent change.
Fear and upward momentum in home prices go together.
Second, the public's faith in glamorous international cities has increased with the explosive growth in global communications due to the Internet and the cell phone.
Just as people increasingly admire international celebrities, so they believe that world famous centers of business, technology, and culture - whose names are household words to people everywhere - are uniquely valuable.
As with fear of terrorism and suspicion of equities, geographical celebrity appears resilient, if not self-reinforcing: the more famous New York, Paris, and London get, the more glamorous they become.
Third, and no less important, is the speculative contagion that underlies any bubble.
The current boom has seen contagionwithin markets andacross markets, as rising prices fuel popular excitement - and hence further price increases - in the same city, and then in other cities, even on the other side of the globe.
People in Shanghai may not talk about London home prices, but Shanghai's opinion leaders know what is happening in London, and the boom there makes it seem plausible that there should be a boom in Shanghai, too.
In contrast to the other two psychological causes, speculative contagion has a natural end.
A speculative bubble, sustaining itself solely by reaction to price increases, cannot go on forever.
So, where does this leave us?
Two of the three psychological causes suggest continued upward momentum in housing prices, while the third suggests that the momentum will come to an end some day, but does not pinpoint when.
I am betting that some high-flying glamour cities will continue to see decelerating growth in home prices - and eventually decreases.
Historically, housing prices have shown a lot of momentum, and prices in all these cities are still going up at a brisk rate, though usually somewhat slower than a year or more ago.
Based on extrapolation of growth trends, it looks safe to predict that prices will go up substantially in most of these places for another year or more, even as the rate of increase continues to decline.
The psychological factors are more important for longer-term forecasts, beyond a year, where momentum no longer plays an important role.
At this point, there is likely to be some downward instability in prices, because enthusiasm for investing in houses is likely to wane in line with declining price growth.
Prices in glamour cities are likely to drop sharply the next time there is a serious recession, or if the local economy suffers a severe shock, or if interest rates rise too fast.
Then, contagion within and across markets can work in a downward direction, propelling prices lower for years.
Global warming is an environmental, economic, scientific, and political problem of the first order, and one doubly difficult to address because its dangers lie decades in the future.
So if we are to act now to head it off, we must first scrutinize what is known about the nature of the threat.
Should we place our faith in the Kyoto Treaty, which sets firm limits on human emissions of so-called greenhouse gases?
Or is the US administration right to reject the Kyoto Treaty, because targeting emissions is based on "bad science"?
Circumstantial evidence does indeed point to our profligate burning of fossil fuels and perhaps also to its impact on global warming.
Since 1900 the global temperature of the Earth's atmosphere and ocean surface waters has risen by 0.5-1 degree Celsius, and the prime suspect is atmospheric carbon dioxide, CO2, which is second only to water vapor in its greenhouse effect.
Since 1860, when the industrial revolution and soaring population growth led to widespread consumption of fossil fuels, the volume of atmospheric CO2 has increased by about 28%.
The increase began slowly, rising from 290 parts per million in 1860 to 295 ppm in 1900.
But it then accelerated rapidly, reaching 310 ppm in 1950 and 370 ppm in 2000, with half of the total gain of 80 ppm occurring just since 1975.
Numerical global climate models suggest that a doubling of the current atmospheric accumulation of CO2 will produce further warming of 3-5 degrees Celsius, perhaps as soon as 2050.
The consequences of this would be devastating: inland areas desiccated, low-lying coastal regions battered and flooded as polar ice melts and sea levels rise, and possibly further warming and a runaway greenhouse effect due to an increase in atmospheric water vapor.
The only rational course of action would seem to be to curtail global consumption of fossil fuels, as the Kyoto Treaty's proponents contend, and invest in alternative energy sources.
But while researchers created impressive global climate models in recent years, they are the first to admit that such models can include only a fraction of the many physical forces that together determine the climate and global mean temperature.
For example, studies during the past 20 years have shown that changes in solar magnetic activity cause the Sun's brightness to vary by 0.1%, and that the average annual temperature in the northern Temperate Zone has tracked the level of solar activity over the last 1,000 years.
Indeed, monitoring of other solar-type stars has revealed one whose brightness decreased by 0.5% in a period of 5 years, during which its magnetic activity declined sharply, suggesting that the Sun behaves similarly.
Core samples from the Greenland ice cap, for example, show occasional sudden drops in temperature.
Contrary to what climate models focusing on greenhouse gas emissions would predict, the samples show that a decline in atmospheric CO2 followed, rather than preceded, these frigid intervals.
What, then, is responsible for global warming so far?
A safe bet is that from 1900 until 1950, global warming was driven mainly by the solar brightening, as solar magnetic activity increased by a factor of two or three during this period.
Atmospheric CO2 could not have been a major contributor, because it had increased by only about 7% before 1950, when the warming leveled off for a couple of decades.
After 1950, however, solar activity showed no significant rise, while atmospheric CO2 increased by 20%, accounting for the warming from 1970 to 2000.
Atmospheric CO2 is therefore presumably the controlling factor for the coming century as well.
But this does not mean that human emissions are responsible for the growing accumulation of atmospheric CO2.
The atmosphere contains about 750 gigatons of CO2, while total annual human emission is approximately 5.5 Gt, thus adding annually roughly 0.7% of the total.
However, there is also an estimated exchange of 90 Gt per year between the atmosphere and the oceans.
This means that Human CO2 emissions do not simply linger and accumulate in the atmosphere. They are rapidly distributed to the ocean surface, so that atmospheric CO2 remains at an equilibrium level.
This equilibrium is, in turn, determined by the temperature of ocean surface water.
So it is plausible that the solar-driven ocean warming between 1900 and 1950 started things off by shifting the equilibrium toward higher concentrations of CO2 in the atmosphere, accelerating global warming since then.
So, while our own contribution of CO2 is not helping matters, it hardly seems to be the determining factor.
On the available evidence, then, skeptics of the Kyoto Treaty appear to have a powerful case.
Yet the threat posed by global warming is nonetheless real, and focusing on human CO2 emissions is not necessarily "bad science," just incomplete science.
For example, aside from solar magnetic activity, the Sun affects the Earth's climate in several other ways, including ultraviolet warming of the upper stratosphere, the nucleation of aerosols, and cloud formation.
The climate is also subject to the rate of water vapor exchange between the atmosphere and Earth's surface, which requires taking into account ocean currents, wind, and geography.
All of these contributing effects must be understood quantitatively in order to produce an accurate model of global climate change and we remain far from that point.
So the only rational response is to research aggressively into the many unknown factors: the physics of cloud formation, the dynamic coupling of the upper stratosphere to the lower atmosphere, the accumulation of atmospheric water vapor.
If effective solutions are to be found, they must await a fuller definition of the problem.
In the year since the terrorist attacks of September 11th, questions about Islam - its nature, its distinctive identity, its potential threat to the West - have seized center stage in intellectual and political debates.
While the 20th century's major conflicts - with fascism, communism, and other "isms" - were primarily ideological, the terrorism of last September 11th posed anew the specter of "culture wars" and "clashes of civilizations."
It is often claimed in the Islamic world that, because one of the five fundamental duties of a Muslim isZakat (charity to the poor), Islamic society is less atomistic, which limits inequality and social exclusion.
At the same time, Western observers often see in Islam a faith that disdains personal freedom, especially for women.
Oriana Fallaci published a long rant along this line shortly after the attacks.
Facts on the ground do seem to support these perceptions.
Muslim countries do tend to be characterized by lower levels of inequality and crime (a good proxy for social exclusion) than other countries at similar stages of economic development, such as those in Catholic Latin America.
But do cold statistics about average income really tell us anything significant?
Not according to the political scientist Francis Fukuyama, who suggests that particular social outcomes (including income levels) result from the fact that countries are at different stages in a modernization process within which everyone and every society is converging towards a set of universal values.
Harvard University's Samuel Huntington also thinks such comparisons wrong-headed, but disagrees with Fukuyama on the diagnosis.
Huntington sees something sinister at work within Islam - that Islam's social outcomes reflect, not its level of modernity, but the tenets of its faith.
Because of Islam's messianic fusion of the political, religious and cultural dimensions, says Huntington, the West and Islam are destined to "clash" because the two systems are fundamentally irreconcilable.
But if we want to discover the role that a religion like Islam plays in determining a society's fundamental shape, we can indeed be led astray by making comparisons between different countries or global regions.
We need to look at individualswithin an individual country to understand the true power of "Islamic values" in shaping a society.
To do so, we need a country with deep religious cleavages between Islam and Christianity and, unlike America's "melting pot," limited mixing among social groups.
Two studies that I conducted with colleagues at the University of Beirut use Lebanon to examine the relationship between religion and such social and cultural characteristics as inequality, preference for sons, and the degree of female labor market participation.
Lebanon is an ideal social laboratory because it has a large number of geographically segregated religious groups and strongly enforced communal boundaries.
Indeed, more than religion divides the population.
Some Lebanese see themselves as Phoenicians rather than as Arabs, and claim closer cultural affinity to France than to the Arab world.
We examined Christian Maronites (who hold beliefs akin to those of Roman Catholicism), Muslim Sunnis (the official religion of most Arab countries), and Muslim Shiites (the official religion of Iran and of Lebanon's Hizbullah movement), and found no evidence of lower inequality among Muslims or less discrimination against women among Christians.
Were Islamic values as fateful as Huntington suggests, there should have been sharp differences in inequality and the treatment of women between these communities.
There were not.
Our study of religion and social inequality in Lebanon examined social mobility rather than overall inequality.
This is because societies in which opportunities and inequality are inherited are considered to be less fair than societies in which family background is less important.
Social mobility in Lebanon, it seems, is extremely low and family background is a key factor in determining social outcomes.
This may explain why Lebanese college graduates of all faiths often include the name and profession of their parents in their resumes, or why one of the first Arabic words that a foreigner learns after settling in Lebanon iswasta(connections).
Moreover, the Christian Maronite and the Muslim Shiite upper and middle classes tend to have similar levels of social mobility.
In both groups social mobility is higher than among Sunni Muslims. Another mark against the notion of Islam's overwhelming power to determine a society's prevailing conditions.
The position of women also does not seem to be primarily determined by adherence to Islam.
Indeed, we found that all Lebanese families strongly prefer sons over daughters.
Families that have two daughters are 9% more likely to have a third child than families that have two sons.
Statistically, this is a huge difference - nine times larger than in the US.
Indeed, just as our initial research uncovered no evidence of relative Muslim egalitarianism, we discovered no major difference between preference for sons among Christians and Muslims.
If anything, bias toward males is stronger in Christian families.
The same holds true for female labor market participation, which in Lebanon is low but uniform across religious groups.
While this does not guarantee that no relationship exists between religion and discrimination against women, it suggests that if such a tie does exist, it is unrelated to female labor market participation or preference for sons.
Of course, disproving the idea that different countries have different values is impossible.
After all, Lebanon does have low social mobility, low female labor market participation, and a strong preference for sons, while other countries do not.
Our work, however, strongly supports Fukuyama's theory that cultures and values take a back seat to the level of a country's modernity in determining its social conditions.
So if the Islamic world is different from the West, it is so because it is backward, not because it is Muslim.
JERUSALEM – The resumption of peace talks between Israel and Syria after eight years of saber-rattling is not a diversion from the political troubles of Israel’s lame-duck prime minister.
Nor are the talks a Syrian ploy to avoid facing an international tribunal on the assassination of Lebanon’s former prime minister, Rafik Hariri.
An Israeli-Syrian peace deal is strategically vital for both sides, and both sides know it.
The two major formative experiences of Syria’s Ba’ath regime have been Hafez al-Assad’s loss of the Golan Heights in the 1967 war with Israel, and the loss of Lebanon by his son, Bashar, who was forced to withdraw his army under irresistible American-led international pressure.
Recovering the Golan Heights and protecting Syria’s vital interests in Lebanon are not only major strategic concerns for Syria’s president; they are also crucial to the regime’s drive for national legitimacy, and to Bashar’s assertion of his own leadership. 
Peace with Israel is not Assad’s priority.
Rather, it is the prerequisite without which superior goals – rapprochement with the United States, legitimization of Syria’s special status in Lebanon, and avoidance of a potentially devastating war with Israel if the Golan Heights are not recovered by peaceful means – cannot be attained.
Indeed, the regime has hinted that it may be willing to compromise on the issue – the delineation of the 1967 border along a tiny piece of land on the Eastern shore of the Sea of Galilee – that wrecked the negotiations eight years ago.
An Israeli-Syrian peace is a weighty strategic necessity for Israel, too.
The complexities of the threats to Israel are such that a possible confrontation with Hamas in Gaza might trigger a flare-up with Hezbollah in Lebanon.
Such a war could be won only by the total destruction of Lebanon by Israel’s air force.
In that case, Syria would likely seize the opportunity to break the deadlock over the Golan Heights through a military move that could develop into a massive war of missiles targeting Israel’s vulnerable home front.
And Iran, in its drive to protect its nuclear program from an Israeli-American attack, might be very active in supporting this ominous scenario.
Admittedly, the strategic conditions in the region are far more complex today than they were eight years ago, when Israel’s requirements for a deal with Syria focused mainly on security arrangements on the Golan Heights, and on Syria using its leverage in Lebanon to permit an Israeli settlement with that country.
Syria’s alliance with Iran was not a major issue.
Syria’s subsequent forced withdrawal from Lebanon was not good news for Israel.
In the last round of Israeli-Palestinian peace talks eight years ago, it was clear that a deal with Syria would automatically pave the way to a settlement with Lebanon, and an end to Hezbollah’s threat to Israel’s northern border.
Today, peace with Syria might facilitate an Israeli peace with Lebanon down the road, but that will not be an automatic outcome.
Indeed, while Hezbollah prospered under Syrian occupation, it never reached the extraordinary political power that it has today.
Nevertheless, peace with Syria could be a major building block in a wider Israeli-Arab settlement, and consequently of a more stable Middle East, though it is unrealistic to expect that Syria would automatically sever its special relationship with Iran in exchange for the Golan Heights.
These are peace talks, not a defense treaty, and Syria would not abruptly disengage from its Iranian friends.
But good relations between an Arab state at peace with Israel and Iran are not necessarily a bad thing.
Syria’s stance might limit, rather than extend, the reach of Iran’s strategy of regional destabilization.
As always, much will depend on America’s readiness to move away from military solutions and rigid ideological imperatives and instead embrace the pragmatic culture of conflict resolution.
A US-backed Israeli-Syrian peace could transform the strategic environment, potentially drawing other Middle East spoilers into a system of regional cooperation and security.
BRUSSELS – The euro area confronts a fundamental crisis that attacks on financial speculators will do nothing to resolve.
The European Council of Ministers had to promise hundreds of billions of euros to its financially imperiled member countries, even though the European economy as a whole is not really in crisis.
On the contrary, most surveys and hard economic indicators point to a strong upswing, with the one country that is in really serious trouble, Greece, representing only 3% of the area’s GDP.
Nevertheless, the crisis poses an almost existential challenge to the European Union – and has required such huge sums – because it directly implicates the key underlying principle of European governance: the nature of the state.
The case of Greece has raised the simple but profound question: can a member state of the EU be allowed to fail?
One view is that the state is sacrosanct: the EU has to intervene and help any errant member to get back on its feet.
But this view assumes that all member states adhere to the Union’s underlying economic values of fiscal prudence and market reform.
Problems could arise only because of unanticipated shocks, temporary local political difficulties, and – the favorite culprit – irrational markets.
Applied to Greece, this view implies that the country’s fiscal crisis resulted from an overreaction by world financial markets to local political difficulties (excessive spending by the Greek government before last year’s elections).
Moreover, it implies that the crisis is fully under European control, and that the European authorities have elaborated a comprehensive plan that will resolve all of Greece’s fiscal and structural problems.
Hence the official – let’s say “Southern” – refrain: “The IMF/EU plan will succeed.
Failure is not an option.”
The alternative view is more pragmatic and rules-based.
This “Northern” view starts from the premise that member states remain sovereign units, and that it is possible that a member country does not implement a necessary economic-adjustment program.
This view is embodied in the “no bailout” clause in the euro’s founding document, which stipulates that each country is responsible for its own public debt.
Failure then becomes an option if the country concerned violates the single currency’s basic rules.
Financial markets do not participate directly in this debate.
But they have much skin in this game.
Any holder of Greek debt, especially long-term debt, must calculate the likelihood that Greece’s political system will prove strong enough to push through the reforms needed to enable the country to service its debt fully (and on time).
The collective judgment of financial markets on any government’s economic and fiscal policy is expressed in the risk premium that the government must pay on its external debt.
Doubts in financial markets lead to higher risk premia, which make it even more difficult to finance a government that is already facing financial problems.
Financial markets are often wrong in their judgments.
But they are a fact of life that cannot just be wished or regulated away.
One might object that the distinction between Southern and Northern views is academic nowadays, because failure really isn’t an option, given that it would trigger a disastrous reaction in global financial markets.
But the European Council also created a Task Force under President Herman Van Rompuy to elaborate concrete proposals for reforming the monetary union.
The key choice for this group is simple: should they direct their efforts solely at preventing failure (including open-ended fiscal support), or should they also prepare for the failure of a member state in order to mitigate the consequences if that should happen?
The first choice is bound to imply elaborate measures designed to deliver “more of the same” – a strengthening of the Stability and Growth Pact, for example, with more provisions for economic policy surveillance and cooperation.
But this approach has no answer to the fundamental question: What if the framework does not work?
So long as EU leaders cannot answer that question, financial markets will continue to harbor doubts about the euro’s long-term stability.
The eurozone cannot stabilize in political and economic terms without a solid framework for crisis resolution and an ability to deal with sovereign default by a member state.
The view that member states cannot be allowed to fail logically implies that a political or at least a fiscal union must underpin the euro.
This is the choice that European leaders now confront: a radical step forward toward political or policy integration, or a clear framework to deal with the consequences of a member country’s failure to abide by the fundamental rules of the monetary union.
No amount of money will allow European leaders to fudge this issue.
A year ago, the dollar bestrode the world like a colossus.
Now it is humbled and the euro looks triumphant.
Is the dollar on the way out as the world's unchallenged reserve and trade currency?
Or is "euro triumphalism" premature?
That question preoccupies not only speculators tracking the dollar's decline, but ordinary businessmen who wonder what currency to use when invoicing imports or exports.
Indeed, the part that currencies play in world trade through their role in invoicing receives too little attention.
Currently, the US dollar remains dominant.
Most US exports and imports are denominated in dollars, and the dollar is extensively used in trade that does not involve America.
Since 1980, however, the dollar has lost ground.
Estimates from the European Commission indicate that the dollar's share in world trade fell from 56% in 1980 to 52% in 1995 (the latest year for which statistics are available).
The Deutsche Mark's share remained relatively unchanged between 1980 and 1995.
The yen lags behind, but had the highest relative growth, with its share of world trade more than doubling from 2% in 1980 to almost 5% in 1995.
Among the reasons for the dollar's longtime dominance as the premier international currency are lower transactions costs in foreign exchange markets, the historical role of the dollar in world trade since 1945, and the sheer size of America's economy.
But the role of size is more complex than it seems.
The second biggest economy in the world is Japan's, but the fraction of its trade denominated in yen remains low, even when compared to the smallest European countries.
One factor that explains this is the large share of US firms in markets where Americans sell their goods.
To understand the reasons behind all this, consider what factors are in play when a firm chooses the currency it uses to invoice for goods.
Here an exporter faces two types of risk: price risk and competitiveness risk.
Consider a Japanese firm seeking to make the highest yen profits on goods sold in Switzerland.
If the Japanese firm sets the price in Swiss francs, it is exposed to price risk as the yen price will fluctuate with the yen-Swiss franc exchange rate.
This tends to make Japanese exporters prefer to price in yen.
But firms also care about what their competitors do.
If the Japanese firm sells its goods to a particular Swiss market dominated by Swiss firms (which invoice in Swiss francs), it would prefer to price in Swiss francs too.
If it priced in yen, it would risk losing its market share if the yen appreciated.
If Japanese firms are dominant in a particular Swiss market, they prefer to price in yen: a Japanese firm then would not have to worry about losing market share when the yen appreciated, because its competitors would face the same pressures.
These arguments explain the big role played by the dollar in trade.
The fact that the US is large makes it more likely that US firms are dominant in a particular market, either as an exporter or as import-competitors when foreign goods are sold in America.
This implies that US firms price in dollars, whether they sell at home or abroad, and foreign firms for competitive reasons will also price in dollars when they export to the US.
Because Japan has the second largest economy in the world, the yen should be a more important currency.
Competitiveness is a key reason for why it is not.
First, the US is Japan's largest trading partner: more than half of Japanese trade with industrialized countries is with the US.
Over 80% of Japanese exports to the US are priced in dollars, in markets where US firms tend to dominate.
Second, even when selling to countries other than the US, Japanese exporters often face stiff American competition.
Take Japanese exports to South East Asia, which are almost 50% denominated in dollars due to competition from US exporters.
These factors are unlikely to change soon and lead us to predict that the yen will keep a low profile in world trade.
They also explain why, over time, the euro should gain weight in international trade.
Euro-zone countries can be considered a single country when dealing with the currency denomination of trade.
This `country' has more market power than the individual countries that form the European Monetary Union.
So the euro should play a larger role in international trade in the future than the sum of the currencies it replaced.
Yet these changes will only occur gradually.
So the "euro triumphalism" that has greeted the dollar's decline is, indeed, premature.
Despite its current distress, the dollar should retain its predominance for some time to come.
Terrorist attacks in Saudi Arabia have led many to question not only the ruling House of Saud's prospects for survival, but also whether the kingdom is fundamentally dysfunctional and destructive.
Somehow, it seems, Saudi society has produced a stream of violent fanaticism that draws its inspiration from extreme religious orthodoxy.
The fact that 15 of the 19 hijackers in the September 11, 2001, attacks on the United States were Saudis crystallized a long-held view of the kingdom as a bastion of authoritarianism and intolerance.
In some respects, this perception is accurate, but it cannot be applied to the broad Saudi public.
On the contrary, it would be a grave mistake to assume that fanatical Islamism fully defines Saudi attitudes toward religion.
Between 2001 and 2003, I was part of a team that undertook an extensive survey of values in Saudi Arabia, Egypt, Iran, and Jordan.
Our results provide a surprisingly nuanced picture of Saudi attitudes.
Compared to respondents in the other Middle Eastern countries, Saudis were less religious overall, and their attitudes toward democracy and arranged marriage also indicate a moderate undercurrent.
To be sure, in all four countries, religiosity is widespread, with more than 90% of respondents collectively reporting that they believe in God, in life after death, and in heaven and hell.
But the Saudis appear to be less religious than their fellow Muslims.
Sixty-two percent of Saudis described themselves as religious, compared with 82% of Iranians, 85% of Jordanians, and 98% of Egyptians.
Americans also appear to be far more religious than Saudis, with 81% describing themselves that way.
Some of this variation may be explained by cross-national differences regarding what it means to be religious.
For example, Americans may define religiosity differently than Middle Easterners, with perhaps a weaker attachment to religious beliefs than is true in Islamic countries.
This might also account in part for the differences between Muslim countries.
But the gap in self-defined religiosity between Saudis, on the one hand, and Iranians, Jordanians, and Egyptians, on the other, is so great that it challenges the prevalent perception of Saudi Arabia as a highly conservative and religious society.
Indeed, actions speak louder than words: only 28% of Saudis said that they participate in weekly religious services, compared to 27% of Iranians, 44% of Jordanians, 42% of Egyptians, and 45% of Americans.
These findings, while running contrary to popular perceptions of Saudi culture, are less startling than they appear.
Sociologists of religion have long argued that in a monolithic religious environment, or when religious institutions are closely tied to the state, the overall religiosity of the public declines.
It makes sense to think that when state authorities enforce strict codes of behavior, people tend to rebel and move away from officially sanctioned religious institutions.
Little wonder, then, that Egyptians and Jordanians, who live in countries where the state does not enforce piety, are more religious than Iranians or Saudis, who must cope with local "virtue" police backed by the state.
Even on marriage, many Saudis expressed surprisingly liberal views.
Respondents were nearly evenly split on the question of arranged marriages, with half supporting the idea that marriage should be based on parental consent, while 48% preferred love as the basis of matrimony.
Given entrenched gender segregation and paternal dominance, this finding appears to reveal a strong desire for greater individual choice in what has traditionally been a family-driven decision.
Finally, the Saudis turn out to be strong supporters of democracy, once again contradicting a popular image of Saudi conservatism.
Of the Saudis polled, 58% considered democracy the best form of government, 23% disagreed, and 18% did not express an opinion.
Majority support for democracy in a country with no prior secular and nationalist history seems counter-intuitive.
In fact, support for democracy corresponds with a number of other liberal attitudes that we found in Saudi Arabia.
Supporters of democracy tend to be less religious, more secular, more tolerant of others, more critical of public-sector performance, and more concerned with Western cultural invasion.
Beyond the survey data, history has shown that liberal ideas become more popular when a despotic monarch governs people in alliance with a religious establishment.
A strong current of liberalism appeared in the late nineteenth century in Ottoman Syria in response to the religious despotism of Sultan Abdulhamid.
At the same time, an anti-clerical, secular movement on behalf of constitutionalism appeared in Iran - a reaction to the absolutist alliance between the Quajar Shahs and the religious establishment.
In view of the similarities between those historical precedents and current conditions in Saudi Arabia, we ought not to rule out the possibility of reform.
Now survey data, too, suggest that Saudis may well begin demanding a more transparent politics and a less interventionist religion.
As the fifth anniversary of the September 11, 2001, attacks on the United States by al-Qaeda approaches, we should take the opportunity to assess the results of the response by the US and the international community.
The attacks and the response to them have obviously brought about a sea change in international relations, but it would be difficult to argue that further atrocities have become less likely as a result.
Why are we no more secure than we were five years ago?
Within a week of the attacks, President George W. Bush declared a “war on terrorism.”
The metaphor of war has the singular advantage that it clearly and strongly evokes the intensity of the counterattack that was called for.
Moreover, the metaphor of war constitutes an implicit appeal to intense mobilization, not only by a country that comes under attack, but also by its friends and allies.
Naturally, no one questions America’s right to defend itself.
The legitimacy of a violent counterattack has never been in doubt.
But the war metaphor also carries inevitable connotations that, when applied to terrorism, are misleading and counterproductive.
Whenever war is invoked, it implies a fight against nations, peoples, or states.
It implies that whole territories and the populations living there are to be considered hostile.
War implies armies and command structures that can be recognized, if not clearly known; in any case, war entails a military confrontation with an identifiable adversary .
On all of these points, the concept of war, to paraphrase US Defense Secretary Donald Rumsfeld, is not helpful.
Even if the scale of the September 11 attack was of such a dimension that only the American army seemed able to face the challenge, in technical terms dealing with a threat that is extra-national rather than international is a matter of police techniques, not military tactics.
The negative consequences of this mistaken vision very quickly became apparent.
It is now widely known that the US government, perhaps partly unconsciously, embraced a deeply distorted image of al-Qaeda that portrayed it as a hierarchical organization with a seamless command structure – the prototype of a foe that the American army could attack and destroy.
But al-Qaeda – the word means “the base” or “the camp,” that is, nothing more or less than a point of gathering and training – is more like a blurred sphere of influence, comprising individuals and small local cells that act on their own initiative and cooperate very rarely, and only for large-scale operations.
It has not been proved that the attacks in London, Madrid, or Bali in the years since the September 11 plot, or the attack on America’s warship the USS Cole in 2000, reflected the existence of a “center” that coordinated the operations or gave orders to carry them out.
It is also wrong to conflate Islamic terrorism with that of the Basque ETA, Sri Lanka’s Tamil Tigers, or the Irish Republican Army.
Whereas these groups have a territorial base and are preoccupied with national aims, Islamic terrorism appears to be the work of a very small number of individuals who seek to avenge the centuries-long “humiliation” of the Muslim world, brought about by colonization, absence of economic development, and political weakness.
The goal of Islamic terrorists is nothing less than the destruction of the “hegemonic” Western world, despite most Muslim nations’ desire to live in peace within the international community and to cooperate in crafting effective development strategies.
The only viable strategy for confronting the threat of Islamic terrorism was, and continues to be, a search for agreement among Muslims, and among the leaders of Muslim nations, on the forms of mutual cooperation, including police cooperation, that are needed to isolate, weaken, or destroy the militants in their midst.
This is a long and difficult enterprise, but there remains no alternative.
Instead, the war metaphor continues to define the US response and that of several of America’s allies.
The attraction of this metaphor may be attributable to the excessive trust that Americans place not only in their army, which is understandable, but in force in general, which is much less understandable in the case of an intelligent people.
Whatever the case, casting the fight against terrorism as a war has led American policymakers to multiply violent military operations that have absolutely no chance of winning hearts and minds in the Muslim world.
Quite the contrary.
Afghanistan was the only case where a military response was understandable: its government had, after all, given al-Qaeda a temporary territorial home.
But to implicate Iraq, which had nothing to do with al-Qaeda or the September 11 attacks, was a huge mistake, one that has strengthened Islamic extremists and has probably helped them recruit terrorists.
Moreover, the US response has strengthened Israel’s belief in the effectiveness of military methods, leading to the recent war in Lebanon and the ongoing invasion of Gaza.
Powerless, the international community does nothing.
The rigidity and brutality of America’s behavior – resulting in many times more civilian deaths than occurred on September 11 – have blocked any useful intervention by countries such as Algeria, Morocco, Jordan, Saudi Arabia, or the United Arab Emirates.
Likewise, the appeal of war has ruled out the prospect of serious negotiations between Israel, Syria, and Lebanon.
By attacking one Muslim country after another, the US and its allies have created the impression that Islam itself is the enemy, leading inexorably to the “clash of civilizations” that America says it wants to avoid.
But America’s strategy has failed.
Force cannot accomplish everything.
The international community must say clearly that Islam is not our enemy and that terrorism must be fought in other ways.
Muslim political leaders, for their part, should declare just as openly that terrorism is not their choice.
If both sides can stifle their murderous deviances, the hope of cultural and political reconciliation will be reborn.
LONDON – The World Court’s recent ruling on Kosovo’s unilateral declaration of independence is being widely touted as giving a green light to secessionist movements to gain statehood.
According to Kosovo President Fatmir Sejdiu, “The decision finally removes all doubts that countries which still do not recognize the Republic of Kosovo could have.”
But this reading is largely wishful thinking by those who support secession.
The Court's non-binding advisory opinion responded to a narrow question posed by the United Nations General Assembly: whether declaring independence is legal under international law.
The judges rightly held that there is no international rule preventing a group from stating its intention or wish to form a state.
But they said nothing about the terms and conditions that apply to following through on this intention – i.e., the act of secession itself.
Indeed, the Court sought to leave no doubt about this: “The question is narrow and specific... it does not ask whether or not Kosovo has achieved statehood.” The judges contrasted their opinion with that handed down by the Supreme Court of Canada when it was asked to rule on Quebec’s right to secede unilaterally.
In that case, the question went far beyond a declaration of independence; the court was asked whether and under what conditions Quebec had a right to break away from Canada, under either the Canadian constitution or international law.
The Canadian judges held that international law granted no such unilateral right (and nor did the country's own constitution).
As the World Court pointed out, its judgment last week did not refute that crucial point: “The Court is not required by the question it has been asked to take a position…on whether international law generally confers an entitlement on entities within a State to break away from this [State].”
Moreover, the Court noted the radically different views expressed before it on whether self-determination in international law implies a unilateral right to secede.
By acknowledging the range and intensity of disagreement among states on a right to secede, the Court seems to have hinted that the necessary consent of the world community does not exist to establish firmly the existence of any such right.
Before concluding that there is now a “clear path” to Kosovo's independence, it is worth pondering the important questions that the Court did not answer (and was not asked by the General Assembly).
The Court was not asked, and thus did not rule on, whether international law requires that the final status of Kosovo protect the group and individual rights of minorities, whether Kosovar Serbs or Roma.
Likewise, the Court was not asked and did not rule on whether Serbia or, indeed, any other state in the world community is required to recognize Kosovo as an independent state.
Nor did the Court’s decision address the borders of an independent Kosovo, or whether and under what circumstances force could legally be used either to impose independence or to resist it.
If the fate of Kosovo – and the entire Balkan region – is to be guided by the global rule of law, these questions need to be answered, not swept under the table.
Under existing procedures, framing questions to the World Court is entirely a prerogative of states, either as contending parties or, as with the Kosovo opinion, operating through the UN.
But the rights of persons and peoples, not just interests of states, are at stake in controversies such as this one.
To fulfill international justice today, we need a new kind of World Court, open to other voices. 
Oil prices are now running well above $50 a barrel, partly owing to short-run supply shocks, such as the Iraq conflict, Nigerian labor disputes, the conflict between Yukos Oil and the Russian government, and Florida's recent hurricanes.
Oil prices may fall once these shocks dissipate, but speculative effects could keep them relatively high, weakening the world economy and depressing stock markets.
Even a temporary spike in oil prices can have long-term effects because of the social reactions they provoke.
High oil prices fuel public discussion about the future of oil prices.
The outcome of any public discussion can never be known with certainty, but chances are that it will amplify stories that imply risks of higher oil prices.
Experts may say that short-run supply factors caused the recent price increases, but the price increases will nonetheless lend credibility to scarier long-term stories.
The scary story that is being amplified now concerns the developing world, notably China and India, where rapid economic growth - and no restrictions on emissions under the Kyoto Protocol - are seen as creating insatiable demands for oil.
The story's premise is that the world will run out of oil faster than we thought, as these billions of people chase their dreams of big houses and sport utility vehicles.
Is this plausible?
Certainly, China, India, and some other emerging countries are developing fast.
But experts find it difficult to specify the long-run implications of this for the energy market.
Too many factors remain fuzzy: the rate of growth of these countries' energy demand, discoveries of new oil reserves, developments in oil-saving technology, and the ultimate replacement of oil by other energy sources.
But what matters for oil prices now and in the foreseeable future is the perception of the story, not the ambiguities behind it.
If there is a perception that prices will be higher in the future, then prices will tend to be higher today.
That is how markets work.
If it is generally thought that oil prices will be higher in the future, owners of oil reserves will tend to postpone costly investments in exploration and expansion of production capacity, and they may pump oil at below capacity.
They would rather sell their oil and invest later, when prices are higher, so they restrain increases in supply.
Expectations become self-fulfilling, oil prices rise, a speculative bubble is born.
But if owners of oil reserves think that prices will fall in the long run, they gain an incentive to explore for oil and expand production now in order to sell as much oil as possible before the fall.
The resulting supply surge drives down prices, reinforces expectations of further declines, and produces the inverse of a speculative bubble: a collapse in prices.
All of this may seem obvious, but we tend not to think of oil prices as being determined by expectations of future prices.
For example, in January 1974, when the first world oil crisis began, oil prices doubled in just days.
The immediate cause was believed to have been Israel's stunning success in the Yom Kippur War, which led Arab oil producers to retaliate by choking off output.
The second crisis, in 1979, is usually attributed to supply disruptions from the Persian Gulf following the Islamic revolution in Iran and the subsequent start of the Iran-Iraq war.
Why, then, did real inflation-corrected oil prices remain at or above their 1974 levels until 1986?
Speculative pressures are likely to have been at work, influencing the decisions of OPEC and many others.
Although changes in market psychology are difficult to understand, the broad concerns that underlie such episodes of irrational exuberance are almost always clear.
For example, in 1972, scientists at the Massachusetts Institute of Technology, including computer pioneer Jay Forrester, published The Limits to Growth .
The book launched an international debate on whether the world would soon face immense economic problems due to shortages of oil and other natural resources - problems that seemed to be presaged by OPEC's production cuts eighteen months later.
The second crisis was immediately preceded by the accident at the Three-Mile Island nuclear reactor in Pennsylvania in March 1979, which reinvigorated the anti-nuclear movement.
With nuclear power - regarded as the main technological bulwark against depletion of the world's oil supplies - suddenly suspect, oil prices doubled again by the year's end.
After 1979, fears about limits to growth and nuclear power ebbed.
Oil prices gradually fell, and the stock market began its long climb towards its peak in 2000.
But the current rise in oil prices shows that people are still eager to embrace "running out of oil" stories - this time focused on China and India - even when short-run factors are to blame.
Indeed, the International Energy Agency noted in September that the usual relationship between oil prices and inventory levels has broken down, with prices much higher than the usual relationship would suggest.
The IEA's report calls this breakdown evidence of a "structural shift in the market."
But the same pattern followed the 1973-4 and 1979-80 oil crises, when prices dropped from their highest peaks, but stayed quite high for years, representing a drag on the stock market, the housing market, and the world economy.
Let's hope that the effects of the present spike will be more short-lived.
But don't hold your breath.
Work can give structure and meaning to life.
But working conditions can also trigger or accelerate the symptoms of ill health - physical and mental - that feed back into our productivity and earning capacity, as well as into our social and family relationships.
In fact, an alarmingly large number of people appear to be at risk. 
Of the EU's 160 million-strong labour force, 56% report working at very high speeds, and 60% to tight deadlines.
More than a third have no influence on task order, and 40% perform monotonous tasks.
This probably contributes to a host of health-related problems: 15% of the workforce complain of headaches, 33% of backache, 23% of fatigue, and 23% of neck and shoulder pains, plus a host of other illnesses, including life-threatening ones. 
Sustained work-related stress is also an important determinant of depressive disorders - the fourth-largest cause of disease world-wide.
They are expected to rank second by 2020, behind only heart disease.
In the EU, the cost of these and related mental health problems is estimated to average 3-4% of GNP, amounting to approximately 265 billion euros annually. 
Moreover, sustained work-related stress is likely to contribute to `metabolic syndrome,' a cluster of pathogenic mechanisms characterised by an accumulation of abdominal fat, a decrease in sensitivity to insulin, increased levels of cholesterol, and heightened blood pressure, all related to the onset of heart disease and diabetes. 
Of course, working conditions may be experienced as threatening even when objectively they are not, or trivial symptoms may be interpreted as manifestations of serious illness.
But stress is worrisome precisely because even misinterpretations can add to, or result in, a wide variety of health problems, including heart disease, stroke, cancer, musculoskeletal and gastrointestinal diseases, anxiety and depression, accidents, and suicides. 
Briefly stress consists of a pattern of built-in processes preparing the human organism for physical activity in response to demands and influences that tax its capacity to adapt.
Activation of our "fight or flight" mechanism is an appropriate adaptive response when facing a wolf pack, but not so when struggling to adjust to rotating shifts, monotonous and fragmented tasks, or over-demanding customers.
If sustained, stress is often maladaptive and eventually disease provoking. 
Stress-related paths to pathologies take a wide variety of forms.
They can be emotional (anxiety, depression, hypochondria, and alienation), cognitive (loss of concentration or recall, inability to learn new things, be creative, make decisions), behavioural (abuse of drugs, alcohol, and tobacco, refusal to seek or accept treatment), or physiological (neuroendocrine and immunological dysfunction). 
To identify, prevent, and counteract the causes and consequences of work-related stress, we need to monitor job content, working conditions, terms of employment, social relations at work, health, well-being and productivity.
The first step is to identify the incidence, prevalence, severity, and trends of work-related stress and its causes and health consequences.
Are they likely to contribute to stress-related ill health?
Can they be changed?
Are such changes acceptable to workers and employers? 
Wherever the answers are affirmative, an integrated package of organisational changes should be considered.
Such changes are likely to include the following areas: 
Work schedule.
 Design labor time to avoid conflict with demands and responsibilities unrelated to the job; 
Participation/control.
 Allow workers to take part in decisions or actions affecting their jobs; 
Workload.
 Ensure that workers have enough time to complete assigned tasks, and allow for recovery from especially demanding physical or mental tasks; 
Content.
 Design tasks to provide meaning, stimulation, a sense of completeness, and an opportunity to use skills; 
Roles.
 Define work roles and responsibilities clearly; 
Social environment.
 Ensure a working atmosphere free of all forms of invidious discrimination and harassment; 
Future.
 Avoid ambiguity in matters of job security and career development; promote life-long learning and employability. 
Although it is likely, the short- and long-term outcomes of such changes may not always suffice in the fight against work-related stress.
They need therefore to be evaluated in terms of exposures and reactions to stress, the incidence and prevalence of ill health, and the quality and quantity of goods or services. 
Many companies world-wide recognize that success requires satisfying the three elements of sustainable development: financial, environmental, and social.
Failure to do so leads, over time, to terminal organizational weakness, owing to lost credibility amongst employees, shareholders, customers, and communities. 
This has numerous implications for relations with employees.
Ensuring long-term economic growth and social cohesion requires a commitment to health and safety, a better balance between work, family and leisure, lifelong learning, greater workforce diversity, gender-blind pay and career prospects, and profit-sharing and equity-ownership schemes. 
These practices can have a positive impact on profits through increased productivity, lower staff turnover, greater amenability to change, more innovation, and better, more reliable output.
Indeed, companies often have an interest in going beyond minimum legal requirements: peer respect and a good reputation as an employer are marketable assets. 
The challenge for science is to find out what to do, for whom, and how.
The challenge to workers, employers, governments, and communities is to translate what we now know into coordinated and sustainable programs. 
Argentina is stuck in a time warp.
Political and economic reforms over the past decade were supposed to lead the country out of chronic economic crisis.
In April 1991 Economy Minister Domingo Cavallo linked the Argentine Peso to America’s dollar at a rate of one to one, kicking off an era of radical reform.
Yet ten years later, the same Signor Cavallo is trying to fend off recession and government default.
Argentina’s cycle of crisis is perplexing.
The past ten years saw industries and social security privatized and international trade liberalized.
A chronic budget deficit was brought under control, infrastructure upgraded, and the banking sector strengthened.
All this, and currency stabilization, made for an economic boom in Argentina that lasted until 1995, as foreign investors poured money in.
In that year, the economy was set back by Mexico’s financial crisis.
Growth rebounded strongly until 1998.
Since then, the economy has confronted prolonged recession, and the government is having trouble refinancing the public debt.
Fears of a default abound.
Starting with Cavallo, Argentina’s boosters argue that these problems are transitory, and blame the country’s difficulties on turmoil in world financial markets and the US dollar’s excessive strength in relation to the Euro, which reduces Argentina’s export competitiveness.
Brazil’s devaluation in 1999 also undermined export competitiveness.
Low world commodities prices and protectionism against Argentina’s agricultural exports are additional factors.
These supporters also argue, with some justice, that Argentina’s crisis results in part from a self- fulfilling prophesy among creditors.
Since Argentina has been in crisis so often, investors always fear the worst and withdraw funds at the first hint of trouble, provoking an even deeper crisis.
But something more than bad luck and self-fulfilling prophecies are at work.
Argentina’s Peso, because it is pegged to the US dollar, provides little flexibility.
There is no safety valve in currency depreciation when the economy is buffeted by external shocks.
Compare Argentina with another grain exporter, Australia, which has been hit by some of the same shocks.
Australia’s dollar depreciated from 78 US cents per Australian dollar in May 1997 to just 53 US cents per Australian dollar in May 2001.
This helped maintain Australia’s exports and kept the economy growing at around 2% per year, while Argentina’s economy has been shrinking at around 2% per year.
But Argentina’s woes go deeper.
Argentina is vulnerable to external shocks such as declining agricultural commodity prices because Argentina failed to develop a diversified export sector, one in which a broad range of industrial and service sectors are internationally competitive.
Argentina’s trade is overwhelmingly concentrated in a small number of commodities, including cereals, meats, processed foods, and other agricultural products.
Exports of machinery and transport equipment, embodying higher technology, claimed only 10% or so of exports and only 1% of GDP.
In other words, Argentina has failed to become a technology-based economy.
Market reformers focused their attention on reducing the size of government, but overlooked the government’s role in raising the country’s technological capacity.
An economy’s technological capacity depends on a wide range of social institutions.
A well-functioning market system helps attract high-tech investors from abroad and fosters high-technology startups at home.
But a high-tech economy also requires strong universities, with high enrolment, and large-scale government support for scientific research.
America, for example, invests around $90 billion of public funds each year in scientific research.
Some developing countries - Israel, Korea, and Taiwan - also invest heavily in higher education and scientific research.
Sadly, Argentina did not.
Under-investment in technology is evident throughout the economy.
There are around 600 scientists for every million Argentines, compared with 2,200 scientists for every million Koreans.
Argentina invests less than 1% of its national income in research and development, compared with around 2.5% of national income in Korea.
Argentine inventors received just 63 patents in the US in the year 2000, compared with 3,400 patents received by Korean inventors.
The difference is reflected in economic growth.
Argentina achieved per capita economic growth of just 0.5% during 1980-1998, while Korea grew at a rate of 6.2% per year, fueled by its high-technology exports.
Argentina’s fate teaches a lot about development strategies.
Argentina has much going for it: widespread literacy, a healthy population, a highly productive agricultural economy, and a strong natural resource base.
Indeed, Argentina has had its share of economic success, with an income level, adjusted for purchasing power, around one-third of that of the US, and is far ahead of most countries in the world.
But Argentina did not make a successful transformation from a resource-based to a technology-based economy.
The reform prescriptions it followed helped end inflation but ignored the need for government to promote a knowledge-based economy.
In the past countries could achieve high living standards by exploiting natural resources.
In today’s global economy, however, international competitive advantage is mostly based upon knowledge and the capacity to harness knowledge in new technologies.
Countries need strategies to foster education and innovation just as they need strategies to preserve macroeconomic stability and a healthy business environment.
The next stage of reforms in Argentina, and in countries in similar positions, should focus on fostering society’s educational, scientific, and technological capacities.
The first glimpses of Argentina's recovery can be seen.
To many, what happened, and what is happening there seems a mystery.
Abandoning "convertibility," i.e. a fixed exchange rate system, was supposed to be a disaster - and it was.
Output fell and unemployment increased dramatically.
Fear of these costs, combined with IMF bailouts, kept Argentina from abandoning its currency board long after it was clear that the system could not be sustained.
This stubbornness made matters worse when things finally fell apart.
But what primarily kept Argentines wedded to a system that could not work was fear of hyperinflation.
When I asked people, during my visits to Buenos Aires, why Argentina persisted in this economic folly, a single answer came back: "Yes, when Brazil went off its peg, its inflation remained moderate; but Brazil is Brazil, and we are Argentina."
There was almost pride in the lack of confidence Argentina's people had in their institutions and their ability to manage without the shackles of convertibility.
The feared hyperinflation, so far, has not materialized.
To be sure, there has been the normal inflation associated with large increases in import prices that always follow large devaluations, but rather than setting off a spiral of price increases, inflation rates appear to be dampening.
Argentina seems set to join the long list of countries - Brazil, Korea, Russia, Thailand, and Indonesia - that managed devaluations without runaway inflation.
To an economist, Argentina's recovery is no surprise.
Devaluation incites several restorative forces.
Exports are cheaper, and revenues from exports (measured in pesos) are up dramatically.
Tourism and related industries are booming.
Import substitution takes place before your eyes: a clothing store that last year sold only imported apparel, now sells only domestically produced goods.
As in East Asia after its crisis of 1998, what inhibits these restorative forces is a lack of credit.
Foreign ownership of banks was supposed to ensure their stability; it was expected that foreign banks would come to the rescue of their Argentine subsidiaries if they needed money.
Deposits in the branches of American banks in Buenos Aires were to be as safe as deposits in Miami.
Unfortunately, depositors learned otherwise.
On the other hand, foreign banks were always falling short in assuring an adequate supply of credit to small and medium sized Argentine firms.
This lack of credit stifled growth, which contributed to the country's economic woes; and now credit has virtually dried up.
To be sure, some domestic banks continue to provide credit.
But if the recovery is to be sustained credit must be expanded, either by creating new financial institutions or by expanding existing ones.
Here credit cooperatives may be particularly important, given the seeming lack of confidence in the more traditional banking sector.
Revival of trade credit is also urgent - its importance was recognized early on during East Asia's crisis, where Japan, in a good neighborly gesture, provided $30 billion dollars through the Miyazawa initiative, much of which went to finance trade credit and help restart the economy.
The point is simple: Argentina's real resources, its people, with their enormous talents and skills, its fertile land, its capital goods remain.
What the economy needs is reactivation , and government policies must focus on this task.
If the private sector cannot improve the availability of credit on its own, and no good neighbor steps forward to help, as Japan did in East Asia, government must take a more active role in restructuring the existing credit institutions as well as creating new ones.
Would government involvement in providing credit create dangerous levels of inflation?
Directing credit in order to increase supply of goods need not be inflationary; on the contrary, the increased supply of domestically produced goods may be an effective instrument for combating inflation.
Appropriate accounting, separating expenditures for recapitalizing banks from ordinary expenditures, such as those needed to run hospitals and schools, would make clear that these expenditures are not by themselves inflationary.
It is only the credit expansion that such expenditures allow which might be inflationary.
In an economy with vast problems, underutilization of resources, and a massive lack of credit, a modest credit expansion would not in fact lead to high inflation.
Centering attention on reactivation makes clear why the focus on IMF credits is misguided.
IMF credits will go to repay the IMF, not to reactivate the economy.
Supposedly, the IMF credit will "restore confidence" in the economy, but whether it does so depends on the conditions that are imposed.
If the IMF imposes fiscal contraction or a misguided strategy for restructuring the financial sector (as it did in Indonesia), then the economy will be weakened and this will lead to a further erosion of confidence.
If, on the other hand, IMF credit is obtained on reasonable terms, it will make a positive contribution.
But it will be no panacea.
Indeed, IMF credit will do little to address the key economic issues, except to the extent that it frees up money from other international sources and those funds are used to reactivate the economy.
Where the international community can help Argentina is by opening its doors to Argentine goods, taking the rhetoric of free trade seriously and recognizing that trade can be an important instrument not only for long-term growth, but also for economic recovery.
Exports will help reactivate the Argentine economy, while consumers in Europe and America will benefit from high quality goods at lower prices.
This is one way of making globalization work to benefit those in need.
BUENOS AIRES –&nbsp;The expropriation of nearly all of the Spanish company Repsol’s stake in Argentina’s energy producer YPF, announced in a vehement speech by President Cristina Fernández de Kirchner, has raised legal alarms worldwide.
In fact, the move will not resolve the country’s energy problems in the absence of enormous inflows of investment to the sector.
Repsol acquired complete control of YPF in 1999; in February 2008, it transferred part of its shares to the Petersen Group, which today holds 25%.
Repsol currently holds 57%, with the rest owned by stock-market investors.
The Argentine government intends to expropriate 51%, leaving Repsol with a 6% stake.
In the 2008 sale of shares, the two majority stockholders agreed to distribute at least 90% of future profits in cash.
That decision was intended to allow the Petersen Group to service the debts to banks, and to Repsol itself, that it incurred with its share purchase, for which it made no initial payment.
This is an extraordinarily high dividend in the world oil industry.
In the past decade, YPF’s reserves diminished significantly, along with those of most oil companies operating in Argentina, because investment in exploration was greatly reduced.
At the same time, natural gas accounts for 51% of energy consumption, compared to 32% for oil and barely 17% for coal, renewables, and hydroelectric and nuclear power.
Worldwide, gas accounts for barely a quarter of total energy consumption – for example, 27% in the United States and just 9% in neighboring Brazil.
Argentina has the world’s largest fleet of vehicles running on compressed natural gas; families use gas intensively; most electricity is generated with gas; and the petrochemical industry is based on it.
Of course, in a few other countries (Qatar, Algeria, the United Arab Emirates, Iran, and Russia), gas also accounts for more than half – or even more than 60% – of energy consumption.
But there is an enormous difference: all of these countries have reserves that will last another 70-100 years.
Argentina, by contrast, is a highly gas-dependent country with diminishing reserves – equivalent to less than eight years of production.
Covering this drop in reserves – more than half of gas reserves and a fifth of oil reserves have been consumed – with imports implies an annual cost of more than $300 billion.
Indeed, after two decades of cheap, abundant energy and exports of surplus output, a new cycle of expensive, scarce, and imported energy has begun, as oil production has fallen by one-third since 1998, and gas production by 15% since 2004.
Argentina’s greatest challenge today is to try to regain energy self-sufficiency through significant investment in exploration on land, as well as in the Atlantic Ocean.
At the same time, the country must modify its consumption model through greater reliance on hydroelectric, nuclear, and wind energy.
While there is great potential for new non-conventional resources, all of this is expensive, requiring annual investment of about 3% of GDP over the next five years.
It is very likely that, in the short term, growing imports of expensive liquid natural gas and other fuels will continue to exert pressure for change.
Last year, the external energy deficit was more than $3 billion, and this year it is expected to double.
The important question is whether the Argentine government’s decision to nationalize 51% of YPF’s shares is the best way to recover self-sufficiency in oil and gas production, and to attract the capital needed for exploration and development of conventional reserves.
Argentina has particularly high potential for production of non-conventional gas resources as well, given that it holds the world’s third-highest level of such reserves, after China and the United States.
But, as with the country’s conventional resources, these reserves will not produce themselves.
Argentina's collapse incited the largest default in history.
Pundits agree this is merely the latest in a string of IMF-led bailouts that squandered billions of dollars and failed to save the economies they were meant to help.
The nature of that failure, however, is disputed.
Some claim that the IMF was too lenient; others that it was too tough.
Those who blame the IMF see the problem as self-inflicted through profligate and corrupt spending by Argentina.
Such attempts at blame-shifting are misguided: one can understand the default as the consequence of economic mistakes made over a decade.
Understanding what went wrong provides important lessons for the future.
The problems began with the hyperinflation of the 1980s.
To slash inflation, expectations needed to be changed; ``anchoring'' the currency to the dollar was supposed to do this.
This was a return to a variant of the old gold standard argument.
If inflation continued, the country's real exchange rate would appreciate, the demand for its exports would fall, unemployment would increase, and that would dampen wage and price pressures. Market participants, knowing this, would realize that inflation would not be sustained.
So long as the commitment to the exchange rate system remained credible, so was the commitment to halt inflation.
If inflationary expectations were changed, then disinflation could occur without the costly unemployment.
This prescription worked for a time in a few countries, but was risky, as Argentina was to show.
The IMF encouraged this exchange rate system.
Now they are less enthusiastic, though Argentina, not the IMF, is paying the price.
The peg did lower inflation; but it did not promote sustained growth.
Argentina should have been encouraged to fix a more flexible exchange rate system, or at least an exchange rate more reflective of the country's trading patterns.
Other mistakes in Argentina's ``reform'' program also occurred.
Argentina was praised for allowing large foreign ownership of banks.
For a while this created a seemingly more stable banking system, but that system failed to lend to small and medium sized firms.
After the burst of growth that arrived with hyperinflation's end, growth slowed, partly because firms in the country couldn't get adequate finance.
Argentina's government recognized the problem, but was hit by numerous shocks beyond its control before it could act.
East Asia's crisis of 1997 provided the first hit.
Partly because of IMF mismanagement, this became a global financial crisis, raising interest rates for all emerging markets including Argentina.
Argentina's exchange rate system survived, but at a heavy price - the onset of double-digit unemployment.
Soon, high interest rates strained the country's budget.
Yet Argentina's debt to GDP ratio - even as it began to collapse - remained moderate, at around 45%, lower than Japan's.
But with 20% interest rates, 9% of the country's GDP would be spent annually on financing its debt.
The government pursued fiscal austerity, but not enough to make up for the vagaries of the market.
The global financial crisis that followed East Asia's crisis set off a series of big exchange rate adjustments.
The dollar, to which Argentina's peso was tied, increased sharply in value.
Meanwhile, Argentina's neighbor and Mercosur trading partner, Brazil, saw its currency depreciate - some say that it became significantly undervalued.
Wages and prices fell, but not enough to allow Argentina to compete effectively, especially since many of the agricultural goods which constitute Argentina's natural comparative advantages face high hurdles in entering the markets of rich countries.
Hardly had the world recovered from the 1997-1998 financial crisis when it slid into the 2000/2001 global slowdown, worsening Argentina's situation.
Here the IMF made its fatal mistake.
It encouraged a contractionary fiscal policy, the same mistake it had made in East Asia, and with the same disastrous consequence.
Fiscal austerity was supposed to restore confidence.
But the numbers in the IMF program were fiction; any economist would have predicted that contractionary policies incite slowdown, and that budget targets would not be met.
Needless to say, the IMF program did not fulfill its commitments.
Confidence is seldom restored as an economy goes into a deep recession and double-digit unemployment.
Perhaps a military dictator, like Chile's Pinochet, could suppress the social and political unrest that arises in such conditions.
But in Argentina's democracy, this was impossible.
In repeated visits to Argentina, I marveled at how long suffering the Argentineans were; to me, it is more a surprise that unrest took so long to manifest itself, not that street turmoil unseated Argentina's president.
Seven lessons must now be drawn:
1.
In a world of volatile exchange rates, pegging a currency to one like the dollar is highly risky.
Argentina should have been encouraged to move off its exchange rate system years ago.
2.
Globalization exposes a country to enormous shocks.
Countries must cope with those shocks - adjustments in exchange rates are part of the coping mechanism.
3.
You ignore social and political contexts at your peril.
Any government that follows policies which leave large fractions of the population unemployed or underemployed is failing in its primary mission.
4.
A single-minded focus on inflation - without a concern for unemployment or growth - is risky.
5.
Growth requires financial institutions that lend to domestic firms.
Selling banks to foreign owners, without creating appropriate safeguards, may impede growth and stability.
6.
One seldom restores economic strength - or confidence - with policies that force an economy into a deep recession.
For insisting on contractionary policies, the IMF bears its great culpability.
1.
7. Better ways are needed to deal with situations akin to Argentina.
I argued for this during East Asia's crisis; the IMF argued against me, preferring its big-bail-out strategy.
Now the IMF belatedly recognizes that it should explore alternatives.
The IMF will work hard to shift blame - there will be allegations of corruption, and it will be said that Argentina did not pursue needed measures.
Of course, the country needed to undertake other reforms - but following the IMF's advice regarding contractionary fiscal policies made matters worse.
Argentina's crisis should remind us of the pressing need to reform the global financial system - and thorough reform of the IMF is where we must begin.
CAMBRIDGE: Efforts to make the world safe for investment bankers are underway once again.
The IMF is preparing a bailout estimated at $20 billion to keep Argentina from defaulting on loans to foreign investors.
As usual, investors will get repaid, while Argentina sinks deeper into crisis.
The story goes back decades.
Argentina was seriously mismanaged from the 1940s to the early 1990s.
Military and civilian governments alternated in irresponsible monetary and fiscal policies, and in trade protectionism that cut Argentina off from world markets.
That combination produced massive foreign debt, a low level of exports relative to the size of the economy, and high inflation.
In the early 1990s, President Carlos Menem and Finance Minister Domingo Cavallo took drastic actions, reducing budget deficits and ending protectionism.
To battle inflation, however, they resorted to a trick.
They fixed the exchange rate of the Argentina Peso at a value of one Peso per US dollar, and promised that the exchange rate would never change.
This system is known as a “currency board” arrangement.
Irrevocably fixing the exchange rate was at best a gamble, at worst a blunder.
The exchange rate is a safety valve: when an economy becomes uncompetitive – say, if international demand for its products declines, or domestic costs rise above other countries – a decline in the currency’s value can restore demand for the nation’s output, and so help preserve employment.
If the exchange rate is irrevocably fixed, that safety valve disappears.
The economy can remain uncompetitive for years, causing chronically high unemployment and slow growth.
At the start, Argentina’s gamble seemed to pay off.
Foreign investors, who understand little about macroeconomics and long-term growth, were delighted with Argentina’s new-found stability.
They poured money in; Argentina seemed to boom.
But it is easy to boom when money pours in.
Investors did not understand that Argentina was at risk of longer-term stagnation as a result of its currency board gamble.
Argentine wages and prices rose significantly from 1991 through 1993.
As a result, Argentina priced itself out of world markets for many exports.
Luckily, Brazil was also becoming a very expensive economy as a result of fixing the Brazilian Real to the US dollar in 1994.
Argentine producers could sell goods to Brazil even when they could not sell them elsewhere.
Argentina experienced a deep financial crisis in 1995, but recovered fast when exports to Brazil increased.
Pleased with its success, Argentina began telling other countries to set up currency boards.
I argued with them, saying that Argentina was in more trouble than appeared, and that Argentina should not encourage others to take the same gamble.
Few listened.
Argentine officials repeatedly told me that I was wrong, that Argentina was in great shape.
The IMF also championed Argentina’s gamble, urging Bulgaria, for example, to follow the same approach.
Predictably, Argentina’s gamble turned sour.
In early 1999 Brazil decided to devalue its currency.
Suddenly, Brazilian goods were cheaper than Argentine goods, so Brazilian consumers and businesses reduced their purchases.
Automobile manufacturers with divided production between Argentina and Brazil shifted production to Brazilian factories.
Unemployment rose in Argentina, and GNP fell by 3.1% in 1999, while Brazil’s GNP rose by 1%.
Argentina was not the only South American economy to suffer in 1999, but the others adjusted their exchange rates to restore international competitiveness.
Argentina was stuck with its currency board and overvalued currency.
Once investors understood Argentina’s predicament, they started dumping its government bonds, and the risk premium on loans to Argentina rose several percent.
Early in the year, investors required a risk premium of almost 6 points in order to buy Argentine debts.
Bond rating agencies downgraded Argentina’s government debt, which contributed to a further rise in the risk premium.
Recently, holders of Argentina’s debts have been receiving a rate of return of 15% per year or even higher.
High interest rate compensate for the risk that Argentina might stop paying the debts or devalue the currency or both.
Holders of Argentine debt now scream that the world will come to an end if Argentina devalues its currency or suspends payments on its debts.
Dutifully, the IMF is going to the rescue of bond holders.
The IMF, World Bank, and the Inter-American Development Bank are gearing up to lend Argentina $20 billion so that it can continue to pay its debts without changing the exchange rate.
(If it devalued the exchange rate, creditors holding Argentine debt denominated in pesos would receive a smaller amount in terms of US dollars).
This “bailout” will not bail out Argentina.
The IMF’s advice - to cut government spending and raise taxes - will deepen the crisis.
This bailout money will encourage investment bankers to continue ignoring their risks.
Yes, Argentina’s debts will probably be paid in full, but Argentina’s taxpayers and workers will bear a heavy burden for years to come.
What should be done?
First, Argentina should end its currency board and devalue its currency.
Argentina is uncompetitive, and will have several years of slow growth if it doesn’t move the exchange rate.
In a bold stroke, it could devalue the currency and then join a monetary union with Brazil.
(The other hope for Argentina is that the US dollar collapses in value compared to the Euro, so that the Argentine peso becomes more competitive vis-a-vis the Euro).
Second, the IMF should let Argentina and its creditors work out a refinancing or rescheduling agreement.
A bailout just enriches creditors and lets them continue irresponsible gambling and ignore macroeconomic realities.
Third, the World Bank and the Inter-American Development Bank, both development institutions, should not be misused for short-term bailouts.
Fourth, the IMF and others should stop peddling monetary mischief such as currency boards and fixed exchange rates.
Such arrangements make sense in rare circumstances (perhaps in a very small and open economy such as Estonia).
Even if the system made sense in Argentina in 1991 to end hyperinflation, it came at a high cost that need not be paid by other countries.
CAMBRIDGE – Where are global currencies headed in 2011?
After three years of huge, crisis-driven exchange-rate swings, it is useful to take stock both of currency values and of the exchange-rate system as a whole.
And my best guess is that we will see a mix of currency wars, currency collapses, and currency chaos in the year ahead – but that this won’t spell the end of the economic recovery, much less the end of the world.
Let’s start by acknowledging that the modern system of floating exchange rates has, on the whole, acquitted itself remarkably well.
True, given complex risk factors and idiosyncratic policy preferences, it has been particularly challenging of late to divine the logic underlying big exchange-rate swings.
For example, even though the United States was at the heart of the financial crisis, the dollar initially soared.
But, even if exchange rates work in mysterious ways, their cushioning effect is undeniable.
The sharp depreciation of the euro after the crisis helped sustain German exports, thereby keeping the eurozone afloat.
Emerging markets’ currencies also collapsed, even in economies with huge foreign-exchange reserves and relatively little debt.
Since then, most emerging-market currencies have rebounded sharply.
In hindsight, these exchange-rate swings mirrored the initial collapse and subsequent rebound in global trade, helping to mitigate the recession.
By contrast, the financial crisis was hardly an advertisement for expanding the scope of fixed exchange rates.
The eurozone’s peripheral countries, including Greece, Portugal, Ireland, and Spain, found themselves pinned to the mast of the common currency, unable to gain competitiveness through exchange-rate depreciation.
The intellectual father of the euro, Columbia University’s Robert Mundell, once famously opined that the optimal number of currencies in the world is an odd number, preferably less than three.
It is hard to see why right now.
Perhaps when we have one world government, it will make sense to have one world currency.  But, even setting aside the equilibrating benefits of flexible currencies, the prospect of a single, omnipotent central bank is not particularly appealing.
Witness the vitriol and hysteria that accompanied the US Federal Reserve’s policy of so-called “quantitative easing.”
Imagine the panic that would have ensued in a world where gold, storable commodities, and art were the only ways for investors to flee from the dollar.
But the continuing success of the floating exchange-rate system does not imply a smooth ride in 2011.
For starters, we can certainly expect a continuation of the so-called currency wars, in which countries strive to keep their exchange rates from appreciating too rapidly and choking off exports.
Asian governments will probably gradually “lose” their battle in this war in 2011, allowing their currencies to appreciate in the face of inflationary pressures and threats of trade retaliation.
As for currency collapse, the most prominent candidate has to be the euro.
In an ideal world, Europe would deal with its excessive debt burdens through a restructuring of Greek, Irish, and Portuguese liabilities, as well as municipal and bank debt in Spain.
At the same time, these countries would regain export competiveness through massive wage reductions.
For now, however, European policymakers seem to prefer to keep escalating the size of bridge loans to the periphery, not wanting to acknowledge that private markets will ultimately require a more durable and sustainable solution.
No risk factor is more dangerous for a currency than policymakers’ refusal to face fiscal realities; until European officials do, the euro remains vulnerable.
The dollar, on the other hand, looks like a safer bet in 2011.
For one thing, its purchasing power is already scraping along at a fairly low level globally – indeed, near an all-time low, according to the Fed’s broad dollar exchange-rate index.
Thus, normal re-equilibration to “purchasing power parity” should give the dollar slight upward momentum.
Of course, some believe that the Fed’s mass purchases of US debt poses an even bigger risk than Europe’s sovereign debt crisis.
Perhaps, but most students of monetary policy view quantitative easing as the textbook policy for pulling an economy out of a zero-interest-rate “liquidity trap,” thereby preventing the onset of a sustained deflation, which would exacerbate debt burdens.
As for China’s renminbi, it is still supported by a highly political exchange-rate regime.
Eventually, China’s rapid growth will have to be reflected in a significant rise in its currency, its domestic price level, or in both.
But, in 2011, most of the equilibration will likely take place through inflation.
Finally, currency chaos is the safest bet of all, with sharp and unpredictable swings in floating exchange rates around the world.
During the mid-2000’s, there was a brief window when some argued that currencies had become more stable as a corollary of the “Great Moderation” in macroeconomic activity.
Nobody is saying that now.
The floating exchange-rate system works surprisingly well, but currency volatility and unpredictability look likely to remain an enduring constant in 2011 and beyond.
Today’s conventional wisdom is that the rise of India and China will be the single biggest factor driving global jobs and wages over the twenty-first century.
High-wage workers in rich countries can expect to see their competitive advantage steadily eroded by competition from capable and fiercely hard-working competitors in Asia, Latin America, and maybe even some day Africa.
This is a good story, full of human drama and power politics.
But I wonder whether, even within the next few decades, another factor will influence our work lives even more: the exponential rise of applications of artificial intelligence.
My portal to the world of artificial intelligence is a narrow one: the more than 500-year-old game of chess.
You may not care a whit about chess, long regarded as the ultimate intellectual sport.
But the stunning developments coming out of the chess world during the past decade should still command your attention.
Chess has long been the centerpiece of research in artificial intelligence.
While in principle, chess is solvable, the game’s computational complexity is almost incomprehensible.
It is only a slight exaggeration to say there are more possible moves in a chess game than atoms in a universe.
For most of the twentieth century, programmers were patently unsuccessful in designing chess computers that could compete with the best humans.
A human chess master’s ability to intuit, visualize, and prioritize easily prevailed over the brute force approach of computers.
The computers gradually improved, but they still seemed far inferior to the top humans.
Or so we thought.
Then, in 1997, in what will surely long be remembered as a historical milestone for modern man, IBM’s “Deep Blue” computer stunned the world by defeating the world champion Garry Kasparov.
Proud Kasparov, who was perhaps more stunned than anyone, was sure that the IBM team must have cheated.
He sarcastically told reporters that he sensed the “the hand of God” guiding his silicon opponent.
But the IBM team had not cheated.
Rather, through a combination of ingenious software and massive parallel computing power, they had produced a silicon-based entity capable of such finesse and subtlety, that international chess grandmasters worldwide (including me) were simply amazed.
Since 1997, the computers have only gotten better, to the point where computer programmers no longer find beating humans a great challenge.
Only a game, you say?
Perhaps, but let me tell you this: when I played professional chess 30 years ago (I once represented the United States in the World Chess Championship cycle), I felt I could tell a lot about someone’s personality by seeing a sampling of their games, even those of an amateur.
Until a short while ago, I could certainly distinguish a computer from a human opponent.
Now everything changed like lightning.
The machines can now even be set to imitate famous human players – including their flaws – so well that only an expert eye (and sometimes only another computer!) can tell the difference.
More than half a century ago, the godfather of artificial intelligence, Alan Turing, argued that the brain’s function could all be reduced to mathematics and that, someday, a computer would rival human intelligence.
He claimed that the ultimate proof of artificial intelligence would be met if a human interrogator were unable to figure out that he was conversing with a computer.
The “Turing test” is the holy grail of artificial intelligence research.
Well, for me, a chess game is a conversation of sorts.
From my perspective, today’s off-the-shelf computer programs come awfully close to meeting Turing’s test.
Over the course of a small number of games on the Internet, I could not easily tell the difference.
True, today’s computers have not evolved to the level of the deranged chess-playing HAL in the filmmaker Stanley Kubrick’s masterpiece “2001: A Space Odyssey,” much less Arnold Schwarzenegger-like droids from the Terminator movies.
But the level that computers have reached already is scary enough.
What’s next?
I certainly don’t feel safe as an economics professor!
I have no doubt that sometime later this century, one will be able to buy pocket professors – perhaps with holographic images – as easily as one can buy a pocket Kasparov chess computer today.
So let’s go back to India and China.
Globalization proceeded at a rapid pace through much of the last century, and at a particularly accelerated rate during its last two decades.
Yet the vast body of evidence suggests that technological changes were a much bigger driver in global wage patterns than trade.
That is, technology, not trade, was the big story of the twentieth-century economy (of course, the two interact, with trade helping to diffuse and stimulate technology, but this is a matter of semantics.)
Are we so sure that it will be different in this century?
Or will artificial intelligence replace the mantra of outsourcing and manufacturing migration?
Chess players already know the answer.
NEW DELHI – US President Barack Obama’s 10-day Asian tour and the consecutive summit meetings of the East Asian Summit (EAS), the G-20, and the Asia-Pacific Economic Cooperation (APEC) have helped shine a spotlight on Asia’s challenges at a time when tensions between an increasingly ambitious China and its neighbors permeate the region’s geopolitical landscape.
Significantly, Obama restricted his tour to Asia’s leading democracies – India, Indonesia, Japan, and South Korea – which surround China and are central to managing its rise.
Yet he spent all of last year assiduously courting the government in Beijing in the hope that he could make China a global partner on issues ranging from climate change to trade and financial regulation.
The catchphrase coined by US Deputy Secretary of State James Steinberg in relation to China, “strategic reassurance,” actually signaled America’s intent to be more accommodating toward China’s ambitions.
Now, with his China strategy falling apart, Obama is seeking to do exactly what his predecessor attempted – to line up partners as an insurance policy in case China’s rising power slides into arrogance.
Other players on the grand chessboard of Asian geopolitics also are seeking to formulate new equations, as they concurrently pursue strategies of hedging, balancing, and bandwagoning.
A fast-rising Asia has, moreover, become the fulcrum of global geopolitical change.
Asian policies and challenges now help shape the international economy and security environment.
But major power shifts within Asia are challenging the continent’s own peace and stability.
With the specter of strategic disequilibrium looming large in Asia, investments to help build geopolitical stability have become imperative.
China’s lengthening shadow has prompted a number of Asian countries to start building security cooperation on a bilateral basis, thereby laying the groundwork for a potential web of interlocking strategic partnerships.
Such cooperation reflects a quiet desire to influence China’s behavior positively, so that it does not cross well-defined red lines or go against the self-touted gospel of its “peaceful rise.”
But building genuine partnerships is a slow process, because it demands major accommodation and adjustment on both sides.
The US, for example, has worked hard in recent years to co-opt India in a “soft alliance” shorn of treaty obligations.
Yet, despite a rapidly warming bilateral rapport and Obama’s recent statement calling India the “cornerstone of America's engagement in Asia,” conflicting expectations and interests often surface.
The US is now courting Vietnam as well, and the two countries are even negotiating a civilian nuclear deal.
The Cold War legacy, however, continues to weigh down thinking in Hanoi and Washington to some extent.
Within Vietnam’s ruling Communist Party, there are deep divisions over the country’s relations with the US.
Even as Vietnam moves closer to the US as a hedge against China’s muscular strategy, some Vietnamese leaders fear that the Americans remain committed to regime change.
After all, despite Burma’s strategic importance vis-à-vis China and Aung San Suu Kyi’s release from house detention, the US continues to enforce stringent sanctions against that country, with the aim of toppling its government.
In the process, Burma has become more dependent than ever on China.
The US-China relationship itself is likely to remain uneasy, but overt competition or confrontation suits neither side.
For the US, China’s rising power actually helps validate American forward military deployments in the Asian theater.
The China factor also helps the US to retain existing allies and attract new ones, thereby enlarging its strategic footprint in Asia.
While the US is thus likely to remain a key factor in influencing Asia’s strategic landscape, the role of the major Asian powers will be no less important.
If China, India, and Japan constitute a scalene strategic triangle in Asia, with China representing the longest side, side A, the sum of side B (India) and side C (Japan) will always be greater than A. Not surprisingly, the fastest-growing relationship in Asia today is probably between Japan and India.
If this triangle turned into a quadrangle with the addition of Russia, China would be boxed in from virtually all sides.
Japan plus Russia plus India, with the US lending a helpful hand, would not only extinguish any prospect of a Sino-centric Asia, but would create the ultimate strategic nightmare for China.
As recent developments show, however, a Russian-Japanese rapprochement remains far off.
Against this geopolitical background, Asia’s power dynamics are likely to remain fluid, with new or shifting alliances and strengthened military capabilities continuing to challenge the prevailing order.
That befits the year of the tiger in Chinese astrology – a year in which China roared by ratcheting up tensions with neighbors from Japan to India by escalating territorial feuds.
In fact, 2010 will be remembered as the year that Chinese leaders undercut their country’s own interests by kindling fears of an expansionist China, thereby facilitating America’s return to center stage in Asia.
CAMBRIDGE – Last year, the leaders of all five permanent members of the United Nations Security Council visited India, accompanied by delegations of business leaders.
The Indian economy has been growing at more than 8% annually, making it increasingly attractive for trade and investment.
When US President Barack Obama visited in November, he supported permanent membership of the UN Security Council for India.
So did British Prime Minister David Cameron, French President Nicolas Sarkozy, and Russian President Dmitri Medvedev.
But the last to visit, Chinese Prime Minister Wen Jiabao, said nothing at all about it.
Official pronouncements stress friendly relations between India and China, and some trade analysts argue that the two giant, rapidly growing markets will become an economic “Chindia.”
When Premier Wen visited several years ago, he signed a comprehensive five-year strategic cooperation pact.
As Indian Prime Minister Manmohan Singh put it at the time, “India and China can together reshape the world order.”
Such statements reflect a considerable change from the hostility that bedeviled Indian-Chinese relations following the two countries’ 1962 war over a disputed border in the Himalayas.
Nevertheless, strategic anxiety lurks below the surface, particularly in India.
China’s GDP is three times that of India’s, its growth rate is higher, and its defense budget has been increasing.
The border dispute remains unsettled, and both countries vie for influence in neighboring states such as Myanmar.
And, in recent years, China has worked behind the scenes to prevent permanent Security Council membership from conveying great-power status on India.
But talk of India as a future great power is unavoidable, and some Indians predict a tri-polar world, anchored by the US, China, and India, by mid-century.
India’s population of 1.2 billion is four times that of the US, and likely to surpass China’s by 2025.
Vijay Joshi of St John’s College, Oxford, argues that, “if we extrapolate present trends, India will have the world’s third largest national income (after the US and China) within 25 years.”
For decades, India suffered from what some called the “Hindu rate of economic growth” of a little over 1% per year.
After independence in 1947, India followed an inward-looking policy that focused on heavy industry.
But it turned out that the rate of economic growth owed less to Hindu culture than to imported British Fabian (and other) socialist economic planning.
After market-oriented reforms in the early 1990’s, growth rates soared, with projections of double-digit growth in the future.
Martin Wolf of the Financial Times calls India a “premature superpower” – a country with low living standards but a huge economy.
He thinks that the Indian economy will be bigger than Britain’s in a decade and bigger than Japan’s in two.
India has an emerging middle class of several hundred million, and English is an official language, spoken by 50-100 million people.
Building on that base, Indian information industries are able to play a major global role.
India has significant hard-power resources as well, with an estimated 60-70 nuclear weapons, intermediate-range missiles, a space program, 1.3 million military personnel, and annual military expenditure of nearly $30 billion, or 2% of the world total.
In terms of soft power, India has an established democracy, and a vibrant popular culture with transnational influence.
India has an influential diaspora, and its motion picture industry, “Bollywood,” is the largest in the world in terms of the number of films produced yearly, out-competing Hollywood in parts of Asia and the Middle East.
At the same time, India remains very much an underdeveloped country, with hundreds of millions of illiterate, destitute citizens.
Around one-third of Indians live in conditions of acute poverty, and India accounts for roughly one-third of the world’s poor.
India’s GDP of $3.3 trillion compares to China’s $5 trillion, and is 20% that of the United States.
As a result, India’s per capita income of $2,900 (in purchasing-power-parity terms) is one-half of China’s and one-fifteenth that of the US.
Even more striking, while 91% of the Chinese population is literate and 43% is urban, the numbers for India are only 61% and 29%, respectively.
Each year, India produces about twice as many engineering and computing graduates as America, but The Economist reports that “only 4.2% are fit to work in a software product firm, and just 17.8% are employable by an IT services company, even with six months training.”
A symptom of this is India’s poor performance in international comparisons of universities: the 2009 Asian University Rankings, prepared by the higher education consultancy QS, shows the top Indian institution to be the Indian Institute of Technology in Bombay, at number 30.
Ten universities in China and Hong Kong are ranked higher.
High-tech exports are only 5% of India’s total exports, compared to 30% for China.
India is thus unlikely to develop the power resources to become an equal to China in the next decade or two.
And, while the two countries signed agreements in 1993 and 1996 that promised a peaceful settlement of the border dispute that led them to war in l962, it is worth noting that, just prior to India’s nuclear tests in March l998, India’s defense minister described China as India’s “potential enemy number one.”
More recently, in 2009, the border issue flared again.
Indian officials are generally discrete in public about relations with China, but in private their concerns remain intense.
Rather than becoming an ally, India is more likely to become one of the Asian countries that will tend to balance China’s strategic rise.
NEW YORK – Before I became the UN’s Secretary-General, I was an Asian diplomat.
While I was foreign minister of the Republic of Korea, my Government and I strongly advocated détente with the North.
When some in the world called for sanctions and punitive action, South Korea pushed for dialogue.
That requires listening as well as speaking.
It means sticking to principles, but also attempting to understand the other side, however irrational or intransigent it may sometimes appear.
This remains my style at the United Nations.
I believe in the power of diplomacy and engagement.
I prioritize dialogue over debate or declaration.
Above all, I seek results.
We are doing that now in Myanmar.
My Special Adviser, Ibrahim Gambari, has been back in Yangon.
His brief is to be the honest broker, the facilitator of a dialogue between government and opposition leaders, particularly Aung San Suu Kyi.
The goal is for Myanmar’s Government to release all detained students and demonstrators, engage with the opposition, move toward a more democratic society, and rejoin the international community.
This brand of diplomacy is not quick or easy.
There is seldom applause, and often no outward evidence of movement.
It is a quiet, painstaking slog behind the scenes.
You have to work the phones, cajole world leaders to do this or that.
It is a symphony – often not a very harmonious one – of small steps that you hope will lead to something greater.
You expect nothing.
You can only keep trying, keep pushing.
Maybe it works, maybe not.
Then you try some more, in a different way, aiming all the while for some small progress that makes the next step possible.
We are at this point in Darfur.
I have spent hundreds of hours working behind closed doors with various parties to the conflict – Sudan’s Government, rebel leaders, neighbouring countries, and African Union partners.
Meanwhile, we are pushing ahead with one of the most complex peacekeeping operations in our history, feeding and protecting hundreds of thousands of displaced people, and sponsoring difficult peace negotiations in Libya.
But even as I push my brand of “Asian” diplomacy, it can sometimes feel a bit lonely to be an Asian at the international community’s diplomatic roundtable.
We Asians inhabit the world’s largest continent, with the world’s largest population and its fastest-growing economies.
We have a rich history and ancient cultures.
Yet our role in international affairs is far less than it could, or should be.
Asia’s contribution to the UN, though significant, could be greater.
Its humanitarian assistance, to put it politely, is less than generous.
We are the only continent where regional integration and common markets have not taken hold.
Latin Americans and North Americans dream of creating a free-trade zone.
Europeans speak of building a United States of Europe.
The African Union aspires to become a United States of Africa.
Why no United States of Asia?
There are many reasons why Asia is different: history, cultural diversity, unresolved territorial and political disputes, a lack of multilateral experience, and the predominance of one or two centers of power.
But the main reason is that we have not tried.
Asia does not do itself justice.
As an Asian Secretary-General, I hope to see this change.
I hope to see an Asia that is both better integrated and more internationally engaged.
I expect particularly great things of my fellow Koreans, a remarkable people who have come into their own.
I hope to see Korea assume more responsibility in the world, commensurate with its growing economic clout – especially in the area of development, one of the three pillars of the UN Charter.
Koreans need to step up, speak out, and do more, and that should start with more generous official development assistance.
Koreans have already shown their penchant for multi-lateral diplomacy and trouble shooting through the six-party talks.
Now, they, and Asians at large, need to bring both their skills and their success to bear on the most pressing global issues of the day.
This is not just my hope, it is also Asia’s obligation.
NEW DELHI – “Tzu-Ch’in asked Tzu-Kung a few questions; Tzu-Kung answered: …Our Master gets things (done) by being cordial, frank, courteous, temperate, deferential.
That is our…way.” But will Chinese Premier Wen Jiabao live up to that standard, as conveyed in the Analects of Confucius, on his current visit to India?
The world has a variety of “special relationships.”
The United States’ partnership with the United Kingdom is one forged in war – and a pillar of the West for more than a half-century.
The US-Soviet rivalry of the Cold War era was special in that relations between those two countries shaped the fate of the world until the USSR imploded.
The US and China are said to be forging a new special relationship.
But, in looking toward the future of Asia – and, indeed, the future of world diplomacy – it is the relationship between the world’s two most populous countries and largest emerging economies, India and China, which will increasingly set the global agenda.
Japan’s change of military doctrine for the first time since the start of the Cold War – a shift that implicitly makes China the greatest threat – suggests that the Chinese leadership needs to take a hard look at its regional grand strategy.
Wen’s priorities for his trip to India are clear: trade, security, and, far behind, the territorial disputes between the two countries.
Such an approach might make tactical diplomatic sense, as long as there is no background clatter.
But it lacks a sense of strategic urgency, which, given rising international tensions across Asia, amounts to a serious strategic blunder.
The sources of those tensions are clear: North Korea’s shelling of South Korea’s Yeonpyeong Island and its flaunting of a modern, previously unknown, nuclear plant; the US-led armada now cruising through the South China and Yellow Sea; and China’s claim that the South China Sea is an area of vital national interest akin to Tibet.
In its bilateral relations with India, China’s shift in focus from its claims on the Northeastern Indian state of Arunachal Pradesh to Jammu and Kashmir is enormously worrisome.
Indeed, around Gilgit in Kashmir, China’s People’s Liberation Army has greatly enhanced its troop presence.
Small wonder that, on the eve of Wen’s visit, China’s ambassador in New Delhi finds relations between the two countries to be “very fragile, easily damaged, and difficult to repair.”
But, despite all this diplomatic friction, Wen’s entourage for his visit is dominated by a large business delegation.
Currently, both countries’ economies are thrusting confidently forward; both are thirsty for more and bigger markets.
India is growing at an annual rate of around 9%; China at around 10%.
So the opportunities for trade between the two are certainly enormous.
But, for both countries, economic growth is not hurdle-free.
India’s economy is continuing to grow, but faces rising inflation, fiscal and current-account deficits, a slowdown in agricultural growth, and infrastructure bottlenecks.
China’s problems arise mainly from widening income disparities, which are inciting hitherto unheard of levels of labor unrest – though this should not be viewed as a precursor to change of the sort that marked the rise of the Solidarity trade union and the end of communism in Poland.
But labor unrest and the desire to maintain 10% growth suggest that China should be taking the lead in ensuring peace on the Korean peninsula and preventing other political developments from derailing its economy.
After all, as the Chinese leadership knows, only continued strong growth will provide the government with the wriggle room it needs to begin to revalue the renminbi.
Revaluation of its currency is necessary in part because the undervalued renminbi has become yet another a source of friction in Asia, as many in the region now believe the Chinese are using their currency as a “policy weapon.”
To untangle the complex policy web surrounding the renminbi’s value will demand greater regional stability, not less.
Yet China’s international grand strategy does not appear to reflect this.
Instead, it remains focused on Northeast Asia, Tibet, Taiwan, and on its aspirations to move into the Indian Ocean, that great global highway of trade in the twenty-first century.
China’s leaders recognize that their country needs time, space, and peace for economic development.
Yet their pursuit of a dominant position on the strategic chokepoints in the Indian Ocean undermines these goals by raising tensions not only with India, but with Asia’s other powers and the US.
Their focus on inhibiting India seems particularly misguided, given that China’s core interests (Tibet, Taiwan, and the heartland of the Chinese mainland) are far beyond the reach of most of India’s military capabilities.
By contrast, India’s most important national security concerns – the unsettled border between the two countries, and Beijing’s ties with Pakistan, which often operates as a Chinese surrogate – are closely connected to China: Both factors are directly linked to China’s perceived threat to India’s Himalayan territory and its rapid development of strategic infrastructure in that region.
India’s concerns also focus on China’s ongoing supply of arms, including missiles and nuclear weapons technology, to Pakistan.
No amount of discussion over trade can obscure the true issues of vital concern between China and India.
China may take comfort in remaining focused on non-core issues, because such an approach suggests tactical cooperation with India.
That is a convenient international ploy, but it leaves the sources of bilateral discord unattended.
The idea of collaboration only in areas of interest to China while neglecting issues of substance to India is untenable, even in the short term.
Indeed, neglect of the core disputes is what has resulted in the relationship’s “extreme fragility.”
India cannot and will not abandon its territorial sovereignty, or its pursuit of secure land borders or a greater balance in trade.
These are challenges that cry out for clarity, not diplomatic fudges.
But surely two great and ancient civilizations can find their way to the type of “cordial, frank, courteous, temperate, deferential…” relations that would have pleased Confucius.
NEW HAVEN – Asia has an inflation problem.
The sooner it comes to grips with its problem, the better.
Unfortunately, the appropriate sense of urgency is missing.
Willingness to tackle inflation is impeded by Asia’s heavy reliance on exports and external demand.
Fearful of a relapse of end-market demand in a still-shaky post-crisis world, Asian policymakers have been reluctant to take an aggressive stand for price stability.
That needs to change – before it’s too late.
Excluding Japan, which remains mired in seemingly chronic deflation, Asian inflation rose to 5.3% in the 12 months ending in November 2010, up markedly from the 3.5% rate a year earlier.
Trends in the region’s two giants are especially worrisome, with inflation having pierced the 5% threshold in China and running in excess of 8% in India.
Price growth is worrisome in Indonesia (7%), Singapore (3.8%), Korea (3.5%), and Thailand (3%) as well.
Yes, sharply rising food prices are an important factor in boosting headline inflation in Asia.
But this is hardly a trivial development for low-income families in the developing world, where the share of foodstuffs in household budgets – 46% in India and 33% in China – is 2-3 times the ratio in developed countries.
At the same time, there has been a notable deterioration in underlying “core” inflation, which strips out food and energy prices.
Annual core inflation for Asia (excluding Japan) was running at a 4% rate in late 2010 – up about one percentage point from late 2009.
A key lesson from the Great Inflation of the 1970’s is that central banks can’t afford a false sense of comfort from any dichotomy between headline and core inflation.
Spillover effects are inevitable, and once a corrosive increase in inflationary expectations sets in, it becomes all the more painful to unwind.
The good news for Asia is that most of the region’s monetary authorities are, in fact, tightening policy.
The bad news is that they have been generally slow to act.
Financial markets appear to be expecting a good deal more Asian monetary tightening – at least that’s the message that can be drawn from sharply appreciating Asian currencies, which seem to be responding to prospective moves in policy interest rates.
Relative to the US dollar, an equal-weighted basket of 10 major Asian currencies (excluding Japan) has retraced the crisis-related distortions of 2008-2009 and has now returned to pre-crisis highs.
Export-led economies, of course, can’t take currency appreciation lightly – it undermines competitiveness and risks eroding the country’s share of the global market.
It also invites destabilizing hot-money capital inflows.
Given the tenuous post-crisis climate, with uncertain demand prospects in the major markets of the developed world, Asia finds itself in a classic policy trap, dragging its feet on monetary tightening while risking the negative impact of stronger currencies.
There is only one way out for Asia: a significant increase in real, or inflation-adjusted, policy interest rates.
Benchmark policy rates are currently below headline inflation in India, South Korea, Hong Kong, Singapore, Thailand, and Indonesia.
They are only slightly positive in China, Taiwan, and Malaysia.
The lessons of earlier battles against inflation are clear on one fundamental point: inflationary pressures cannot be contained by negative, or slightly positive, real short-term interest rates.
The only effective anti-inflation strategy entails aggressive monetary tightening that takes policy rates into the restrictive zone.
The longer this is deferred, the more wrenching the ultimate policy adjustment – and its consequences for growth and employment – will be.
With inflation – both headline and core – now on an accelerating path, Asian central banks can’t afford to slip further behind the curve.
Asia has far too many important items on its strategic agenda to remain caught in a policy trap.
This is especially true of China, whose government is focused on the pro-consumption rebalancing imperatives of its soon-to-be-enacted 12th Five-Year Plan.
So far, the Chinese leadership has adopted a measured approach to inflation.
Its efforts focus mainly on increasing banks’ mandatory reserve ratios while introducing administrative measures to deal with food price pressures, approving a couple of token interest-rate hikes, and managing a modest upward adjustment in the currency.
The mix of Chinese policy tightening, however, needs to shift much more decisively toward higher interest rates.
With the Chinese economy still growing at close to 10% per year, the government can afford to take more short-term policy risk in order to clear the way for its structural agenda.
Indeed, China’s dilemma is emblematic of one of developing Asia’s greatest challenges: the need to tilt the growth model away from external toward internal demand.
That can’t happen without increased wages and purchasing power for workers.
But, in an increasingly inflationary environment, any such efforts could fuel an outbreak of the dreaded wage-price spiral – the same lethal interplay that wreaked such havoc in the United States in the 1970’s.
Asia can avoid this problem and get on with the heavy lifting of pro-consumption rebalancing only by nipping inflation in the bud.
Much is made of Asia’s Teflon-like resilience in an otherwise tough post-crisis climate.
Led by China, the high-flying economies of developing Asia are increasingly viewed as the new and powerful engines of a multi-speed world.
While the jury is out on whether there has really been such a seamless transition of global economic leadership, Asia must face up to the critical challenges that may come with this new role.
Inflation, if not addressed now, could seriously compromise the region’s ability to meet those challenges.
Mention Asia, and most people think of the region’s fascinating, rising giants, China or India – or both.
Or people think about North Korea’s nuclear program, some terrorist incident, or the humanitarian consequences of the latest earthquake or tsunami.
But often overlooked – or at least underestimated – is Japan.
This is odd, given that Japan is still the world’s second largest economy, with a GDP of $5 trillion – more than China and India combined.
Despite Japan’s relatively modest rate of economic growth, its GDP per capita is roughly $38,000, more than ten times that of either China or India.
Moreover, there are important stirrings in Japan that suggest change on both the economic and security fronts.
The 1990’s may have been a lost decade, but Japan’s economy has begun to recover, now growing at more than 2% a year and boasting several firms that are truly global and hugely successful.
Changes in foreign and defense policy are more considerable.
Japan’s self-defense agency was upgraded in January to a full ministry.
Japan now spends more than $40 billion a year on defense and maintains one of the world’s most diverse and modern militaries.
Approximately 1,000 Japanese forces serve in and around Iraq.
Intellectuals, journalists, and politicians are now saying and writing things about Japan’s role in the world that were unthinkable a decade ago.
It is a question of when, not if, the Japanese amend Article IX of their constitution, which limits the role of Japan’s armed forces to self-defense.
Not everyone will welcome these changes.
Japan’s neighbors, who continue to harbor concerns stemming from World War II and Japan’s failure to deal adequately with its history, will worry about Japanese nationalism.
Nevertheless, a more active and more capable Japan, with a robust democracy and a thriving economy, is in its neighbors’ best interests.
The danger is not renewed Japanese militarism, but rather a Japan that is unable and unwilling to do its share to meet the regional and global challenges facing Asia.
Japan, for its part, needs to continue to open and reform its economy, improve its military, and make its forces available for the sort of low-intensity but manpower-intensive missions, ranging from genocide prevention to nation-building to peacekeeping, that are increasingly required in the greater Middle East and Africa.
Japanese leaders also need to act with sensitivity.
Prime Minister Shinzo Abe is off to an uneven start.
On one hand, he is wise not to have visited the Yasukuni shrine, which honors millions of Japan’s war dead, including 14 Class A war criminals.
On the other hand, Abe’s public statements denying Japan’s coercion of “comfort women” in China and Korea have been clumsy at best, insensitive at worst.
It is essential that Japan and China forge a modern relationship.
The increasing frequency of high-level visits – Prime Minister Abe went to China in October, and Chinese Premier Wen Jiabao was just in Japan – is a welcome development.
But more is needed.
Trade and investment flows can and should be expanded, which is likely only if political relations improve.
Both countries should commit themselves to a diplomatic resolution of competing claims to offshore resources.
Exchanges of every kind – military, educational, touristic – should be facilitated.
The world also needs to take into account Japan’s importance.
Japan should no longer be denied fair treatment because of events more than 60 years ago.
There is no reason Japan should not hold a permanent seat in the United Nations Security Council.
Japan should also be a full participant in Asian regional arrangements.
Asia is rich in dynamism, but relatively thin in influential political, economic, and security-related institutions, in contrast to Europe, which often lacks dynamism but is institution-heavy.
The Franco-German relationship, central to much twentieth-century conflict, now forms the core of modern Europe.
The goal should be the same for China and Japan.
The agenda is virtually limitless, including trade and investment, energy and climate change, and confidence-building in the security sphere.
A new regional institution could be based on an existing one (such as the six-party arrangement used to manage North Korea’s nuclear challenge) or start afresh.
Moreover, just as the United States continues to play a major role in Europe, so, too, should it act as a guarantor of Asia’s stability and a source of regional prosperity.
The US-Japan alliance is central to America’s position in Asia.
The goal is not to enlist Japan in any anti-Chinese coalition, but rather to increase the depth and breadth of US-Japanese cooperation.
Both countries have many reasons to pursue this goal, considering North Korea’s missile and nuclear programs, terrorism, and the numerous challenges to stability around the world.
Abe’s visit to Washington in late April is an opportunity to continue to modernize a relationship conceived in an earlier geopolitical era.
It is to be hoped that it will not be overshadowed by calls in Congress for Japan to apologize more formally than it already has for the comfort women.
Rather, the focus should be on the future and on welcoming the emergence of a Japan that is increasingly able and willing to act as a partner of the US in addressing regional and global challenges.
MEXICO CITY – These last few weeks have been unfortunate for Latin America.
In addition to the massive earthquakes that struck Haiti and Chile, the region has also been shaken by a hunger-strike death in Cuba and a growing crackdown on human rights and opposition in Venezuela.
Making matters worse, the region also witnessed a superficially silly but actually dangerous attempt by the ALBA countries – Cuba, Venezuela, Nicaragua, Ecuador, Bolivia, and Paraguay – to create, with the acquiescence of Mexico, Brazil, and Argentina, a regional organization excluding the United States and Canada.
The hope is that this new grouping will eventually supplant the Organization of American States.
The OAS will have to decide on March 24 whether to re-elect Chilean diplomat and politician José Miguel Insulza as its Secretary General.
It should, because Insulza is probably the only figure who can both learn from and correct the OAS’s mistakes of the past five years, and thus save it from oblivion.
The crackdown on freedom of the press, the rule of law, and electoral processes in Venezuela – as reported by Amnesty International, Human Rights Watch, and, most recently, in a damning, 300-page report by the Inter-American Human Rights Commission – has been steadily worsening.
The OAS can involve itself in domestic electoral, political, or human rights issues only if a majority of its members mandates it to do so, and countries like Mexico and Brazil are fearful of picking fights with Venezuela.
Nevertheless, Hugo Chávez is right to be nervous.
Legislative elections next September will be more challenging for Chávez than on previous occasions.
Electric power blackouts, a prolonged drought, inflation, and shortages are making life increasingly difficult for ordinary Venezuelans, and Chávez’s standing in opinion polls is dropping.
So is his international stature and popularity, especially after a Spanish judge accused him of conspiring to assassinate former Colombian president Andrés Pastrana in Madrid back in 2002.
Moreover, Chávez has suffered several regional setbacks recently, and all have domestic repercussions.
The death of Cuban hunger striker and dissident Orlando Zapata, while Latin leaders were pow-wowing in Cancún and creating their new organization, unleashed a wave of indignation against the Castro brothers in the US, Europe, and Latin America (though not among its governments, which all remained silent).
Chávez knows that his personal security depends on the permanent protection of the Cuban intelligence services.
Any change in government in Havana would leave him in a tight spot.
But, just as Chávez is worried about rumblings and dissidents in Cuba, the island’s leaders are concerned about the news from Caracas; they know they cannot survive without Chávez’s oil and subsidies.
That is why the Castro brothers dispatched the regime’s number three boss, Ramiro Valdez, who has been involved in Cuban security since 1959, to keep watch on matters in Venezuela.
Venezuela ’s circle of friends in the region is shrinking.
The new Honduran and Chilean presidents are not allies, unlike their predecessors.
The end of President Alvaro Uribe’s re-election bid in Colombia will complicate life for the Caracas caudillo , removing a pretext for his own perpetuation in power.
It may also give way to a president in Bogota who advocates a tougher line with Chávez than Uribe did.
Given all of this, as well as Chávez’s penchant for spectacular antics and the Cubans’ skill in taking the diplomatic offensive, the ALBA countries may be preparing some major Latin American mischief.
Honduras was suspended from the OAS last year, after the June coup that overthrew elected president Manuel Zelaya.
Subsequently, the interim government was able to resist pressure from abroad to restore him, held a previously scheduled election, and handed power over to a new, democratically-elected president, Porfirio Lobo, who has now been recognized by the US, the EU, and several, though not all, of the region’s governments.
Chávez, the Cubans and their allies, however, want no part of Lobo, and vetoed his attending the Cancún summit where the new Latin American organization was conceived.
That it might appear absurd to invite Cuba, which has not had an elected president since the 1950’s, and not Lobo, who was cleanly elected just months ago, did not seem to worry either Mexican host Felipe Calderón or his colleagues.
But the problem is that the OAS will be holding its annual assembly in June this year in Peru, and several countries -– Canada, Costa Rica, the US, Colombia, Panama, Peru itself, and probably Chile – will push to have Honduras re-admitted.
Venezuela, Nicaragua, Bolivia, Ecuador, Paraguay, and possibly Argentina will refuse.
The outcome may well be that these countries leave the OAS, and seek refuge in the new organization that they just established.
Mexico and Brazil will not follow, but would not oppose the move, either.
The fact that the Cancún meeting provided no funds, location, charter, or staff for the new organization will not matter: Latin American leaders are used to building castles in the air.
But even a purely rhetorical structure would probably sound the death knell of the OAS, and weaken its human rights instruments, which have proved increasingly valuable and effective.
The main challenge facing the OAS – if it survives the departure of the radical left – is to close the loopholes in its basic documents regarding the collective defense of democracy and human rights.
These loopholes consist in not defining precisely what an interruption to constitutional rule signifies – just the overthrow of an elected president, or also shutting down a legislature or TV station? – and giving the OAS teeth beyond suspension of members for violating its precepts.
This review should be the main task of the re-elected Secretary-General, together with keeping the OAS united and defending Latin American democracy against the ALBA onslaught.
In the past, intentionally hastening the death of any person was always a crime, no matter the circumstances.
But public attitudes have been changing.
Assisting a person who has explicitly asked to die is increasingly being seen as a justifiable action, especially in the context of a terminal illness.
This is a consistent finding of opinion polls in westernized countries.
Still, legislative bodies are cautious when considering possible changes to the law.
So far only the Netherlands, Belgium, and the state of Oregon in the US have put explicit legislation into practice.
But serious political discussions on similar legal changes are taking place in many other countries, including the UK, South Africa and Australia.
As adamant opposition to the legal regulation of assisted dying weakens, so the issues of practical applicability become more important.
Of course there is the question of who qualifies for an assisted death.
Should it be only the terminally ill?
Should, for instance, the early stages of Alzheimer’s disease qualify?
Or even any serious and incurable illness or disability?
And what about people whose reason for wanting to die is not related to their medical condition at all?
There is also another central question that has not yet been granted the attention it merits: who should actually take responsibility for the assistance?
In public discussions there is often a presumption that it is the task of the medical profession.
There are sometimes specific references to the Dutch practice that allows doctors to end their patients’ lives if they explicitly ask for it, as long as certain preconditions of due practice are met.
Assistance in dying provided by a non-physician remains illegal.
In such a medicalized framework it is morally and legally almost irrelevant who finally administers the lethal drug: if physicians are closely involved, there is no reason why they should not administer the lethal drug themselves.
Although Belgium recently followed the Dutch way of regulating voluntary active euthanasia in a strictly medicalized framework, it is precisely this sort of regulation that is increasingly challenged.
Doctors have pointed out that, whilst recognizing that an increasing majority of the population wants such a service to be available, to hasten death intentionally is still inherently incompatible with the basic objectives of medicine.
In this respect, the Death with Dignity Act in Oregon is an interesting law.
Of course, any regulation in this field requires at least some involvement by a doctor but the Oregon Act recognizes the fundamental dilemma faced by doctors confronted with a patient’s request to die and strives to keep that involvement to a minimum.
Oregon physicians may write a prescription for a lethal substance on the explicit request of a terminally ill patient, provided they can confirm the fatal prognosis, the patient’s decision-making capacity, and have informed the patient about any feasible alternative such as hospice care or pain-control options.
Physicians are not required to be present at the suicide, and they are not allowed to administer the lethal drug.
In Oregon, the patient decides independently of the physician where and when he or she wants to die, or even at all.
Compassion in Dying, a right-to-die society and non-medical NGO, participates in a consultative way in most of these cases.
Interestingly, research on the rationales of people who have legally hastened their death under the Oregon Death with Dignity Act reveals that the fear of pain and other distressing symptoms was not a major concern in most cases.
Instead, issues of personal independence, retaining control and not becoming a burden to family, friends, or caregivers turned out to be the main reasons.
Recent developments in the Netherlands have also shown that euthanasia is discussed more in the context of autonomy, control, and rational choice rather than of uncontrollable medical symptoms.
The decision in such cases is based mostly on personal and social considerations rather than medical ones.
Given that this framework extends far beyond any medical expertise, it is not surprising that no medical association anywhere in the world has so far embraced the Dutch regulation.
Whilst the Dutch Medical Association does not oppose the profession’s role in the practice of euthanasia, current evidence suggests a continuing unwillingness on the part of Dutch doctors to report cases of assistance in dying to the authorities, and a return to practices that are closer to a medical context, such as terminal sedation.
So there is great tension everywhere between how the public, and how doctors regard a possible contract in the field of assisted dying.
What is happening at the moment could be described as a power struggle over who should be responsible for a service that more and more people wish to be available but where no amount of professional expertise can fully safeguard the right decision.
At the same time, any wrong decision has far-reaching and irreversible consequences.
It has been said that assisted dying is pivotal to the discussion about what constitutes a good death; it is also a focal point in the relationship between the medical profession and society as a whole.
This year's Nobel Prize in Economic Sciences went to George Akerlof of the University of California at Berkeley, Michael Spence of Stanford University, and myself for our work on ``asymmetry of information.''
What is that work about and why did we undertake it?
For two hundred years, economists used simple economic models that assumed that information was perfect - i.e. that all participants have equal and transparent knowledge of the relevant factors.
They knew that information wasn't perfect, but hoped that a world with moderate imperfections of information would be akin to a world with perfect information.
We showed that this notion was ill-founded: even small imperfections of information could have profound effects on how the economy behaved.
The Nobel committee cited our work on ``asymmetries of information,'' an aspect of imperfections of information caused by the fact that different people in a market know different things.
For example: the seller of a car may know more about his car than the buyer; the buyer of insurance may know more about his prospects of having an accident (such as how he drives) than the seller; a worker may know more about his ability than a prospective employer; a borrower may know more about his prospects for repaying a loan than the lender.
But asymmetries of information are only one facet of information imperfections, and all of them - even when small - can have large consequences.
George Akerlof and I were classmates at MIT in the early 1960s.
We were taught the standard models of the day, but they made little sense to us.
These models rather simplistically said that demand equaled supply.
The joke was that you could teach a parrot to be an economist simply by repeating ``demand and supply.''
This produced rather curious results.
If the demand for labor equaled the supply, for example, there couldn't be any unemployment.
I grew up in an industrial town on the south shore of Lake Michigan - Gary, Indiana - and saw poverty, unemployment, and discrimination.
I entered economics because I wanted to understand and do something about these phenomena.
To be taught models that began by assuming that unemployment didn't exist seemed a peculiar place to begin.
Our models helped explain why markets didn't work in the way the standard theory said they should: why markets might not exist, why there might be unemployment, why there might be credit rationing.
They also explained why shocks to the economy might be amplified, and their effects persist, well after the original disturbance disappeared.
One of the most profound results of our work concerned Adam Smith's notion that competitive markets led, ``as if by an invisible hand,'' to efficient outcomes.
Our analysis suggested that the invisible hand not only couldn't be seen - it wasn't there, or was at best decrepit.
In work with Bruce Greenwald of Columbia University, we demonstrated that within a market economy there exist interventions in the market on the part of government that can make everyone better off - even when government is faced with the same information imperfections as the private sector.
Economists have long recognized that in the face of ``externalities'' to economic activity, such as air and water pollution, market solutions are often inefficient.
There can be too much production of some commodities - say, pollution generating steel - and too little production of others - like research that advances knowledge.
What we showed is that, as soon as one recognizes that information is imperfect - as it obviously is - then these externalities can be shown to be pervasive, and that market failures are similarly pervasive.
It is an irony of history that just as a host of researchers around the world were developing these ideas and enhancing our understanding of the limitations of markets, international economic institutions were pushing the Washington consensus - based on market fundamentalism - which ignored market failures.
Today, although these lessons on the limits of the markets have become commonplace in academia, they have still not been brought on board by many international economic institutions.
This contributes to frictions between these institutions and countries they advise: many bright, young economists working for developing country governments base their analyses on a deeper understanding of the market economy than that provided by the old ideology and the simplistic models guiding some of the international bureaucrats.
Some people have suggested that the theoretical work on information imperfections recognized by the Nobel committee is unrelated to the policy positions I took at the World Bank on East Asia, on Russia, or development.
Not true.
The stances I took on financial market liberalization were based on a theory of regulation that was based on asymmetries of information.
Concerns about bankruptcy - that the high interest rates pushed by the IMF in East Asia would force firms into distress, even adversely effect the exchange rates while destroying economies and making countries less attractive to investors - derived from a theory of corporate finance, itself derived from theories of asymmetric information.
At the most simplistic level: in a world with perfect information, bankruptcy would not exist - why, indeed, would anyone lend to someone who they knew would not repay them?
In the real world, failures in privatization were related in part to problems of corporate governance, problems related to asymmetries of information between managers and owners.
Ideas can sometimes be as powerful as interests.
When old ideologies and interests work together as they have in the past, some interests get served and others get left behind.
Asymmetries of information are related to asymmetries of economic (market) power.
There is a role for government, not only in correcting market failures, but in redressing these asymmetries of power.
Our work, which the Nobel Prize Committee has helped to bring to the attention of a wider public, provides a part of the intellectual foundation of the Third Way, which is increasingly recognized as the only means by which we can achieve economic progress with social justice.
GUANTÁNAMO BAY – I write this from the United States Detention Center at Guantánamo Bay, where I have been held without charge for almost seven years.
My detention here is the result of being in the wrong place at the wrong time.
More than two years ago, I was notified that I was cleared for release.
I would have been happy about this news if I did not come from Uzbekistan, a country with one of the worst human rights records in the world.
It is not safe for me to go home.
My journey to Guantánamo began in December 1998, after I finished my mandatory service in the Uzbek army.
Uzbekistan, a former Soviet Republic, is a poor country without many employment opportunities.
After several months of job hunting, I joined my brother in a business venture buying and selling apples, honey, and other goods in neighboring Tajikistan.
I lived in a community of Uzbeks, and met my wife, Fatima, another Uzbek, while living there.
We had a child, and my mother came from Uzbekistan to join us.
Unfortunately, there were some in Tajikistan who didn’t like having a bunch of Uzbeks living in their country.
So, one day, in November 1999, the Tajik authorities rounded up 200-300 Uzbeks and said they were taking us back to Uzbekistan.
Instead, they dumped us in Afghanistan.
There, we met a group of Afghan Uzbeks who helped us to settle in Mazar-i-Sharif.
I began working as a traveling salesman, selling goat’s milk, hens, roosters, and sheep.
In the fall of 2001, when fighting broke out between the Taliban and the Northern Alliance, I could not travel and was stranded at a roadside teahouse for several weeks.
One day, Northern Alliance soldiers came to the teahouse and offered to give me a ride to Mazar-i-Sharif.
Instead, they drove me to Bagram Air Base and handed me over to the Americans stationed there.
I found out later that the Americans were offering bounties of several thousand dollars for Taliban and “foreign fighters.”
At first, I was happy to be in American hands.
I held the US in high regard and figured that it would be only a matter of time before they realized that I was innocent and let me go.
But they didn’t.
They held me in Bagram, then Khandahar, and eventually Guantánamo Bay.
The Americans now realize that I ended up here by mistake and have told me that they want to let me go.
But where can I go?
Members of the Uzbek security service visited me here at Guantánamo and accused me of being a member of the Islamic Movement of Uzbekistan.
When I told them that I didn’t know anything about this group, they warned that once I was back in their custody, they would make me cooperate.
It is not hard to imagine what those ways are.
Torture, beating, and other mistreatment of Uzbek detainees are widespread.
Sometimes people who are taken into Uzbek custody are never heard from again.
I am not alone.
I am one of several dozen of the Guantánamo who cannot return to our native countries because we would likely be tortured and abused.
Our only hope of getting out of this prison is that another country decides to provide safe haven to men like us – men who did nothing wrong and never should have been detained here in the first place.
BEIJING – While parts of the world are dealing with the aftermath of the financial crisis or an emerging sovereign-debt crisis, China is coping with the risk of overheating and/or an asset bubble.
Many factors may be pushing China’s economy in this direction.
One of the most worrying is the same which fueled the current crisis in the eurozone: mushrooming public debt.
In the eurozone, the problem is member countries’ sovereign debt; in China, the problem is borrowing linked to local governments.
In the eurozone, a bloated social-welfare system, particularly for the rapidly growing population of retirees, and the economic slowdown caused by the financial crisis are key components of the structural debt problem.
In China, local officials increased borrowing in order to ensure that their regions’ economic growth rates remain at double-digit levels.
There are, no surprise, commonalities between China and the eurozone.
Obviously, debt accumulates wherever people want to spend more than they have saved.
But a more specific similarity is that highly indebted eurozone countries and Chinese provinces and counties have been spending too much of a common currency.
Because these funds are not issued or controlled by any member country or local government, eurozone members and Chinese local governments cannot relieve their debt problems through devaluation.
So, in both cases, when a debt is defaulted upon or loans become non-performing, the negative consequences are felt by the entire financial and monetary “zone” – the entire EU and all of China.
To avoid such an internal “sovereign debt crisis,” China’s Budget Law, adopted in 1994, forbade local governments from borrowing autonomously, either by issuing bonds to the public or by getting credits from banks.
In theory, this means that local governments cannot finance their deficits by increasing their debt levels, because they can borrow only from the central government or other central authorities.
But the Budget Law did not end the problem.
While local governments have been unable to borrow, locally controlled state-investment companies can.
So it is no surprise that a huge volume of bank loans has passed through the local branches of state-owned banks to finance local public-investment projects.
These borrowings caused a surge in non-performing bank loans in the early and mid-1990’s, when total non-performing loans hit 40% of GDP.
This caused a credit crunch and prolonged deflation in the late 1990’s, as the central government tried to clean up the mess.
Due to privatization of state-owned enterprises and improved financial regulation, including bank supervision and risk control, since 2000 both central and local budgets have basically been in good order.
The ratio of total public debt to GDP was less than 22% in 2007-2008, before the global financial crisis.
There was still some borrowing by local governments, of course, but on a limited scale (totaling 3-4% of GDP), owing to institutionalized surveillance of lending.
Then came the financial crisis, with the central government adopting fiscal stimulus and relaxing monetary policy.
Local governments were encouraged to increase their spending on public infrastructure projects in order to maintain growth.
As a result, the volume of bank credits financing local investments increased six-fold in 2009 alone.
Indeed, total borrowing by local government now amounts to roughly $900 billion, up from $150 billion year on year and the equivalent of almost 20% of GDP.
This level of borrowing poses a new type of financial risk for China.
But how big and dangerous is that risk?
I believe that it remains manageable.
Some local borrowing can be justified by the central budgetary allocation to local projects.
Moreover, some local spending took place in regions that will continue to enjoy high growth in tax revenues for the foreseeable future, thus ensuring that the debts will be serviced.
Perhaps only one-third of the total volume of loans is problematic; the rest may or will continue to perform.
The most important change that may keep the problem manageable is that China’s monetary authorities have been putting the brake on the growth of these debts since late last year.
In general, local borrowing windows are closed, and inspections are underway to gain an accurate picture of the situation.
With economic growth continuing, the potential risk posed by this debt will diminish.
Chinese officials are drawing lessons from this heavy debt burden, as they fear the prospect of local governments creating an internal “Greek crisis” for the rest of China.
The authorities recognize the need for strict fiscal discipline and financial regulation.
The leverage of any public entity must be monitored, supervised, and restricted.
Of course, Chinese local governments have never had total financial or fiscal autonomy.
Indeed, ever since the Qin Dynasty united the country and established a centralized regime some 2,000 years ago, accountability for debt has been treated as a central government problem.
Those who advocate fiscal decentralization and deregulation in China should think about establishing real local fiscal accountability first.
China’s current legal framework contributed to fiscal balance and financial stability in the past, and it continues to play a positive role.
Otherwise, China might already have experienced its own localized “sovereign debt” crisis and, perhaps, hyper-inflation.
But when local governments are barred from debt finance, they look for other means.
For example, they try to squeeze as much as possible out of land sales, thereby pushing up housing prices and helping to inflate asset bubbles.
Given the negative consequences of this approach, it might be wise for the central government to consider establishing, for the short-run, quotas or ceilings for total local government borrowing.
But, in the long run, China’s fiscal and financial stability will be ensured only by systematic institutional reform of central-local government relationships.
If the world is to have a decent economic recovery, an upturn will depend on America getting off its back and continuing to fulfill its role as global importer of last resort.
No other country is capable of picking up the slack if America's economy remains soft.
There is some optimism about Japan getting on its feet again, but over the past, vastly disappointing, decade, too many pseudo-recoveries have been glimpsed in Japan to justify such hopes.
Europe also seems likely to disappoint.
Projections of European growth continue to decline, yet the outlook for government policy is for reduced spending and increased taxes as the fiscal stability and growth pact bites.
Moreover, the European Central Bank appears helpless because it is bound by the self-imposed fetters of its inflation target.
Nor are emerging markets yet large enough to play a meaningful role in the balance of total global demand.
So America remains the world economy's last best hope.
But this is worrisome for two reasons.
First, America cannot run enormous (and growing!) current-account deficits forever: at some point the desire of foreign investors to hold ever-increasing shares of their wealth in America must wane and then reverse.
When that happens, the dollar will fall and the stimulus provided to the world by America's demand for imports will come to an end.
Second, there are no signs that the US government either understands or has the will to stimulate the American economy sufficiently to produce rapid economic growth.
Consider US monetary policy.
America's Federal Reserve has pushed the short-term safe interest rates it controls down to remarkably low levels: 1.25% per year.
Short-term interest rates cannot be pushed much lower.
More importantly, would the limited amount that interest rates can yet be cut do much to boost demand?
Not likely.
Long-term interest rates could be pushed significantly lower if the Federal Reserve were to undertake the unprecedented step of mammoth purchases of long-term government bonds.
But would the Fed take that unprecedented step without a severe domestic crisis?
A situation in which the US muddles through with growth that is positive but slower than the growth rate of potential output--today's conditions--is unlikely to prompt drastic action from the Fed.
However, US growth that is positive but slow is of little help to the rest of the world.
Now consider fiscal policy.
The baroque structure of US government has always been hostile to the effective exercise of fiscal policy.
Attempts to use fiscal policy to stabilize the economy usually show up too late to help, no matter the situation.
Fortunately, such efforts have usually been too small in magnitude to do significant economic destruction.
Until now.
Whatever tax-law changes the US Congress approves this summer are unlikely to have big effects on the flow of purchasing power to households until April, 2004.
Similarly, whatever spending increases the US Congress approves this fall will not have significant effects on government spending until the summer and fall of 2004.
But this time, slow stimulus is amplified by failures in the design of the Bush economic program.
Even the conservative-minded " Economist" observes that the Bush Administration's proposals are not a short-term economic stimulus: they simply do "not provide the short, sharp boost for which many political leaders, including Mr Bush himself, have been calling."
If and when the proposed tax cuts are fully phased in, they will not provide the $1,000 a year boost to the income of 90 million households that the Bush Administration implies they will.
Instead, they will likely provide something like an additional $250 a year to the incomes of typical households--and much larger windfalls for households with annual incomes exceeding $200,000.
But these are the people least likely to take their tax cuts and spend them to boost aggregate demand.
Looking further out, US fiscal policy's long-run problems will become increasingly visible and urgent: there is not even a hint of a plan for reconciling the long-term costs of the social insurance state with American taxpayers' limited patience with high taxes.
For most of the 1990s, the world economy did remarkably well, despite large-scale financial crises, the spread of AIDS in stagnating Africa, and the problems of transition economies.
This was due to sound economic policy in the US (starting with the Bush-Mitchell-Foley tax increase of 1990), as well as some extraordinarily good luck in America.
There are no signs that wise economic policy in the US will continue in the first decade of the new century.
If global prosperity is to return, America's economic luck will have to be even better than it was in the 1990s.
The rest of the world economy would do well to play it safe and start making its own luck.
As French cities have burned, other countries have been very severe in judging France.
Embassies have issued warnings to tourists and their citizens living in France; television news programs have shown hours of footage of burning cars. Other countries’ governments, it seems, have been trying to distance themselves from the problem, fearing a contagion that they know is likely to spread.
Mayors across Europe, however, have responded more moderately, feeling and showing solidarity with the plight of their French colleagues.
They know that their cities are also vulnerable to urban violence, in so far as they have pockets of social inequality, including marginalized and excluded young people.
The specificity of the French situation is that the revolt is targeted against the state, and more precisely against the police forces.
Unlike recent riots in the United Kingdom, which were inter-ethnic, the confrontations in France put their participants face to face with the police.
Indeed, there is no specific religious or ethnic character to these riots, in so far as youth from various ethnic backgrounds have taken part.
Minority youth are, to be sure, over-represented among those involved.
This is easily explained by their geographic segregation, higher levels of unemployment, higher school dropout rates, and disproportionately frequent interactions with the criminal justice system.
But, in view of the diversity of the young people convicted so far, it would be a mistake to say that these riots are the result of Muslim radicalization.
There is absolutely no indication so far that organized networks or religious groups are manipulating these youth.
Of course, this is not to say that Muslim radicals will not exploit the disarray if a satisfying resolution is not found rapidly.
The rioting may not be organized - no clear leaders or political demands have emerged.
Yet these violent acts can be viewed as a political conflict in the sense that young people are directly challenging the state by attacking its representatives.
The violence seems to be proportional to these disenfranchised young people’s sense of perceived injustice and the lack of opportunities for them to express themselves.
In this sense, France is paying the price for the lack of continuity, coherence, and appropriate funding given to social development policies over the past 30 years.
Although these policies have undoubtedly helped residents of disadvantaged neighborhoods, they have not been sufficiently ambitious to dampen resentment.
One example of overly timid policies involves policing.
In the last few years, France has distinguished itself from other European nations by gradually abandoning community-based policing, which the government considers too “social” and prevention-oriented.
While European police forces place prevention at the top of their agendas, France has chosen to treat it as a marginal goal.
As a result, tensions between the police, who are increasingly perceived as “outsiders,” and residents have grown to all-time highs.
In the absence of a community-based approach, interactions with law-enforcement authorities are now limited to tense, conflict-ridden situations, reinforcing the confrontational atmosphere between rebellious youth and the police.
At the same time, the fact that police agents must intervene in places with which they are not familiar severely impedes their effectiveness.
In the current violence, the police have unfortunately been placed in the position of sole representative of the state.
But all public actors, not just the police, must respond to urban problems.
First and foremost, mayors should be mobilized as mediators, because they are on the front line in implementing urban policy.
When these policies fail, citizens hold mayors responsible.
But mayors are also the most knowledgeable about communication links within their communities, and are thus the most capable of organizing effective partnerships to address and resolve local issues.
The events in France also point to the need, at the European level, to reinforce policies against discrimination and that promote social equality.
Although these policies must be implemented at a local level, they should be catalyzed and supported by European institutions.
Efforts in this area already exist, but it has become increasingly urgent that these efforts be strengthened.
Equality and social cohesion form the backbone of liberty, justice, and security for European cities.
This is why Europe’s mayors call upon European institutions to focus on social cohesion with the same commitment that has been invested until now in asylum and border controls.
Last Thursday, judges at Indonesia's Central Jakarta Court sentenced me to one year in prison.
As the editor-in-chief of Tempo Weekly Newsmagazine , I am guilty, according to the court, of defaming a business tycoon named Tomy Winata by implying his possible involvement in a fire at Jakarta's South-East Asia textile market, and of fomenting riots by disseminating lies.
Does my case, and others like it, portend the end of yet another short-lived experiment with democracy in Indonesia?
The "riot" that I allegedly fomented occurred in March last year, when almost two hundred thugs claiming to be Winata's followers attacked Tempo's office, threatened to burn down the building, harassed staff, and injured one reporter.
Trying to help resolve the situation peacefully, I was persuaded to negotiate at the Central Jakarta Police Station, but found to my horror that the mob leaders controlled the station.
I was punched and kicked as the police looked the other way.
Fortunately, many journalists came to our rescue with tape recorders and cameras rolling.
Their broadcasts caused a public outcry, which forced our parliament to organize a public hearing.
The National and Jakarta police chiefs were called and, under massive public pressure, the leaders of the mob were criminally charged.
But Winata himself eluded police investigation, merely by claiming publicly that his followers acted without his prior knowledge and consent.
He then filed criminal charges of his own, against Ahmad Taufik, who wrote the article, Teuku Iskandar Ali, who edited it, and me.
The yearlong court proceedings were marked by a series of suspicious developments, all favoring Winata.
First, the case built by the police and state prosecutor contained documents that were so blatantly falsified that the police indicted two officers.
But the court rejected our request that proceedings be delayed until the legality of the state's case could be clarified.
The case against the officers involved appears to be going nowhere.
On the contrary, one of them has been promoted to command the newly formed (and US-funded) Jakarta Anti-Terror Unit.
The other has reportedly been sent to the police staff school for advanced training.
Then, in the sixth month of the case, the Head Judge in the three-judge panel was suddenly promoted to become the head of a city court an hour from Jakarta.
One of my lawyers noted that in his 35 years experience at the court, he had never seen a Head Judge replaced in an ongoing case.
In fact, despite her promotion, the judge continued to preside over another case in the same building.
A judge who had previously ruled against Tempo in Winata's civil suit filled her vacancy.
Finally, when Winata testified, he perjured himself by denying that Tempo had interviewed him.
A recording of the telephone interview was played in court; sworn testimony was heard from the reporter who conducted the interview and from two editors who witnessed it; the official record from the telephone company was submitted as evidence of the call; and an expert witness concluded that the voice on the recording belonged to Tomy Winata.
But the judges denied Tempo's request that Winata be arrested and tried for perjury, telling us to report it to the police, which we did.
The judges then denied our request for a postponement of the court decision until Mr. Winata's perjury case was resolved.
Given such flawed proceedings, my conviction and prison sentence come as no surprise.
But I remain hopeful that we will prevail in the end, when higher courts hear Tempo's appeal.
Indonesia's courts are cleaner at the top, and the Head of the Supreme Court is a staunch advocate of democracy and press freedom. Tempo's case could become a landmark victory for our democracy, like the US Supreme Court's famous decision in The New York Times v. Sullivan .
By raising the bar for defamation charges, that decision ensures that American journalists can hold public officials accountable.
No country knows better than Indonesia that free speech and a free press are proven indicators of democratic development, and that criminalizing journalists is an early symptom of authoritarianism.
Indonesia was a liberal democracy in the 1950's, before President Sukarno, supported by the military, began a crackdown on the press in 1956.
With critical voices silenced, consolidating unchecked power became easier and, in July 1959, Sukarno decreed the beginning of "Guided Democracy."
For the first few years after Sukarno's fall in 1966, all the benefits of genuine democracy, including freedom of the press, were restored (except for the communists).
But President Suharto's regime began another press crackdown in the early 1970's, ultimately banning various media and jailing many journalists.
With the press under control, other political rights were quickly curtailed and Indonesian democracy failed again.
Since Suharto's fall in 1998, Indonesia has become the third largest democratic country in the world and the largest democratic Muslim community in history.
Two parliamentary elections and two direct presidential elections - including the latest presidential run-off - have been free, fair, and peaceful, proving that Islam and democracy can coexist.
Democracy's enemies, however, never rest.
Radical Islamic groups have engaged in indiscriminate bombings, while groups with strong authoritarian tendencies have made inroads into President Megawati's inner circle.
But Mrs Megawati has just been defeated in her bid for reelection.
Will newly elected President Susilo continue to prosecute journalists?
Will my conviction, and the trials and convictions of other journalists, mark the beginning of the end of Indonesia's hard-won third democracy?
The answer lies in the support that Indonesian pro-democracy activists can generate domestically and internationally.
To lose Indonesia - a potential beacon of hope to all pro-democracy activists in the world Muslim community - would be a terrible defeat.
People are fascinated by wealth.
They enjoy watching the wealthy, savoring the thought of their fine homes, luxurious vacations, fancy cars, and gourmet dining.
But if you infer from this that people spend a lot of time planning the lifetime accumulation of their own wealth, you would be wrong.
Most people do not seem to think very hard about how much to save from their income, or about how big the differences in their wealth could be in their later years if they just adjusted their saving rate today.
Most people just pay off their mortgage, make the mandatory contributions to their state or private pension (if they have one), and keep some money for short-run contingencies.
That’s about it.
The economist Frank Ramsey, in a famous article published in 1928, said that people have a “weakness of the imagination” about how their actions today affect their own future.
He said that if people thought about it correctly, they might well conclude that they should save half their income.
That way, the accumulated wealth might make them very happy in their later years.
But, mostly, they don’t even think about that possibility.
Richard Thaler, a contemporary economist, spoke in 1980 of an “endowment effect.”
Even though people may admire other things, they act as if they are mostly happy enough with whatever they already have, and lack the will to consider real change.
One of the biggest challenges governments face is humans’ apathy about future saving.
Thoughtful leaders recognize that the problem is there and tangible, not to be ignored.
Yet it is hard to fit solutions into either a traditional liberal or traditional conservative political philosophy.
Since 1955, Singapore has taken a direct approach: a compulsory national saving plan, which generates very high saving rates.
The contribution rate for the Central Provident Fund is now 34.5% for people with higher incomes.
The United States has no compulsory saving plan, and it has an abysmally low – in fact, negative – personal saving rate.
But the government is loath to consider a mandatory saving plan.
Instead, it is taking steps to overcome the individual inertia that inhibits saving.
The US Pension Protection Act of 2006 encourages employers to enroll employees automatically in a personal saving plan for old age.
This differs fundamentally from Singapore’s scheme, since employers are not required to do so, and, while enrolled employees’ paychecks are deducted without their consent, they can drop out of the plan at their own request.
New Zealand’s recent “KiwiSaver” plan and the United Kingdom’s Pensions Act of 2007 are similarly based on automatic enrollment for employees with free opt-out provisions.
Nevertheless, according to Brigitte Madrian of Harvard University, automatic enrollment in savings plans is critically important, even if the employee is completely free to drop out.
If employers tell their new employees that a pension saving plan is available, and even promise to match employees’ contributions, a significant fraction of employees still will not participate.
But if employers actually enroll their employees automatically in the plan, telling them that they can drop out at any time simply by notifying the employer, a large majority of employees will just accept the plan.
Moreover, it appears that whatever contribution rate the employer chooses tends to be accepted passively by the employee, as does whatever investment allocation (between stocks and bonds, for example) is established.
The research of Madrian and her colleagues suggests that the new pension plans will improve saving in the countries that adopt them.
Maybe these countries could do even better by adopting a compulsory saving plan, but they are not about to do so.
So, although they won’t succeed in raising saving on the scale that Singapore has, they can make real progress.
The best reason not to make savings plans compulsory is that different people face very different circumstances that only they know about.
Some people love their work, and never want to retire; for them, saving is less important.
Some people want to spend a lot now on education, or psychotherapy, or whatever else is important to them now, and so want to postpone saving until later.
The fundamental problem is that while some people postpone saving for sensible reasons, and will resume saving later, many others fail to save for no good reason, and are unlikely to make up for it later.
A government saving plan that is based on automatic, though not compulsory, enrollment has the ability to deal with this problem, if only imperfectly.
Automatic enrollment creates a saving plan that is sensible for the typical person.
People who are not paying attention and are just not active will simply remain in the plan, while those who want badly enough to opt out can do so by writing a letter.
These saving plans show that there are methods other than outright compulsion to overcome human inertia.
One hopes that, in the future, such plans will be adopted on a large enough scale that we can devise a variety of new programs that serve both inertial and active individuals well.
While the unremitting violence in Iraq grabs the world’s headlines, Afghanistan still struggles for peace.
The country’s parliament is packed with warlords, the drug trade is thriving, and violence is on the rise.
This week, world leaders have an opportunity to steer developments onto a new and more hopeful path when they meet in London to forge a new compact with Afghanistan.
The compact builds on the 2001 Bonn Agreement, which laid the framework for a democratic Afghanistan but left much to be done to overcome that war-torn country’s tragic legacy.
The need for renewed attention to Afghanistan could hardly be greater.
Decades of neglect coupled with foreign intervention left the country in ruins, with reverberations across the world.
It is now in everyone’s interest to help Afghanistan rebuild.
The drug trade exemplifies the far-reaching impact of domestic instability.
Last year, the value of drugs produced in Afghanistan – the world’s largest supplier of opiates – is estimated to have reached up to 25% of GDP.
Security, too, remains a serious concern.
In 2005, more than 125 Coalition troops were killed, while suicide bombing emerged as a new and increasingly common tactic of the insurgency.
Corruption is rampant, with government officials accused of cronyism and drug trafficking.
Several members of the newly elected parliament are known warlords with bloody records.
With international aid poorly coordinated and the United States reducing its troop strength, many Afghans believe that the outside world is abandoning them.
But the massive scale of the challenges facing Afghanistan should not overshadow the opportunities for positive change.
The Bonn process established the principle of democratic accountability, gave Afghanistan its first directly elected president, and provided a new constitution that – approved after genuine debate and compromise – created a legitimate central government.
It also paved the way for a parliament in which over a quarter of the members are women – this in a country where, just five years ago, women were not even allowed to leave the house without a male relative.
Moreover, most of the 20,000 village councils were elected through secret ballot.
In a nod to the importance of the councils to realizing change at the most local level, the World Bank and its partners have adopted a highly innovative program that channels rural development aid through the councils, which have been empowered to decide how the funds will be spent.
At the national level, the government recently approved a new development strategy that goes far to advance a vision for Afghanistan’s future stability and growth.
Public opinion reflects widespread support for the latest changes.
A recent poll shows that Afghans overwhelmingly favor their country’s new direction – backing the participation of women in public life and international intervention against al Qaeda, the Taliban, and the drug economy.
But Afghanistan’s potential for progress must be bolstered by concerted international action.
At the London Conference, world leaders should support the counter-narcotics strategy recently approved by the Afghan government, which would reduce economic dependence on opium production, punish traffickers and dealers, and provide sustainable economic alternatives for poppy farmers.
Afghanistan is grappling with the world’s biggest narcotics problem and donors must commit to a long-term drug control strategy.
The conference should follow up on a resolution by the European Parliament to consider whether Afghanistan should become one of the countries licensed to produce opium for medical purposes.
Furthermore, instead of pouring hundreds of millions of dollars into technical assistance and short-term capacity-building programs, the London conference should strive to help meet the Afghan government’s benchmark for equipping young people with the skills and education necessary to lead their nation to a future of peace and prosperity.
International support could help educate 40,000 Afghans each year in urgently needed fields, such as engineering, management, agriculture, law, and economics.
Judicial reform is another pressing issue.
Currently, the judiciary is incapable of trying a case of petty theft much less of ensuring human rights.
A Supreme Court dominated by conservative factions has selected judges and prosecutors, and Afghans have little legal redress in a system that allows local commanders, who hold sway over the judiciary, to act with impunity.
Without a viable legal system, foreign investment will remain elusive.
Even Afghan expatriates in the Gulf states, who have invested roughly $5 billion in regional and global trading networks, are reluctant to invest in their homeland.
Reform is nonetheless clearly possible.
Last month, the Afghan leadership finally adopted – albeit half-heartedly – a transitional justice plan that could remove from power the biggest war criminals who have consolidated their grip on the country over the past five years.
Implementation of this plan would not only give a boost to the rule of law, but also would enhance security and lead to better governance.
Failure to act would mean a betrayal of the Afghan people, who in 2001 welcomed the US army and NATO forces as liberators.
For their sake, and ours, we must not let them down.
The campaign for Ukraine’s parliamentary election of September 30th is scarcely underway and yet Prime Minister Viktor Yanukovich is already trying to steal it.
Yanukovich was the man who sought to falsify the result of the presidential election of 2004, inciting the Orange Revolution.
Back then, a peaceful and honest result was reached in the end because Ukraine’s President Leonid Kuchma refused to heed Yanukovich’s call to use violence to defend his rigged election.
This time it appears that Yanukovich is prepared to do anything to remain in power.
The dirty tricks began in the midnight hours of August 11th, when Ukraine’s Central Election Commission (which is packed with Yanukovich placemen) refused to certify the largest opposition party, the bloc of former Prime Minister Yuliya Tymoshenko, to participate in the election.
The technicality the commission cited would be absurdly funny if its potential results were not so incendiary: the CEC objected to the fact that the Tymoshenko bloc candidates listed only their home towns on the party list, not their precise street address.
But Tymoshenko’s party successfully submitted its list in the very same format at the March 2006 election, which demonstrates the glaringly partisan nature of the election commission’s ruling.
By seeking to cling to power by hook or by crook, Yanukovich is likely to bring on the deluge.
In Ukraine that means not only violent unrest, but economic decline and renewed repression.
At the end of the day it could lead to the sort of huge street protests that marked the Orange Revolution, and their attempted violent suppression.
Recent history is replete with alarming examples of dictators and would be dictators who refuse to recognize when their time has run out.
But for the past twenty years their blatant political chicanery has been met with a potent new force: the massed voices of ordinary people who refuse to be cowed.
From the “People Power” revolution that toppled Ferdinand Marcos in the Philippines in 1986 to Boris Yeltsin’s defiance of the attempted coup against Mikhail Gorbachev of August 1991, to the Rose, Orange, and Cedar Revolutions of recent years, dictators have been forced to admit defeat when enough people stand up to them.
Will it really be necessary for Ukrainians to repeat the Orange Revolution by again gathering in their millions to shame Yanukovich (a twice convicted violent felon before he entered politics) to change course?
There is a person who might compel Yanukovich to retreat to democratic norms and thus hold off such protests &#45;&#45; Russia’s President Vladimir Putin.
It is certainly in Russia’s national interest to prevent chaos in the country’s big next door neighbor.
But Putin’s idea of what constitutes Russia’s national interest makes that type of intervention unlikely.
Weak neighbors are states that the Kremlin can control, so why not expand Russian power by letting Ukraine slide into protest and anarchy if by doing so it brings that country back under Putin’s thumb?
Moreover, Putin himself is in the business of sterilizing Russia’s democratic processes by handpicking his successor and having his courts and electoral commissions block his opponents from political participation, often tarring them as traitors.
Someone with such contempt for the democratic rights of his own people is unlikely to champion them abroad.
As is usual with this ex-KGB man, Putin is being cunning about Ukraine, but he is deluding himself if he thinks that siding with Yanukovich will bring back effective Russian overlordship of Ukraine.
The days of empire are over, no matter how much wealth oil and gas is bringing to Russia.
Only if Ukraine maintains its independence will the imperial nostalgia of Russia’s elites be shattered.
So other pressure will need to be applied, primarily by the European Union and the United States.
In 2004, both the EU and US were tardy in speaking in defense of Ukraine’s democrats.
Only when the courage of millions of ordinary Ukrainians gathered in central Kyiv galvanized world opinion did the US and EU marshal the courage to stand up for an honest election result.
And the one state that did stand with Ukraine from the start back then, Poland, has now antagonized much of EU opinion, particularly in Germany, because of the paranoid behavior of its current leaders.
So Polish influence in Union councils is at rock bottom.
Luckily, the leaders of Europe’s three biggest states are different people than in 2004.
Angela Merkel, Nicolas Sarkozy, and Gordon Brown appear to have a clearer appreciation of the Union’s security problems to its east, and so may find the will to act decisively now, rather than dither as their predecessors did when Ukraine moved into crisis in 2004.
Unless Ukraine’s democratic opposition is allowed to take part in the election, a new crisis is certain.
Tymoshenko, who has survived three assassination attempts, is not the type of woman to surrender her campaign on a technicality.
While the Orange Revolution made ordinary Ukrainians more conscious of their rights than ever before, this alone cannot guarantee that they are certain to see those rights vindicated in the coming weeks.
However, it will make the job of repressing them much harder.
And isn’t that what the battle for democracy is all about?
Some years ago the historian Fritz Stern wrote a book about Germany entitled The Politics of Cultural Despair.
He used the example of three (now forgotten) bestselling authors of the late nineteenth and early twentieth centuries to show the deep aversion of many Germans to the modern world, notably to market economics and democratic politics.
For Stern, this was part of the cultural soil in which National Socialism flourished.
Much has changed since the Nazi era.
The murderous triumph and bloody defeat of the politics of cultural despair was followed by an economic miracle that made Germany one of the world’s most prosperous countries, with nearly six decades of increasingly stable democracy.
Yet there are still traces within Germany of an attitude that finds modern economics distasteful and the opening of all frontiers to a globalized world frightening. “Pure capitalism” and “globalization” evoke horrific images.
Swarms of capitalist “locusts” threaten to descend on defenseless, hardworking people, to quote the unfortunate metaphor used in a recent speech by Franz Müntefering, the chairman of the governing Social Democrats.
Of course, revulsion for liberal economies and global markets is not confined to Germany.
A similar sentiment formed one of the motives for the French and perhaps even the Dutch to reject the European Union’s Constitutional Treaty, which some regarded as too “Anglo-Saxon” in its economic liberalism.
For many, the alternative to capitalism and globalization is an idyllic image of a “European social model,” which no one has yet defined.
Indeed, it would be difficult to do so.
Social policies in Europe – like everything else – vary widely, and popular attitudes cover a spectrum, from tired protectionism and longing for subsidies in some of “old Europe” to the free-market enthusiasm of more recent EU members in the West (Ireland and Portugal) and the East (Poland and Slovakia).
In fact, Europe’s much-vaunted social model is more a dream than a reality, the dream of a cozy world in which a benevolent state looks after us.
This world has ceased to be viable in large part for reasons of demography, as ever more claimants for assistance make costs unaffordable.
Some people – and even a few politicians – are drawing the right conclusions from this.
They know that ultimately we all must rely on our own initiative and effort, and they make use of the opportunities of open markets.
But others in Europe treat such attitudes like a cartoon whose caption could be in French or German: “Self-reliance is absolutely important, we depend on politics for it”.
Behind such differences lie deep political and cultural traditions concerning the role of the state in everyday life.
This is where the United States really is different from France and Germany, while Britain has a similar tradition of distrusting the state rather than relying on it.
In a different way, this is true of Italy as well.
Italy has long had a large Communist Party, and the left may be in power again; but there is no gut antagonism to the freedoms that capitalism encourages.
Poland is another country in which individual initiative flourishes – to the point that the apocryphal “Polish plumber” came to epitomize the threats posed by globalization in France.
Needless to say, there are no such hang-ups in many of the high-growth economies of Asia.
True, in India the inertia of an indigenous version of Fabian socialism had to be overcome; but this has happened.
In fact, new models to square the circle of economic growth, social cohesion, and political liberty may be emerging in some of the countries that have grasped the mantle of globalization.
The entrenched anti-capitalist, anti-globalization mood elsewhere is a source of concern.
After all, Fritz Stern wrote his book to warn of the dangers posed by a romantic abhorrence of modernity.
High, often long-term unemployment and cuts in social benefits nurture, but do not cause such attitudes; their deep-seated cultural roots matter far more.
So do their consequences.
A sense of frustration that results from anti-capitalist, anti-globalization sentiment leads to a lethal combination of Arcadian dreams (“France to the French”) and the reality of ruthless, if seductive, leaders on the right (Jean-Marie Le Pen in France) and the left (Oskar Lafontaine and his new party in Germany).
Prosperity and liberty will be the victims, unless those who grasp the opportunities of the new world prevail.
London – The British comic genius Spike Milligan once observed that he would love to have the opportunity to discover that money wouldn’t make him happy.
Big lottery winners, it is claimed, end up miserable, though real-life research suggests that they are as happy as you and I would be with a check for a million dollars.
Money, however, can trigger all sorts of other emotions – like rage, for example.
That is pretty much how most people reacted to the stories about bankers’ bonuses, when the great crash of 2007-2008 wiped out banks, businesses, shareholders’ savings, growth, and jobs.
There was, as one banker charmingly conceded, a bit of asymmetry between what bankers were being paid and what their banks had lost.
The Nobel Laureate Amartya Sen notes in his latest magisterial book The Idea of Justice that most people understand that a process is fair when they can detect a connection between effort and reward.
The bankers failed this test dismally.
We gritted our teeth and for the sake of our national economies supported our governments as they bailed out the banks with public money.
It was a necessary, if infuriating, act of salvation to avoid economic disaster.
Having socialized banks’ losses after we had seen the privatization of their gains, our rage quotient has shot up once more at the news that the banks we saved are again filling the troughs into which all those snouts are enthusiastically dipped.
The sheer unseemliness of what is happening raises blood pressure as well as eyebrows.
How do they have the nerve?
We should not, however, allow this sentiment to turn into an all-purpose rant against personal wealth.
Sometimes its owners use it in hugely generous amounts for great public gain.
Consider the cases of two of the world’s biggest philanthropists, George Soros and Mo Ibrahim.
George Soros, the enormously successful investor, has used much of his own wealth to establish the Open Society Institute, which has helped to underpin the democratic revolution in Central and Eastern Europe and to press for human rights worldwide.
Mo Ibrahim is one of Africa’s most distinguished entrepreneurs.
He built a business empire on technology, software, and mobile telecommunications.
Ibrahim has established a foundation whose main purpose is to raise standards of governance in Africa.
The continent certainly needs to pay heed.
With a billion people living in more than 50 countries, Africa is wracked by poverty and, in too many places, torn apart by war.
The Oxford development economist Paul Collier reckons that 75% of the poorest people in the world live in countries that have only recently recovered from conflict or are still in conflict.
Most of them are in Africa.
These are countries where it sometimes seems easier to start an uprising than to start a business.
Guinea, with a nasty military junta in power, is on the brink of disaster.
In Sudan, the Darfur conflict is unresolved and divisions between the north and the south once again threaten peace, with a promised referendum on southern independence due by 2011.
Hundreds of thousands of displaced people huddle in camps in Somalia, where warlords rule.
The list, alas, goes on.
It is not as though Africa lacked resources or the ability to govern itself well.
Peaceful Botswana is a good example of what can be achieved.
While climate, geography, and the colonial past share some of the blame for today’s misery, most of the responsibility belongs to those African governments that have behaved so badly.
Ibrahim wants to stamp out corruption, to see the rule of law applied everywhere, to foster policy environments that encourage businesses to start up and thrive, and to strengthen the role of women.
He wants to reward those who support pluralist democracy and is a champion of civil society and a free press, and the Ibrahim Foundation is also deeply involved in the fight against global warming.
He also points out that less than 5% of total trade in Africa is undertaken between African countries.
There is a powerful argument for regional economic integration on the continent, abolishing trade barriers, sharing infrastructure like power generation, and allowing free movement of people, goods, money, and jobs.
Some countries in East Africa are now trying to do something about that for themselves.
Philanthropists like Mo Ibrahim and George Soros – or Bill Gates and Warren Buffett – can use their fortunes to make the world a better place.
We shouldn’t allow our exasperation with bankers to morph into an assault on the creation of wealth.
As Spike Mulligan was unable to discover for himself, money really can make people happier, producing a more just world with greater opportunity for the poor and disadvantaged.
Let’s hope that we move in that direction in 2010.
NEW YORK – It doesn’t take a genius to figure out that the United States’ financial system – indeed, global finance – is in a mess.
And now, with the US House of Representatives having rejected the Bush administration’s proposed $700 billion bailout plan, it is also obvious that there is no consensus on how to fix it.
The problems in the US economy and financial system have been apparent for years.
But that didn’t prevent America’s leaders from turning to the same people who helped create the mess, who didn’t see the problems until they brought us to the brink of another Great Depression, and who have been veering from one bail-out to another, to rescue us. 
As global markets plummet, some version of the rescue plan will almost certainly be put to another vote in Congress.  Unless the plan is markedly different from the current one, while it may help Wall Street,  what about the economy?
What about taxpayers, already beleaguered by unprecedented deficits, and with bills still to pay for decaying infrastructure and two wars?
In such circumstances, is there any bailout plan that can work?
To be sure, the rescue plan that was just defeated was far better than what the Bush administration originally proposed.
But its basic approach remained critically flawed.
First, it relied – once again – on trickle-down economics: somehow, throwing enough money at Wall Street would trickle down to Main Street, helping ordinary workers and homeowners.
Trickle-down economics almost never works, and it is no more likely to work this time. 
Moreover, the plan assumed that the fundamental problem was one of confidence.
That is no doubt part of the problem; but the underlying problem is that financial markets made some very bad loans.
There was a housing bubble, and loans were made on the basis of inflated prices. 
That bubble has burst.
House prices probably will fall further, so there will be more foreclosures, and no amount of talking up the market is going to change that.
The bad loans, in turn, have created massive holes in banks’ balance sheets, which have to be repaired.
Any government bailout that pays fair value for these assets will do nothing to repair that hole.
On the contrary, it would be like providing massive blood transfusions to a patient suffering from vast internal hemorrhaging.
Even if a bailout plan were implemented quickly – which appears increasingly unlikely – there would be some credit contraction.
The US economy has been sustained by a consumption boom fueled by excessive borrowing, and that will be curtailed.
States and localities are cutting back expenditures.
Household balance sheets are weaker.
An economic slowdown will exacerbate all our financial problems.
We could do more with less money.
The holes in financial institutions’ balance sheets should be filled in a transparent way.
The Scandinavian countries showed the way two decades ago.
Warren Buffet showed another way, in providing equity to Goldman Sachs.
By issuing preferred shares with warrants (options), one reduces the public’s downside risk and ensures that they participate in some of the upside potential. 
This approach is not only proven, but it also provides both the incentives and wherewithal needed for lending to resume.
It avoids the hopeless task of trying to value millions of complex mortgages and the even more complex financial products in which they are embedded, and it deals with the “lemons” problem – the government gets stuck with the worst or most overpriced assets.
Finally, it can be done far more quickly. 
At the same time, several steps can be taken to reduce foreclosures.
First, housing can be made more affordable for poor and middle-income Americans by converting the mortgage deduction into a cashable tax credit.
The government effectively pays 50% of the mortgage interest and real estate taxes for upper-income Americans, yet does nothing for the poor.
Second, bankruptcy reform is needed to allow homeowners to write down the value of their homes and stay in their houses.
Third, government could assume part of a mortgage, taking advantage of its lower borrowing costs.
By contrast, US Treasury Secretary Henry Paulson’s approach is another example of the kind of shell games that got America into its mess.
Investment banks and credit rating agencies believed in financial alchemy – the notion that significant value could be created by slicing and dicing securities.
The new view is that real value can be created by un-slicing and un-dicing – pulling these assets out of the financial system and turning them over to the government.
But turning them over to the government at market value doesn’t improve banks’ balance sheet; to do that requires overpaying for the assets, a transfer of wealth from ordinary taxpayers to the banks..
In the end, there is a high likelihood that if such a plan is ultimately adopted, American taxpayers will be left on the hook.
In environmental economics, there is a basic principle, called “the polluter pays principle.”
It is a matter of both equity and efficiency.
Wall Street has polluted the economy with toxic mortgages.
It should pay for the cleanup. 
There is a growing consensus among economists that any $750 billion bailout based on Paulson’s plan won’t by itself do the trick of resuscitating our economy.
If so, the huge increase in the national debt and the realization that even $700 billion is not enough to rescue the US economy will erode confidence further and aggravate its weakness.
But it is impossible for politicians to do nothing in such a crisis.
So we may have to pray that a agreement crafted with the toxic mix of special interests, misguided economics, and right-wing ideologies that produced the crisis can somehow produce a rescue plan that works – or whose failure doesn’t do too much damage. 
Getting things right – including a new regulatory system that reduces the likelihood that such a crisis will recur – is one of the many tasks to be left to the next administration.
OXFORD – George W. Bush is approaching the end of his presidency mired in low popularity ratings, which partly reflects his policies in the Middle East.
But Bush leaves behind a better legacy in Asia.
American relations with Japan and China remain strong, and he has greatly enhanced the United States’ ties with India, the world’s second most populous country.
In 2005, Secretary of State Condoleezza Rice prepared a visit to Delhi by Bush the following year in which he announced a major agreement on US-Indian civilian nuclear cooperation, as well as a variety of measures for commercial and defense cooperation.
The nuclear cooperation agreement was criticized in the US Congress for not being strict enough on non-proliferation issues, but it looked likely to pass.
In India, the Communist Party, a small (but important) member of Prime Minister Manmohan Singh’s ruling coalition, has blocked the agreement.
But, as one Indian friend explained to me, this is mainly symbolic politics for India’s Left.
Even if the nuclear agreement fails, the improvement in US-India relations is likely to continue.
Some attribute this to the fact that India and the US are the world’s two largest democracies.
But that was true for much of the Cold War, when they frequently talked past each other.
More importantly, with the end of the Cold War, the Soviet Union was no longer available as an Indian ally, and the US began to assess India and Pakistan in terms of separate interests, rather than as a pair linked in a South Asia balance of power.
As Evan Feigenbaum, the top State Department official for South Asia recently said, “the world of 2008 is not the world of 1948.
And so India really has the capacity, and, we think, the interest, to work with the United States and other partners on a variety of issues of global and regional scope.” This change began under the Clinton administration and is likely to continue regardless of who is elected president in 2008.
Personal contacts between Indians and Americans have increased greatly.
There are now more than 80,000 Indian students studying in the US, and many have stayed to establish successful companies.
The Indian diaspora in the US constitutes roughly three million people, many of whom actively participate in politics.
For example, Louisiana’s governor is of Indian origin, and has been mentioned as a possible running mate for John McCain.
In addition, India’s economy has begun to grow by 8% annually, making it more attractive for foreign investment.
Trade between India and American is increasing, and reached $26 billion (11% of India’s total trade) in 2006.
In addition to these practical reasons for the improvement in bilateral relations, the rise of China poses a strategic consideration.
As Bill Emmott, the former editor of The Economist argues in his new book The Rivals , “where Nixon had used China to balance the Soviet Union, Bush was using India to balance China.
Like Nixon’s move, with hindsight Bush’s approach to India made perfect sense.” And the concern is reciprocated on the Indian side.
As a senior foreign ministry official told Emmott in 2007, “the thing you have to understand is that both of us [India and China] think that the future belongs to us.
We can’t both be right.”
Official pronouncements stress friendly relations between India and China, and some trade analysts argue that, given their rapid growth, the two giant markets will become an economic “Chindia.”
When Chinese Premier Wen Jiabao visited India in 2005, he signed eleven agreements, including a comprehensive five-year strategic cooperation pact.
In addition, Wen announced that China would support India’s inclusion as a permanent member of an expanded United Nations Security Council, and oppose Japan’s inclusion, which the US supports.
As Singh put it during Wen’s visit, “India and China can together reshape the world order.” 
The two countries’ recent rapprochement marks a considerable change from the hostility that bedeviled their relations following their 1962 war over a disputed border in the Himalayas.
Nevertheless, strategic anxiety lurks below the surface, particularly in India.  China’s GDP is three times that of India, its growth rate is higher, and its defense budget increased by nearly 18% last year.
The border dispute remains unsettled, and both countries vie for influence in neighboring states such as Myanmar.
China’s rise has also created anxiety in Japan, again despite professions of good relations during Chinese President Hu Jintao’s recent visit to Tokyo.
Thus, Japan has increased its aid and trade with India.
Last year, the US suggested quadrilateral defense exercises including US, Japanese, Indian, and Australian naval units, but the newly elected Australian Prime Minister Kevin Rudd has pulled his country out of such arrangements.
Rudd wisely believes that the right response to China’s rise is to incorporate it into international institutional arrangements.
Or, as Robert Zoellick, currently the president of the World Bank, put it when he was a State Department official, the US should invite China to become a “responsible stakeholder” in the international system.
Improved relations between India and the US can structure the international situation in a manner that encourages such an evolution in Chinese policy, whereas trying to isolate China would be a mistake.
Handled properly, the simultaneous rise of China and India could be good for all countries.
BEIJING – China’s national savings rate has been very high in recent years, amounting to 52% of GDP in 2008 (the most recent year for which statistics are available), and is often blamed for today’s global imbalances.
Countries that save too much export too much, according to conventional wisdom, resulting in high trade surpluses and growing foreign-exchange reserves.
But this is not always true.
For instance, if I save $100, but at the same time I invest $100 in my factories’ fixed assets, I am “balanced domestically” and not running an export surplus with anyone.
Such an example captures China’s recent economic situation.
In late 2009 and in early 2010, China’s savings rate might well have remained at 50% of GDP had its trade surplus not narrowed significantly compared to previous years.
Indeed, China recorded a trade deficit in part of this period, as high investment in fixed assets (owing to government stimulus policies enacted in the wake of the global financial crisis) fueled domestic demand for goods in the same way that higher consumer spending would.
Only when a country invests less in fixed assets than the amount that it saves will the “surplus savings” show up in the trade balance.
The same logic can be applied to the US economy, but in the opposite way: even if the US wants to consume a lot and does not save, it may not run trade deficits if it does not invest much.
It runs a trade deficit only when it invests a lot while simultaneously not limiting consumption.
Savings are, of course, no bad thing.
If Americans and Europeans had saved more, they might not have created the global imbalances that fueled the financial crisis, or the worldwide sovereign-debt problems that have since emerged.
And savings are particularly good for developing countries.
One of the most daunting challenges for poor countries is the need to accumulate investment capital under conditions of low savings without incurring too much foreign debt.
Even for a developing economy with per capita income of $3,000, such as China, building wealth in the middle classes remains a central issue.
Spurring faster growth of small- and medium-size enterprises through relatively high investment in physical assets and R&amp;D programs, improved infrastructure, and more rapid urbanization, all of which require a lot of savings to invest, is vital.
In any meaningful international comparison, China’s per capita stock of physical capital is still 8-10 times lower than in advanced countries like the United States and Japan.
Without relatively high savings, a developing country like China may never catch up.
If a developing country has high savings (despite efforts to increase current consumption) as a result of structural factors, the best strategy is not to reduce savings through short-run “external shocks,” such as dramatic exchange-rate appreciation, which may kill export industries overnight.
Rather, savings should be channeled even more – and more efficiently – to domestic investment in order to avoid large external imbalances.
For example, China should use its current high savings to build up the country’s infrastructure and speed up urbanization, thereby laying a firmer foundation for future development.
Savings could remain high, even as current consumption grows slowly, while the trade balance would be held in check by higher demand for imported capital goods.
Moreover, investment in public infrastructure and urban facilities will not create industrial “over-capacity”; instead, it will provide long-term public consumption durables that households and companies will use for years to come.
If China continues on this path, its external surplus will decrease further, other conditions being equal.
Of course, a country must deal with a savings rate that is “too high” even if it is not necessarily the main cause of external imbalances.
That is certainly the challenge for China in the long run.
A savings rate of 50% of GDP is too high under any circumstances, and household consumption equivalent to 35% of GDP is too low.
But this can and should be addressed by domestic policies aimed at bringing about structural change, not by external policies like exchange-rate appreciation.
Without domestic structural change, currency appreciation would not only undermine exports, but might also decrease imports, owing to higher unemployment and lower income.
China must recognize that high savings will not provide stable growth over the long run.
High domestic investment may for the time being prevent “surplus savings” from creating too much upward pressure on the external balance, but, given trends in China’s terms of trade, growth without an increase in domestic consumption is unsustainable over the long run.
High investment may cause economic overheating and increase the price of capital goods in the medium term, eventually triggering inflation.
So bringing the savings rate down is necessary if domestic and external balances are to be achieved.
Meanwhile, China’s so-called “export-oriented growth policy” itself may not be wrong for a developing country, because international trade in general creates more jobs and brings more income.
But if exports continue to grow in the absence of consumption-led import growth, distortions occur and the trade surplus and foreign reserves increase.
China has adopted some policies to reduce its trade surplus, such as lowering import tariffs, withdrawing tax rebates for exported goods, and gradual exchange-rate appreciation.
But what China really needs is a greater effort to promote domestic consumption and lower the savings rate.
Good times – and these are good times for the global economy – are rarely the moment for concrete initiatives to deal with difficult problems.
It is against this backdrop that I find welcome this weekend’s announcement by a group of major economies acknowledging their shared responsibility for the orderly resolution of global imbalances while sustaining robust growth.
For the past year, China, the euro zone, Japan, Saudi Arabia, and the United States have been discussing these plans among themselves and with the IMF.
Behind the somewhat forbidding label of “multilateral consultation” are discussions that are the first of their kind, and that have proved to be a promising tool for dealing with an issue of global importance.
These five economies are relevant to global imbalances in different ways: either on account of their current account deficits or surpluses, or because they represent a very large share of world output.
They all agree that resolving these imbalances is in each of their interests.
But they also recognize that it is a multilateral challenge and a shared responsibility for them all.
Over the last year, partly reflecting past policies in these countries, the imbalances have shown signs of stabilizing and, indeed, even of improving slightly.
But these countries must signal that policies will continue to ensure a progressive and orderly reduction in imbalances together with sustained growth.
Otherwise, the global economy will remain at risk from renewed protectionist pressures and economic or political events that might trigger a disorderly resolution of the imbalances and undermine growth.
The five economies spelled out their policy plans in considerable detail to the semi-annual meeting of the IMF’s membership, which gave them a warm welcome.
This is the first time such plans have been presented together.
As Gordon Brown, the chairman of the Fund’s International Monetary and Financial Committee, noted, these plans are fully in line with the medium-term approach to solving imbalances that the Fund’s membership has consistently supported:
China has elevated the reduction of external imbalances to a major national objective in 2007.
It intends to boost domestic demand and is committed to moving gradually toward greater exchange rate flexibility.
Euro-zone countries reaffirmed their intention to press ahead with structural reforms across a broad front, in product, labor, and financial markets.
Japan plans to accelerate labor market reforms, strengthen competition, and advance fiscal consolidation to sustain domestic confidence.
Saudi Arabia is boosting its spending on social and infrastructure investments substantially, as well as expanding oil sector capacity.
And the US is taking steps to balance its budget, boost private savings, and enhance energy efficiency.
The US also intends to strengthen capital market competitiveness and ensure that it remains an attractive environment for foreign investment.
Just as global imbalances were not built up overnight, nor will they be solved quickly.
The aim of multilateral consultation was not to seek to solve imbalances in one fell swoop, but rather to solidify agreement on a medium-term approach that could reduce imbalances gradually over time.
The policies outlined by the participants will, when implemented, constitute a step in that direction.
Publication of their plans sends an additional signal of their commitment and provides a valuable roadmap with which to assess progress, and thus help build confidence that all countries are working to reduce imbalances.
The IMF, for its part, will monitor these plans regularly as part of our responsibility to provide policy analysis and advice.
The countries have made it clear that their future policy plans will continue to be consistent with the strategy called for by the IMF’s membership.
The five participants and the rest of our members, as well as we at the Fund, all agree that this has been a fruitful exercise.
An indicator of success is that a second multilateral consultation, aimed at fostering dialogue on how financial globalization and innovation influence growth and stability, is under consideration.
Like the first round of talks, this consultation would occur between a group of economies that have special relevance to the issue.
NEW YORK – The world can breathe easier with the reelection this month of United Nations Secretary-General Ban Ki-moon to a second term in office.
In a fractious world, global unity is especially vital.
During the past five years, Ban Ki-moon has embodied that unity, both in his unique personal diplomacy and in his role as head of this indispensable global organization.
Winning re-election to lead the UN is no straightforward matter.
As head of an organization of 192 member states, the Secretary-General inevitably feels the powerful crosscurrents of global divisions.
On almost any issue, the Secretary-General is likely to find himself between contending groups of countries.
Yet Ban has inspired global confidence in his leadership to the point of securing an uncontested and unanimous second mandate.
The consensus in favor of Ban’s re-election is all the more striking because it includes the so-called P-5, the five permanent members of the UN Security Council – the United States, the United Kingdom, China, France, and Russia.
These five powerful countries owe their UN pre-eminence to the post-World War II settlement, when they were allies in victory.
Under the UN Charter, all five must endorse the election of every Secretary-General.
Ban Ki-moon has maintained the strong backing of all five permanent members.
I have the honor to serve as the Secretary-General’s Special Adviser on the Millennium Development Goals.
In that capacity, I see the Secretary-General in action in all parts of the world.
It is a rewarding experience, one that gives me great hope for ultimate success in resolving global problems such as poverty, environmental threats, and violent conflict.
The world’s many problems make their way to the Secretary-General’s office day and night.
Whether the issues are war and peace; revolutions and coups; natural disasters; epidemics; disputed elections; or the grinding challenges of hunger, poverty, climate change, and mass migration, the crises inevitably demand the Secretary-General’s attention.
It is a workload that boggles the mind, and demands the round-the-clock commitment of the Secretary-General and his team.
During a recent trip with Ban to Egypt and Tunisia, I watched in awe as he deftly backed the democratic changes underway in those two countries while simultaneously dealing with many other upheavals in the region.
Ban generously and inspiringly offered his support to the brave youth leaders in both countries who are at the forefront of the political changes set in motion this year.
From his first days in office, Ban emphasized that many or most of the world’s greatest challenges come down to a simple yet stark reality: we are now a crowded, interconnected, global society, with seven billion people struggling to find a foothold on a highly vulnerable planet.
The challenges of feeding the world, keeping it safe from epidemic diseases such as malaria and AIDS, and combining economic progress with local and global environmental safety are the defining challenges of our time.
War and violence often have as underlying causes hunger, poverty, and environmental degradation, such as human-induced climate change.
We are, in short, in a new global era, which may be defined as the Age of Sustainable Development, in which our security, even our survival, will depend on the world forging a triple commitment: to end extreme poverty; to ensure human rights for all; and to protect the natural environment from human-induced crises of climate change, destruction of biodiversity, and depletion of fresh-water reserves and other vital resources.
Ban has tirelessly emphasized the need to put sustainable development at the center of our thinking.
The challenges of poverty, resource depletion, climate change, and human rights will dominate Ban’s second term, and the work of those who will follow him as Secretary-General.
In 2012, world governments will reunite in Rio de Janeiro, 20 years after the historic conference at which they signed the first comprehensive treaty to fight human-induced climate change.
Far too little has been accomplished since, and, behind the scenes, Ban is working relentlessly to clear the bottlenecks and avert climate disaster.
At the start of the third millennium, Ban’s predecessor, Kofi Annan, brought the world’s leaders together to adopt the Millennium Development Goals, which established ambitious targets to be achieved in the fight against poverty, hunger, and disease by 2015.
Ban has been a tireless champion of the MDGs, and has initiated several highly creative campaigns to enlarge worldwide engagement with them.
This past year, for example, Ban launched a bold new global initiative, “Every Mother, Every Child,” to improve health care for women and children.
He has championed the fight against HIV/AIDS, tuberculosis, and malaria, bringing many global leaders and public figures to the cause.
Under Ban’s leadership, remarkable progress is being made, though as he emphasizes, even faster progress is both possible and needed.
In 2015, the Secretary-General will help guide the world towards even bolder commitments in the fight to end extreme poverty and deprivation in the coming two decades.
There is a great personal satisfaction in Ban’s own story, one that gives hope for all.
When Ban travels to Africa’s impoverished regions, he mingles with villagers and recounts his own upbringing amid the poverty and deprivation of Korea in the 1950’s – and how, by committing itself to hard work, education, modern science, and shared values, South Korea became one of the world’s richest and most successful countries.
Ban’s rise from poverty to global leadership parallels his country’s trajectory.
It is a story of decency, commitment, and generosity that has won global confidence, and that can help to guide the world at a time of unprecedented risks and unique opportunities.
NEW YORK – Days after Sri Lanka’s government defeated its long-time foe, the Tamil Tigers, in May, United Nations Secretary-General Ban Ki-moon flew into the country’s capital, Colombo, for a 24-hour visit to urge its president to open up its refugee camps to international aid groups.
This was another urgent trip by Ban to a war-torn capital, as part of his regular duties as the UN’s chief representative, seeking to uphold peace and restore global comity.
But who really knew much about this latest foray into a troubled region by the UN chief?
Not many.
Ban, who has just marked the half-way point in his five-year term in office, has so far been unable to attract a large worldwide audience for his activities.  This is due, in part, to stylistic reasons, but also to the vagaries of UN diplomacy.
Still in his quiet way, Ban is spending more than a third of his time on the road, and has accomplished much over the past 30 months.
In Darfur, he managed to get African Union peacekeepers into Sudan’s killing zone in his first year in office through intensive behind-the-scenes diplomacy.
Though the political process has since stalled, he has pushed for more peacekeepers and helicopters.
In Kosovo, Ban was able to lower the temperature on the boiling issue of the province’s independence.
He persuaded the European Union and the United States to allow continued UN oversight in Kosovo while gradually permitting self-governance – all without triggering dangerous confrontations with the two states which oppose its breakaway, Serbia and its close ally, Russia.
In Myanmar, despite bitter resistance from the military regime, Ban pressured the authorities to let in humanitarian aid after Cyclone Nargis devastated the country last year.
His public and private entreaties, including dozens of phone calls and meetings, saved perhaps a half-million lives.
Today, he continues his call for the release of the democracy leader, Aung San Suu Kyi.
In Haiti, which still suffers from underdevelopment, political turmoil, and the effects of destructive hurricanes, Ban appointed former US President Bill Clinton as his Special Representative to help deal with the country’s plight.
This followed two visits he made to Haiti over the past 18 months and a donor’s conference he sponsored in April that sought to raise $300 million in aid and investment.
More recently, Ban took an active role in the Gaza crisis.
He has regularly defended the Palestinians’ rights to a state, but he also condemned Hamas’s rocket attacks on southern Israel.
During the fighting in Gaza, he publicly demanded a halt to the warfare and requested that Israel open Gaza’s borders to relief aid.
He also visited the UN compound in the center of Gaza to express the UN’s grave concern over its bombing.
Ban has taken a leadership position on the problem of global warming.
He tackled the issue at the Bali Conference of 2007, made it one of his central concerns at the UN, and will attempt to forge a new agreement among all global states at the UN Conference in Copenhagen in December 2009.
And he has moved forward in the health field.
He accelerated efforts to eliminate the world’s most dangerous ancient scourge, malaria, by naming a special adviser on the disease, and by forging innovative partnerships within the UN system that have brought together private industry, foundations, and non-governmental organizations.
His campaign has already helped to reduce the incidence of malaria.
The problem for Ban is his diffident manner, which stands in stark contrast with that of his predecessor, Kofi Annan, a larger than life secretary-general who dominated the scene through his flair, eloquence, and star power.
Ban, by contrast, is neither charismatic nor an inspirational speaker – indeed, his English is not as good as Annan’s.
In his own way, though, he is an engaging, polite man, hip to contemporary cultural icons, and even given to singing at public occasions with wry lyrics and verses.
Nonetheless Ban is sometimes criticized for not doing more, not listening enough, or deferring too much to the Big Five countries on the Security Council.
One of the main complaints is that communicating with him can be difficult.
Ban invariably nods his head in polite agreement without giving clear guidance.
Others say he has yet to prove he is a good manager and must push harder for internal management reforms at the UN.
Ban, in turn, has openly chastised member states for not giving him sufficient resources.
But, wherever the truth may lie, few critics take into account that he, like all former UN chief executives, has to deal with the reality that he possesses only moral power, not economic, military, or political power.
Still throughout his tenure, Ban has consistently displayed progressive instincts on issues, despite the fact that his candidacy was originally championed by an authoritarian Chinese government and a right-wing, UN-bashing American envoy to the organization, John Bolton.
In the end he should be measured by what he has accomplished rather than by personal foibles or flatness of style.
FRANKFURT – With the deepening of the global financial crisis, spreads between the government bonds of different European Monetary Union (EMU) countries for a while widened dramatically.
Relative to German bonds, the spreads in February of secondary-market yields of government bonds with maturities of close to ten years were 141 basis points for Italy, 257 for Greece, and 252 for Ireland, compared to just 32, 84, and 25 basis points, respectively, in 2000.
In EMU’s early years, long-term interest rates in euro-zone countries more or less converged to the low levels seen in countries like France, Germany, and the Netherlands before the euro’s introduction.
Italy and Greece enjoyed huge declines in the cost of servicing their public debt in comparison to pre-EMU days.
For many people, the introduction of the euro meant not only that currency risk – i.e., the risk of devaluation – had disappeared, but also that all euro-zone members now belonged to an economic area of monetary stability and, thanks to the discipline of the Stability and Growth Pact, of fiscal stability.
Moreover, before the crisis, differences in long-term interest rates among EMU members were around 25 basis points, despite unfavorable fiscal developments in some EMU countries.
But today, countries with rising budget deficits, like Ireland, along with countries with high levels of public debt, like Greece and Italy, are at risk to pay substantially higher rates on their government bonds.
Risk-averse investors may now demand higher risk premia for buying bonds from countries seen as weak debtors.
On the other hand long-term interest rates in countries with stronger fiscal positions – France, Germany, and Finland – have enjoyed low rates as a consequence of a “flight to quality.”
This rise in long-term interest rates has hit the countries with sharply deteriorating fiscal positions hardest.
It is even suggested that some countries might abandon EMU if this process continues – a threat that, if carried out, would amount to economic suicide.
It comes as no surprise, then, that the idea of a common European bond is becoming popular as a way to counter the risk of rising EMU interest-rate spreads.
The main idea is to reduce the risk premia paid by debtors with lower fiscal credibility.
But this can be achieved only by implicit or explicit guarantees from EMU countries with sound public finances. A “true” pan-European bond would have to entail a joint guarantee by all countries of the full bond issue, with the “strongest” guaranteeing the “weakest,” which supporters of a bond idea suggest constitutes true European solidarity.
A common bond would eliminate the interest-rate spread between bonds issued by different euro-zone countries, so the question that must be addressed is what effect its issuance would have on the level of the interest rate, and more importantly on future fiscal policy and the euro itself.
A common euro-zone bond certainly implies that countries like France and Germany would have to pay higher interest rates, ultimately resulting in higher tax burdens for their citizens.
Moreover, once the markets expect substantial amounts of the common bond to be issued, interest rates on the huge stock of existing – purely national – bonds of solid countries would be likely to increase substantially.
No one can possibly know in advance exactly how big this “bill” might be, though that question – important as that is – misses the crucial point: a common bond would be the first step down a slippery slope to bail-outs, and thus to the end of the euro area as a zone of stability.
To see why, recall that the immediate trigger for rising interest-rate spreads was financial markets’ growing concerns about the solidity of some euro-zone countries, owing to dramatic deterioration in their current and expected fiscal positions.
A common bond would be no cure for a lack of fiscal discipline; on the contrary, it would be no more than a placebo for a “weak” country, but it would also be harmful because it would foster the illusion that it is possible to get out of fiscal difficulty without undertaking fundamental reform.
Encouraging weak countries to prolong their reliance on budget deficits by holding out the hope of a 
 de facto
 bail-out would be very costly for EMU’s more solid countries, while undermining EMU’s hard-won credibility as an area of stability and fiscal soundness.
And this latter cost would have to be paid by all euro-zone countries.
A pan-European bond would also have serious political repercussions.
Any policy that forces countries that opted for fiscal solidity to pay for those with large deficits and high debt levels would strongly undermine public support for the euro zone. “Solidarity” in the true sense means that all euro-zone countries should comply with EMU’s fundamental rules by adhering to the Stability and Growth Pact and the “no bail-outs” principle.
Countries tempted to undermine these principles by failing to fulfill their solemn commitments only demonstrate their own lack of solidarity.
FRANKFURT – At the height of the financial crisis in 2008-2009, it seemed as if Western banks would pull up their foreign stakes and go home, leaving financial markets much more fragmented along national lines.
But, as a new report by Deutsche Bank Research shows, banks’ cross-border business – direct or via branches or subsidiaries – has now broadly stabilized.
During the crisis, the level of banking activity fell particularly strongly in capital-intensive areas such as traditional lending to the private sector.
The effect was especially pronounced in lending to non-financial companies, whereas lending to households – an area with traditionally lower internationalization – remained more robust.
In part, the decline was due to increased holdings of foreign public debt relative to private debt.
Prior to the crisis, banks had often been net sellers of foreign government bonds, but they significantly increased their purchases during 2008-2009.
With the onset of the European sovereign-debt crisis in 2010, banks’ appetite for public debt fell again.
In contrast to lending activities, banks’ commitment to foreign markets has remained virtually unaffected with respect to purely intermediary activities such as investment banking and asset management.
Interbank relationships, as well as investment-banking operations, are already highly international.
The deep cross-border links between financial institutions and the activity of globally active investment banks only took a brief hit from the crisis.
By contrast, the importance of foreign markets for asset managers remains very limited and has not changed significantly since 2007.
Despite the recent setback, banks’ presence in foreign markets today is much greater overall than it was a few years ago.
One reason is that revenue growth usually goes hand-in-hand with macroeconomic growth, which increasingly is found in emerging-market countries, rather than in many banks’ mature Western home markets.
Moreover, private and public-sector debt levels tend to be much lower in the emerging economies.
At the same time, geographically diversified institutions outperformed even during the recent global crisis, because they were less vulnerable to downturns in individual regions.
And, at least until a certain stage of growth, economies of scale and scope beckon, with expansion abroad often the only way to increase size, given already-saturated domestic markets.
Of course, integrated financial markets also benefit banks’ clients by enabling institutions to provide broader and higher-quality financial services at lower prices.
Furthermore, strong international financial partners are indispensable to multinational corporations, which often need global cash management or support for large-scale transactions.
Given these advantages, the pace of internationalization has been swift.
As recently as 2001, Europe’s top 20 banks still generated more than half of their revenues at home.
By 2010, this share had fallen by 10 percentage points, to 42% – a remarkable decline that was interrupted only briefly by the financial crisis.
Interestingly, most large European banks’ prime investment destination was other European markets, not other parts of the world, raising Europe’s contribution to total revenue to nearly 30%, from less than 20% a decade ago.
There may be two explanations for this: for one thing, Asia’s share in European banks’ revenues has probably risen.
But this may have been offset by a decline in the proportion of earnings coming from the US.
And, while this reflects changes in relative importance, European banks’ business volumes might have increased in absolute terms even in the US, though at a slower pace than elsewhere.
Overall, the outlook for post-crisis international banking has turned positive.
But regulation could change that.
In the current environment, with a renewed focus on regulating markets, institutions, and financial instruments, some international differences in scale, scope, and application of the new rules may be inevitable.
But, without a broadly consistent approach, the authorities risk creating a legal patchwork that would make cross-border banking less efficient, more expensive, and more difficult to conduct.
Apart from discouraging banks from investing abroad, outright restrictions on foreign banks’ market access cannot be ruled out, either.
The rapid growth in intra-European banking relations in the past decade was made possible to a large extent by the abolition of formal and informal barriers to foreign service providers.
Though this environment may not be fundamentally at risk, the current trend towards increasing capital requirements for international banks – reflected, for example, in calls for the establishment of independent subsidiaries with autonomous capital and liquidity pools – is clearly worrisome.
Nonetheless, given the relatively favorable outlook for cross-border banking, Western banks’ presence in emerging markets could strengthen further, while banks domiciled in these regions might start looking beyond national borders.
Traditional lending and deposit-taking still offers much growth potential – and may become more attractive relative to investment banking or asset management as a result of new regulation.
In that case, banking will become more like other industries that have benefited themselves and their customers by evolving into truly global networks.
CHICAGO – The biggest financial nightmare looming over the world economy is the insolvency of a large international bank.
Be it because of a sovereign default or because of large losses accumulated under complacent accounting rules, the insolvency of a large bank (particularly a European bank) is far from a remote possibility.
Even if it were a remote possibility, the 2008 financial crisis has taught us that rare events occur.
What makes this possibility the financial nightmare of choice, worse than the collapse of Lehman Brothers in 2008, is the fear that many sovereign states have already shot all their bullets and would thus be powerless to intervene.
Credit default swaps (CDS) of major southern European banks trade slightly lower than the CDS of their sovereign states, indicating that the market does not perceive the latter as able to support the former.
Unfortunately, almost two years after Lehman’s collapse, little has been done to address this risk.
The United States Congress is about to finalize a bill that will grant resolution authority over major US financial institutions to a newly formed systemic council.
The procedures to trigger this intervention, however, are complex and the funding is sufficiently opaque that the bill will not eliminate collateral damage from a large bank failure even for US institutions, let alone for international ones, whose unwinding would require coordination by several states, with varying degree of solvency.
To minimize the risk of an unruly collapse, it is necessary to approve an international resolution mechanism with authority over all major international financial institutions.
The goal would not be to rescue banks and their creditors, but to minimize the disruption that an uncontrolled default might cause.
This institution should be an international version of the US Chapter 11 Bankruptcy Code.
But, while the goal of Chapter 11 is to save the ongoing value of a firm, the goal of the international resolution mechanism should be to preserve the ongoing value of the counterparties of insolvent financial institutions.
The first problem to resolve in approving this mechanism is who should have this authority.
The obvious answer is the International Monetary Fund.
Created after WWII to finance temporary imbalances of the members of a fixed-exchange rate system, the IMF has been in search of a cause since the demise of the dollar exchange-rate system in 1971.
More importantly, through its numerous rescues of sovereign states, the IMF has acquired expertise in debt restructuring, while developing a reputation for toughness and impartiality, which would be very useful in these situations.
The IMF also has the unique advantage of being the only depositary of international reserves.
In the absence of an international fiscal authority, the IMF is the organization that comes closest to being one.
When a large financial institution is insolvent, the IMF should take it over, guaranteeing its short-term obligations, but wiping out the shareholders and repaying the long-term creditors only after all the other creditors (including the IMF itself) are repaid.
Some people would scream that this is tantamount to nationalization, but it is no more a nationalization that the US Chapter 11 bankruptcy process is.
Takeover by an international organization has three advantages over a domestic solution.
First, it makes certain that the cost (if the losses exceed the combined value of equity and long-term debt) is shared by the international community and not only by the country where the institution is located, making the intervention credible even when the sovereign state is not.
Second, by removing decision-making power from the national government that hosts an insolvent institution, this solution minimizes the potential distortions created by the lobbying power of the incumbent bankers.
Would you trust the Greek government to run a Greek bank in a non-corrupt way after a government takeover?
The IMF would be better.
Finally, thanks to IMF involvement, even less advanced countries would be able to take advantage of the best international expertise to address the problem.
If a major oil spill in Haiti were threatening the Gulf of Mexico, wouldn’t we want the best technology (and not just the technology available in Haiti) to try to contain it?
Why should it be any different in financial markets?
The last problem to be resolved is the trigger.
In the case of the US resolution authority, this has been a very controversial issue.
The fear was that powerful banks would exploit national government help, asking for intervention too soon.
Two safeguards can avoid this problem in the international context.
First, rigid rules that wipe out shareholders and penalize long-term creditors are a clear deterrent from bankers’ point of view.
Second, because IMF intervention would reduce the influence of powerful domestic insiders, early intervention would be less attractive to them.
The trigger should be the domestic government itself.
Refusing international help in such instances would mean electoral suicide for any government that faces a major bank collapse.
There are few areas in which government intervention is known to create value: reducing the devastating effects of a bank run is one.
Only a government that is sufficiently powerful, in terms of legal authority and solvency, can do so.
Unfortunately, in the international arena these two conditions are almost never met.
Empowering the IMF to take over failed international banks would fill this gap – and chase away our worst nightmare.
PRINCETON – The most recent phase of the financial crisis, since the collapse of Lehman Brothers in September 2008, has been characterized by large bank losses and the continued threat of bank collapses.
The size of the calamity raises the question of whether small countries can really afford bank bailouts.
But the definition of “small” keeps changing: a few months ago, small meant Iceland, then it meant Ireland, and now it means the United Kingdom.
The aftermath of the banking crisis requires thinking about not only the most appropriate form of banking legislation, but also the appropriate size of the state.
There has always been uncertainty about the best design of a banking system, and there has always been competition between different sorts of banking regulation.
On the one hand, there is the idea – which defined banking for much of American history – that banks should be close to the risks that they must judge.
This ideal grew out of Andrew Jackson’s titanic struggle with Nicholas Biddle and the Second Bank of the United States.
Populism was pitted against the financiers, and populism won.
As a result, most nineteenth-century US banks did not have branches, and were limited to one state.
The alternative approach was that of Canada, which, because of its roots in secure British rule, had much less fear of political centralization, and was prepared to tolerate a nation-wide banking system.
Canada’s large banking system distributed risk more widely, and fared better in episodes of financial panic, whether in 1907 or in 1929-1933.
The larger-bank principle has two chief attractions.
First, it promises more effective risk management, because large banks are less exposed to a single sort of customer (in contrast to rural American banks, which suffered when American farmers suffered).
Second, it lends itself much more effectively to long-term strategic thinking about the overall direction of the national, or even the international, economy.
But larger banks can get into trouble when these two principles get mixed up.
The idea of the larger bank reached its high point in continental Europe, and especially in Germany, whose big banking system developed out of trade finance and into industrial finance in the late nineteenth century.
By that time, countries were looking with eager interest at financial models developed elsewhere.
After the 1907 panic, the US Congress convened a National Monetary Commission, whose most interesting and attractive potential model for the US was German-style universal banks, which were imitated in Russia, Japan, Italy, and Egypt.
By 1931, even Britain found it hard to resist the German model.
It, too, conducted an official inquiry, establishing the Macmillan Committee to hear evidence about how poorly British banks served British industry, and how the German model did a much better job at converting savings into industrial finance.
The Great Depression ended this imitative surge in which the universal bank appeared to triumph.
By an unfortunate coincidence, the Macmillan Committee produced its report on July 13, 1931, the day that Germany’s most dynamic universal bank, the Darmstädter Bank, failed.
By the 1990’s, however, emulation of other banking models was back in fashion.
Financial empire building drove late twentieth-century globalization.
There was a competitive race across the Atlantic and – to a lesser extent – the Pacific.
Indeed, gradual integration of the potentially vast European capital market, and the creation of cross-border European banks as a result of mergers, made it look as if a new European breed of superbanks was emerging.
Likewise, Japan responded to its banking crisis by creating very large merged institutions, while the US repealed much of the depression-era legislation that restricted banking.
Finally, after Mexico’s 1994-95 peso crisis and the 1997-1998 Asian financial crisis, the US exported its new banking model to the emerging-market economies.
Spanish and US banks moved heavily into Latin America.
The appeal here was the opportunity for strategic vision, most clearly seen and pursued by Robert Rubin, first as Treasury Secretary in the Clinton administration and then as an adviser to the new giant of US banking, Citigroup, which emerged out of a 1998 merger.
But the new superbanks were inherently vulnerable because of the vast diversity and complexity of their transactions.
Long before the emergence of the sub-prime mortgage problem, Citigroup was damaged by the behavior of its London traders, who tried to manipulate the European government bond market, and by its Tokyo traders.
It is much simpler for a transnational manufacturing corporation to implement controls to ensure product quality.
By contrast, in a company whose business is financial intermediation, millions of judgments are made independently, and their implications may be serious enough to threaten the entire firm.
When the strategy goes wrong, the recriminations begin.
Traditional mid-sized European states cannot afford to have a strategic vision for their banks.
But, even for the US, the notion of a world held together by Citigroup’s business plan is simply too costly.
There is a danger that in the push to nationalize banks as a consequence of the financial crisis, governments will see it as their duty to implement strategies.
The strategic vision of a bank shaping the economic fortunes of a country, or the whole world, is as flawed as was the idea of central economic planning.
In this sense, 2007-2009 is the capitalist equivalent of the communist demise of 1989-1991.
CAMBRIDGE – One of the first challenges that President Barack Obama will face is the effects of the ongoing financial crisis, which has called into question the future of American power.
An article in The Far Eastern Economic Review proclaims that “Wall Street’s crack-up presages a global tectonic shift: the beginning of the decline of American power.”
Russian President Dmitri Medvedev sees the crisis as a sign that America’s global leadership is coming to an end, and Venezuelan President Hugo Chávez has declared that Beijing is now much more relevant than New York.
Yet the dollar, a symbol of American financial power, has surged rather than declined.
As Kenneth Rogoff, a Harvard professor and former chief economist of the IMF notes, “It is ironic, given that we just messed up big-time, that the response of foreigners is to pour more money into us.
They’re not sure where else to go.
They seem to have more confidence in our ability to solve our problems than we do.”
It used to be said that when America sneezed, the rest of the world caught a cold.
More recently, many claimed that with the rise of China and the petro-states, an American slowdown could be decoupled from the rest of the world.
But when the United States caught the financial flu, others followed.
Many foreign leaders quickly switched from schadenfreude to fear – and to the security of US treasury bills.
Crises often refute conventional wisdom, and this one reveals that the underlying strength of the American economy remains impressive.
The poor performance of Wall Street and America regulators has cost America a good deal in terms of the soft power of its economic model’s attractiveness, but the blow need not be fatal if, in contrast to Japan in the 1990’s, the US manages to absorb the losses and limit the damage.
The World Economic Forum still rates the American economy as the world’s most competitive, owing to its labor-market flexibility, higher education, political stability, and openness to innovation.
The larger question concerns the long-term future of American power.
A new forecast for 2025 being prepared by the US National Intelligence Council projects that American dominance will be “much diminished,” and that the one key area of continued American superiority – military power – will be less significant in the competitive world of the future.
This is not so much a question of American decline as “the rise of the rest.”
Power always depends on context, and in today’s world, it is distributed in a pattern that resembles a complex three-dimensional chess game.
On the top chessboard, military power is largely unipolar and likely to remain so for a while.
But on the middle chessboard, economic power is already multi-polar, with the US, Europe, Japan and China as the major players, and others gaining in importance.
The bottom chessboard is the realm of transnational relations that cross borders outside of government control.
It includes actors as diverse as bankers electronically transferring sums larger than most national budgets, as well as terrorists transferring weapons or hackers disrupting Internet operations.
It also includes new challenges like pandemics and climate change.
On this bottom board, power is widely dispersed, and it makes no sense to speak of unipolarity, multipolarity, or hegemony.
Even in the aftermath of the financial crisis, the giddy pace of technological change is likely to continue to drive globalization, but the political effects will be different for the world of nation-states and the world of non-state actors.
In inter-state politics, the most important factor will be the continuing “return of Asia.”
In 1750, Asia had three-fifths of the world population and three-fifths of the world’s economic output.
By 1900, after the industrial revolution in Europe and America, Asia accounted for just one-fifth of world output.
By 2040, Asia will be well on its way back to its historical share.
The rise of China and India may create instability, but it is a problem with precedents, and we can learn from history about how policies can affect the outcome.
A century ago, Britain managed the rise of American power without conflict, but the world’s failure to manage the rise of German power led to two devastating world wars.
The rise of non-state actors also must be managed.
In 2001, a non-state group killed more Americans than the government of Japan killed at Pearl Harbor.
A pandemic spread by birds or travelers on jet aircraft could kill more people than perished in World Wars I or II.
The problems of the diffusion of power (away from states) may turn out to be more difficult than shifts in power between states.
The challenge for Barack Obama is that more and more issues and problems are outside the control of even the most powerful state.
Although the US does well on the traditional measures of power, those measures increasingly fail to capture much of what defines world politics, which, owing to the information revolution and globalization, is changing in a way that prevents Americans from achieving all their international goals by acting alone.
For example, international financial stability is vital to American prosperity, but the US needs the cooperation of others to ensure it.
Global climate change, too, will affect the quality of life, but the US cannot manage the problem alone.
And, in a world where borders are becoming increasingly porous to everything from drugs to infectious diseases to terrorism, America must mobilize international coalitions to address shared threats and challenges.
As the world’s largest economy, American leadership will remain crucial.
The problem of American power in the wake of the financial crisis is not one of decline, but of a realization that even the most powerful country cannot achieve its aims without the help of others.
Fortunately, Barack Obama understands that.
For eight years, George W. Bush has managed to incarnate and reinforce all the prejudices and negative stereotypes the world has of the US.
He has antagonized the world more than any other American president before him, seriously damaging America’s “soft” power by inefficient and excessive use of its “hard” power.
Reconciling the United States with itself and the world should thus be the twin priorities for America’s next president.
If there is one candidate who can accomplish this, who can contribute, in a split second, to restoring America’s international reputation, it is Barack Obama.
Exceptional periods sometimes create exceptional leaders.
Without the French Revolution, Napoleon Bonaparte would have remained a gifted and frustrated junior military officer.
Likewise, the current period in America and its relations with the world have been truly exceptional, requiring a leader who can fundamentally challenge a global majority’s view that America has become arrogant, impotent, and selfish.
Of course, diehard anti-Americans will never be persuaded, but they remain a minority, with the possible exception of the Muslim world.
The silent majority is ready to be convinced that there is life after Bush.
Why is Obama so different from the other presidential candidates, and why could he make such a large difference internationally?
After all, in foreign policy matters, the next president’s room for maneuver will be very small.
He (or she) will have to stay in Iraq, engage in the Israel-Palestine conflict on the side of Israel, confront a tougher Russia, deal with an ever more ambitious China, and face the challenge of global warming.
If Obama can make a difference, it is not because of his policy choices, but because of what he is.
The very moment he appears on the world’s television screens, victorious and smiling, America’s image and soft power would experience something like a Copernican revolution.
Think of the impression his election would make not only in Africa, but in Asia, the Middle East, and even Europe.
With its rise to global supremacy, America had become the incarnation of the West, and the West was seen as “white.”
Power in America shifted first from the East Coast to the West Coast, and then to the South.
But if a shift across America’s racial divide is not truly revolutionary, then what is?
Of course, to reduce Obama to the color of his skin is a grave oversimplification, even if he has been keen to emphasize his “black roots.”
In fact, African-Americans do not fully support him.
With his white mother and his African father, he does not fit any African-American precedent.
But that is another reason why Obama is exceptional: the complexity of his identity makes him truly universal, a global candidate for a global age.
By virtue of his unique personal history, he can bridge Africa, America, and even Asia – where he studied as a young boy in a Muslim school – thereby reviving the universal image and message of America.
But, above all, what makes Obama unique, given what the US has been through during the Bush years, is the nature of the message he embodies, which is best summed up in the title of his book The Audacity of Hope .
If America can move from a culture of fear to one of hope – and again incarnate hope for the world – it will require a leader who embodies the American dream: modern and armed with a humanistic religious message, in contrast to the anxious irrationalism of the Christian conservative movement that fueled Bush’s political base.
Regardless of whether Obama can deliver on his promises, America will not regain the stature it had between 1941 and 2000.
With or without Obama, the “American century” will not be repeated.
But Obama can learn from the early mistakes made by Jimmy Carter in the mid-1970’s.
Neo-isolationism is not an option, but restraint – based on confidence and wisdom – is.
The world needs a more modest and confident America.
For a European who has been deeply troubled and saddened by America’s evolution in the last decade, Obama, of all the declared presidential candidates, seems to come closest to incarnating such an America.
On his second full day in office, President Barack Obama made a major gesture toward restoring the Constitution and the rule of law by signing two executive orders: one closed the prison at Guantánamo Bay, and the other restored America to the company of civilized nations by closing so-called “black sites” that facilitated state-sanctioned torture.
Nice start, and the credit goes both to Obama and to the millions of Americans who stood up and took risks to fight against gathering tyranny.
But it is not enough.
There is a speech that we still need to hear, detailing five tasks that, in order to repair the damage to liberty caused by the previous administration, he must pursue as quickly as he handled the first two executive orders.
Its substance should be something like the following:
“My fellow Americans, the Founders had the wisdom to guarantee our freedoms in many ways.
They could not guarantee our souls.
That is up to us and how we act.
“In every major religion, a version of the following question is asked: what does it profit us to gain wealth and power if we lose our moral values?
In the past eight years, we have colluded with acts that jeopardized the very soul of our nation.
The greatest crime we committed or tolerated was the savaging of our cherished Constitution.
“Without our Constitution, America is just another world power made great by wealth and weapons instead of by values and convictions; so we are at risk of collapse when our wealth and weapons fail us.
It is our Constitution that is our true wealth and the true guarantee of our nation’s endurance.
“After closing Guantánamo Bay and forbidding torture, we must repeal the Patriot Act, thereby restoring the Constitution’s restraints against warrantless wiretapping and surveillance.
“Second, though we have closed the prisons, we must seek the forgiveness of our fellow nations for the horrors that we committed or with which we colluded by engaging in state-sanctioned torture and “extraordinary rendition” of detainees to countries that torture.
I am appointing a commission to establish a truth and reconciliation process to put the accounting of these horrors before our own consciences and before the world.
“Third, we must have a special prosecutor to prosecute the culpable.
Many in the military or the intelligence services now fear criminal liability for actions they took at the behest of those at the top of the chain of command.
But the proper course of action is that taken in Nuremberg, The Hague, Sierra Leone, and after the Bosnian conflict: prosecute those who designed, approved, and implemented the policy of torture and rendition, however high the chain of commission goes – including the lawyers who justified legal perversions that led to torture and murder – rather than targeting those farther down the chain of command.
 “Fourth, let us once again outlaw the presence of the military on our streets, as the Founders intended.
On October 7, 2008, more than 3,000 American troops were deployed from Iraq to the United States, in violation of Posse Comitatus, which has protected us from military policing for a century, and in violation of the Insurrection Act, which protected us for the century before that.
Today, there are 20,000 soldiers – not accountable to the people, but only to the executive – on our streets.
“The danger of that situation is why the Founders adopted the Second Amendment, which is meant to restrict domestic policing to militia – the National Guard and civilian police – that are answerable to the people.
America is neither a battlefield nor a police state, so we should send our soldiers to the actual front or else back home to their families.
“Finally, we must ensure that this darkness never descends again.
Half of American children grow up with no civic education.
Half of states no longer teach civics – the study of our Republic and how it works – in middle school.
So half of incoming American college students don’t know what our democracy is, let alone how to defend it when it is threatened.
I call on states throughout the land to re-institute the study of US civics so that we will produce citizens who understand our legacy and can defend liberty and the Constitution when it is threatened.
“Join me in accomplishing these next five tasks, and we can look at ourselves in the mirror again, recognizing ourselves as true Americans.”
TEL AVIV: The landslide victory of the leader of the Labour Party, General Ehud Barak, in the May 17th elections in Israel means not only a new government and a new foreign policy.
It also signifies the beginning of a new era in Israeli political culture.
The three years (1996-9) of Benjamin Netanyahu's government were characterized by the politics of confrontation and animosity in all spheres of political life.
Former Prime Minister Netanyahu focused not only on a politics of confrontation with the Palestinian leadership under Yassir Arafat, but also cultivated a politics of internal confrontation - between religious and secular Jews, between "old timers" and newcomers from the former Soviet Union, between European and Middle Eastern Jews (Ashkenazi versus Sephardi).
This divide-to-rule policy was a way of life which characterized Mr. Netanyahu even before he became Prime Minister.
As leader of the nationalist Likud opposition to the governments of Yitzhak Rabin and Shimon Peres, his tactics in opposing the Oslo agreements between the Labour led government of Israel and the PLO was to characterize both Mr. Rabin and Mr. Peres as traitors, the functional equivalents of such infamous collaborators as Petain and Quisling.
It was in this atmosphere of confrontation and hatred, nurtured by Mr. Netanyahu, that a right-wing nationalist religious Jewish student assassinated Prime Minister Rabin because he saw him as a traitor who, at Oslo, gave up parts of the historical homeland of the Jewish people to the "terrorist" Palestine Liberation Organization.
When he became Prime Minister in elections six months after the assassination of General Rabin, Mr. Netanyahu continued in this strategy of exclusion and confrontation.
The consequences have been a deep crisis in relations with the Palestinians, a cooling of relations between Israel and its great strategic partner, the United States, and an internal climate of deep divisions, ethnic tension and a vulgar coarsening of almost all political discourse.
Ehud Barak, the Labour leader, is made of different stuff.
Born on a kibbutz, he served most of his life in the Israeli army, became its Chief-of-Staff and also its most decorated soldier.
But like many Israeli military leaders - Rabin himself comes to mind - as a military man he is also a pragmatist, knowing the limits of power.
When he became the leader of the Labor party less than three years ago, he also developed a new style of politics: instead of confrontation, dialogue; instead of exclusion, the politics of inclusion.
General Barak won the election as head of a broad coalition led by his own Labour Party, but including also the Gesher Party, representing North African working-class Jewish immigrants as well as the Meimad movement, representing Orthodox Jews.
It was this coalition, based on the politics of inclusion, which gave Barak his impressive victory: while Netanyahu won the 1996 election by a margin of 0.5%, Barak won this time by a margin of about 10%.
Many Russian immigrants voted for the first time for a Labour candidate.
As Prime Minister, Mr Barak will have a difficult agenda before him: going back to the Oslo agreements, which signify the historical compromise between Israel and the PLO; negotiating a territorial agreement with the Palestinians which will have to balance between their legitimate rights and Israel's security concerns; not letting extremist terrorism derail a peace process which is supported by a large majority of both peoples; finding a mutually acceptable formula for the difficult problem of Jerusalem.
Negotiations with Syria have to be restarted. Internationally he will have to get the Israeli economy out of its current recession, a downturn that it was thrown into because of the deadlock of the peace process as well as the total mismanagement of the economy under Mr Netanyahu.
Prime Minister Barak will also have to be a healer: he will have to heal the wounds between Jews and Arabs, and between Jews and Jews.
It is not an easy task, and there are no quick fixes.
A lot of patience will be needed but now at least the political will to confront Israel's domestic divide, and its long divide with the Palestinians, is there.
Europe's lumpen outsiders are becoming insiders as the Continent's political pendulum swings to the right.
After the Netherlands and France, Germany may be next (German elections are due in the autumn, and the center-right candidate - Minister/President Stoiber of Bavaria - is now the favorite).
Spain, Austria, Italy, Denmark, Portugal are already ruled by center-right governments.
This swing does not simply mark the return of traditional conservative parties and policies - smaller governments, more attention to the interests of capital - to power.
Something new is at work.
What's new is the fact that many of today's center-right governments are supported by populist or nationalist parties.
In Italy, the Netherlands, Austria, and Denmark, the government is either a coalition or a minority government propped up by the pivotal support of populist right-wing parties.
In France the government is composed of mainstream center-right politicians. Yet, President Chirac owes his victory to the success of the far right National Front.
This is a decisive novelty.
In the past, Europe's political contests were waged between left wing parties representing the interests of labor, and right wing parties representing the interests of capital.
Centrist parties that represented the middle classes and moderated the ideological extremes of left and right were pivotal.
Nowadays, ideological differences between left and right are blurred.
So a new breed of politicians and a new constituency of voters hold the balance of power.
The successes of populist/right wing parties can largely be attributed to the failures of left-leaning governments. Europe's disappointing economic performance lies at the root of this.
European unemployment remains high, and productivity growth (and hence living standards) has slowed since the mid-1990s.
Even non-economically-minded voters perceive the striking difference with the US, where productivity growth has skyrocketed since the mid-1990s and unemployment is far lower.
Some voters are beginning to think that their cherished European welfare state may be to blame.
Many European voters also feel threatened and unprotected.
A common slogan is that Europe's social model trades less economic growth for more social protection and less risk.
But this idea does not convince everyone.
Large groups of "outsiders" (young unemployed and first time job seekers, temporary workers, shopkeepers and other self-employed) do not see these supposed benefits because they lack a stable and protected job, or do not qualify for unemployment insurance, or are too young to benefit from public pension systems.
These voters also complain about crime, and of the deteriorating quality of life in their cities.
Many "outsiders" supported right-wing populist parties in the latest elections; their votes are critical for the survival of the new center-right governments in many European countries.
These "outsiders" were often neglected in Europe's traditional political competition, and their demands received little or no attention.
Across Europe, they have suddenly become political arbiters.
What these newly influential voters want is clear: less immigration, crackdowns on crime, more economic opportunities, but also more protection against economic risk and international competition.
Politicians representing these voters lack experience in government, sometimes are technically unprepared for governance, and are suspicious of technocrats and bureaucrats, particularly those in Brussels.
On many issues, the positions of populist parties conflict with the traditional pro-capital and pro-market platforms of established center-right parties.
Not all of this is black.
Some of the demands of these voters are sensible and will improve policymaking.
Most of Europe, for example, needs better crime prevention and a serious effort at cracking down on illegal immigration.
But in other important policy choices, populist parties could lead Europe astray.
Of course, most European countries need to rethink the foundations of their welfare state.
Working life needs to be lengthened, public pensions are often too generous, labor markets too rigid.
Traditional pro-capitalist right-wing parties would welcome such reforms.
Yet, welfare state reform is not a priority of right-wing populists.
But the biggest risks are to European integration.
The new populist and nationalist parties are suspicious of Europe in general, and of EU enlargement in particular.
This hostility comes at the wrong moment in time, with Europe engaged in ambitious and difficult constitutional reforms.
European enlargement, moreover, although imminent, is not a done deal.
Negotiations for enlargement are still under way.
The Convention on the Future of Europe is discussing ways to integrate new policy areas, such as internal security, immigration, elements of a common foreign policy and of external security.
But the Convention's outcome is unpredictable.
The opposition posed by this newly empowered political constituency could be decisive.
Traditional center-right parties have been pro-Europe.
European integration has rarely been affected by the left/right divide.
That holiday from serious politics may be over for good.
MUNICH – Europe is currently experiencing a huge wave of migration between its east and west.
This movement resembles the Great Migrations (Völkerwanderung) that marked Europe between the fourth to sixth centuries.
Within the first year of Romania’s accession to the EU on January 1, 2007, for example, roughly a million Romanians migrated to Italy and Spain.
More than 800,000 East Europeans have become workers in the United Kingdom over the past four years, most coming from Poland.
Indeed, in the last two years alone, 1.5 million Poles emigrated, and overall probably more than two million have done so since Poland’s EU accession in 2004.
On a smaller scale, the migration of Ukrainians to the Czech Republic, Bulgarians to Turkey, and British citizens to Spain is also noteworthy.
Because Germany still restricts the immigration of dependent workers from eastern EU countries, most of its immigrants come as self-employed or economically inactive people.
In Munich, the number of self-employed tilers increased in 2004 and 2005, the first two years after the first eastern enlargement wave, from 119 to 970.
But despite restrictions, by 2005 Germany had absorbed 37% of all migrants from Eastern Europe that came before and after eastern EU enlargement, whereas Italy had absorbed 22%, Greece 11%, Switzerland 8%, and the UK only 3%.
In the same year, 13% of the population living in Germany was foreign born, more than in Britain (10%), France (7%), Spain (5%), or Italy (3%).
The immigration waves of the last two years to Britain, Spain, and Italy will have significantly changed these figures, but the information needed to update the statistics is not yet available.
Nowadays, people move faster than statistical offices can count them.      
Before the EU’s eastern enlargement, many studies predicted the likely migration waves.
The forecasts of the proportion of East Europeans who were expected to move west within a 15 years ranged from 2.5% to 6%.
Given that about 5% of the Polish population has now emigrated within a period of only four years, despite immigration restrictions by important target countries, these estimates were much too cautious.
Before enlargement, it was politically incorrect to discuss possible waves of migration to the West, as EU politicians saw this as an obstacle to the enlargement process.
Now that enlargement has taken place, it is easier to discuss migration objectively.
This immigration is not an invasioni barbariche, as Italians refer to the Völkerwanderung, although the orders of magnitude are comparable.
As migrants move between markets with well-defined property rights, immigration in principle is beneficial for both the immigrants and the target country.
The immigrant receives a higher wage than at home, and the target country benefits from cheap labor, which creates more value than it costs.
But in practice, immigration is often not as beneficial as it could be, because the target country has a rigid wage structure that prevents the additional jobs needed to employ the immigrants from being created.
If, for example, a target country provides minimum wage guarantees and replacement incomes for the domestic unemployed, immigrants simply force domestic residents into the care of the welfare state.
This is not a problem of immigration as such, but of poorly designed domestic social and labor market institutions.
To be on the safe side, host countries often try to limit immigration to skilled workers, because they join segments of the labor market in which sufficient downward wage flexibility provides immigrants with additional jobs.
But countries have so far had mixed success in attracting skilled immigrants.
The most successful countries in this regard have been the Anglo-Saxon countries (Canada, Ireland, Australia, the United States, and the UK, in that order), as well as Denmark and Norway.
More than one-third of immigrants to these countries have tertiary education, with Canada and Ireland at 45%.
In the more unsuccessful countries – Italy, Austria, Germany, France, Portugal, and the Netherlands – the proportion of immigrants with a tertiary education is below a quarter.
In Italy, the share is just 11% – the lowest in the available statistics.
The brain drain to the Anglo-Saxon countries, the US in particular, is astounding.
The graduating classes of top American universities are packed with foreign students, and 27% of physicians practicing in the US today come from abroad.
America’s postwar growth and dynamism largely resulted from skilled immigrants.
Before and after World War II, many skilled people came from Europe, Germany in particular; in recent decades, Asian immigrants dominate, with India, Pakistan, and the Philippines occupying the top ranks.
Today’s brain drain is not only from emerging and developing countries to richer countries, but also from European countries to the US.
In most research disciplines, European-born “superstars” work and teach in the US rather than in Europe, and, according to a study by Gilles Saint-Paul, it is the superstars in particular who generate growth and prosperity for a country.
Of course, people with a decent tertiary education are also important for a country’s economy, and here the loss of some European countries is substantial.
While only 3% of Spanish and 4% of French people with tertiary education live abroad, 7% of Italians and 9% of Germans do.
Surprisingly, Ireland and the UK lead in this category, with 34% and 17%, respectively.
This may reflect the high interchange in both directions between the Anglo-Saxon countries, or replacement migration in which skilled people arrive from elsewhere as the domestic skilled migrate to other Anglo-Saxon countries.
The European landscape will change as rapidly in the course of this century as it did at the time of the Völkerwanderung.
History will have many tales to tell about what this really meant for the Continent.
At the moment, though, the casual observer is still rather clueless.
CAMBRIDGE – The prices of hydrocarbons, minerals, and agricultural commodities have been on a veritable roller coaster.
While commodity prices are always more variable than those for manufactured goods and services, commodity markets over the last five years have seen extraordinary, almost unprecedented, volatility.
Countries that specialize in the export of oil, copper, iron ore, wheat, coffee, or other commodities have been booming, but they are highly vulnerable.
Dollar commodity prices could plunge at any time, as a result of a new recession, an increase in real interest rates in the United States, fluctuations in climate, or random sector-specific factors.
Countries that have outstanding debt in dollars or other foreign currencies are especially vulnerable.
If their export revenues were to plunge relative to their debt-service obligations, the result could be crises reminiscent of Latin America’s in 1982 or the Asian and Russian currency crises of 1997-1998.
Many developing countries have made progress since the 1990’s in shifting from dollar-denominated debt toward foreign direct investment and other types of capital inflows, or in paying down their liabilities altogether.
But some commodity exporters still seek ways to borrow that won’t expose them to excessive risk.
Commodity bonds may offer a neat way to circumvent these risks.
Exporters of any particular commodity should issue debt that is denominated in terms of the price of that commodity, rather than in dollars or any other currency.
Jamaica, for example, would issue aluminum bonds; Nigeria would issue oil bonds; Sierra Leone would issue iron-ore bonds; and Mongolia would issue copper bonds.
Investors would be able to buy Guatemala’s coffee bonds, Côte d’Ivoire’s cocoa bonds, Liberia’s rubber bonds, Mali’s cotton bonds, and Ghana’s gold bonds.
The advantage of such bonds is that in the event of a decline in the world price of the underlying commodity, the debt-to-export ratio need not rise.
The cost of debt service adjusts automatically, without the severe disruption that results from loss of confidence, crisis, debt restructuring, and so forth.
The idea is not new.
So, why has it not been tried before?
When one asks finance ministers in commodity-exporting debtor countries, they frequently reply that they fear insufficient demand for commodity bonds.
That is a surprising proposition, given that commodity bonds have an obvious latent market, rooted in real economic fundamentals.
After all, steel companies have an inherent need to hedge against fluctuations in the price of iron ore, just as airlines and utilities have an inherent need to hedge against fluctuations in the price of oil.
Each of these commodities is an important input for major corporations.
Surely there is at least as much natural demand for commodity bonds as there is for credit-default swaps and some of the bizarrely complicated derivatives that are currently traded!
It takes liquidity to make a market successful, and it can be difficult to get a new one started until it achieves a certain critical mass.
The problem may be that there are not many investors who want to take a long position on oil and Nigerian credit risk simultaneously.
A multilateral agency such as the World Bank could play a critical role in launching a market in commodity bonds.
The fit would be particularly good in those countries where the Bank is already lending money.
Here is how it would work. Instead of denominating a loan to Nigeria in terms of dollars, the Bank would denominate it in terms of the price of oil and lay off its exposure to the world oil price by issuing that same quantity of bonds denominated in oil.
If the Bank lends to multiple oil-exporting countries, the market for oil bonds that it creates would be that much larger and more liquid.
This pooling function would be particularly important in cases where there are different grades or varieties of the product (as with oil or coffee), and where prices can diverge enough to make an important difference to the exporters.
An alternative for some commodity exporters is to hedge their risk by selling on the futures market.
But an important disadvantage of derivatives is their short maturity.
A West African country with newly discovered oil reserves needs to finance exploration, drilling, and pipeline construction, which means that it needs to hedge at a time horizon of 10-20 years, not 90 days.
Another disadvantage of derivatives is that they require a high degree of sophistication –both technical and political.
In the event of an increase in a commodity’s price, a finance minister who has done a perfect job of hedging export-price risk on the futures market will suddenly find himself accused of having gambled away the national patrimony.
This principal-agent problem is much diminished in the case of commodity bonds.
If the international financial wizards can get together and act on this idea now, commodity exporters might be able to avoid calamity the next time the world price of their product takes a plunge.
The World Bank should take up the cause.
BRUSSELS – It is time for José Manuel Barroso to start selling himself.
His chances of being re-appointed as President of the European Commission depend on the case he makes.
Until the global financial crisis broke, Barroso looked fairly certain to get a second five-year term.
Now, it is becoming increasingly hard to find diplomats or policymakers who support him.
French President Nicolas Sarkozy is said to have been disappointed by Barroso’s performance during last autumn's financial meltdown, and German Chancellor Angela Merkel also seems to have fallen silent on the matter of his future.
No one doubts that Barroso is in an awkward position.
The European Commission has few powers of its own with which to confront the recession as it spreads throughout the European Union; most powers belong to the European Central Bank.
But the Commission does have a voice with which to rally people, and it is for their silence that Barroso and his fellow commissioners are being rebuked.
The perceived lack of leadership from the Commission at this time of deepening economic gloom is just the tip of the iceberg.
The events of recent months have crystallized more deep-seated concerns.
When Barroso, the former Portuguese prime minister, was awarded the EU post by his fellow heads of government, he appeared to be a dynamic new broom who would sweep away the cobwebs left by his predecessor, Italy’s Romano Prodi.
But, with the passage of time, the Barroso-led Commission has also come under fire for being unadventurous and lacklustre.
Even before the clouds of recession began to gather, Euroskepticism was on the rise, with the Commission blamed, rightly or wrongly, for the EU’s failure “to reach out to the citizen.”
The job of Commission President is arguably among the most difficult in the world.
The institution has been in near-imperceptible decline for almost 20 years, thanks to the rise of the European Parliament and the way EU member governments have whittled away its authority while consolidating their own powers as the EU’s true legislators.
Yet the head of the Commission is called upon to be the dynamic public face of Europe.
The Commission’s own internal culture of cautiousness and red tape is a constraint that nobody in Brussels much likes to talk about.
It is not a structure that is conducive to political coups de theâtre , and most of the Commission’s work is the relentless grind of EU regulation and re-regulation.
But the bottom line is that at a time when everyone is asking, “What is Europe doing?”, the Commission’s responses have seemed inadequate.
For reasons that are now obscure, there is an unwritten rule that Commission presidents must be drawn from the ranks of past or current prime ministers.
This has in large part accounted for Barroso’s high hopes of getting a second term.
There was, it appeared, no other credible candidate to challenge him.
For his part, Barroso is widely seen as having avoided controversy throughout 2008 in order not to risk offending any governments that might have been inclined to block his reappointment.
That seeming passivity is now his greatest problem.
France’s presidency of the EU during the second half of 2008 showed that dynamic leadership is a quality widely appreciated by the European public.
With his sense of showmanship, Sarkozy almost effortlessly eclipsed Barroso when handling the Russia-Georgia crisis in August, followed by the EU’s responses to the autumn crisis of cascading bank collapses.
The Commission was left on the sidelines.
What is to be done?
France’s successful presidency has intensified doubts about the effectiveness of the Commission and its president, so much so that even in Paris concerns are being voiced that the Brussels executive must somehow be strengthened if it is not to become a mere secretariat.
EU governments have wanted a pliable Commission, but now the cost could be the death of the “community method” that protects the EU against national frictions.
Barroso needs to respond to all these doubts.
If he is to reassure EU national leaders that they should re-appoint him, then he needs to signal that his second term can hold out fresh promise.
He is good at giving upbeat speeches, but this will not be enough.
Some sort of plan is needed.
When he arrived in Brussels in 2004, Barroso was repeatedly asked whether he had a “big idea” for Europe’s future.
Back then, he did not need one to be appointed.
This time, he must produce one if he is to save his skin.
WASHINGTON, DC – Over the past eighteen months, oil prices have more than doubled, inflicting huge costs on the global economy.
Strong global demand, owing to emerging economies like China, has undoubtedly fueled some of the price increase.
But the scale of the price spike exceeds normal demand and supply factors, pointing to the role of speculation – and underscoring the need for policy action to clean up the oil market.
Reflecting their faith in markets, most economists dismiss the idea that speculation is responsible for the price rise.
If speculation were really the cause, they argue, there should be an increase in oil inventories, because higher prices would reduce consumption, forcing speculators to accumulate oil.
The fact that inventories have not risen supposedly exonerates oil speculators.
But the picture is far more complicated, because oil demand is extremely price insensitive.
In the short run, it is technically difficult to adjust consumption.
For instance, the fuel efficiency of every automobile and truck is fixed, and most travel is non-discretionary.
Though higher airline ticket prices may reduce purchases, airlines reduce oil consumption only when they cancel flights.
This illustrates a fundamental point: in the short run, reduced economic activity is the principle way of lowering oil demand.
Thus, absent a recession, demand has remained largely unchanged over the past year.
Moreover, it is relatively easy to postpone lowering oil consumption.
Consumers can reduce spending on other discretionary items and use the savings to pay higher gasoline prices.
Credit can also temporarily fill consumer budget gaps.
Although the housing boom in the United States – which helped in this regard – ended in 2006, consumer debt continues to grow, and America’s Federal Reserve has been doing everything it can to encourage this.
Consequently, for the time being the US economy has been able to pay the oil tax imposed by speculators.
Unfortunately, proving that speculation is responsible for rising prices is difficult, because speculation tends to occur during booms, so that price increases easily masquerade as a reflection of economic fundamentals.
But, contrary to economists’ claims, oil inventories do reveal a footprint of speculation.
Inventories are actually at historically normal levels and 10% higher than five years ago.
Furthermore, with oil prices up so much, inventories should have fallen, owing to strong incentives to reduce holdings.
Meanwhile, The Wall Street Journal has reported that financial firms are increasingly involved in leasing oil storage capacity.
The root problem is that financial markets can now mobilize tens of billions of dollars for speculative purposes.
This has enabled traders collectively to hit upon a strategy of buying oil and quickly re-selling it when end users accommodate higher prices – a situation that has been aggravated by the Bush administration, which has persistently added oil supplies to the US strategic reserve, further inflating demand and providing additional storage capacity.
Absent a change in trader beliefs, the current oil price spike will be broken only by a recession that exhausts consumers’ capacity to buffer higher prices, or when the slow process of substitution away from oil kicks in.
Thus, economic fundamentals will eventually trump speculation, but in the meantime society will have paid a high price.
Whereas oil speculators have gained, both the US and global economies have suffered and been pushed closer to recession.
In the case of the US, heavy dependence on imported oil has worsened the trade deficit and further weakened the dollar.
This sobering picture calls for new licensing regulations limiting oil-market participation, limits on permissible trading positions, and high margin requirements where feasible.
Sadly, given the conventional economic wisdom, implementing such measures will be an uphill struggle.
But some unilateral populist action is possible.
A major form of gasoline storage is the tanks in cars.
If people would stop filling up and instead make do with half a tank, they would immediately lower gasoline demand.
Given lack of storage capacity, this could quickly lower prices and burn speculators.
GENEVA – When the Swiss National Bank (SNB) recently brought its interest rate down to 0.25%, it announced that it would engage in “quantitative easing,” following in the footsteps of the United States Federal Reserve and the Bank of England.
More surprising was the simultaneous announcement that it was intervening on the foreign-exchange market with the aim of reversing the appreciation of the franc.
Will this be the first salvo in a war of competitive devaluations?
Interest rates are traditionally low in Switzerland.
Like most other central banks confronted with the recession, the SNB has reduced its policy interest rate all the way to the zero lower bound.
Once there, traditional monetary policy becomes impotent, as the interest-rate tool is no longer usable.
This is why central banks are now searching for new instruments.
Quantitative easing represents one such attempt.
It remains to be seen whether it can effectively restore some monetary-policy influence.
However, an important issue is rarely mentioned: in small, open economies – a description that applies to almost every country except the US – the main channel of monetary policy is the exchange rate. 
This channel is ignored for one good reason: exchange-rate policies are fundamentally of the beggar-thy-neighbor variety.
Unconventional policies that aim at weakening the exchange rate are technically possible even at zero interest rates, and they are quite likely to be effective at the level of individual countries.
Boosting competitiveness through exchange-rate depreciation may not succeed in raising exports in a situation where world trade is rapidly contracting, but it can cushion the blow by switching demand toward domestically produced goods and services.
The risk is that those countries that suffer from the switch retaliate and depreciate their own currencies.
That could easily trigger a return to the much-feared competitive depreciations that contributed to the Great Depression.
The first casualty would be whatever small scope remains for international policy coordination.
The second would be the world international monetary system.
In fact, one key reason for the creation of the International Monetary Fund was to monitor exchange-rate developments with the explicit aim of preventing beggar-thy-neighbor policies.
This is why the Swiss move comes as a surprise.
It is true that the franc has appreciated in real terms by 8% since the crisis started in August 2007.
This is commonly attributed to the currency reputation as a safe haven during troubled times.
What this really means is that the appreciation is neither a consequence of monetary policy nor the other usual factors.
In any case, while the Swiss authorities’ discomfort with the situation is understandable, their decision is disquieting.
The Swiss franc is not the only currency that has appreciated in recent months.
Other small economies have undergone even sharper real appreciations.
For example, Poland and the Czech Republic have seen their currencies go up by close to 30% and 15%, respectively.
Major countries also have undergone currency appreciations – 30% for Japan and 15% for China.
These countries, too, are facing a recession, and, while the interest rate has not yet reached its zero bound everywhere, incentives to depreciate might grow in the near future.
In fact, the incentives are already there. Some fairly large countries – Korea, Sweden, and the United Kingdom, to name a few – have already undergone some very large depreciations.
In fact, Poland’s currency recently started to depreciate.
None of these countries’ central banks has indicated that it was involved in depreciating its currency.
Of course, statements and intentions may not be identical.
It may be that the SNB merely acknowledges what other central banks do not.
In doing so, however, the SNB is violating a taboo: “Thou shall not engage in competitive depreciations.” Alternatively, it may be that the SNB mostly wishes to talk the franc down to break the safe-haven effect.
Having promptly achieved depreciation, it may have succeeded.
In that case, the franc will not move much more, in any direction, and there will be no need for further interventions.
Nevertheless, the limited reaction to the SNB move is somewhat surprising.
The move came one week after the IMF concluded its annual Article IV visit to Switzerland, and the report has yet to be released; it could make for unusually interesting reading.
Other central banks have not expressed any view, which may suggest that they do not intend to retaliate, at least at this stage.
They may have been reassured by the SNB’s official statement that the appreciation represented “an inappropriate tightening of monetary conditions,” and that the policy move merely aims “to prevent any further appreciation of the Swiss franc against the euro.”
It may also be that notice has been taken of the precedent, and that those authorities that intend to use it to justify future moves are loathe to criticize it.
In that case, the generalized silence could indicate that all other central banks entertain the possibility of using that option, which would be most worrisome.
CHICAGO – Global capital is on the move.
As ultra-low interest rates in industrial countries send capital around the world searching for higher yields, a number of emerging-market central banks are intervening heavily, buying the foreign-capital inflows and re-exporting them in order to keep their currencies from appreciating.
Others have been imposing capital controls of one stripe or another.
In recent weeks, Japan became the first large industrial economy to intervene directly in currency markets.
Why does no one want capital inflows?
Which intervention policies are legitimate, and which are not?
And where will all this intervention end if it continues unabated?
The portion of capital inflows that is not re-exported represents net capital inflows.
This finances domestic spending on foreign goods.
So, one reason countries do not like capital inflows is that it means more domestic demand “leaks” outside.
Indeed, because capital inflows often cause the domestic exchange rate to appreciate, they encourage further spending on foreign goods as domestic producers become uncompetitive.
Another reason that countries do not like foreign capital inflows is that some of it might be “hot” (or dumb) money, eager to come in when foreign interest rates are low and local asset prices are rising, and quick to leave at the first sign of trouble or when opportunities back home beckon.
Volatile capital flows induce volatility in the recipient economy, making booms and busts more pronounced than they would otherwise be.
But, as the saying goes, it takes two hands to clap.
If countries could maintain discipline and limit spending by their households, firms, or governments, foreign capital would not be needed, and could be re-exported easily, without much effect on the recipient economy.
Problems arise when countries cannot – or will not – spend sensibly.
Countries can overspend for a variety of reasons.
The stereotypical Latin American economies of yesteryear used to get into trouble through populist government spending, while the East Asian economies ran into difficulty because of excessive long-term investment.
In the United States in the run up to the current crisis, easy credit, especially for housing, induced households to spend too much, while in Greece, the government borrowed its way into trouble.
Unfortunately, though, so long as some countries like China, Germany, Japan, and the oil exporters pump surplus goods into the world economy, not all countries can trim their spending to stay within their means.
Since the world does not export to Mars, some countries have to absorb these goods, and accept the capital inflows that finance their consumption.
In the medium term, over-spenders should trim their outlays and habitual exporters should increase theirs.
In the short run, though, the world is engaged in a gigantic game of passing the parcel, with no country wanting to take the habitual exporters’ goods and their capital surpluses.
This is what makes today’s beggar-thy-neighbor policies so destructive: though some countries will eventually have to absorb the surpluses and capital, each country is trying to avoid them.
So which policy interventions are legitimate?
Any policy of intervening in the exchange rate, or imposing import tariffs or capital controls, tends to force other countries to make greater adjustments.
China’s exchange-rate intervention probably hurts a number of other emerging-market exporters that do not intervene as much and are less competitive as a result.
But industrial countries, too, intervene substantially in markets.
For example, while US monetary-policy intervention (yes, monetary policy is also intervention) has done little to boost domestic demand, it has spurred domestic capital to search for yield around the world.
The US dollar would fall substantially – encouraging greater exports – were it not for the fact that foreign central banks are pushing much of that capital right back by buying US government securities.
All this creates distortions that delay adjustment – exchange rates are too low in emerging markets, slowing their move away from exports, while the ease with which the US government is being financed creates little incentive for US politicians to reduce spending over the medium term.
Rather than intervening to obtain a short-term increase in their share of slow-growing global demand, it makes sense for countries to make their economies more balanced and efficient over the medium term.
That will allow them to contribute in a sustainable way to increasing global demand.
China, for example, must move more income to households and away from its firms, so that private consumption can increase.
The US must improve the education and skills of significant parts of its labor force, so that they can produce more of the high-quality knowledge and service-sector exports in which the US specializes.
Higher incomes would boost US savings, reducing households’ dependence on debt, even as they maintained consumption levels.
Unfortunately, all this will take time, and citizens impatient for jobs and growth are pressing their politicians.
Countries around the world are embracing shortsighted policies that cater to the immediate needs of domestic constituencies.
There are exceptions.
India, for example, has eschewed currency intervention thus far, even while opening up to long-term rupee debt inflows, in an attempt to finance much-needed infrastructure projects.
India’s willingness to spend when everyone else is attempting to sell and save entails risks that need to be carefully managed.
But India’s example also provides a glimpse of what the world could achieve collectively.
After all, beggar-thy-neighbor policies will succeed only in making us all beggars.
Most new revelations about Pakistan's nuclear scandal focus on the clandestine supply of uranium enrichment technology to Iran, North Korea, and Libya by the celebrated bomb-maker Dr. A. Q. Khan.

(Even though Dr. Khan earned his Ph.D in metallurgy, not nuclear physics or nuclear engineering, yet journalistspress reports usually refer to him as a "nuclear scientist").
But the documents that Libya turned over to the International Atomic Energy Agency, and subsequently to the US, show that Pakistan supplied more than just equipment for making bomb fuel.
Dr. Khan allegedly also supplied a detailed nuclear weapon design that US experts say is of a 1964 Chinese vintage passed on to Pakistan two decades ago.
This disclosure raises interesting new questions because Dr Khan was peripheral to actual weapons-related work.
Pakistan's nuclear establishment has essentially two divisions.
One, once headed by Dr. Khan, is responsible for producing bomb-grade uranium gas that, when converted to metal, provides the crucial fuel for a nuclear explosion.
The other division, which falls under the Pakistan Atomic Energy Commission and the National Development Complex, has a much wider range of responsibilities - conversion of uranium gas to metal, weapons design and manufacture, and nuclear testing.
Dr. Khan was barely mentioned by the head of the NDC, Dr. Samar Mubarakmand, in his victory speeches after the successful May 1998 nuclear tests.

Thus the mystery: how could Dr. Khan - who had no need to possess weapons design information - have handed over detailed bomb design documents to Libya?
Dr. Khan's televised confession and acceptance of sole responsibility for proliferation activities has done nothing to reduced suspicion that there is more here than meets the eye, and of the Pakistani military's complicity in proliferation.
Dr. Khan's export of centrifuge technology was unknown to successive governments in Pakistan, says the country's leader, General Pervez Musharraf.
But for over a decade, Dr. Khan had openly advertised his nuclear wares.
Year after year -(2003 includinged 2003, when the proliferation controversy was already red-hot-) Islamabad was festooned with colorful banners advertising workshops on "Vibrations In Rapidly Rotating Machinery" and "Advanced Materials," sponsored by the Dr. A. Q. Khan Research Laboratories (also known as the Kahuta Research Laboratories).
These had obvious and immediate utility for centrifuge technology, essential for producing weaponsbomb-grade uranium.
In earlier years, Dr. Khan and his collaborators published a number of papers detailing critical issues regarding the balancing of centrifuges and magnetic bearings.
These dealt with technical means for enabling centrifuge rotors to spin close to the speed of sound without disintegrating, -essential for making bomb-grade uranium.
Dr. Khan's proliferation activitiesIt could scarcely be more blatant.
But to make it absolutely certain, Kahuta issued glossy brochures aimed at "classified organizations."
To protect itself, Pakistan's desperate military establishment, fearful of being labelled a proliferator and of ultimately being deprived of its nukes, has chosen to sacrifice Dr. Khan.
Yet his public confession and apology are unlikely to end the matter.
The US Intense is certain to apply intense pressureis certain to be applied by the US for on-site inspection and monitoring of Pakistani fissile material production at the enrichment facility at Kahuta, the plutonium production reactor at Khushab, and elsewhere.
Although Pakistan will publicly resist this demand, it may secretly agree to allow installation of cameras and various sensing devices in these nuclear facilitiesinstallations.
For the moment, the efforts of some Pakistani bomb-makers to peddle nuclear secrets appear to have been stymied.
But, having invoked solidarity with Islamists all over the world, these expertsy have created a high demand for their skills.
While it is inconceivable that any Muslim country will now ask Pakistan for nuclear weapons, non-state actors are clearly more enthusiastic.
One recalls that two years ago, highly placed members of the Pakistan Atomic Energy Commission wanted to play atheir role in the jihad against America.
In a fit of Islamic solidarity, they went to Afghanistan and met with Osama bin Laden and the Taliban.
It is difficult to believe that they were the only ones so inclined.
As a result, Pakistan's bomb-makers have seriously jeopardized the safety of their country.
Imagine, for example, the horrific situation consequences ofarising from an atomic explosion in some American city.
Blinded with grief and rage, the US would exact a terrible revenge.
Mere suspicion might form the basis of action.
It is possible that America would bomb Pakistan first - perhaps with nuclear weapons - and look later for justifications later.
Iraq stands as a reminder of America's furious desire to avenge the terrorist attacks of September, 2001 and hurt punish even those unconnected with the perpetrators.
The failure to subsequent non-discovereither y of weapons of mass destruction, or connections with Al-Qaeida, have both been shrugged off by George Bush and his neo-conservative cabal.
It is time to give up the fantasy of an Islamic Bomb, and it is past the time to rein in Pakistan's rogue bomb-makers.
Their illegitimate nuclear commerce has created a nightmare for the reputation, safety, and security of their country.
It is difficult to know what Dr. Khan meant when he said he had acted in "good faith."
After all, what kind of faith allows putting instruments of mass murder on sale in the black market.
BERKELEY – US Federal Reserve Board Chairman Ben Bernanke is not regarded as an oracle in the way that his predecessor, Alan Greenspan, was before the financial crisis.
But financial markets were glued to the speech he gave in Jackson Hole, Wyoming on August 26.  What they heard was a bit of a muddle.
First of all, Bernanke did not propose any further easing of monetary policy to support the stalled recovery – or, rather, the non-recovery.
Second, he assured his listeners that “we expect a moderate recovery to continue and indeed to strengthen.”
This is because “[h]ouseholds also have made some progress in repairing their balance sheets – saving more, borrowing less, and reducing their burdens of interest payments and debt.”
Moreover, falling commodity prices will also “help increase household purchasing power.”
Finally, Bernanke claimed that “the growth fundamentals of the United States do not appear to have been permanently altered by the shocks of the past four years.”
Frankly, I do not understand how Bernanke can say any of these things right now.
If he and the rest of the Federal Open Market Committee thought that the projected growth of nominal spending in the US was on an appropriate recovery path two months ago, they cannot believe that today.
Two months of bad economic news, coupled with asset markets’ severe revaluations of the future – which also cause slower future growth, as falling asset prices lead firms to scale back investment – mean that a policy that was appropriate just 60 days ago is much too austere today.
But let me focus on Bernanke’s fourth statement.
Even if we project a relatively rapid economic recovery, by the time this lesser depression is over, the US will have experienced an investment shortfall of at least $4 trillion.
Until that investment shortfall is made up, the missing capital will serve to depress the level of real GDP in the US by two full percentage points.
America’s growth trajectory will be 2% below what it would have been had the financial crisis been successfully finessed and the lesser depression avoided.
There is more: state and local budget-cutting has slowed America’s pace of investment in human capital and infrastructure, adding a third percentage point to the downward shift in the country’s long-term growth trajectory.
After the Great Depression of the 1930’s, the vast wave of investment in industrial capacity during World War II made up the shortfall of the lost decade.
As a result, the Depression did not cast a shadow on future growth – or, rather, the shadow was overwhelmed by the blinding floodlights of five years of mobilization for total war against Nazi Germany and Imperial Japan.
There is no analogous set of floodlights being deployed to erase the shadow that is currently being cast by the lesser depression.
On the contrary, the shadow is lengthening with each passing day, owing to the absence of effective policies to get the flow of economy-wide nominal spending back on its previous track.
Moreover, there is an additional source of drag.
A powerful factor that diminished perceived risk and encouraged investment and enterprise in the post-WWII era was the so-called “Roosevelt put.”
Industrial-country governments all around the world now took fighting depression to be their first and highest economic priority, so that savers and businesses had no reason to worry that the hard times that followed 1873, 1884, or 1929 would return.
That is no longer true.
The world in the future will be a riskier place than we thought it was – not because government will no longer offer guarantees that it should never have offered in the first place, but rather because the real risk that one’s customers might vanish in a prolonged depression is back.
I do not know by how much this extra risk will impede the growth of the US and global economies.
A back-of-the-envelope estimate suggests that a five-year lesser depression every 50 years that pushes the economy an extra 10% below its potential would reduce average investment returns and retard private investment by enough to shave two-tenths of a percentage point from economic growth every year.
As a result, America would not just end this episode 3% poorer than it might have been; the gap would grow – to 7% by 2035 and 11% by 2055.
This is the shape of things to come if steps are not taken now to recover rapidly from this lesser depression, and then to implement policies to boost private capital, infrastructure, and education investment back up to trend.
Perhaps that would be enough to reassure everyone that policymakers’ current acquiescence in a prolonged slump was a horrible mistake that will not be repeated.
NEW DELHI – By marking the Cold War’s end and the looming collapse of the Soviet Union, the fall of the Berlin Wall 20 years ago transformed global geopolitics.
But no continent benefited more than Asia, whose dramatic economic rise since 1989 has occurred at a speed and scale without parallel in world history.
For Asia, the most important consequence of the fall of the Berlin Wall was that the collapse of communism produced a shift from the primacy of military power to economic power in shaping the international order.
To be sure, rapid economic growth also occurred during the Industrial Revolution and in the post-WWII period. But in the post-Cold War period, economic growth by itself has contributed to altering global power relations.
Another defining event in 1989 was the Tiananmen Square massacre of pro-democracy protestors in Beijing.
If not for the Cold War’s end, the West would not have let China off the hook over those killings.
Instead, the West adopted a pragmatic approach, shunning trade sanctions and helping to integrate China into the global economy and international institutions through the liberalizing influence of foreign investment and trade.
Had the United States and its allies pursued an approach centered on punitive sanctions, as with Cuba and Burma, the result would have been a less prosperous, less open, and potentially destabilizing China.
Indeed, China’s phenomenal economic success – illustrated by its world-beating trade surplus, world’s largest foreign-currency reserves, and highest steel production – owes a lot to the West’s decision not to sustain trade sanctions after the Tiananmen Square massacre.
Having vaulted past Germany to become the world’s biggest exporter, China now is set to displace Japan as the world's second largest economy.
India’s rise as an economic giant is also linked to the post-1989 events.
India was heavily involved in barter trade with the Soviet Union and its communist allies in Eastern Europe.
When the East Bloc unraveled, India had to start paying for imports in hard cash.
That rapidly depleted its modest foreign-exchange reserves, triggering a severe financial crisis in 1991, which in turn compelled India to embark on radical economic reforms that laid the foundations for its economic rise.
More broadly, the emblematic defeat of Marxism in 1989 allowed Asian countries, including China and India, to pursue capitalist policies overtly.
Although China’s economic renaissance had already begun under Deng Xiaoping, the Chinese Communist Party, after 1989, was able publicly to subordinate ideology to wealth creation.
That example, in turn, had a constructive influence on surviving communist parties in Asia and beyond.
Geopolitically, the post-1989 gains extended far beyond the West.
The Soviet Union’s sudden collapse was a strategic boon to Asia, eliminating a menacing empire and opening the way for China rapidly to pursue its interests globally.
Russia’s decline in the 1990’s became China’s gain.
For India, the end of the Cold War triggered a foreign-policy crisis by eliminating the country’s most reliable partner, the Soviet Union.
But, as with its 1991 financial crisis, India was able to emerge with a revamped foreign policy – one that abandoned the country’s quixotic traditions and embraced greater realism and pragmatism.
Post-Cold War India began pursuing mutually beneficial strategic partnerships with other key players in Asia and the wider world.
The new “global strategic partnership” with the United States – a defining feature of this decade – was made possible by the post-1989 shifts in Indian policy thinking.
Of course, not all post-1989 developments were positive.
For example, the phenomenon of failing states, which has affected Asian security the most, is a direct consequence of the Cold War’s end.
When the Cold War raged, one bloc or the other propped up weak states.
But, with the Soviet Union’s disappearance, the US abandoned that game.
As a result, dysfunctional or failing states suddenly emerged in the 1990’s, constituting a threat to regional and international security by becoming home to transnational pirates (Somalia) or transnational terrorists (Pakistan and Afghanistan), or by their defiance of global norms (North Korea and Iran).
Asia has suffered more casualties from the rise of international terrorism than any other region.
Moreover, two decades after the Berlin Wall fell, the spread of democracy has stalled.
Between 1988 and 1990, as the Cold War was winding down, pro-democracy protests erupted far from Eastern Europe, overturning dictatorships in countries as different as Indonesia, South Korea, Taiwan, and Chile.
After the Soviet disintegration, even Russia emerged as a credible candidate for democratic reform.
But, while the overthrow of totalitarian or autocratic regimes shifted the global balance of power in favor of the forces of democracy, not all the pro-democracy movements succeeded.
And the subsequent “color revolutions” in places like Ukraine only instilled greater caution among the surviving authoritarian regimes, prompting them to implement measures to counter foreign-inspired democratization initiatives.
Aside from the retreat of democracy in Russia, China – now the world’s oldest autocracy – is demonstrating that when authoritarianism is entrenched, a marketplace of goods and services can stymie the marketplace of political ideas.
Twenty years after communism’s fall, authoritarian capitalism has emerged as the leading challenger to the spread of democratic values.
Silvio Berlusconi, who becomes President of the European Union on July 1 st , is a man of vision who once loved risk--and whose business bets paid off big.
In the 1960's, he was the first to see that Milan, then a traditional Italian city where people walked to work, would become a modern metropolis, surrounded by American-style suburbs.
So his fortune began in real estate development.
Fifteen years later, Signor Berlusoni understood that the Italian state's monopoly of television would not survive and jump-started what became Italy's main privately owned media group.
But you don't win in TV and the real estate business without the right political connections.
On both occasions, Berlusconi outwitted his competitors by siding with the Socialists, at the time the rising stars of Italian political life.
His long association with Bettino Craxi, Milan's most influential politician in the 1970's and Italy's prime minister through much of the 1980's, started early.
On the other hand, political connections do not make a politician.
Indeed, the jump from business into politics was probably not Berlusconi's own preference.
By the 1990's, his media group was in trouble, weakened by excessive diversification (the decision to enter the retail-distribution business almost destroyed the group).
Almost at the same time, ex-premier Craxi fled to Tunisia, chased there by the Italian courts at the height of the mani pulite (clean hands) investigation into the vast network of corruption known as Tangentopoli (Bribesville).
Craxi's flight and exile left Berlusconi feeling lost--and without the reliable political backing that he needed.
So he decided that he needed to become his own political sponsor.
As has happened frequently in Italian history, Berlusconi's decision to form a new political party, Forza Italia , just a few months before the 1994 general election paid off handsomely.
Berlusconi's lack of experience in politics doomed his first government to collapse after only six months.
Any other man as rich as Berlusconi would probably have given up.
But Berlusconi remained and led the opposition for six years.
In 2001 his determination was rewarded with a clear victory and, more importantly, a seemingly clear mandate for change.
Once again Berlusconi probably had no choice: by the late 1990's, his association with the disgraced Socialists was haunting him politically and legally.
His only hope of fending off the magistrates was to control parliament and introduce new laws that would stop the series of corruption trials he faces--a strategy that has now given him immunity from prosecution until he leaves office.
Unfortunately, while Berlusconi's government is invariably long on speeches, legal provisions designed to stop the clock on his court cases are among the few laws that have passed in his two years of government.
Berlusconi's performance in government is a combination of good intuition--for instance the early attempt to reform Italian pensions in 1994--and poor implementation, most likely because of a lack of courage, as surprising as that seems.
In 1994, during his first government, he understood early on that Italy needed to overhaul its pension system, and introduced bold legislation.
But one general strike was enough to kill his reformist zeal.
More recently, he courageously sided with the US on the war in Iraq, against the majority of the country and most of his own political coalition.
But soon he seemed scared of his own boldness and faded into an almost invisible ally.
Despite Berlusconi's rhetoric, he did not go (or was not invited) to the summit meeting with President Bush in the Azores, where the final decision to go to war was taken.
On labor reforms, he fought the unions head on, but he chose the wrong fight: Italy's infamous "Article 18," which allows labor courts to return a worker to his job if a judge believes that the worker was unjustly fired.
But while Article 18 is important in principle, it is almost irrelevant in practice.
The outcome was a confrontation with the unions that distracted from more important labor reforms.
Contrary to what happened in 1994, Berlusconi's current government survives, but whoever hoped for a free-market revolution will be disappointed.
There has been no tax cut of any significance, and pension reform is still waiting.
Berlusconi's powerful finance minister, Giulio Tremonti, speaks often and fondly of the necessity of renewed government intervention in the economy; nothing is done to prevent strikes in the public transportation sector.
Moderate right-wing voters, who wanted an Italian (i.e., somewhat watered-down) version of the Reagan/Thatcher era are disillusioned.
Berlusconi tries to mask his inactivity by scaring his voters, repeating again and again that electing the moderate left would mean signing a pact with the devil, i.e., the "communists."
Italians seem smarter, as the result of the June administrative elections clearly have shown.
Why has the courageous visionary of the 1960's and 1970's lost his shine?
Part of it is precisely that it is no longer the 1960's and 1970's: Berlusconi is 40 years older and for the past ten years has lived in the world of Roman politics.
There he learned the art of political (and personal) survival, but lost his vision and his love for risk taking.
Italy now looks as unsettled and decrepit as Britain did when Margaret Thatcher assumed power 24 years ago. Fiat wallows in crisis; university rectors resign en mass; judges attend the opening session of the judicial year carrying copies of the constitution as a warning to the government.
When he returned to power, Silvio Berlusconi promised bold Thatcherite reforms to set things right.
His reforms, however, have been few and insipid, aimed mostly at benefiting himself, says Ferdinando Targetti.
Italy is in economic decline.
Its share of exports in world markets is contracting.
On the list of "most competitive countries" prepared by the World Economic Forum, Italy has fallen in one year from 26
 th
 place to 39
 th
 .
Unemployment is higher than the EU average (9% against 7.6% ).
Inflation is nearly twice that of France and Germany, though all three countries use the euro.
The ratio of debt to GDP (110%) is almost twice the European average and growing.
Fiat's crisis may see the country lose its last great internationally competitive industrial enterprise. 
In response, Italy's President has asked the entrepreneurial classes to help shore up the country's competitiveness.
Unions should return to the policy they adopted during the successful struggle against inflation in the 1990s.
The state must improve public services, strengthen the educational system, and devote greater resources to research and development.
The government must reform social welfare and pensions. 
The entire political spectrum, indeed, must recognize the country's predicament and find common ground for legislation.
But this will be impossible so long as Prime Minister Berlusconi dominates Italian politics. 
Berlusconi is a new phenomenon on the European right.
In recent decades, mainstream right-leaning parties in most Western countries evolved from a defense of tradition (sometimes with a tinge of nationalism) to a more liberal worldview favoring a limited role for the state and greater individual responsibility.
Coming from the pinnacle of Italian business, Berlusconi might have been expected to conform to this pattern.
In fact, however, Berlusconi represents political extremism and programmatic ambiguity. 
Berlusconi's extremism manifests itself in several ways.
First, he thinks of politics as a soccer match.
On one side are the "good guys," the 
 Azzurri
 (the Italian national team, in their blue shirts), led by a manager who, because he was successful in business, is convinced he will be successful at managing the state.
On the other side are the bad guys, the Reds, who, because they are politicians, do not know what it means to work. 
Berlusconi's vision of democracy--more populist than liberal--is that everything is allowed to those who win, even changing laws to favor the prime minister's special interests.
His government has done so at least three times. It passed a law making it easy for politicians to ignore conflicts of interest, authored tendentious legislation on media ownership (Berlusconi controls much of Italy's media), and effectively got the Prime Minister off the hook on a series of criminal indictments. 
But Berlusconi is also a master of ambiguity, someone who appeals to liberal values while pursuing an anti-liberal, populist, and corporatist agenda.
Giulio Tremonti, Berlusconi's Economy and Finance Minister and ideologue of the alliance with Umberto Bossi's xenophobic 
 Lega Nord
 , declared in a recent interview: "Let's be done with the utopia of privatization.
The right does not remain static and it does not reject the idea of state intervention." 
According to Tremonti, what Italy needs are a "new European protectionism" against unfair competition from developing countries and a rightwing "New Deal" that rejects independent enforcement of antitrust laws in favor of corporatist ideas. 
In reality, Italy's government has done little on the economic front, and what it 
 has
 done it has gotten wrong.
The Prime Minister often speaks about pension reform, but has failed to offer any new proposals.
He has not supported any major privatizations; indeed, he tried to restore to government hands control of energy and banking. 
The only economic policy put into effect took the form of industrial subsidies.
To finance this, the government passed a series of amnesties, forgiving penalties for past tax evasions, allowing underground business to come above ground without paying its obligations, and allowing Italians to bring capital illicitly stashed abroad back into the country. 
In the last budget, revenue from amnesties amounted to eight billion euros, and the fiscal reductions for businesses were 7.5 billion euros.
To finance measures that require permanent outlays with one-time revenues presages a new spike of public debt--a policy criticized by the European Commission and the IMF. 
Another of Berlusconi's economic wheezes is decriminalization of accounting fraud, something his government launched just when the world, in particular America, was establishing harsher punishments for dishonest managers and other fiduciaries. 
As to Fiat, Berlusconi's government failed to put forward a Thatcherite scheme aimed at bringing in foreign capital to salvage both it and other declining industrial enterprises.
Instead, he backs a plan by a group of Italian financiers to pry control of Fiat from the dominance of the Agnelli family.
Fiat controls one of Italy's great newspapers, 
 Corriere della Sera
 , which may become more friendly to Berlusconi with an ownership change approved by him. 
Berlusconi's programmatic ambiguity and political extremism are polarizing Italy and radicalizing the opposition.
Growing numbers of people, even moderates, are moving into active opposition.
In this climate, Italy's decline will be difficult to arrest. 
Silvio Berlusconi was elected as Italy's prime minister after campaigning on a platform of reinvigorating the economy through tax cuts and liberalization.
After three years in office, he has not delivered on his economic agenda and his government is in shambles.
What went wrong?
Italy's economic ills are well known.
At the risk of over-simplifying, they can be grouped under three headings:
· 
 Weak public finances
 . When Italy joined the European Monetary Union, its primary budget surplus (tax receipts in excess of government spending, excluding interest payments) was about 5% of national income.
In 2004, the surplus will shrink to about 1.5% - before the tax cuts that Berlusconi promised for next year.
Excessive social welfare spending (mainly public pensions) and the cost of servicing the public debt drain resources from more productive government spending and impose a high tax burden.
The government has failed to take any meaningful action, and the problem is getting worse.
Unsurprisingly, the rating agency Standard &amp; Poor's recently downgraded Italian public debt.
· 
 Declining competitiveness
 . Italy's most dynamic producers are small manufacturing firms in traditional sectors with relatively low technological content.
With these firms now exposed to foreign competition from low-cost producers in Asia and Eastern Europe, Italy's share of world exports has been shrinking in recent years.
Italy has a few large corporations, mainly in services, utilities, or sectors shielded from competition.
These monopolistic producers act like a distorting tax on the rest of the economy.
Smaller but more competitive manufacturing firms lack the resources to expand in more advanced technological sectors.
The volume of private and public R&amp;D spending is one of the lowest among industrial countries.
As a result, Italy is receiving immigrants with relatively low skills, while many of its most productive young graduates emigrate to the US, the UK, or other European countries.
The government has done little to remedy this.
Liberalization attempts in energy and public utilities have faltered, perhaps also because the government pockets monopoly rents through dividends from public enterprises.
Privatization has stalled. 
· 
 The Mezzogiorno
 .
Labor productivity is traditionally much lower in Italy's south than in the rest of the country.
But centralized wage negotiations impose the same salary everywhere.
So many in the South remain poor and out of work, particularly the young.
Early on, the government proposed legislation to increase labor market flexibility and relax constraints on firing rules.
But its strategy of dividing the trade unions failed and some of the proposed legislation was eventually withdrawn. 
Why has the government achieved so little, despite a large majority in Parliament, widespread backing among the population, and supportive media?
The main reason is government infighting.
In a well functioning democracy, electoral competition between government and opposition induces the government to pursue efficient policies.
Not so in Italy, where the main site of electoral competition has always been 
 within
 the governing coalition.
Each government party is afraid of losing votes to its coalition partners, and undermines or blocks whatever the government is trying to do.
The result is policy paralysis, until time has run out for everyone. 
The same problems led to the collapse of the previous government (a left-wing coalition led by current EU Commission President Romano Prodi), and they would certainly continue under a new government if a left-wing coalition was voted into office at the next election.
Unstable coalition governments have been typical of Italy's postwar politics.
In an attempt to solve the problem, a mixed electoral system was introduced in the early 1990's, with about three quarters of the seats assigned under plurality rule in single member districts and the rest allocated under proportional representation.
But the hope that this would ensure greater stability has been unfulfilled.
The residual proportional component of the electoral system has kept many political parties alive.
Because all of them compete for these proportional seats, government infighting remains acute.
A logical solution would be to scrap the proportional component of the electoral system altogether, and move decisively toward a two-party political system under fully majoritarian elections.
But that is unlikely.
On the contrary, the smaller centrist parties that scored a victory in the recent European Parliament elections are now demanding a return to full proportionality. 
If they get it, matters will most likely go from bad to worse.
Under the current system, Italian governments achieve little, but at least they last longer.
A return to full proportionality would probably mean a return to rapid government turnover, which carries with it the risk that policy horizons will also become shorter.
As Italians know all too well, government instability inevitably breeds financial volatility.
CAMBRIDGE – At the United States Federal Reserve’s recent and first-ever public press conference, Chairman Ben Bernanke gave a spirited defense of the Fed’s much-criticized policy of mass purchases of US government bonds, also known as “quantitative easing.”
But was his justification persuasive?
Most economists viewed his performance as masterful.
But the fact that the dollar has continued to slide while gold prices have continued to rise suggests considerable skepticism from markets.
One of the hardest things in central banking is that investors often hear a very different message from that which the central bank intends to send.
The Fed, of course, has been forced to turn to “QE,” as traders call it, because its normal tool for fine-tuning inflation and growth, the overnight interest rate, is already zero.
Yet US economic growth remains sluggish, and is accompanied by stubbornly high unemployment.
QE has been blamed for everything from asset-price bubbles to food riots to impetigo.
Everyone from foreign finance ministers to cartoon satirists (check out the video “quantitative easing explained”) to Sarah Palin has ripped into the policy.
Critics insist that QE is the beginning of the end of the global financial system, if not of civilization itself.
Their most telling complaint is that too little is known about how quantitative easing works, and that the Fed is therefore taking undue risks with the global financial system to achieve a modest juicing of the US economy.
Whether or not the critics are right, one thing is clear: with the Fed lagging other global central banks in the monetary-tightening cycle, and with rating agencies contemplating a downgrade of America’s credit score, the US dollar’s purchasing power has sunk to an all-time low against the currencies of America’s trading partners.
Bernanke’s defense was robust and unequivocal.
He argued that QE is not nearly as unconventional as its critics claim.
If one looks at how it has affected financial conditions, including long-term interest rates, volatility, and stock prices, QE looks an awful lot like conventional interest-rate policy, which we think we understand.
Thus, concerns about QE’s supposed ill effects are wildly overblown, and there is nothing especially challenging about eventually reversing course, either.
Bernanke dismissed complaints about commodity prices and emerging-market inflation, arguing that these phenomena had far more to do with lax monetary policies and overly rigid exchange rates in fast-growing developing economies.
The Fed chairman’s comments come at a critical and sensitive moment.
Over the next year or so, the Fed is likely to enter a tightening cycle, raising interest rates on a steady and sustained basis.
It does not want to rush, because the US economy is still weak, with first-quarter growth a lackluster 1.8%.
But it cannot wait too long, lest inflation expectations drift to a dangerously high level, forcing the Fed to move aggressively – and at the cost of considerable economic pain – to wring inflation out of the system.
In unwinding QE, Bernanke must avoid another landmine, namely an unwelcome collapse in asset prices.
Many savvy Wall Street traders are convinced that QE is just the old “Greenspan put” on steroids.
The cult of the “Greenspan put” stemmed from the previous Fed chairman’s avowed belief that the Fed should not try to resist a sharply rising stock market, except to the extent that such a market undermines the long-term stability of prices for ordinary goods.
But if the stock market collapses too quickly, the Fed should worry about a recession and react aggressively to cushion the fall.
Are traders right?
Is QE merely the sequel to the “Greenspan put”?
It is certainly the case that today’s super-low interest rates encourage investors to pour funds into risky assets.
The Fed probably would argue that it is the job of regulators to make sure that asset bubbles do not induce too much borrowing and an eventual debt crisis, though of course monetary policy has to be in the mix.
Given the sluggish recovery, Bernanke could have gone even further and argued that the Fed is the one who has it right.
Other advanced-economy monetary authorities, such as the European Central Bank, might be over-reacting to short term inflation volatility.
However, perhaps not wanting to cause problems for his foreign counterparts, Bernanke took a more cautious approach, merely defending the Fed’s policy as the right choice for America.
In defending the Fed’s policy, Bernanke had to be careful not to say anything that might overly alarm investors.
Indeed, there is already reason enough for them to be nervous: after all, the Fed’s epic easing of financial conditions must eventually be followed by exceptionally painful tightening.
Will the economy be ready when the time comes?
Explaining the inevitable shift to tightening could prove a far greater challenge than explaining the exceptional accommodation of quantitative easing.
The Fed must always remember that no matter how calm and rational its analysis may be, it is dealing with markets that can be anything but calm and rational.
Precisely because so much emotion has been invested in QE, the psychological effects of returning to normalcy are going to be perilous and unpredictable.
BERKELEY – William McChesney Martin, a Democrat, was twice reappointed to the job of Chairman of the United States Federal Reserve by Republican President Dwight D. Eisenhower.
Paul Volcker, a Democrat, was reappointed once by the Reagan administration (but not twice: there are persistent rumors that Reagan’s treasury secretary, James Baker, thought Volcker was too invested in monetary stability and not invested enough in producing strong economies in presidential years to elect Republicans).
Alan Greenspan, a Republican, was reappointed twice by Bill Clinton.
And now Barack Obama has announced his intention to re-nominate Republican appointee Ben Bernanke to the post.
As this history suggests, it is more remarkable for a US president not to reappoint a Fed chairman named by the opposite party than to reappoint one who wishes it.
Reagan’s failure to reappoint Volcker and Jimmy Carter’s failure to reappoint Arthur Burns are the main exceptions.
The Fed chairmanship is the only position in the US government for which this is so: it is a mark of its unique status as a non- or not-very-partisan technocratic position of immense power and freedom of action – nearly a fourth branch of government, as David Wessel’s recent book In Fed We Trust puts it.
The reason, I think, that American presidents are so willing to reappoint Fed chairmen from the opposite party is closely linked to one of the two things that a president seeks: the confidence of financial markets that the Fed will pursue non-inflationary policies.
If financial markets lose that confidence – if they conclude that the Fed is too much under the president’s thumb to wage the good fight against inflation, or if they conclude that the chairman does not wish to control inflation – then the economic news is almost certain to be bad.
Capital flight, interest-rate spikes, declining private investment, and a collapse in the value of the dollar – all of these are likely should financial markets lose confidence in a Fed chairman.
And if they occur, the chances of success for a president seeking re-election – or for a vice president seeking to succeed him – are very low.
By reappointing a Fed chair chosen by someone else, a president can appear to guarantee financial markets that the Fed is not too much under his thumb.
And that can be a very valuable asset for an incumbent Fed chair – one that no other candidate could match.
But US presidents seek more than just a credible commitment to financial markets that the Fed chair will fear and fight inflation.
They seek intelligence, honor, and a keen sense of the public interest and the public welfare.
Presidents’ futures – their ability to win re-election, to accomplish other policy goals, and to leave a respectable legacy – hinge on the economy’s strength.
It may or may not be true, especially these days, that what is good for General Motors is good for America and vice versa, but certainly what is good economically for America is good politically for the president.
It is here, I think that President Barack Obama has lucked out.
Ben Bernanke is, I think, a very good choice for Fed chair because he is so intelligent, honest, pragmatic, and clear-sighted in his vision of the economy.
He has already guided the Fed through two very tumultuous years with only one major mistake – the bankruptcy of Lehman Brothers.
Bernanke’s deep knowledge of the Great Depression and of financial crises is exactly what America – and the world – needs in a Fed chair now.
And his commitment not to err on the side of underestimating either the difficulty of the situation or the value of keeping employment high would make him, I believe, one of the best possible choices for the position, even if he were not now the incumbent.
Will the inexorable rise in medical costs around the world someday pose a major challenge to contemporary capitalism?
I submit that in the not-so-distant future, moral, social, and political support for capitalism will be severely tested as would-be egalitarian health systems face ever-rising costs.
Rising incomes, population aging, and new technologies for extending and enhancing life, have caused health costs to rise 3.5% faster than overall income for many decades now in the United States.
Some leading economists project that health expenditures, which already constitute 16% of the US economy, will rise to 30% of GDP by 2030, and perhaps approach 50% later in the century.
Other rich and middle-income countries, although typically spending only half what the US does today, won’t lag far behind.
Countries in Europe and elsewhere have shielded their citizens from a part of this rise by piggybacking on US technological advances.
Ultimately, though, they face the same upward cost pressures.
Hasn’t the start of the twenty-first century marked the death of all other ideologies, with China’s raw capitalism putting pressure on gentler forms in Europe and elsewhere?
The problem is that attitudes towards healthcare are fundamentally different.
Many societies view healthcare as a right, not a luxury.
When medical expenses constituted only a small percentage of income, as was typically the case 50 years ago, an egalitarian approach to healthcare was a small extravagance.
The direct and indirect costs were relatively minor and affordable.
But as health expenses start taking up a third of national income, healthcare socialism starts becoming just plain Marxism: to each according to his needs.
Even China’s authoritarian capitalism will someday feel the pressure, as its rural populations, who currently have little access to doctors or hospitals, eventually explode with discontent.
One often hears about rising healthcare costs in the context of future government budget projections, with old-age health costs expected to dominate growth in government expenditures in coming years.
But a careful look at the projections by, say, the US Congressional Budget Office, show that the aging of our societies is only a part of the problem, and not the larger part.
The real issue is whether societies are willing to provide elderly people with equal access to ever newer and improved medical techniques.
A change on the horizon that will exacerbate current frictions is the growing importance of individualized health care.
For most of modern history, relatively inexpensive public health precautions, such as providing clean drinking water and routine vaccinations, have been the main factor pushing up life expectancy.
Public health measures have trumped the importance of individual care.
But today, the balance is shifting.
Heart operations are already a major factor in extending life in many rich countries.
Sophisticated X-ray diagnostic techniques such as CT scans make it possible to detect many cancers at a treatable stage.
Some drug researchers predict that with continuing advances in understanding the human genome, doctors may eventually be able to predict illnesses 15-20 years in advance, and begin prophylactic treatment immediately.
(With some experts predicting that individuals will routinely live beyond 110-115 years by mid-century, one might wonder what all this will do to other social conventions such as marriage, but I will leave this thought to another day.)
In addition to reducing mortality, new medical techniques can also have a huge effect on the quality of life.
Roughly 250,000 hip replacements are performed in the US each year.
Under-60 patients are becoming more important as newer artificial joints prove their capacity to withstand more active lifestyles.
At $6,000, the average cost of a hip replacement is only a thousandth the cost of what it supposedly took to implant a bionic arm, eye, and two legs on the fictional “The Six Million Dollar Man” in the popular mid-1970’s TV show.
Of course, hip replacement patients don’t get super-human speed, strength, and vision – at least not yet.
If Tour de France officials think they have big problems now with steroids, just wait ten years.
In principle, greater use of market mechanisms to allocate health care can slow or even temporarily reverse the rise in healthcare costs.
But improved efficiency has its limits.
Ultimately, the evidence suggests that societies spend ever-larger fractions of their income on health over time, in contrast to food expenditures, for example, which fall as countries become wealthier.
Spending pressures, in turn, lead to acceleration of innovation.
This raises long-term well being all around, but exacerbates short-term inequalities and frictions.
I am not arguing against healthcare capitalism, but warning that support will become fragile, far more so than for, say, globalization nowadays.
Most countries rely far too much on command and control, and provide far too few incentives for patients and providers to make efficient choices.
Nevertheless, it remains to be seen whether healthcare pressures will ultimately cause the current trend towards free (and freer) market capitalism to reverse, with a very large chunk of the economy reverting to a more socialist system.
Some societies might decide that it is better to be red than dead.
ROME – The Basel Accords – meant to protect depositors and the public in general from bad banking practices – exacerbated the downward economic spiral triggered by the financial crisis of 2008.
Throughout the crisis, as business confidence evaporated, banks were forced to sell assets and cut lending in order to maintain capital requirements stipulated by the Accords.
This lending squeeze resulted in a sharp drop in GDP and employment, while the sharp sell-off in assets ensured further declines.
My recent study with Jacopo Carmassi, Time to Set Banking Regulation Right, shows that by permitting excessive leverage and risk-taking by large international banks – in some cases allowing banks to accumulate total liabilities up to 40, or even 50, times their equity capital – the Basel banking rules not only enabled, but, ironically, intensified the crisis.
After the crisis, world leaders and central bankers overhauled banking regulations, first and foremost by rectifying the Basel prudential rules.
Unfortunately, the new Basel III Accord and the ensuing EU Capital Requirements Directive have failed to correct the two main shortcomings of international prudential rules – namely, their reliance on banks’ risk-management models for the calculation of capital requirements, and the lack of supervisory accountability.
The latest example highlighting this flaw is Dexia, the Belgian-French banking group that failed in 2011 – just after passing the European Banking Authority’s stress test with flying colors.
The stunning opacity of solvency ratios encouraged regulators to turn a blind eye to banks’ excessive risk-taking.
The problem is that the Basel capital rules – whether Basel I, II, or III – are of no help in separating the weak banks from the sound ones.
Indeed, more often than not, the banks that failed or had to be rescued in the wake of the 2008 financial crisis had solvency ratios higher than those of banks that remained standing without assistance.
Compounding the problem, the diversity in banks’ capital ratios also indicates a dramatic distortion of the international playing field, as increasingly competitive conditions in financial markets have led to national discretion in applying the rules.
Meanwhile, the opacity of capital indicators has made market discipline impossible to impose.
Thus, large banks are likely to continue to hold too little capital and to take excessive risks, raising the prospect of renewed bouts of financial instability.
In order to overcome these shortcomings in international banking regulations, three remedies are needed.
First, capital requirements should be set as a straightforward ratio of common equity to total assets, thereby abandoning all reference to banks’ own risk-management models.
The new capital ratio should be raised to 7-10% of total assets in order to dampen risk-taking by bankers and minimize the real economic impact of large-scale deleveraging following a loss of confidence in the banking system.
Second, new capital ratios with multiple and decreasing capital thresholds, which trigger increasingly intrusive corrective action, should serve as the basis for a new system of mandated supervisory action.
Supervisors should be bound by a presumption that they will act.
They could argue that action is not necessary in a specific case, but they would have to do so publicly, thus becoming accountable for their inaction.
In order to eradicate moral hazard, the system must have a resolution procedure to close banks when their capital falls below a minimum threshold.
Finally, solvency rules should be complemented by an obligation that banks issue a substantial amount of non-collateralized debt – on the order of 100% of their capital – that is convertible into equity.
These debentures should be designed to create a strong incentive for bank managers and shareholders to issue equity rather than suffer conversion.
These three measures, if applied to all banks, would eliminate the need for special rules governing liquidity or funding (which would remain open to supervisory review, but not to binding constraints).
There would also be no need for special restrictions on banking activities and operations.
The most remarkable feature of the policy deliberations on prudential banking rules so far has been their delegation to the Basel Committee of Banking Supervisors and the banks themselves, both of which have a vested interest in preserving the existing system.
Governments and parliaments have an obligation to launch a thorough review of the Basel rules, and to demand revisions that align them with the public interest.
Homeowners around the world effectively gamble on home prices.
Their risks today are often big due to real estate bubbles in such glamour cities as London, Paris, Madrid, Rome, Istanbul, Moscow, Shanghai, Hangzhou, Sydney, Melbourne, Vancouver, Los Angeles, Las Vegas, Boston, New York, Washington, D.C., and Miami.
Those bubbles may keep expanding, or may burst, leaving many homeowners mired in debt.
The risk to home prices in the aftermath of a bubble is real and substantial.
In the last cycle of real estate busts, real (inflation-corrected) home prices fell 46% in London in 1988-95, 41% in Los Angeles in 1989-1997, 43% in Paris in 1991-98, 67% in Moscow in 1993-97, and 38% in Shanghai in 1995-1999.
All of these drops were eventually reversed, and all of these markets have boomed recently.
But this does not guarantee that future drops will have a similar outcome.
On the contrary, the future real value of our homes is fundamentally uncertain.
Most homeowners are not gambling for pleasure.
They are just buying real estate because they need it.
But, because they do nothing to protect themselves against their real estate price risks, they are unwitting gamblers.
In fact, home buyers in most countries do nothing to protect themselves – short of selling their homes – because there is nothing to be done.
A market for real estate derivatives that can help balance these risks is only just beginning to appear.
Well-developed markets for real estate derivatives would allow homeowners to kick the gambling habit.
A liquid, cash-settled futures market that is based on an index of home prices in a city would enable a homeowner living there to sell in a futures market to protect himself.
If home prices fall sharply in that city, the drop in the value of the home would be offset by an increase in the value of the futures contract.
That is how advanced risk management works, as financial professionals know.
But the tools needed to hedge such risks should be made available to everyone.
Attempts to set up derivatives markets for real estate have -- so far -- all met with only limited success.
In May 2003, Goldman, Sachs & Co. began offering cash-settled covered warrants on house prices in the United Kingdom, based on the Halifax House Price Index and traded on the London Stock Exchange.
In October 2004, Hedgestreet.com began offering “hedgelets” on real estate prices in US cities – contracts that pay out if the rate of increase in home prices based on the OFHEO Home Price Index falls within a pre-specified range.
My former student Allan Weiss and I have been campaigning since 1990 for better risk management institutions for real estate.
In 1999, we co-founded a firm, Macro Securities Research, LLC, to promote the development of such institutions, working with the American Stock Exchange to create securities that would allow people to manage real estate as well as other risks.
These will be long-term securities that pay regular dividends, like stocks, whose value is tied – either positively or negatively ­– to a real estate price index.
Early this month, the Chicago Mercantile Exchange announced that it will also work with us to explore the development of futures markets in US metropolitan-area home prices.
We hope to facilitate the creation of such markets in other countries as well.
Because even many financially sophisticated homeowners will find direct participation in derivative markets too daunting, the next stage in the development of real estate risk management will be to create suitable retail products.
For example, the derivative markets should create an environment that encourages insurers to develop home equity insurance, which insures homeowners not just against a bust but also against drops in the market value of the home.
Such insurance ­should be attractive to homeowners if it is offered as an add-on to their existing insurance policies.
Derivatives markets for real estate should also facilitate the creation of mortgage loans that help homeowners manage risks by, say, reducing the amount owed if a home’s value drops.
Such products should appeal to homebuyers when the mortgage is first issued.
Insurance companies and mortgage companies ought to be willing to offer such products if they can hedge the home-price risks in liquid derivative markets.
Creating these retail products will require time, experimentation, and some real innovation.
Over the next decade, we might expect that a broad spectrum of insurance, lending, and securities companies will become involved.
As these retail products start to take shape, they will spur increased activity in the derivative markets.
As the new risk-management industry develops, its components will gradually boost each other.
These developments offer hope that current and future homeowners will be spared the agony of worrying about the vicissitudes of the real estate market.
They will be able to leave the game of real estate speculation to professionals and rest assured about the value that they have accumulated in their homes.
That is good news, because there is a pretty strong chance that we are going to see major price declines in a number of cities around the globe in the next few years, and these price declines will cause real pain to many homeowners.
But if the momentum toward better risk management continues, it will be the last real estate cycle in which homeowners are unable to protect themselves.
Many people have been asking why the dollar hasn’t crashed yet.
Will the United States ever face a bill for the string of massive trade deficits that it has been running for more than a decade?
Including interest payments on past deficits, the tab for 2006 alone was over $800 billion dollars – roughly 6.5% of US gross national product.
Even more staggeringly, US borrowing now soaks up more than two-thirds of the combined excess savings of all the surplus countries in the world, including China, Japan, Germany, and the OPEC states.
Foreigners are hardly reaping great returns on investing in the US.
On the contrary, they typically get significantly lower returns than Americans get on their investments abroad.
In an era in which stock and housing prices are soaring, the central banks of Japan and China are holding almost two trillion dollars worth of low-interest bonds.
A very large share of these are US treasury bonds and mortgages.
This enormous subsidy to American taxpayers is, in many ways, the world’s largest foreign aid program.
If America’s competitive position is so weak, what magic is holding up the dollar?
Most sober analysts have long been projecting a steady trend decline in the dollar against the currencies of America’s trading partners, especially in Asia and emerging markets.
So why hasn’t more adjustment taken place already?
The first answer, of course, is that the trade-weighted dollar has fallen – by more than 15% in real terms since its peak in early 2002.
Yet the US deficits have persisted, and even risen, since then.
The real driving force has been two-fold.
First and foremost, America’s government and consumers have been engaged in a never-ending consumption binge.
On the consumer side, this is quite understandable.
With over 80% home ownership, the epic boom in housing prices of the last ten years has spread deep into the American middle class.
Equity holdings are somewhat more concentrated, but many middle class Americans have still benefited indirectly through their pension funds.
Overall, after almost 25 years of stunning prosperity, punctuated by only two mild recessions, most Americans feel pretty confident about their economic situation.
Unemployment is at a cyclical low, and the economy appears to be less volatile than at any point in modern history.
So it is not surprising that private consumption continues to hold up even as US economic growth has shifted into lower gear.
People have enjoyed such huge capital gains over the past decade that most feel like gamblers on a long winning streak.
By now, they see themselves as playing with the house’s (or their houses’) money.
It is less easy to rationalize why the US government is continuing to run budget deficits despite a cyclical boom.
When a fiscally responsible government launches a war, it typically cuts back on other domestic expenditures and raises taxes.
The Bush administration did the opposite.
It may not be good economics, but the strategy proved to be good politics, for a time.
Unfortunately, it is unlikely the new Democratic majority in Congress will do much about it.
Of course, it takes two to tango.
In order for the US economy to run deficits with the world, other countries must be willing to spin off a counterbalancing supply of savings.
Ben Bernanke, the US Federal Reserve chairman, once famously pinned the whole US current account deficit on a “global savings glut.”
But it would be more accurate to say that there is global investment shortfall, with investment trending downwards despite the upward trend in global growth.
This investment shortfall is due to many factors, but perhaps the main one is that there are substantial medium-term institutional roadblocks to investment in many developing countries, where long-term returns now seem to be by far the highest.
The net result is that money is being parked temporarily in low-yield investments in the US, although this cannot be the long-run trend.
What then is future of the dollar?
As long as the status quo persists, with strong global growth and stunning macroeconomic stability, the US can continue to borrow and run trade deficits without immediate consequence.
Over time, the dollar will still decline, but perhaps by no more than a couple of percent per year.
Nevertheless, it is not hard to imagine scenarios in which the dollar collapses.
Nuclear terrorism, a slowdown in China, or a sharp escalation of violence in the Middle East could all blow the lid off the current economic dynamic.
In principle, one can also think of scenarios in which the dollar shoots up, but overall these seem less likely.
In sum, the fact that the US trade balance has defied gravity for so many years has made it possible for the dollar to do so, too.
But some day, the US may well have to pay the bill for its spendthrift ways.
When that day arrives, Americans had better pray that their creditors will be as happy to accept dollars as they are now.
NEW YORK – During their most recent meetings, the G-8 took a strong stance against protectionist measures in the area of foreign direct investment (FDI), echoing calls for a moratorium in such measures issued earlier by the G-20.
Both were right to do so.
According to the United Nations Conference on Trade and Development, only 6% of all the changes in national FDI regulations around the world between 1992-2002 were in the direction of making the investment climate less welcoming.
That figure doubled to 12% of all regulatory changes in 2003-2004, and almost doubled again, to 21% of all FDI regulatory changes, in 2005-2007.
In Latin America, for example, some 60% of all FDI regulatory changes in 2007 were unfavorable to foreign investors.
Overall, countries that had implemented at least one regulatory change that made the investment framework less welcoming in 2006-2007 accounted for some 40% of world FDI inflows during that period – an impressive figure that demonstrates that something very dubious is afoot.
And these data refer to formal changes in laws and regulations; no data are available on the extent to which unchanged laws and regulations are implemented in a more restrictive manner, increasing informal barriers to the entry and operations of foreign firms.
Of course, not every measure that makes the climate less welcoming for foreign direct investors is protectionist.
Basically, there are two situations that should qualify.
In the case of inward FDI, protectionism involves new official measures that are used to prevent or discourage investors from coming to or staying in a host country.
For outward FDI, protectionism involves measures that require domestic companies to repatriate assets or operations to the home country, or that discourage certain types of new investments abroad.
But the definition of FDI protectionism can become more complicated, because measures taken in the interest of legitimate public policy objectives – for example, protecting national security or increasing FDI’s contribution to the host economy – are not necessarily instances of it, even if they make the foreign-investment climate less hospitable.
Nevertheless, even with this caveat, there has been a rise of FDI protectionism that predates the current financial crisis and recession.
This suggests that a reevaluation of the costs and benefits of FDI was already underway, led, interestingly enough, by developed countries, which in the past had championed liberalization of entry and operational conditions for foreign investors and their protection under international law.
For some countries, like the United States, this reevaluation is grounded in national security concerns (largely undefined) that arose in the aftermath of the terrorist attacks of September 11, 2001.
But there also seems to be a bit of a reaction against the “new kids on the block,” namely multinational enterprises from emerging markets, especially when these are state-owned and seek to enter the US market through mergers and acquisitions.
Hence the strengthening of the active screening mechanism of the Committee on Foreign Investment in the US.
In the case of some other developed countries (for example, Canada, France, Germany), national security concerns extend to economic considerations and the protection of “national champions.”
In these countries, too, screening mechanisms have been strengthened, and China and Russia, as well as some other emerging markets, are following suit.
In some of these cases, legitimate public-policy objectives may well be involved.
But the boundary line between such objectives and protectionism can be a very fine one.
The financial crisis and recession may dampen the rise of FDI protectionism, as countries seek capital to shore up local firms and increase investment to help them promote economic recovery.
But the global downturn may also accentuate protectionism, especially if nationalistic impulses gain the upper hand, perhaps stimulated by fire-sales of domestic assets (as we saw during the Asian financial crisis).
The bottom line is that the investment climate for foreign direct investors is becoming less welcoming.
While this is certainly not the dominant approach toward FDI, we need to be vigilant that it does not become so.
What would be helpful in this respect is an objective FDI Protectionism Observatory that monitors FDI protectionist measures and names and shames countries that adopt them.
WARSAW – Remember the Partnership and Cooperation Agreement (PCA), aimed at enshrining “commonly-shared values” between Russia and the European Community?
Signed in 1994 during the hopeful early days of Russia’s first-ever democracy, the PCA was bolstered in 1999 by the creation of the European Union’s Common Security Defense Policy (CSDP).
Both sides often refer to this desire to forge closer relations as a “strategic partnership.”
But as French President Nicolas Sarkozy and German Chancellor Angela Merkel meet Russian President Dmitri Medvedev in Deauville, it would be wise to recognize that the Kremlin appears to be changing the terms of this nascent relationship.
In the wake of Russia’s apparent departure from democratization during Vladimir Putin’s presidency, and of the wars in Chechnya and Georgia, the EU has adopted increasingly cautious language, sounding less optimistic about the prospects of a real partnership.
Thus, the European Security Strategy, adopted in 2004, says only that, “we should continue to work for closer relations with Russia, a major factor in our security and prosperity.
Respect for common values will reinforce progress towards a strategic partnership.”
Russia’s August 2008 invasion of Georgia produced a sterner variation: “No strategic partnership is possible if the values of democracy, respect for human rights, and the rule of law are not fully shared and respected.”
Russians, meanwhile, are struggling to reconcile their disparate views on Europe.
Some profess to be “sick and tired of dealing with Brussels bureaucrats.”
As Konstantin Kosachev, chairman of the Russian Duma’s foreign relations committee, put it, “In Germany, Italy, France, we can achieve much more.”
Kosachev and others do not believe that the EU is committed to serious talks on “hard” security, a Russian imperative – and with good reason.
How to deal with Russia on security issues – particularly on energy security – is one of the most divisive issues facing the EU.
Despite their commitment to speak to Russia with one voice, various EU countries negotiate with Russia bilaterally whenever possible (especially over lucrative business contracts), congregating under the EU umbrella only when necessary.
That gives Russia great scope to play one country against another.
Russia, meanwhile, harbors deep disappointment with the West for its actions after communism’s collapse.
During the Gorbachev era, it was assumed that the West would stick to the essence of its Cold War containment policies.
Russians expected that, once their country was seen to be no longer confrontational and expansionist, it would be treated as a legitimate partner, not as a defeated enemy.
It would retain its status alongside the United States’ on the world stage, its territorial integrity would be unquestioned, and it would be left to manage its domestic affairs without outside interference or criticism.
Growing resentment toward the West has reinforced Russian leaders’ enduring penchant for the concepts of “Great Powers” and “spheres of influence,” and the belief that international relations is a zero-sum game, in which others’ gain is Russia’s loss.
Thus, they cannot accept that more robust multilateral institutions, confidence, cooperation, and interdependence could assure international security.
On the contrary, Russia’s loss of superpower status is completely unacceptable.
Economic growth during the Putin years, combined with the defeat of Georgia – which was regarded in Russia as the beginning of a great political comeback – provided the confidence needed to embrace efforts to re-model the transatlantic security architecture.
Medvedev’s proposed transatlantic security treaty would enshrine the principle of avoiding external force to resolve national disputes, which would rule out international intervention in the conflicts affecting the northern Caucasus, including Chechnya.
The status quo would be reinforced further by the principle that no country may increase its security to the detriment of another.
But it is unclear who decides what is detrimental.
Worse, the freedom to join military treaties, stipulated in the Helsinki Accords of 1975 and in other major international agreements like the Charter of Paris for a New Europe or the Charter for European Security, is ominously omitted.
The expansion of military alliances, such as NATO, would be declared a threatening measure.
Europe should react to this Russian proposal, first, by acknowledging that Russia has a critical role to play in transatlantic security, and that it should be treated not only with caution, but also with respect.
At the same time, a range of institutions already deals with the issue: OSCE, the NATO-Russia Council, and the Euro-Atlantic Partnership Council, to name but a few.
These existing institutions might need to be reinvigorated and fortified, but there is no need for more of them.
Second, the principle of the indivisibility of European and US security, so fundamental during the Cold War, remains valid.
Security initiatives should therefore first be discussed bilaterally within the NATO-EU framework; only then should a common position be presented at the OSCE.
Speaking to Russia with one voice is absolutely essential.
Third, the idea implicit in Medvedev’s plan – that Russia should have veto power over all security-related decisions of NATO or the EU – must be rejected.
Given that Russia’s own new military doctrine presents NATO as a potential threat, its leaders can logically claim that NATO enlargement undermines Russian security.
Russia should nonetheless be consulted on all major security issues.
NATO-Russia consultation during the drafting of the latest NATO Strategic Concept is a good example – an approach that Russia itself rejected before adopting its new military doctrine.
Consultations on the Medvedev Plan should also include other former Soviet-bloc countries, such as Ukraine.
The best way to proceed on the Medvedev Plan would be an OSCE declaration similar to the one adopted in Istanbul in 1999 – that is, a political resolution, not a legally binding treaty.
According Russia more formal recognition as a great power might help EU and US efforts to engage its leaders in a serious security dialogue.
But no treaty should be signed so long as the sincerity of Russia’s commitment to the norms of international behavior remains in doubt.
Argentina's crisis has been heating up for a long time.
So long has the country been in crisis, indeed, that the question is no longer if it may boil over, but when.
The origins of Argentina's crisis date back to decisions taken in 1991, in the fight to contain the steep inflation that marked the death throes of the military junta.
In that year, Domingo Cavallo, who already held the post of Secretary of the Treasury, took the highly symbolic decision to fix the value of the peso to the dollar through a fixed exchange rate.
Moreover, he executed this decision in another highly symbolic way, by setting the rate of exchange at one peso for one dollar.
As symbolism, this was fine.
The new ``hard'' peso marked the end of Argentina's inflationary era, a time when the country showed itself, time and again, as incapable of controlling either its budget, its currency, its inflation or its exchange rate.
This was to be the beginning of a new era, one in which a responsible, modern Argentina opened itself in a disciplined way to the United States and the world.
But, as the ancient Greeks taught, the gods destroy by granting us our wishes or fulfilling them too completely.
Without any doubt, Argentina's currency reform of a decade ago forms the roots of today's crisis.
The reason is almost obvious: Argentina is not the United States, and the peso is not the dollar.
Argentina is a little economy of the Southern hemisphere; the US is a large and diversified economy of the Northern hemisphere.
Argentina exports cows and raw materials; America exports high tech and services.
Argentina trades with Brazil, America with Japan.
Argentina must struggle to attract capital; America sucks in capital from all over the world.
For the two countries to have the same exchange rate is a crime against logic; it proved itself also a crime against Argentina.
Until 1999, everything seemed to prove Domingo Cavallo right.
Argentina's growth was fast, its inflation disappeared fast, too.
Then, the inevitable boomerang occurred: a bitter combination of shocks shattered Argentina's growth: Brazil devalued its currency, the Real, by around 50%; the cost of raw materials, prime Argentine exports, fell sharply.
All this, while the dollar was appreciating briskly, reflecting the boom of America's Clinton years.
That combination was lethal.
De facto, since 1999, growth has been negligible and Argentina has endured a thorough crisis.
This current financial crisis, which now dominates everything in Argentina, is more recent and almost tangential.
Under the influence of the recession, the budget deficit has ballooned and the creditors of Argentina's government have concluded that they would not get their money back.
In reality, the budgetary situation is not so bad: despite today's recession, Argentina's budget deficit, save for interest payments, is only about 1% of GDP.
The national debt-GDP ratio is less than 60 %, which is the average within the European Union.
Signor Cavallo, who returned to the Treasury Department in order to save his baby, is right when he asserts that the budgetary problems are simply not as awful as many people believe.
But Argentina's creditors, fearful of default, are demanding interest rates so high (around 50 % today) that there is no hope that the government can borrow at such rates.
So default no longer seems a question of ``If'' but of ``When.''
This financial crisis will probably mark the end of the Cavallo experiment, which was promoted around the world.
But the main crisis still ahead for Argentina is the economic one, which itself has lasted since 1999.
Finding a route out of it will not be easy, for no escape seems obvious: Argentina's debt is now expressed in dollars and, as in Asia in 1997, a devaluation will increase the weight of the debt.
Argentina now has just as good a chance to make things worse as to make them better.
In economics (as in most other fields of human existence), it is better to beware of symbols.
CAMBRIDGE – G-20 leaders who scoff at the United States’ proposal for numerical trade-balance limits should know that they are playing with fire. The US is not making a demand as much as it is issuing a plea for help.
According to a recent joint report by the International Monetary Fund and the International Labor Organization, fully 25% of the rise in unemployment since 2007, totaling 30 million people worldwide, has occurred in the US.
If this situation persists, as I have long warned it might, it will lay the foundations for huge global trade frictions.
The voter anger expressed in the US mid-term elections could prove to be only the tip of the iceberg.
Protectionist trade measures, perhaps in the form of a stiff US tariff on Chinese imports, would be profoundly self-destructive, even absent the inevitable retaliatory measures.
But make no mistake: the ground for populist economics is becoming more fertile by the day.
The new US Congress is looking for scapegoats for the country’s economic quagmire.
And, with a president who has sometimes openly questioned rigid ideological adherence to free trade, anything is possible, especially in the run-up to the 2012 presidential election.
If trade frictions do boil over, policymakers may look back on today’s “currency wars” as a minor skirmish in a much larger battle.
In light of America’s current difficulties, its new proposal for addressing the perennial problem of global imbalances should be seen as a constructive gesture.
Rather than harping endlessly on China’s currency peg, which is only a small part of the problem, the US has asked for help where it counts: on the bottom line.
True, today’s trade imbalances are partly a manifestation of broader long-term economic trends, such as Germany’s aging population, China’s weak social safety net, and legitimate concerns in the Middle East over eventual loss of oil revenues.
And, to be sure, it would very difficult for countries to cap their trade surpluses in practice: there are simply too many macroeconomic and measurement uncertainties.
Moreover, it is hard to see how anyone – even the IMF, as the US proposal envisions – could enforce caps on trade surpluses.
The Fund has little leverage over the big countries that are at the heart of the problem.
Still, even if other world leaders conclude that they cannot support numerical targets, they must recognize the pain that the US is suffering in the name of free trade.
Somehow, they must find ways to help the US expand its exports.
Fortunately, emerging markets have a great deal of scope for action.
India, Brazil, and China, for example, continue to exploit World Trade Organization rules that allow long phase-in periods for fully opening up their domestic markets to developed-country imports, even as their own exporters enjoy full access to rich-country markets.
Lackluster enforcement of intellectual property rights exacerbates the problem considerably, hampering US exports of software and entertainment.
A determined effort by emerging-market countries that have external surpluses to expand imports from the US (and Europe) would do far more to address the global trade imbalances over the long run than changes to their exchange rates or fiscal policies.
Emerging markets have simply become too big and too important to be allowed to play by their own set of trade rules.
Their leaders must do more to tackle entrenched domestic interests and encourage foreign competition.
Germany might rightly argue that it has followed a relatively laissez-faire attitude towards trade, and that it should not be punished, despite its chronic surpluses.
After all, it has stood by as the euro has soared recently.
Nevertheless, Germany is a huge winner from global free trade, and it is hardly without tools and means to reduce its surpluses – for example, by pressing to de-regulate its highly rigid product markets.
Given all its recent economic challenges, it is remarkable how, so far, the US has remained steadfast in its support of free trade.
Even in cases where its rhetoric has sent mixed messages, US policies have been decidedly liberal.
Consider the long-suffering US-Colombia free-trade negotiations.
Although one would never know it from listening to the Congressional debate, the main effect of an agreement would be to lower Colombian barriers on US goods, not vice versa.
Colombian goods already enjoy virtual free entry to the US market, while Colombian consumers would benefit enormously if their country were to reciprocate by opening its markets to US goods and services.
This has not happened – one of countless examples of obstacles faced by US companies around the world.
All should be eliminated.
American hegemony over the global economy is perhaps in its final decades.
China, India, Brazil, and other emerging markets are in ascendancy.
Will the transition will go smoothly and lead to a global economy that is both fairer and more prosperous?
However much we may hope so, the current rut in which the US finds itself could prove to be a problem for the rest of the world.
Unemployment in the US is high, while fiscal and monetary policies have been stretched to their limits.
Exports are the best way out, but the US needs help.
Otherwise, simmering trade frictions could suddenly throw globalization sharply into reverse.
It wouldn’t be the first time.
NEW YORK – The killing of Osama bin Laden by United States special forces constitutes a significant victory over global terrorism.
But it is a milestone, not a turning point, in what remains an ongoing struggle with no foreseeable end.
The significance of what was accomplished stems in part from Bin Laden’s symbolic importance.
He has been an icon, representing the ability to strike with success against the US and the West.
That icon has now been destroyed.
Another positive consequence is the demonstrated effect of counter-terrorism operations carried out by US soldiers.
As a result, some terrorists, one hopes, will decide to become former terrorists – and some young radicals might now think twice before deciding to become terrorists in the first place.
But any celebration needs to be tempered by certain realities.
Bin Laden’s demise, as welcome as it is, should in no way be equated with the demise of terrorism.
Terrorism is a decentralized phenomenon – in its funding, planning, and execution.
Removing Bin Laden does not end the terrorist threat.
There are successors, starting with Ayman al-Zawahiri in Al Qaeda, as well as in autonomous groups operating out of Yemen, Somalia, and other countries.
So terrorism will continue.
Indeed, it could even grow somewhat worse in the short run, as there are sure to be those who will want to show that they can still strike against the West.
The best parallel that I can think of when it comes to understanding terrorism and how to deal with it is disease.
There are steps that can and should be taken to attack or neutralize certain types of viruses or bacteria; to reduce vulnerability to infection; and to reduce the consequences of infection if, despite all of our efforts, we become ill.
Disease is not something that can be eliminated, but often it can be managed.
There are obvious parallels with terrorism.
As we have recently witnessed, terrorists can be attacked and stopped before they can cause harm; individuals and countries can be defended; and societies can take steps to bolster their resilience when they are successfully attacked, as on occasion they inevitably will be.
These elements of a comprehensive counter-terrorism strategy can reduce the threat to manageable, or at least tolerable, levels.
But tolerable is not good enough when it comes to protecting innocent life.
We want to do better.
The answer is to be found in the realm of prevention.
More must be done to interrupt the recruitment of terrorists, thereby reducing the threat before it materializes.
Most terrorists today are young and male.
And, while the overwhelming majority of the world’s Muslims are not terrorists, many of the world’s terrorists are Muslim.
It would help enormously in this regard if Arab and Muslim political leaders spoke out against the intentional killing of men, women, and children by anyone or any group for political purposes.
There is also a pivotal role here for religious leaders, educators, and parents.
Terrorism must be stripped of any legitimacy that it may be viewed as having.
One potential positive development here stems from the political changes that we are seeing in many parts of the Middle East.
There is a greater chance than before that young people will become more integrated in their own societies (and less susceptible to the appeal of extremism) if they enjoy greater political and economic opportunity.
Pakistan will most likely prove critical in determining the future prevalence of terrorism.
Unfortunately, while it is home to some of the world’s most dangerous terrorists, it is decidedly less than a full partner in the struggle against it.
Some parts of the Pakistani government are sympathetic to terrorism and unwilling to act against it; other parts simply lack the capacity to act against it effectively.
Capacity is much easier to provide than will.
The outside world can and should continue to provide assistance to help Pakistan acquire the strength and skills required to tackle modern-day terrorists.
But no amount of external assistance can compensate for a lack of motivation and commitment.
Pakistani leaders must choose once and for all.
It is not enough to be a limited partner in the struggle against terror; Pakistan needs to become a full partner.
There will be Pakistanis who protest against the recent American military action, arguing that it violated Pakistan’s sovereignty.
But sovereignty is not an absolute; it involves obligations as well as rights.
Pakistanis must understand that they will forfeit some of those rights if they do not meet their obligation to ensure that their territory is not used to shelter terrorists.
If things do not change, the sort of independent military operation carried out by US soldiers will become less the exception than the rule.
This is not nearly as desirable an outcome as Pakistan joining what should be a common international effort.
At stake is not only assistance, but Pakistan’s own future, for, in the absence of genuine commitment to counter-terrorism, it is only a matter of time before the country falls victim to the infection that it refuses to treat.
VIENNA – Nuclear power has become safer since the devastating accident one year ago at Fukushima, Japan.
It will become safer still in the coming years, provided that governments, plant operators, and regulators do not drop their guard.
The accident at Fukushima resulted from an earthquake and tsunami of unprecedented severity.
But, as the Japanese authorities have acknowledged, human and organizational failings played an important part, too.
For example, Japan’s nuclear regulatory authority was not sufficiently independent, and oversight of the plant operator, TEPCO, was weak.
At the Fukushima site, the backup power supply, essential for maintaining vital safety functions such as cooling the reactors and spent fuel rods, was not properly protected.
Training to respond to severe accidents was inadequate.
There was a lack of integrated emergency-response capability at the site and nationally.
Human and organizational failings are not unique to Japan.
Fukushima was a wake-up call for all countries that use nuclear power.
It prompted serious soul-searching and recognition that safety can never be taken for granted anywhere.
Key causes of the accident have been identified.
Indeed, governments, regulators, and plant operators around the world have begun learning the right lessons.
A robust international nuclear safety action plan is being implemented.
As a result, the likelihood of another disaster on the scale of Fukushima has been reduced.
What, exactly, has changed?
Perhaps most importantly, the worst-case assumptions for safety planning have been radically revised.
At Fukushima, the reactors withstood a magnitude 9.0 earthquake – far more powerful than they were designed to tolerate.
But the plant was not designed to withstand the 14-meter-high tsunami waves that swept over its protective sea wall less than an hour later.
In the aftermath of Fukushima, defenses against multiple severe natural disasters, including earthquakes and tsunamis, are being strengthened at nuclear facilities all over the world.
Measures are being taken to improve preparedness for prolonged power outages, protect backup power sources, and ensure the availability of water for cooling even under severe accident conditions.
Global nuclear safety standards are being reviewed.
National and international emergency-response capabilities are being upgraded.
Plant operators and national regulators are being scrutinized more critically.
Countries are opening their plants to more –amp#160;and more thorough – international safety reviews.
Despite the accident, global use of nuclear power looks set to grow steadily in the next 20 years, although at a slower rate than previously forecast.
The reasons for this have not changed: rising demand for energy, alongside concerns about climate change, volatile fossil-fuel prices, and the security of energy supplies.
It will be difficult for the world to achieve the twin goals of ensuring sustainable energy supplies and curbing greenhouse gases unless nuclear power remains an important part of the global energy mix.
The International Atomic Energy Agency expects at least 90 additional nuclear-power reactors to join the 437 now in operation globally by 2030.
Although some countries abandoned or scaled back their nuclear energy plans after Fukushima, major users of nuclear power, such as China, India, and Russia, are going forward with ambitious expansion plans.
Many other countries, mainly in the developing world, are considering introducing nuclear power.
Nuclear safety is of the utmost importance to both established users and newcomers.
It matters to countries that have decided to phase out nuclear power, because their plants will continue to operate for decades and will need to be decommissioned, with nuclear waste stored safely.
And it matters to countries that are firmly opposed to nuclear power, as many of them have neighbors with nuclear-power plants.
Countries planning new nuclear-power programs must recognize that achieving their goals is a challenging, long-term undertaking.
They need to invest considerable time and money in training scientists and engineers, establishing genuinely independent, well-funded regulators, and putting in place the necessary technical infrastructure.
Some countries still have shortcomings in this regard.
Nonetheless, contrary to popular perception, nuclear power has a good overall safety record.
New reactors being built today incorporate significantly enhanced safety features, both active and passive, compared to the Fukushima generation of reactors.
But, in order to regain and maintain public confidence, governments, regulators, and operators must be transparent about the benefits and risks of nuclear power – and honest when things go wrong.
The fact that an accident such as Fukushima was possible in Japan, one of the world’s most advanced industrial countries, is a reminder that, when it comes to nuclear safety, nothing can be taken for granted.
Complacency can be deadly.
The safety improvements seen in the past 12 months can only be a start.
We must not slip back into a “business as usual” approach as Fukushima recedes from memory.
NEW YORK – The World Health Organization has now officially declared the H1N1 flu virus to be a global pandemic.
Governments, international organizations, and people around the world are rightly focused on fighting it.
The speed with which the H1N1 virus has spread to almost every continent highlights our mutual interdependence.
Nowadays, the impact of disease in one country is ultimately felt by all.
Any effective response, therefore, must be grounded in a sense of global solidarity and enlightened self-interest.
We must recognize, yet again, that we are all in this together.
When a new disease sweeps the world, access to vaccines and anti-viral medicines cannot be limited to those who can pay for them.
Wealthy nations cannot hope to remain healthy if poorer nations do not.
Virus samples and information must be shared openly and quickly.
Governments and major pharmaceutical companies must be sure that poorer nations receive the medical supplies they need.
Even as we cope with today’s challenge, however, we must look ahead.
Beyond this pandemic, there almost certainly lurks another down the road – potentially far more serious.
The same principles of solidarity must guide us as we mobilize to meet the other health challenges that afflict the world populations, and the poorest in particular.
Around the world, one woman dies every minute in childbirth.
More than a billion people continue to suffer from neglected tropical diseases – often easy to prevent and easy to control.
Just as we once eliminated smallpox, so can we eliminate others.
It also bears remembering that 60% of the world’s population dies of non-communicable illnesses such as cancer or heart disease.
That is why, in speaking about development and the stability of nations, we place such emphasis on health, particularly of the most vulnerable, and why, at a time of multiple crises, we will take up the issue of health this week in New York.
Continuing to invest in global health makes sense both in terms of lives and dollars saved.
Healthy people are more productive.
They take fewer days off work.
They live longer, go further in school, and tend to bear fewer and more prosperous children as they invest more in the children they do have.
Studies have shown that investments in health care can yield a six-fold economic return.
To offer but one example: the global impact of maternal and newborn deaths has been estimated at US$15 billion a year in lost productivity.
And yet, when hard times hit, spending on health is often among the first things to be cut.
During past recessions, especially in developing economies, the best care has tended to go to the wealthy; the poor, too often, have been left to fend for themselves.
But the social and economic health of any society depends on the physical health of all its members.
When governments cut back on primary health care for their poorer citizens, the entire society ultimately pays a high price.
Today, large parts of Africa, Latin America, and Asia have still not recovered from mistakes made during previous economic downturns.
Nothing is more important than investing in maternal health.
In the poorest countries, especially, women make up the fabric of society.
Disproportionately, they farm the land, carry the water, raise and educate the children, and care for the sick.
Investing in maternal health should thus be a high priority.
Yet, of all the Millennium Development Goals, maternal health is the slowest to be achieved.
As a result, worldwide mortality rates in 2005 were 400 maternal deaths per 100,000 live births – barely changed since 1990.
In Africa, the ratio is 900 per 100,000.
The harsh reality behind these figures is this: mothers, very often young, are dying for lack of what most of us take for granted in the twenty-first century – access to affordable health care.
Maternal health care is also a barometer of how well a health system functions.
If women have access to hospitals and clinics, they are less likely to die in childbirth.
These hospitals and clinics in turn reduce the burden of illness and deaths from other causes as well.
Failure to mobilize the resources and muster the political will to put an end to this senseless tragedy would be unforgivable.
We have made progress on so many other fronts.
We are within a few years of ending deaths from malaria.
Mass immunization has largely eliminated polio.
Thanks to new programs of oral rehydration and improved water and sanitation, we have seen marked gains in treating dysentery and other parasitic diseases, contributing to a 27% decline between 1990 and 2007 in mortality rates for children under five.
Yes, the world faces its first influenza pandemic in more than 40 years.
We must remain on guard against changes in the virus.
We must also be prepared for potentially different impacts in parts of the world where malnutrition, HIV/AIDS, and other serious health conditions are prevalent.
In short, we must remain vigilant and continue actively to manage this pandemic.
At the same time, the pandemic reminds us that we need to think and act beyond it.
Only by doing so can we truly protect our people, our countries, our economy, and our global society.
All revolutions, in the end, turn from euphoria to disillusion.
In a revolutionary atmosphere of solidarity and self-sacrifice, people tend to think that when their victory is complete, paradise on Earth is inevitable.
Of course, paradise never comes, and – naturally - disappointment follows.
That seems to be the case in Ukraine today, as its people prepare to vote for a new parliament little more than a year after their successful Orange Revolution.
Post-revolutionary disillusion, especially after the revolutions against communism - and in Ukraine's case revolution against post-communism - is rooted in psychology.
New circumstances imposed new challenges for most people.
Formerly, the state decided everything, and many people, particularly in the middle and older generation, began to see freedom as a burden, because it entailed continuous decision-making.
I have sometimes compared this psychological ennui to my own post-prison situation: for years I yearned for freedom, but, when finally released, I had to make decisions all the time.
Confronted suddenly with many options every day, one starts to feel a headache, and sometimes unconsciously wants to return to prison.
This depression is probably inevitable.
But, on a societal scale, it is eventually overcome, as new generations grow up.
Indeed, 15 years after the disintegration of Soviet Union, a new catharsis seems underway, and Ukraine’s Orange Revolution was part of that.
As Ukraine so clearly shows, the process of self-liberation from communism was, by definition, associated with a gigantic privatization.
Naturally, members of the old establishment, with their inside knowledge and connections, gained much of the privatized property.
This "inevitable" process poisoned political life and the media, which led to a strange state of limited freedom and a mafia-like environment.
The shadings differed from country to country in the post-communist world, but the new generations rising in these societies now seem to be fed up with it.
Ukraine’s Orange Revolution, as well as Georgia’s Rose Revolution, seems to confirm this.
While revolutions in the late 1980’s and early 1990’s were directed against totalitarian communist regimes, nowadays they aim to get rid of this mafia-type post-communism.
But to make the change irreversible, a truly independent and incorruptible judiciary is essential.
Too often in politically connected cases, suspicions and charges of wrongdoing are not pursued to an unambiguous conclusion.
This is understandable: the communist justice system was manipulated to serve the regime, and thousands of judges cannot be replaced overnight.
Although it is clear that a return to the old Soviet Union is not possible, some blame Russian influence for the disillusion in Ukraine.
Yes, there are some alarming elements in Russian policy, mostly because Russia has never really known where it begins and where it ends.
It either owned or dominated many other nations, and now it is only with grudging reluctance dealing with the loss of them all.
Some of Russian President Vladimir Putin’s statements seem to recall the Soviet era with nostalgia.
Indeed, he recently called the disintegration of the Soviet Union a tragic mistake.
But Soviet nostalgia has far more to do with Russia’s traditional Great Power ambitions than with communism.
Russia, I believe, should clearly say – and the international community should clearly say to Russia – that it has defined borders that will not be questioned, because disputed borders lie at the core of most conflicts and wars.
On the other hand, I don’t want to demonize Putin.
He may lower oil prices for someone close to him, like Belarus’ dictator Alexander Lukashenko, and insist on a market price for someone else, but that’s basically all he can do.
I don't envision any serious conflict beyond that.
The promise of Western integration is one reason that conflict seems impossible, for it is a question of geography as much as shared values and culture.
Ukraine belongs to a united European political entity; the values that Ukraine endorses and that are embedded in its history are European to the core.
The Czech experience shows that implementing all of the European Union’s norms so as to be ready to qualify for membership takes some time.
But in principle, Ukraine can succeed as well.
Much the same is true for Ukraine and NATO.
Partnerships based on shared rules, standards, and values are the heartbeat of modern security.
Moreover, NATO in a way defines the sphere of a civilization, which of course doesn’t mean that NATO’s community is better than any other.
But it’s a community that is good to belong to – provided that people want it and that it makes historical sense for them.
NATO membership carries obligations, because situations may arise – and we have already experienced them – when NATO follows a United Nations appeal and conducts an out-of-area military intervention where, for example, genocide is being committed.
In other words, NATO membership, like EU membership, comes at a price.
However, I think that the advantages far outweigh any possible disadvantages.
It is up to Ukrainians to decide this for themselves and thus to overcome post-revolutionary disillusion.
COPENHAGEN – At its heart, much of the debate over climate change deals with just one divisive and vexing question: How big should cuts in carbon emissions be?
This narrow focus makes the debate unconstructive.
Everybody wants to prevent global warming, and the real question is: How can we do that best?
We should be open to other ways to stop warming – such as cutting carbon emissions in the future instead of now, or focusing on reducing emissions of other greenhouse gases.
Global warming will create significant problems, so carbon reductions offer significant benefits.
Cutting carbon emissions, however, requires a reduction in the basic energy use that underpins modern society, so it will also mean significant costs.
The prominent climate economist Professor Richard Tol of Hamburg University has analyzed the benefits and costs of cutting carbon now versus cutting it in the future.
Cutting early will cost $17.8 trillion, whereas cutting later will cost just $2 trillion.
Nonetheless, the reduction in CO2 concentration – and hence temperature – in 2100 will be greater from the future reductions.
Cutting emissions now is much more expensive, because there are few, expensive alternatives to fossil fuels.
Our money simply doesn’t buy as much as it will when green energy sources are more cost-efficient.
Tol strikingly shows that grand promises of drastic, immediate carbon cuts – reminiscent of the call for 80% reductions by mid-century that some politicians and lobbyists make – are an incredibly expensive way of doing very little good.
All the academic models show that, even if possible, limiting the increase in global temperature to 2oC, as promised by the European Union and the G-8, would cost a phenomenal 12.9% of GDP by the end of the century.
This would be the equivalent of imposing a cost of more than $4,000 on each inhabitant every year, by the end of the century.
Yet, the damage avoided would likely amount to only $700 per inhabitant.
The real cost of ambitious, early, and large carbon-cutting programs would be a reduction in growth – particularly damaging to the world’s poor – to the tune of around $40 trillion a year.
The costs would also come much sooner than the benefits and persist much longer.
For every dollar that the world spends on this grand plan, the avoided climate damage would only be worth two cents.
It would be smarter to act cautiously by implementing a low carbon tax of about $0.5 per ton – about 0.5 US cent per gallon of gas or 0.1 euro-cent per litre of petrol – and increase it gradually through the century.
This would not cut carbon emissions spectacularly, but nor would it be a spectacular waste of public funds.
Each dollar would avoid $1.51 of global warming damages – a respectable outcome.
Taxing fossil fuels to reduce carbon emissions is a sensible part of the solution to climate change, but it is not the only or best way to prevent warming.
There are other ways to cut carbon from the atmosphere.
One of these is protecting forests, since deforestation accounts for 17% of emissions.
If we are actually serious about grand promises to keep global temperature rises below 2ºC, we obviously need to find ways of making this cheaper.
Professor Brent Sohngen of Ohio State University points out that forests could be important: including forestry in the control of greenhouse gases could somewhat reduce costs.
Moreover, although politicians focus nearly exclusively on cutting carbon emissions, CO2 is not the only gas causing warming.
The second-biggest culprit is methane.
Cutting methane is actually cheaper than cutting carbon.
And because methane is a much shorter-lived gas than CO2, we can prevent some of the worst of short-term warming through its mitigation.
Agricultural production accounts for half of anthropogenic methane, but wastewater systems, landfills, and coal mining also create the gas.
Professor Claudia Kemfert of the German Institute for Economic Research (DIW) argues that spending $14 billion to $30 billion to reduce methane would create benefits – from the reduction in warming – between 1.4 and three times higher.
We could also put a bigger focus on reducing black carbon, considered responsible for as much as 40% of current net warming and one-third of Arctic melting.
Black carbon is essentially the soot produced by diesel emissions, and – in developing countries – by the burning of organic matter to cook food and stay warm.
It can be eliminated with cleaner fuels and new cooking technologies.
Doing so would yield other benefits as well.
Sooty pollution from indoor fires claims several million lives each year, so reducing black carbon would be a life-saver.
A team of economists led by David Montgomery estimates that spending $359 million could realistically slash 19% of black carbon emissions.
This would have a significant cooling impact on the planet, and would save 200,000 lives from pollution.
The net annual benefits would run into several billion dollars, which equates to $3.60 worth of avoided climate damage for each dollar spent.
Costs and benefits matter.
The best solution to climate change achieves the most good for the lowest cost.
With this as our starting point, it is clear that a narrow focus on short-term carbon emission cuts is flawed.
The most pertinent question of all is: Why don’t we choose a solution to global warming that will actually work?
China’s decision to execute the head of its drug regulatory agency has rekindled international debate about capital punishment.
It is an age-old question, one that harks back to Plato, who in his “Laws” saw the need to punish by death those who commit egregious crimes.
Supporters of capital punishment usually put forward three arguments to justify state-sanctioned killing of those who take the life of another.
First, there is the old law of “an eye for an eye, a tooth for a tooth.”
In the words of Immanuel Kant, not some Texas governor, no other “penalty is capable of satisfying justice.”
Then there is a utilitarian argument: capital punishment deters many criminals from murder.
Furthermore, killing murderers prevents recidivism: if released from prison, they might kill again.
The third argument is also utilitarian, although of a lower quality: the state saves money by killing murderers instead of keeping them in prison for life at the expense of the community.
Abolitionists respond with two ethical arguments.
First, in a modern democracy, punishment must be not only retributive, but should also try to rehabilitate the criminal in order to enable him to live in society with other human beings.
But, while this is a compelling argument, those who know modern prisons recognize that many inmates are not susceptible to improvement – a fact that cannot be attributed only to conditions of detention.
The second ethical argument is based on the commandment “thou shalt not kill” which also enjoins the state from killing.
But this argument is undermined by the fact that the state can resort to lethal force to prevent serious crimes, or to fight a war or rebellion.
Opponents of the death penalty also rely on utilitarian arguments.
The death penalty is irreversible.
If a convict turns out to be innocent, his execution cannot be undone.
Moreover, abolitionists assail the deterrent effect of the death penalty.
Thucydides, in recounting the Athenians’ discussion of what penalty to impose on the rebellious Mytilenians, noted that “the death penalty has been laid down for many offenses, yet people still take risks when they feel sufficiently confident; it is impossible for human nature, once seriously set upon a certain course, to be prevented from following that course by the force of law or by any other means of intimidation whatsoever.”
Criminologists have shown, statistically, that in US states where convicts are executed, serious crimes have not diminished.
Other criminologists argue that this finding, if well-founded, should then apply to any criminal law: every day, criminal prohibitions are infringed; yet if we did not have such prohibitions, crimes would be even more rampant.
In their view, capital punishment serves at least to restrain the homicidal leanings of human beings.
So the death penalty debate boils down to an exchange of conflicting ethical and utilitarian views.
But we should not sit idly by and refrain from taking sides.
I, for one, believe that the death penalty radically negates the doctrine of human rights, which is founded on respect for life and the dignity of human beings.
But, whether or not you oppose the death penalty, two lessons can be drawn from the debate.
First, the fight for human dignity and respect for life, as with any struggle for human rights, is set in motion and tenaciously pursued by members of civil society, by individuals more than by states.
It was a representative of the Age of Reason, Cesare Beccaria, who first advocated in 1764, in a few pages of a seminal booklet, the abolition of capital punishment.
Indeed, it is thanks to a few thinkers and activists that states have gradually moved away from age-old tenets.
As Tommaso Campanella, a great philosopher who spent much time in prison and was tortured because of his ideas, wrote a few centuries ago, “history is changed first by the tongue and then by the sword.”
Nowadays, it is associations such as Amnesty International and Hands Off Cain that push states to abolish capital punishment.
The second lesson is that the death penalty debate should not absorb all our attention.
If we intend to abolish the gallows, we should also fight for the prevention of crime and against the inhumanity of many prisons.
After all, what is the point of suggesting imprisonment as an alternative to electrocution, if inmates are subjected to inhuman and degrading treatment?
How can we ignore that a high number of inmates commit suicide – self-inflicted capital punishment – to escape the inhumanity of their imprisonment?
How can we ignore that many states today kill not only through legal punishment, but also by murdering and massacring in international or civil wars, or by allowing starvation?
In short, opposition to the death penalty cannot be an end in itself, for it is only one element of a more general fight for human dignity.
TEL AVIV – Finally, the long-sought truce between Israel and Hamas in the Gaza Strip has become a reality.
Reaching this uneasy state has not been easy.
For months, wise and responsible people had exhorted Israel to accept the ceasefire that the Hamas leadership in Gaza had proposed.
But Israel’s government, using all kinds of pretexts, stubbornly resisted.
“A truce would weaken Palestinian President Abu Mazen,” officials claimed, as if the construction of new Israeli settlements in East Jerusalem and the refusal to dismantle previous illegal ones had not already weakened him.
Or they argued that “Hamas does not recognize the state of Israel,” as if other ceasefire agreements with the Arab states and the PLO in the last 60 years had been based on recognition of Israel, rather than on a simple ethical principle that has guided Israel for many years, namely to gain, for us and our enemies, a pause in hostilities.
In the end, however, logic prevailed over escapism and hesitation, a ceasefire was signed, and we can only regret all the time that was lost and the unnecessary suffering on both sides.
In this war, which has been going on for nearly a century, it is important to keep one principle in mind: the Palestinians are Israel’s neighbors and will live side by side with Israelis forever.
Because of this simple fact, the military considerations are very different from those in a conflict between countries that are distant from each other.
Memories of spilled blood, be it Israeli or Palestinian, remain vivid in the hearts of both peoples.
An immediate break in the hostilities is therefore more important than a chimerical long-term “capitulation.”
The launch of five Qassam rockets into Israel five days after the signing of the truce suggests its precariousness.
So can it last and evolve into something durable?
Opponents of the truce predict, – indeed, wish – that it will be short-lived.
But even skeptics nourish many hopes.
To be sure, if this new truce is merely technical, if efforts are not made to stabilize and consolidate it, it could become just one another in a long string of bitter episodes.
But all who had feared a “great Israeli offensive” in Gaza should make every effort to strengthen the truce and create a climate for relaxing tensions that could, with time, lead to a peace agreement with the Palestinian Authority.
So what should be done to bring this about?
Above all, border crossings between Israel and the Palestinian territories should be reopened for the sick, for students, and for families whose members were separated by the blockade.
Second, a generous (and, with time, growing) quota should be set for Palestinian laborers to work in Israel – indeed, they must be allowed to work in the very agricultural centers around Gaza which were the most affected by the rocket attacks.
Palestinians working in Israel are good for both sides, and better than the foreigners who come from distant lands and live an isolated life in Israel, solitary and under constant threat of expulsion.
Palestinian workers, who go back home every night, do not become alienated from their normal life.
Future workers from Gaza, having a moral right to earn their living in Israel, will become natural supporters of the maintenance of the truce.
Furthermore, past industrial projects that fell victim to the hostilities should be revived and made more legitimate in the eyes of Hamas through the participation of the Arab state.
The killing by Israel of Hamas terrorists in the West Bank should also be stopped – or at least limited as much as possible – and the Palestinian Authority should be permitted to deal with them in their own way.
Above all, we must assure that the armistice has its own dynamic.
In a state of war, people get used to the status quo and cannot imagine anything else.
But when tensions relax, the idea of taking up arms again becomes painful and unsupportable inasmuch as it means a return to the familiar and terrible experience of suffering.
So this truce must be seen not as a piece of paper with some legal significance, but as a young plant that needs to be tended to, watered, nursed, and protected, so that it grows into a strong and robust tree that cannot be uprooted with an occasional Qassam rocket or a stray grenade.
Last Spring, The Economist trumpeted “womanpower” as 
 the
 driving force for the world economy.
But if Europe’s economy is to become more competitive and innovative, it is not enough that women enter the labor market in droves.
To reap the full fruits of women’s talents, they must be in more top jobs, too, both in the public and private sector.
Women in Western Europe have long since bridged the education gap with their male peers.
Women not only outnumber men at universities; they also outperform them, most notably in math, physics, and information science.
But female students’ academic achievements have not increased women’s presence in top jobs.
In Europe, the percent of women on corporate boards remains in single digits, as is true of the top ranks of government and academia.
While in the United States almost one out of five corporate officers are women, in mainland Europe the female to male ratio on company boards is one to twenty or worse.
The situation is only slightly better in science.
One of every ten professors in Europe is a woman.
In the US, the ratio is – once again – more favorable to women, with more than 20% of professors at American universities being female. 
Europe cannot afford to waste valuable human capital at a time when China and India are on the rise and its own population is aging.
The first baby boomers have reached retirement age, and the labor force will soon be shrinking in most parts of Europe.
To cover the costs of aging and maintain its position as an economic power, Europe must increase overall labor participation considerably.
Not only can and must fathers assume a greater role in child rearing; a large part of homemaking is perfectly suitable to be met by the market.
As economists Ronald Schettkat and Richard Freeman have pointed out, career women do not necessarily work more hours per week than women with part-time jobs or stay-at-home moms.
Instead, they tend to outsource activities like grocery shopping, cooking, and cleaning.
If women in Europe work more hours in better quality jobs, it will stimulate demand for service jobs like cleaning and child care, thus reducing unemployment among low-skilled workers.
Moreover, the increased supply of high-quality female labor will not incur additional healthcare and pension costs, unlike labor immigration.
Women use those benefits anyway, whether they are stay-at-home moms or perform paid work outside the home.
Because people live longer and procreate less, raising and caring for children requires less of a parent’s life than it used to.
Women should be able to aspire to top jobs without squandering their fertility, and their success would encourage women in lower-ranking positions, because female managers tend to implement more gender-conscious hiring policies and serve as strong role models.
Obstacles to the professional advancement of educated women in Europe is rooted in corporate culture, gender biases, and stereotyping, rather than outright discrimination.
Group dynamics prevent company boards that consist solely of males from including women, even if members individually would support such a decision.
Moreover, those women who do reach higher-ranking positions are susceptible to a visibility-vulnerability spiral, owing to their minority status.
As long as women are perceived to be the weaker sex, men and women alike will project their own feelings of vulnerability onto the female candidate.
Such exclusionary group dynamics can be overcome only by attaining a critical mass of women in high-ranking positions.
The benefits of doing so would be enormous.
Studies show that companies with more women in senior management are more profitable than those with few women at the top.
Diversified management means better management.
Including more women in top positions, both in the public and private sector, changes decision-making processes fundamentally, because women tend to play down the importance of formalities and communicate directly, thereby overcoming organizational blockages.
A decisive pro-women strategy would thus create new momentum for Europe, allowing it to compete with the United States and Asia.
At the start of this year, Norway enacted legislation that requires that both sexes be represented by at least 40% on all corporate boards.
Companies that do not meet the new gender rules, which also apply to the public sector – risk being dissolved by court order.
Spain’s prime minister, José Zapatero, recently proposed similar standards for gender balance in business and politics.
Norway has set an excellent example – one that all of Europe should follow as the best way to transcend the culture of gender bias and stereotyping that is still prevalent in many companies and institutions.
But women, too, must adjust.
The reality is that top jobs require more than two workdays a week, and they do not coincide with school hours.
Assuming the responsibilities that have long belonged to men requires that women let go of the tasks that have prevented them from advancing beyond low-ranking positions. 
China's government has sentenced two of its citizens to life in prison for their role in securing prostitutes for hundreds of male Japanese visitors in the southern city of Zhuhai last autumn.
The Chinese government is also pressuring Tokyo to turn over the Japanese businessmen who allegedly requested the prostitutes.
This story made headlines around the world, and fits well with how the world press typically covers Sino-Japanese relations.
Regrettably, such incidents recur with enough regularity to feed the media machine that continues to stir a nationalism rooted in conflicting historical memories.
Japanese Prime Minister Junichiro Koizumi's annual visits to the Yasukuni Shrine - which is widely viewed as a symbol of Japan's former militarism - is a conspicuous example of this.
The publicity that the press gives to these visits has helped impede an invitation to Koizumi from China's leaders for a state visit.
Recently, the discovery of mustard gas canisters left behind by Japanese forces during World War II has also served to keep memories of the Imperial Japanese Army's wartime conduct alive among older Chinese.
Moreover, rival Sino-Japanese claims to the Senkaku (or Diao Yutai) Islands resurfaced last year when the Japanese government leased three islets in the chain from private parties.
The action, purportedly undertaken to reduce the prospect of landings and demonstrations by Japanese right-wingers, set off a brief, though frenzied, reaction in China, as well as in Hong Kong and Taiwan.
Meanwhile, differences over Taiwan also foster tensions periodically, such as when former Taiwanese President Lee Teng-hui sought to visit Japan for medical treatment.
But this is not the whole story.
Although such incidents reveal a troubling level of mistrust between the Chinese and Japanese that is not merely a product of media coverage, it is noteworthy that both governments have worked consistently, diligently, and with considerable success to resolve such problems and contain their political fallout.
Of course, official relations between the two countries are marked by much political and economic competition - some of it healthy, some of it a possible harbinger of future strategic rivalry.
The competitive strain in Sino-Japanese relations is especially visible in energy politics.
Demand for oil in Asia is growing rapidly, and with China and Japan increasingly dependent upon imports, each has naturally sought to improve its energy security by diversifying sources of supply.
Both countries covet access to Russian reserves, especially those located in the Angarsk fields of Siberia.
Last spring China appeared to have locked up a Russian commitment to build a pipeline to service the China market at Daqing.
Japan, however, raised the ante with new offers of financial incentives.
Its bid for an alternative pipeline to Nakodka to serve Japanese, Korean, and other markets remains alive, creating another point of competitive friction.
In their rivalry for leadership in promoting Asian regional cooperation, meanwhile, China has taken an early lead.
Two years ago, China trumped Japan by offering a Free Trade Agreement to the members of the Association of Southeast Asian Nations, while front-loading its own tariff concessions.
More recently, China, along with India, signed an ASEAN-proposed Treaty of Commerce and Amity, while the Japanese hesitated.
In addition, China has served as the principal broker in talks between the US and North Korea on nuclear issues, in which Japan has a huge stake.
But this backdrop of contention and competition masks emerging collaborative aspects of Sino-Japanese relations that are profoundly important, but which, unfortunately, seem to the world's media to be too mundane to "sell."
For example, trade and investment flows continue to expand rapidly.
Bilateral trade topped $100 billion in 2003, as Japan's exports to China increased by more than 10%, fuelled by semiconductors, electrical equipment, and automobiles.
Meanwhile, China replaced the US as Japan's biggest source of imports, and is now one of the few non-members of the Organization of Petroleum Exporting Countries with which Japan runs a trade deficit.
Similarly, direct investment by Japanese firms is increasing as they relocate production facilities to China to capitalize on lower labor costs and high-quality engineering talent.
Even the 20% cut in Japan's Official Development Assistance for China scarcely harmed their smooth economic ties.
Of course, there is no assurance that today's expanded commerce will preclude eventual strategic rivalry, or succeed in erasing lingering wartime animosity.
But both countries now place a premium on extending their economic interdependence.
China sees economic ties as a way to hasten its modernization.
Japan sees them as a way to enhance its international competitiveness, and to provide China with incentives for geopolitical moderation.
Most importantly, a new generation of leaders in both countries seems less hung up on divisive memories.
They may also see in Europe's surge toward economic integration a model for themselves and an inducement to intensifying regional cooperation.
Pragmatic leaders in both countries clearly recognize the benefits of diplomatic collaboration on issues that affect the region, such as North Korea's nuclear ambitions.
Ultimately, the historical wounds that have long divided China and Japan, and the more current diplomatic flashpoints that the global media inevitably trumpet, only tell part of the Sino-Japanese story.
There are economic and geopolitical rivalries between China and Japan that dwarf in importance the high-profile insults to national pride that make headlines.
But there are also compelling economic and political inducements toward cooperation that prevent these rivalries from developing into full-blown crises.
MOSCOW – “Google violates its ‘don’t be evil’ motto.” To Google’s credit, if you Google that sentence, you can find reference to a debate on that claim that I took part in recently.
As it happens, I have a complex relationship with Google.
I have fed at its trough many times – as a personal guest; as an advisory board member of Stop Badware, an NGO it sponsors; and as a speaker at its events.
I also sit on the board of 23andMe, co-founded by the wife of Google co-founder Sergey Brin. 
But I also sit on the boards of Yandex in Russia, one of a small number of companies around the world who beat Google in their local markets, and of WPP, a worldwide advertising/marketing company famous for its rivalry with Google.
Finally, I’m suspicious of concentrations of power of any kind.
So I welcomed the chance to clarify my thinking.
I took the con side of the debate: Google does not violate its motto.
However, I do think there is a danger that someday it could.
The danger lies in the concentration of information – arguably a concentration of power – that Google represents.
Google doesn’t merely point users to existing information on the Web; it also collects information that it doesn’t share about its users’ behavior.
If you can use patterns in Google searches to track flu outbreaks and predict a movie’s commercial prospects, can you also use it to forecast market movements or even revolutions?
Even if Google uses personal information only for their benefit (whatever that means), it represents an attractive target for governments.
In fact, Google generally fights government requests for personal information.
(It was Yahoo, not Google, that gave personal information to China’s government, which then jailed a blogger.)
Google has become a de facto gatekeeper of information, to the extent that if your site is not highly ranked by Google, you are like the tree falling in the forest with no one to hear it.
It doesn’t matter that people seeking information are free to bypass Google and use other tools; they don’t. 
So how does information equal power?
The active power that information provides is typically the threat of exposure.
Such information gives you power primarily in a secretive, opaque world where access to information is limited. 
But generally, the free flow of information reduces the concentration of power.
So, rather than suppressing or regulating the information that Google uncovers, we are better off making it more freely available.
A Google that is accountable to its users – searchers, advertisers, investors, and governments – is likely to be a better outfit that does more good in today’s relatively open market.
In short, there is no regulatory system that I trust more than the current messy world of conflicting interests.
Whatever short-term temptations it faces – to manipulate its search results, use private information, or throw its weight around – Google, it is clear, could lose a lot by succumbing to them in a world where its every move is watched.
Meanwhile, Google is not merely avoiding evil; it actively fights against it.  
For example, Google fights censorship – by doing, not by shouting.
Rather than stand on the sidelines and proclaim censorship evil, it is picking its way through the landmines in China – competing with a politically well-connected rival and politely letting its users know that they aren’t always getting the whole picture.
In short, Google is changing expectations about what people can know – even in the United States, where formal censorship is absent, but government obfuscation, opaque corporations, and the like are not.
Moreover, in countries where Google is criticized for blocking access to information, it points out the information’s absence when something is blocked – letting people know that it exists but that they can’t have access to it.
On the other hand, every time someone in China Googles something and gets an answer – a product’s good and bad points, the details about someone the government does not like – he must wonder, “Why can’t I get this kind of information about everything?” With Google, people start to expect answers about everything .
A little transparency inevitably leads to more.
Rather than demand an end to censorship now – an impossible dream – Google is working to make that happen by eroding government control over information.
Moreover, from a purely practical point of view, Google makes the world more efficient.
Buyers and sellers can find one another, schoolchildren can find information needed for their homework, and sick people can find health information.
The real threat of evil, I think, lies in the temptations of “international governance” – say, a sinister multilateral government body called the World Information Center.
Nice as it sounds, the reality is likely to be ridden with bureaucracy, susceptible to control by the worst of the world’s governments rather than its best ones, and incapable of innovation.  
Take, for example, ICANN, the body that sets policy for the Domain Name System.
I was its founding chairman, and I don’t think anyone considers it a success.
Its saving grace is that it is widely considered illegitimate and therefore has little power.
By contrast, Google is effective at what it does, and therefore has the legitimacy of results.
But it has little coercive power, because anyone is free to try an alternative.
Its only option is to be better than the competition.
The fact that these issues are being debated is a good sign in itself – keeping Google and its watchers on guard.
Fortunately, a wary press corps, powerful governments, and nervous competitors watch its every move, hoping the company to fight its many temptations.
Abuse of power is evil, but power itself is not. 
NEW YORK – Amid the pressures of the global financial crisis, some ask how we can afford to tackle climate change.
The better question is: how can we afford not to?
Put aside the familiar arguments – that the science is clear, that climate change represents an indisputable existential threat to the planet, and that every day we do not act the problem grows worse.
Instead, let us make the case purely on bread-and-butter economics.
At a time when the global economy is sputtering, we need growth.
At a time when unemployment in many nations is rising, we need new jobs.
At a time when poverty threatens to overtake hundreds of millions of people, especially in the least developed parts of the world, we need the promise of prosperity.
This possibility is at our fingertips.
Economists at the United Nations call for a Green New Deal – a deliberate echo of the energizing vision of United States President Franklin Roosevelt during the Great Depression of the 1930’s.
Thus, this week the UN Environment Program will launch a plan for reviving the global economy while dealing simultaneously with the defining challenge of our era – climate change.
The plan urges world business and political leaders, including a new US president, to help redirect resources away from the speculative financial engineering at the root of today’s market crisis and into more productive, growth-generating, and job-creating investments for the future.
This new “Green Economy Initiative,” backed by Germany, Norway, and the European Commission, arises from the insight that the most pressing problems we face are interrelated.
Rising energy and commodity prices helped create the global food crisis, which fed the financial crisis.
This, in turn, reflects global economic and population growth, with resulting shortages of critical resources – fuel, food, and clean air and water.
The commingled problems of climate change, economic growth, and the environment suggest their own solution.
Only sustainable development – a global embrace of green growth – offers the world, rich countries as well as poor, an enduring prospect of long-term social well-being and prosperity.
The good news is that we are awakening to this reality.
We have experienced great economic transformations throughout history: the industrial revolution, the technology revolution, and the era of globalization.
We are now on the threshold of another – the age of green economics.
Visiting “Silicon Valley” in California last year, I saw how investment has been pouring into new renewable-energy and fuel-efficiency technologies.
The venture capital firm that underwrote Google and Amazon, among other archetypal entrepreneurial successes, directed more than $100 million into new alternative energy companies in 2006 alone.
In China, green capital investment is expected to grow from $170 million in 2005 to more than $720 million in 2008.
(In just a few short years, China has become a world leader in wind and solar power, employing more than a million people.)
Globally, the UN Environment Program estimates that investment in low-greenhouse-gas energy will reach $1.9 trillion by 2020.
The financial crisis may slow this trend.
But capital will continue to flow into green ventures.
I think of it as seed money for a wholesale reconfiguration of global industry.
We can already see its practical expression.
More than two million people in the advanced industrial nations today find work in renewable energy.
Brazil’s bio-fuels sector has been creating nearly a million jobs a year.
Economists say that India, Nigeria, and Venezuela, among many others, could do the same.
In Germany, environmental technology is expected to quadruple over the coming years, reaching 16% of manufacturing output by 2030 and employing more people than the auto industry.
Mexico already employs 1.5 million people to plant and manage the country’s forests.
Governments have a huge role to play.
With the right policies and a global framework, we can generate economic growth and steer it in a low-carbon direction.
Handled properly, our efforts to cope with the financial crisis can reinforce our efforts to combat climate change.
In today’s crisis lies tomorrow’s opportunity – economic opportunity, measured in jobs and growth.
Most global CEOs know this.
That is one reason that businesspeople in so many parts of the world are demanding clear and consistent environmental policies.
It is also the reason that global companies like General Electric and Siemens are betting their future on green.
But it is important that the global public recognize this fact, perhaps nowhere more so than in the US.
When the next American president takes office, voters and elected officials alike should be reassured by studies showing that the US can fight climate change by cutting emissions at low or even no cost, using only existing technologies.
We know that the poorest of the world’s poor are the people most vulnerable to climate change.
They are also the most vulnerable to the shocks of the financial crisis.
As world leaders, we are morally bound to ensure that solutions to the global financial crisis protect their interests, not just the citizens of wealthier nations.
Those left behind by the previous boom – the so-called “bottom billion,” living on less than $1 a day – must be brought into the next economic era.
Again, a solution to poverty is also a solution for climate change: green growth.
For the world’s poor, it is a key to development.
For the rich, it is the way of the future.
An independent central bank focused exclusively on price stability has become a central part of the mantra of "economic reform."
Like so many other policy maxims, it has been repeated often enough that it has come to be believed.
But bold assertions, even from central bankers, are no substitute for research and analysis.
Research suggests that if central banks focus on inflation, they do a better job at controlling inflation.
But controlling inflation is not an end in itself: it is merely a means of achieving faster, more stable growth, with lower unemployment.
These are the real variables that matter, and there is little evidence that independent central banks focusing exclusively on price stability do better in these crucial respects.
George Akerlof, who shared the Nobel Prize with me in 2001, and his colleagues have argued forcefully that there is an optimal rate of inflation, greater than zero.
So ruthless pursuit of price stability actually harms economic growth and well being.
Recent research even questions whether targeting price stability reduces the tradeoff between inflation and unemployment.
A focus on inflation may make sense for countries with long histories of inflation, but not for others, like Japan.
America's central bank, the Federal Reserve, is mandated not only to ensure price stability, but also to promote growth and full employment.
There is broad consensus in the US against a narrow mandate, such as that of the European Central Bank.
Today, Europe's growth languishes, because the ECB is constrained by its single-minded focus on inflation from promoting economic recovery.
Technocrats and financial market players who benefit from this institutional arrangement have done an impressive job of convincing many countries of its virtues, and of the need to treat monetary policy as a technical matter that should be put above politics.
That might be the case if all that central bankers did was, say, choose computer software for clearing payments.
But central banks make decisions that affect every aspect of society, including rates of economic growth and unemployment.
Because there are tradeoffs, these decisions can only be made as part of a political process.
Some argue that in the long run there are no tradeoffs.
But, as Keynes said, in the long run, we are all dead.
Even if it were impossible to lower unemployment below some critical level without fuelling inflation, there is uncertainty about what that critical level is.
Accordingly, risk is unavoidable: monetary policy that is too loose risks inflation; if it is too tight, it can cause unnecessary unemployment, with all the suffering that follows.
During America's growth boom in the 1990s, the Clinton Administration believed that it was worth risking pushing the unemployment rate lower, especially when the social gains--declining welfare roles, reduced violence--were added to the direct economic benefits.
By contrast, the IMF urged tighter monetary policy, because it put far less weight on the cost of unemployment, seemingly no weight on the ancillary social benefits of reducing it, and much greater weight on the costs of potential inflation.
The economic analysis of Clinton's Council of Economic Advisers turned out to be right; the models of the IMF (and the Fed) were wrong.
America secured a much lower rate of unemployment without inflation--eventually unemployment fell to below 4%.
But that is not the point: the point is that no one could be sure.
A calculated risk is always unavoidable.
Who bears it varies with different policies, and that is a decision that cannot--or at least should not--be left to central bank technocrats.
While there is a legitimate debate about the degree of independence accorded to central banks and other decision-making bodies, within a democracy, the perspectives of those whose well-being is affected by the decisions taken should be represented in the process.
Workers, for instance, who have much to lose if the central bank pursues an excessively tight policy, do not have a seat at the table.
But financial markets--which do not have much to lose from unemployment, but are affected by inflation--are typically well represented. And yet financial markets hardly have a monopoly on technical competency.
Indeed, many in the financial community have little understanding of the intricate workings of the macroeconomic system--as evidenced by their frequent mistakes in managing it.
For example, most US recessions since 1945 were caused by the Fed stepping on the brakes too hard.
Similarly, central banks adopted monetarism with a fervor in the late 1970's and early 1980's, just as empirical evidence discrediting the underlying theories was mounting.
Whatever the merits of a common currency, those in Europe deliberating about adopting the Euro should consider whether to tie their fortunes to an institutional arrangement whose flaws are increasingly apparent.
Likewise, developing countries need to consider not only the central bank's independence, but also its mandate and representativeness.
They need to balance concerns about economic efficiency with those of democratic accountability.
In many new democracies, citizens are bewildered.
The virtues of the new regime are first praised, but then they are told that the macroeconomic policy decisions about which they care most are too important to be left to democratic processes.
Citizens are warned against the risks of populism (meaning the will of the people?).
There are no easy answers.
But in too many countries, nor is there democratic debate about the alternatives.
PARIS – All over the world, Internet users entertain romantic delusions about cyberspace.
To most of us Web surfers, the Internet provides a false sense of complete freedom, power, and anonymity.
Every once in a while, of course, unsolicited messages and ads that happen to be mysteriously related to our most intimate habits intrude.
They remind us that we Internet users are, indeed, under constant virtual surveillance.
When the watchers have only commercial motives, such “spam” feels like a minor violation.
But in China or Russia, the Internet is patrolled not by unsolicited peddlers, but by the police.
So Russian human-rights activists and the environmental organization Baikal Environmental Wave should not have been surprised when, earlier this month, flesh and blood policemen – not Internet bots – confiscated their computers and the files stored within them.
In the time of the Soviet Union, the KGB would have indicted these anti-Putin dissidents for mental disorders.
This supposedly being a “new Russia,” cyber-dissidents are accused of violating intellectual property rights.
You see, they were using Microsoft-equipped computers and could not prove that the software had not been pirated.
By confiscating the computers, the Russian police could supposedly verify whether or not the Microsoft software that the activists were using had been installed legally.
On the surface, Microsoft and Prime Minister Vladimir Putin’s police look like strange bedfellows.
But are they?
Microsoft’s authorized representatives declared that they could not oppose the Russian police actions, because the Seattle-based company had to abide by Russian law.
Such an ambiguous declaration can be interpreted either as active support for the Russian police or as passive collaboration.
Moreover, in previous cases, Microsoft assisted the Russian police in their investigations of non-governmental organizations.
Clearly, human-right activists in Russia cannot and should not count on Microsoft as an ally in their efforts to build a more open society.
But Microsoft’s ambiguous – at best – behavior is part of a pattern.
Indeed, the record of Internet companies in authoritarian countries is both consistent and grim.
Yahoo set the pace in pioneering the active collaboration of Internet and high-tech firms with political repression.
In 2005, Yahoo gave the Chinese police the computer identification code for a dissident journalist, Shi Tao.
Shi Tao had sent a message in praise of democracy, which the censors had detected.
Following Yahoo’s lead, the police arrested him.
Shi remains in jail to this day.
At that time, Yahoo’s managers in the United States, like Microsoft in Russia, declared that they had to follow Chinese law.
Shi Tao, in his jail cell, was undoubtedly pleased to learn that China is ruled by law, not by the Communist Party.
After all, the rule of law is what Shi Tao is fighting for.
Google, at least for a short while, seemed to follow different guidelines in its Chinese business, appearing to adhere to its widely proclaimed ethical principle, “Don’t be evil.” To protest against censorship, the Silicon Valley-based company relocated from mainland China in 2009 to the still relatively free Hong Kong.
On the Hong Kong-based search engine, Chinese internauts could read about Taiwan, the Tiananmen Square massacre of 1989, or the Dalai Lama.
On Google.cn, these sources, along with the results of searches using many other forbidden terms, simply did not appear.
Google’s move seemed to reconcile its proclaimed libertarian philosophy with its business ethics.
But that reconciliation did not last long: Google, after all, had accepted censorship from the beginning of its efforts in China, in 2006, in order to gain entry into the Chinese market.
After six months of life in Hong Kong, money talked: Google reinstated its mainland China service, and with the same level of censorship as before.
In the end, Google, not the Chinese Communist Party, lost face.
Yahoo, Google, and Microsoft have thus followed a strikingly similar road: access to lucrative markets trumped ethical anxiety.
The tools that they provide are politically neutral.
Dissidents try to use them to pursue a democratic agenda.
Police use them to detect and repress dissidents.
Either way, Microsoft, Yahoo, and Google make money – just like, say, IBM, which in the 1930’s sold its computing machines to the Nazi regime: the Nazis used these machines to make the destruction of their victims routine and bureaucratic.
Should we be shocked that Internet companies put profits ahead of morals?
After all, they are ordinary, profit-seeking corporations, just like the IBM of Hitler’s era.
Internet companies may, more than most, hide their true motives behind ersatz, democratic-sounding slogans, but in the end they are advertising products like any other.
In advertising or self-promotion, the choice of words is determined by customer expectations, not by managers’ philosophy, as they mostly have none.
Capitalism is always a trade-off: we must live with unethical behavior by money-making corporations that provide us with useful new tools.
These tools can be used by Iranians fighting dictatorship, or by Tibetan dissidents trying to save their culture.
They also can be used to compute the number of exterminated Jews, to arrest a Chinese dissident, or to break a human-rights group in Russia.
Microsoft in Russia or Google in China teach us that capitalism is not ethical: it is only efficient.
Entrepreneurs are greedy by definition: if they were not, they would go bankrupt.
An open society will never be created or sustained by righteous entrepreneurs or be the mere byproduct of political engineering.
Liberty, as always, remains the endeavor of vigilant, free men and women.
LONDON – Osama bin Laden’s death in his Pakistani hiding place is like the removal of a tumor from the Muslim world.
But aggressive follow-up therapy will be required to prevent the remaining Al Qaeda cells from metastasizing by acquiring more adherents who believe in violence to achieve the 'purification' and empowerment of Islam.
Fortunately, Bin Laden’s death comes at the very moment when much of the Islamic world is being convulsed by the treatment that Bin Laden’s brand of fanaticism requires: the Arab Spring, with its demands for democratic empowerment (and the absence of demands, at least so far, for the type of Islamic rule that Al Qaeda sought to impose).
But can the nascent democracies being built in Egypt and Tunisia, and sought in Bahrain, Libya, Syria, Yemen, and elsewhere, see off the threats posed by Islamic extremists?
In particular, can it defeat the Salafi/Wahhabi thought that has long nurtured Osama bin Laden and his ilk, and which remains the professed and protected ideology of Saudi Arabia?
The fact is that before the US operation to kill Bin Laden, Al Qaeda’s symbolic head, the emerging democratic Arab revolutions had already, in just a few short months, done as much to marginalize and weaken his terrorist movement in the Islamic world as the war on terror had achieved in a decade.
Those revolutions, whatever their ultimate outcome, have exposed the philosophy and behavior of Bin Laden and his followers as not only illegitimate and inhumane, but actually inept at achieving better conditions for ordinary Muslims.
What millions of Arabs were saying as they stood united in peaceful protest was that their way of achieving Arab and Islamic dignity is far less costly in human terms.
More importantly, their way will ultimately achieve the type of dignity that people really want, as opposed to the unending wars of terror to rebuild the caliphate that Bin Laden promised.
After all, the protesters of the Arab Spring did not need to use – and abuse – Islam to achieve their ends.
They did not wait for God to change their condition, but took the initiative by peacefully confronting their oppressors.
The Arab revolutions mark the emergence of a pluralist, post-Islamist banner for the faithful.
Indeed, the only people to introduce religion into the protests have been rulers, such as those in Bahrain, Yemen, Libya, and Syria, who have tried to use fear of the Shia or Sunni “other” to continue to divide and misrule their societies.
Now that the US has eradicated Bin Laden’s physical presence, it needs to stop delaying the rest of the therapeutic process.
For the US has been selectively – and short-sightedly – irradiating only parts of the cancer that Al Qaeda represents, while leaving the malignant growth of Saudi Wahabism and Salafism untouched.
Indeed, despite the decade of the West’s war on terror, and Saudi Arabia’s longer-term alliance with the US, the Kingdom’s Wahhabi religious establishment has continued to bankroll Islamic extremist ideologies around the world.
Bin Laden, born, raised, and educated in Saudi Arabia, is a product of this pervasive ideology.
He was no religious innovator; he was a product of Wahhabism, and later was exported by the Wahhabi regime as a jihadist.
During the 1980’s, Saudi Arabia spent $75 billion for the propagation of Wahhabism, funding schools, mosques, and charities throughout the Islamic world, from Pakistan to Afghanistan, Yemen, Algeria, and beyond.
The Saudis continued such programs after the terror attacks of September 11, 2001, and even after they discovered that “the Call” is uncontrollable, owing to the technologies of globalization.
Not surprisingly, the creation of a transnational Islamic political movement, boosted by thousands of underground jihadi Web sites, has blown back into the Kingdom.
Like the hijackers of 9/11, who were also Saudi/Wahhabi ideological exports (15 of the 19 men who carried out those terror attacks were chosen by Bin Laden because they shared the same Saudi descent and education as he), Saudi Arabia’s reserve army of potential terrorists remains, because the Wahhabi factory of fanatical ideas remains intact.
So the real battle has not been with Bin Laden, but with that Saudi state-supported ideology factory.
Bin Laden merely reflected the entrenched violence of the Kingdom’s official ideology.
Bin Laden’s eradication may strip some dictators, from Libya’s Muammar el-Qaddafi to Yemen’s Ali Abdallah Saleh, of the main justification they have used for their decades of repression.
But the US knows perfectly well that Al Qaeda is an enemy of convenience for Saleh and other American allies in the region, and that in many cases, terrorism has been used as a pretext to repress reform.
Indeed, now the US is encouraging repression of the Arab Spring in Yemen and Bahrain, where official security forces routinely kill peaceful protesters calling for democracy and human rights.
Al Qaeda and democracy cannot coexist.
Indeed, Bin Laden’s death should open the international community’s eyes to the source of his movement: repressive Arab regimes and their extremist ideologies.
Otherwise, his example will continue to haunt the world.
Last summer, at a meeting outside Aspen, Colorado, several dozen physicists gathered to celebrate what the journal 
 Nature
 described as the "growing feeling that their discipline's mindset will be crucial to reaping the harvest of biology's post-genomic era."
In fact, with genetics set to improve everything from human health to agriculture, physicists and mathematicians worldwide are pouring into the life sciences.
Biology is where the scientific action--and the money--will be in the coming century. 
But this is not the first time that physicists and mathematicians have looked to biology for new fields to plow, and the history of such efforts has been fairly dismal.
Biologists and physicists have different goals and traditions, and they look for different kinds of answers, because they ask different kinds of questions. 
My first glimpse of this disciplinary divide came many years ago while teaching a course on mathematical methods in biology.
After introducing a biological problem with 11 variables, I used a simple method called dimensional analysis to demonstrate that only three needed to be studied empirically; the relations among the rest of the variables could be inferred logically. "But you haven't done the experiments," the students complained, "so how can you know?" 
I've been thinking about that question ever since.
As a theoretical physicist, I had been trained to trust only mathematical and logical arguments and to view experimental evidence as fallible.
But to many, if not most, biologists, experimental evidence, however fallible, still provided a surer path to truth.
Where, in a purely deductive argument, was there room for nature's surprises, for mechanisms that look nothing like what we imagine in our initial assumptions? 
Philosophers of science have traditionally approached questions concerning what counts as knowledge, explanation, and theory as if they could be answered universally.
But the communication gap between experimental and mathematical biologists suggests that the answers depend on specific disciplinary cultures. 
Consider the interdisciplinary efforts--and ultimate failure--of Nicolas Rashevsky, a Russian theoretical physicist who emigrated to the US in 1924.
Rashevsky wondered whether a similar mechanism might account for the division of biological cells and the onset of instability in liquid droplets.
Soon, he set out to build "a systematic mathematical biology, similar in its structure and aims to mathematical physics."
By 1940, he had published his magnum opus, 
 Mathematical Biophysics
 , established a program by the same name at the University of Chicago, and founded the 
 Bulletin of Mathematical Biophysics
 . 
But by 1954, Rashevsky had lost his grants and budget, and today little remains of his institutional and scientific efforts.
The main criticism against him was that he failed to engage with practicing biologists.
But Rashevsky did make at least one early effort to interest biologists in his work.
In 1934, he presented a "physico-mathematical" analysis of the forces acting on an idealized spherical cell, a model that he argued was sufficient to explain cell division. 
When the biologists objected that not all cells are spherical, Rashevsky responded that the theory must first be applied to the simplest cases.
E. B. Wilson, the proverbial giant of cell biology, had the last word, concluding in a brief paper following Rashevsky's presentation that mathematics may be helpful in studying the growth of populations, but not individuals.
Wilson's colleague, Eric Ponder, was even more pointed, saying that what is required "is more measurement and less theory." 
By the early 1950's, however, biologists still could not explain how an organism reproduces its characteristic form from one generation to another.
In 1952, Alan Turing--best known for his work on computation and the mind--proposed a mathematical model consisting of a pair of equations describing the reaction and diffusion of two imaginary chemicals.
His model, which he admitted was "a simplification and an idealization," aimed to highlight the "features of greatest importance" in an embryo's development.
He emphasized that the reactions he described bore no resemblance to those in nature.
They reflected only the desire "that the argument be easy to follow." 
Turing appears here as a caricature of the mathematical physicist.
Like Rashevsky, he had been steeped in mathematical and physical scientists' belief that an imaginary construction making no pretense to literal truth can nonetheless capture the "features of greatest importance" and hence serve a useful explanatory function. 
But experimental biologists ask a different question: not whether organisms 
 could
 grow as an imaginary model suggests, but whether they
 do
 .
On this score, Turing's reaction-diffusion model has been greatly disappointing.
Over the last 20 years, molecular biologists have found that the progressive activation of a hierarchy of genes--which play no role in Turing's model--defines an organism's final structure and form.
More broadly, the best explanations of how biological systems solve particular problems come from experimental genetics, not mathematics and logic. 
Physicists and mathematicians nonetheless have reason to celebrate.
Since 1983, the proportion of funding for mathematical and computational research that comes from the Biological Division of the US National Science Foundation has increased about 50-fold. 
To their credit, many new programs in mathematical biology encourage researchers coming from the mathematical sciences to become practicing biologists themselves.
Meanwhile, "user-friendly" computer programs enable biologists to build their own mathematical/theoretical models. 
The net effect could be a new disciplinary culture that transforms the aims, methods, and epistemological basis of research.
Theoretical biology's models will be formulated not in a few simple equations, but in a complex of algorithms, statistical analyses, and simulations.
And, recognizing the ever present possibility of exceptions, they will aspire to "generalities" rather than "laws," leaving room for accidental particularities of biological structure.
Biology is not physics, and to ignore its evolutionary history is to invite irrelevance. 
Skeptics about agricultural biotechnology lambaste it as unproven, untested, unnatural, and uncontrollable.
Nothing could be farther from the truth.
On the contrary, neither biotechnology nor genetic engineering are new, and consumers, government, and industry all have had long, extensive, and positive experience with both. 
Early biotechnology--the application of biological systems to technical or industrial processes--dates to 6000 B.C., when the Babylonians used specialized microorganisms in fermentation to brew alcoholic beverages.
Genetic engineering can be dated from man's recognition that animals and crop plants can be selected and bred to enhance desired characteristics.
Early biologists and agriculturists carried out selection for desired traits, generating poorly understood changes in the organisms' genetic material. 
Put another way, "nature" didn't give us seedless grapes, the tangelo (a tangerine-grapefruit hybrid), and fungus-resistant strawberries: farmers and plant breeders did.
During the past half-century, better understanding of genetics at the molecular level has added to the sophistication of the genetic improvement of all manner of organisms. 
Opponents of biotech repeatedly raise dire warnings of the movement of "rogue genes" between the modified crop and wild (or domesticated) relatives.
But, at the risk of mixing metaphors, this is a red herring. 
Gene flow is ubiquitous.
All crop plants have relatives somewhere, and some gene flow commonly occurs if the two populations are grown close together.
Gene flow from wild relatives to crop plants may even be encouraged by subsistence farmers to maintain the broad genetic base of the varieties that they plant using seed harvested from an earlier crop.
Such gene flow does not occur when farmers buy their seeds from seed producers, of course, but in that case gene flow in the other direction is still possible, with genes from the cultivated crop ending up in the wild relative. 
That is most likely if genes from the crop confer a selective advantage on the recipient, an occurrence that is uncommon with gene-splicing, where most often the added gene places the recipient at a natural 
disadvantage.
The worst-case scenario would be gene transfer from plants engineered for enhanced resistance to certain herbicides.
Once the gene has been transferred to the wild relative, there will be a strong selection pressure to maintain it there if the same herbicide is used, making the weedy wild relatives more difficult to control.
But even this scenario raises no issues of ecological or food safety.
For if the use of one herbicide were compromised, farmers would simply use another. 
Gene transfer is an age-old concern for farmers.
Growing hundreds of crops, virtually all of which have been genetically improved, the practitioners of "conventional" agriculture in North America meticulously developed strategies for preventing pollen cross-contamination in the field--when and if it is necessary for commercial reasons. 
A good example is Canola--the genetically improved rapeseed developed by Canadian plant breeders a half-century ago.
The original rapeseed oil was harmful when ingested because of high levels of erucic acid.
After conventional plant breeding led to the development of rapeseed varieties with low concentrations of erucic acid, canola oil became the most commonly consumed oil in Canada.
But high-erucic acid rapeseed oil is still used as a lubricant and plasticizer.
So the high- and low-erucic acid varieties of rapeseed plants must be carefully segregated in the field and thereafter.
Canadian farmers and processors accomplish this routinely and without difficulty. 
These applications of conventional biotechnology, or genetic engineering, represent monumental scientific, technological, commercial, and humanitarian successes.
But the techniques they were relatively crude and recently have been supplemented--and in many cases replaced--by "the new biotechnology," a set of enabling techniques that enable genetic modification at the molecular level.
The prototype of these techniques, variously called gene-splicing or genetic modification ("GM"), is a more precise, better understood, and more predictable method for altering genetic material than was possible previously. 
An authoritative 1989 analysis of genetic technologies by the US National Research Council summarized the scientific consensus: "With classical techniques of gene transfer, a variable number of genes can be transferred, the number depending on the mechanism of transfer; but predicting the precise number or the traits that have been transferred is difficult, and we cannot always predict the [traits] that will result.
 With organisms modified by molecular methods, we are in a better, if not perfect, position to predict [their traits]." 
The desired "product" of gene-splicing may be the engineered organism itself--a bacteria to clean up oil spills, a weakened virus used as a vaccine, or a papaya tree that resists viruses--or it may be a biosynthetic product of the cells, such as human insulin produced in bacteria, or oil expressed from seeds. 
Gene-spliced plants have for several years been grown worldwide on more than 100 million acres annually.
More than two-thirds of processed foods in the US contain ingredients derived from gene-spliced organisms.
There has not been a single mishap that resulted in injury to a single person or ecosystem.
Thus, both theory and experience confirm the extraordinary predictability and safety of gene-splicing technology and its products. 
The new gene-splicing techniques have yielded many important new research tools and commercial products, and have only begun to change the way we do biological research and to increase the choices available to farmers, food producers, physicians, and consumers.
But they are merely an extension, or refinement, of the kinds of genetic modification that preceded the era of "new bio-technology."
So welcome to Biotech's Brave 
 Old
 World. 
This summer, friends who live a few kilometers from us in rural Montana in the western US had to interrupt their dinner when a black bear suddenly came out of the trees.
They went indoors to watch as it came up to the picnic table, licked the dishes clean, and then drank two cans of beer. 
Over the following days, the bear turned over the garbage cans of two neighbors and terrorized children and pets.
Forest Service rangers set up a cage and put some bacon inside, soon catching and transporting the bear 30 kilometers into the wilderness.
The bear was tagged before it was released, to show that it had been causing trouble. “Unfortunately,” said the ranger, “that bear may be back here even before our truck returns.
Once they develop a taste for bacon and beer, you can't keep them away.” If a tagged bear is caught two or more times causing disruption, the rangers have orders to shoot it.
It is easy to feel sorry for an animal that discovers tasty food and can’t resist getting more the easy way.
The bear has no idea that its days are numbered unless it remains in the forest and hunts in the traditional way for its meals.
But that bear was following the wisdom natural selection had programmed in its genes: food that is high in proteins and sugars is good for you, and the less energy you expend getting it, the better.
That much the bear knows well.
It had no chance to learn – and probably never will – that picnic tables and garbage cans are defended by forest rangers with orders to kill.
How much luckier we humans are, knowing what is good and bad for us.
We cannot be trapped so easily by things that taste good but will cause our downfall.
But, in reality, most of us are no different from that bear.
Most people are aware that high-fat diets, too much alcohol, smoking, promiscuous sex, and recreational drugs, while pleasant, can ruin one's health.
Yet we can’t resist the lure of the garbage can and its delights.
But at least we have had clear warnings about the dangers of such habits, so people who want to use such knowledge can avoid being trapped.
There are other potentially harmful pleasures in the environment that are less known, but not less destructive than those that are.
One of the most seductive of these pleasures – and thus one of the most dangerous – is television.
Television is attractive to the architecture of the human nervous system: our brains are built to absorb information and follow rapid changes in the sensory field.
TV provides these in easily digestible, sumptuously prepared morsels.
Constant change and the appearance of excitement absorb viewers’ attention.
The Sistine Chapel cannot compare with it – most children will become bored after ten minutes by the frescoes of Michelangelo, but will watch a detergent commercial with riveted interest.
All of this applies just to the way the medium works, without taking content into consideration.
The content in turn reinforces the seductive qualities of the medium by offering generous helpings of sex, violence, easy comfort, and other material that we are genetically prepared to respond to, but that in large doses detract from the ability to lead productive and serene lives.
Indeed, by now the evidence that television watching is a dangerous habit has grown to such proportions that it is a wonder that stronger warnings and effective prevention have not been adopted.
Among the many findings is that watching too much television induces passivity, both at the level of neural functioning and of behavior and that it interferes with learning and reduces political and civic participation.
It also encourages aggressive behavior in children and produces negative moods such as sadness and loneliness.
Nor is there any evidence of benefits to counterbalance these negative effects.
When television was in its infancy, many thinkers ­ and not surprisingly, television producers – painted the future of the medium in glowing terms: TV would keep us informed, cultured, and entertained; it would strengthen family life and civic virtues.
None of this happened.
Even the informational value of television turned out to be a dream: individuals and communities that watch TV often know much less about what is happening in the world than comparable audiences that do not.
The only clearly positive effect of TV watching is that people feel relaxed while doing it, and many people are willing to exchange that relaxation for the more enjoyable and useful things they might be doing instead.
Like the bear that learned to fill his stomach comfortably, they feel satisfied to be entertained without having to exert themselves.
Of course, television can be nice when consumed in small doses and with discernment.
Like drinking a glass or two of wine, it helps digestion and lightens the mind. But those who spend hours watching it each evening, with less and less control over their attention, and deriving progressively less enjoyment from what they watch, risk becoming as besotted as an alcoholic who only feels alive when he blots out reality.
No bear, if it knew what we do, would fall into that trap.
BERLIN – In today’s global financial crisis, the image of a black swan has become a symbol for the seemingly impossible that somehow occurs, turning the world upside down.
This year will afford us ample opportunity to examine the black swans that are already among us, and to prepare for the arrival of even more.
November, for example, marks the 20th anniversary of the fall of the Berlin Wall.
The night of November 9, 1989, marked the beginning of the end of the Soviet Union and its empire, and thus also of the bipolar world that had, for five decades, divided Germany and Europe.
A year before, few people considered this world-shaking event even a remote possibility.
Yet it happened, and the world changed almost overnight.
After the disappearance of the Soviet Union and the bipolar world order, victorious Western capitalism, under the leadership of the only world power, the United States, reigned supreme in global politics, and even more so in the global economy.
Nothing and no one, it seemed, could stem the global triumph of the market, with its transcendence of all previous limits on wealth – that is, until September 15, 2008, the fateful date when Lehman Brothers went bust and the meltdown of the global financial system began.
While a distraught world is still trying to fathom the consequences of this global crash and to mitigate its impact, the call of the next black swan can already be heard: the global climate disaster.
It seems to be part of human nature willfully to deny the possibility of great crises, or at least to downplay them. “Impossible” or “It won’t be all that bad” are the two magic formulae on which we tend to rely.
And we refuse to learn the lesson of the black swan even when the next one is already visible for all to see!
Although the generations alive today have witnessed two completely unexpected crises of epic proportions within the last 20 years, we indulge in a shocking collective repression of a climate disaster with far more serious – and foreseeable – consequences.
But, in fact, by linking the answers to the global climate and economic crises, we can find a way out of both.
The solutions to the climate crisis are already well known, the money is available, and so are the technologies, or where they aren’t, they could be developed.
What is lacking is the strategic vision and determined action of the major political players.
As for the economic crisis, bailouts and stimulus packages on the order of billions of dollars, euros, yen, or yuan have been planned or implemented to stem the further slide of the global economy.
But, while references to the Great Depression are justified, the lesson of that crisis, and of the New Deal, is that effective programs can at best cushion the fall and bring about stabilization.
The real economic recovery – and this is the bad news – came only with WWII and the long Cold War that followed.
Rather than relying on war as an economic mega-project to end today’s recession, the international community should bet on the fight against the climate crisis, because globalization will continue, rapidly increasing the threats to the world’s climate.
In 1929, there were slightly more than two billion people living on the planet; today, there are 6.7 billion, and in 2050 there will be nine billion.
All of them, thanks to globalization and new communication technologies, will strive for the same standard of living, give or take, which will necessarily lead to an overstretched global ecosystem.
The question of whether to use coal or nuclear power is simply no longer apposite: without a breakthrough in renewable energies, global energy demand cannot be met, not to mention the dangers of a new Chernobyl.
Where this will lead the world can be seen even today: China already has the world’s most ambitious scheme for expanding nuclear energy, and every year it builds coal-fired power plants whose electricity output is roughly equivalent to the capacity of the entire British power grid!
So the black swan of the climate crisis is already preparing to land.
To fight the climate crisis effectively demands nothing less than a green revolution of the global economy, the mega-project of the twenty-first century.
Only the rich industrial nations of Europe, America, and Japan can afford to pay for the necessary investments in emerging countries.
But this green revolution must be about more than spending money; it must also be about laws and standards, i.e. about political regulation and new technologies, as well as new products and markets, which mean new economic opportunities.
This year, a new global climate agreement will be negotiated in Copenhagen to replace the Kyoto Protocol.
This is effectively the last chance to prevent the next black swan from landing.
But we must understand that Copenhagen is also a big chance to revive the global economy.
All of the relevant powers of the twenty-first century are represented in the G-20, and they should see the success of Copenhagen as part of their direct responsibility.
This time, unlike at the London G-20 meeting, they should do the job properly – both to protect our climate and to reboot the global economy.
When voters in France and the Netherlands turned down the proposal for a Constitution for the European Union, the world knew that the European project was in deep trouble.
Last week’s bruising battle over the medium-term future of the Union’s budget has confirmed that verdict with a vengeance.
It also brought to a sorry close the UK’s six-month presidency of the European Council, confirming Britain’s long-standing reputation as the odd-man-out in the European Union.
The two events are intimately connected.
French and Dutch voters did not say why they voted against the planned Constitution.
But many commentators believe that they were protesting against what they perceived as the precipitate admission of ten new member states, mainly much poorer countries from Central and Eastern Europe.
In particular, voters were afraid that their jobs would be lost to hordes of Eastern immigrants, exemplified in the image widely quoted at the time, of the low-cost Polish plumber.
The irony, of course, was that most of the 15 old member states had refused to give the new members full and immediate access to the Western job markets.
But in any event, it was too late to protest: the ten Eastern states had already been granted membership of the Union.
But now the 25 member states must deal with the financial consequences of that enlargement, not just in the overall size of the European Union budget for the next seven years, but in who pays and who benefits.
In particular, the central issue is how far the old member states are willing to pay to boost the less developed economies of the new members.
In the event, it turned into a three-way battle between Britain, France and the new member states.
Traditionally, a large majority of the budget has gone either on agriculture or on the development of backward regions.
In practice, this has meant large flows of money either to big agricultural producers, like France, or to poorer member states, like Greece and Portugal.
On both counts, the new member states expected to benefit substantially from the EU system.
In the past, the big loser from the EU system, in budgetary terms, was the UK; for while agriculture accounted for two thirds of all EU spending, the UK had a small farm sector, and therefore received small farm payments.
The British long complained of the unfairness of these rules, especially in view of the fact that the UK was one of the relatively poorer member states; and in 1984, Margaret Thatcher’s Conservative government demanded, and got, a massive rebate on its net contribution to the EU budget.
Today, the situation has changed in three important respects.
EU farm policy has started to be reformed, and its share of the EU budget has fallen from over 60% to 40%; Britain has for several years enjoyed significantly faster economic growth than most other member states, so that it is now one of the richer EU countries, even compared with France and Germany; and the new member states are so much poorer than even the poorest of the old members, that they have an unanswerable moral case for a generous share of whatever budget could be negotiated.
When negotiations started six months ago, it was Britain’s turn to take over the Presidency of the European Council.
Tony Blair, British Prime Minister, electrified the world of European politics by telling the European Parliament that he was a “passionate pro-European”.
This was a message for which Britain’s European friends had long been hoping, and for which they had waited in vain since Blair’s election in 1997.
Certainly, he had never expressed any such sentiment inside the British Isles during the previous eight years.
Since Britain had been one of the most insistent advocates of enlargement of the EU to the candidates from Central and Eastern Europe, one might have expected that the Blair government would have wished to be correspondingly generous to the new-comers in the conduct of the budgetary negotiations.
At first, this seemed to be the British government’s chosen tactic.
Against all expectations, it struck a morally advantageous posture by offering to surrender some part of its budget rebate, but only if the rest of the European Union (i.e. France, in particular) would agree to fundamental reforms of EU farm policy.
It took some time before the British came to understand that since President Jacques Chirac is a beleaguered lame-duck President, who will remain in office but not in power until 2007, he is in no position to agree to any such bargain.
So when the British came to terms with this harsh reality, they played out the lamentable end-game of their management of the negotiations with small-minded cheese-paring and logic-chopping offers, all designed primarily to safeguard narrow British interests, mainly at the expense of the new member states.
It is a sad conclusion to a presidency, launched six-months ago, with Blair’s claim that he was a “passionate pro-European”.
Yet the full text of his speech tells it all.
Blair is in favour of Europe; but not this Europe.
He wants to be a part of a political Europe; but only if the other member states follow Britain’s model of economic and social reform.
The problem is that economic and social reform are purely national responsibilities, and do not lie within the competence of the Union; if there is to be economic and social reform in France and Germany, that is a matter exclusively for French and German voters and politicians.
It could only be a European matter, if the EU were a real federation.
Is Blair a federalist, then?
Heavens, no!
He is merely an unthinking nationalist, living in terror of the nationalist yellow tabloid press.
So why does he say he is a passionate pro-European?
Because he has not thought about the question for one moment.
Tony Blair has achieved a remarkable third successive electoral victory.
But his sharply reduced majority in the House of Commons, and his damaged personal reputation, mean that his political position is seriously weakened.
As a result, he will be poorly placed to handle the challenges ahead, the most intractable of which will be the European Union’s new Constitution.
The Constitution, adopted by the 25 member states last year, is not, in itself, a big deal.
It introduces some significant improvements for majority voting in the Council of Ministers.
It gives some more powers to the European Parliament.
It includes a Charter of Fundamental Rights.
It might help harmonize the foreign policies of the member states.
But it is no revolutionary document.
According to normal British constitutional practice, the government would be expected to ratify this Constitution by a vote in the House of Commons; and, until the recent general election, the government’s huge majority should have been more than sufficient.
But Blair, beset by controversy over the unpopular and possibly illegal war in Iraq, thought he could avoid trouble at Westminster by postponing ratification until 2006 (that is, a comfortably long time in the future), and proposing that it be carried out by popular referendum.
Unfortunately, as things stand, this is a referendum that Blair will not win, because all polls show a large and solid majority against the European Constitution.
Blair’s government may hope to be rescued by outside events.
France will hold a referendum on the Constitution for the end of this month, and a French “No,” the British seem to think, might make their problem go away.
For the general expectation is that if France rejects the Constitution, the Constitution would be dead, and no British referendum would be needed.
If this is Blair’s calculation, he is mistaken.
Moreover, it is the kind of mistake that the British have been making in relations with Europe for the past half-century.
Some recent French polls now show a majority in favor of the Constitution.
But even if the French do vote “No,” that will not solve the British problem: on the contrary, it will precipitate a major political crisis, in France and across Europe, concerning the future of the EU – the type of crisis that the British have spent fifty years trying to evade.
For if the Constitution is indeed dead, what happens next?
None of the leading members of the Union will be interested in Britain’s views on this question.
When Tony Blair swept to power in 1997, he was widely welcomed throughout Europe as the most pro-European British Prime Minister since Edward Heath a quarter of a century earlier.
He spoke French and seemed at ease with Britain’s neighbors across the Channel; more importantly, he seemed to sympathize with European integration.
Eight years on, Europe knows better.
It is now clear to all that Blair is fundamentally opposed to the idea of a more politically integrated Europe.
Not only has he kept Britain out of the single European currency over the past four years, he made it clear during the election campaign that he does not expect the UK to join the Euro during the next five years either.
Occasionally Blair flirts with the idea of more European cooperation on foreign policy and defense.
But the past three years proved in practice that he prefers subservience to the war policy of President Bush to any sense of community with Europe.
In short, Blair is as opposed to the European project as all his predecessors.
One fundamental difference between France and Britain is that most of the mainstream political elite in France has long been broadly pro-European.
If the French electorate votes “No,” it will be much less a vote against the Constitution than a protest vote against President Jacques Chirac, or an expression of anxiety about the implications of the EU’s enlargement to Central Europe.
By contrast, Blair cannot win a referendum on the Constitution, not only because it is opposed by virtually all the popular press, but also because neither he nor any major political leader in Britain has ever had a good word to say about European integration.
The crisis over the Union’s future direction triggered by a French “No” vote could last for some time.
But if the British imagine that the Constitution will just die, and that that will be the end of the story, they are deceiving themselves.
On the contrary, they will find themselves embroiled, like the rest of Europe, in a fundamental debate about the objectives of the Union.
They will then be forced to make public and explicit choices about the sort of Europe that they want, and this will put them at odds with their neighbors.
In the end, the French and other leading member states are likely to explore alternative ways of working towards a more politically integrated Europe.
The most plausible institutional mechanism for this alternative way forward will be the existing grouping of those member states that have wanted to belong to a more united Europe by joining, or seeking to join, the euro zone.
If the Constitution is rejected, the British, having chosen to stay out of that grouping, may find that they have maneuvered themselves into an even more remote outer circle of Europe.
CAMBRIDGE – As the world economy tumbles off the edge of a precipice, critics of the economics profession are raising questions about its complicity in the current crisis.
Rightly so: economists have plenty to answer for.
It was economists who legitimized and popularized the view that unfettered finance was a boon to society.
They spoke with near unanimity when it came to the “dangers of government over-regulation.”
Their technical expertise – or what seemed like it at the time –�gave them a privileged position as opinion makers, as well as access to the corridors of power.
Very few among them (notable exceptions including Nouriel Roubini and Robert Shiller) raised alarm bells about the crisis to come.
Perhaps worse still, the profession has failed to provide helpful guidance in steering the world economy out of its current mess.
On Keynesian fiscal stimulus, economists’ views range from “absolutely essential” to “ineffective and harmful.”
On re-regulating finance, there are plenty of good ideas, but little convergence.
From the near-consensus on the virtues of a finance-centric model of the world, the economics profession has moved to a near-total absence of consensus on what ought to be done. 
So is economics in need of a major shake-up?
Should we burn our existing textbooks and rewrite them from scratch?
Actually, no.
Without recourse to the economist’s toolkit, we cannot even begin to make sense of the current crisis.
Why, for example, did China’s decision to accumulate foreign reserves result in a mortgage lender in Ohio taking excessive risks?
If your answer does not use elements from behavioral economics, agency theory, information economics, and international economics, among others, it is likely to remain seriously incomplete.
The fault lies not with economics, but with economists.
The problem is that economists (and those who listen to them) became over-confident in their preferred models of the moment: markets are efficient, financial innovation transfers risk to those best able to bear it, self-regulation works best, and government intervention is ineffective and harmful.
They forgot that there were many other models that led in radically different directions.
Hubris creates blind spots.
If anything needs fixing, it is the sociology of the profession.
The textbooks –�at least those used in advanced courses – are fine.
Non-economists tend to think of economics as a discipline that idolizes markets and a narrow concept of (allocative) efficiency.
If the only economics course you take is the typical introductory survey, or if you are a journalist asking an economist for a quick opinion on a policy issue, that is indeed what you will encounter.
But take a few more economics courses, or spend some time in advanced seminar rooms, and you will get a different picture.
Labor economists focus not only on how trade unions can distort markets, but also how, under certain conditions, they can enhance productivity.
Trade economists study the implications of globalization on inequality within and across countries.
Finance theorists have written reams on the consequences of the failure of the “efficient markets” hypothesis.
Open-economy macroeconomists examine the instabilities of international finance.
Advanced training in economics requires learning about market failures in detail, and about the myriad ways in which governments can help markets work better.
Macroeconomics may be the only applied field within economics in which more training puts greater distance between the specialist and the real world, owing to its reliance on highly unrealistic models that sacrifice relevance to technical rigor.
Sadly, in view of today’s needs, macroeconomists have made little progress on policy since John Maynard Keynes explained how economies could get stuck in unemployment due to deficient aggregate demand.
Some, like Brad DeLong and Paul Krugman, would say that the field has actually regressed.
Economics is really a toolkit with multiple models – each a different, stylized representation of some aspect of reality.
One’s skill as an economist depends on the ability to pick and choose the right model for the situation.
Economics’ richness has not been reflected in public debate because economists have taken far too much license.
Instead of presenting menus of options and listing the relevant trade-offs – which is what economics is about – economists have too often conveyed their own social and political preferences.
Instead of being analysts, they have been ideologues, favoring one set of social arrangements over others.
Furthermore, economists have been reluctant to share their intellectual doubts with the public, lest they “empower the barbarians.”
No economist can be entirely sure that his preferred model is correct.
But when he and others advocate it to the exclusion of alternatives, they end up communicating a vastly exaggerated degree of confidence about what course of action is required.
Paradoxically, then, the current disarray within the profession is perhaps a better reflection of the profession’s true value added than its previous misleading consensus.  Economics can at best clarify the choices for policy makers; it cannot make those choices for them.
When economists disagree, the world gets exposed to legitimate differences of views on how the economy operates.  It is when they agree too much that the public should beware.   
NEW YORK – The future of capitalism is again a question.
Will it survive the ongoing crisis in its current form?
If not, will it transform itself or will government take the lead?
The term “capitalism” used to mean an economic system in which capital was privately owned and traded; owners of capital got to judge how best to use it, and could draw on the foresight and creative ideas of entrepreneurs and innovative thinkers.
This system of individual freedom and individual responsibility gave little scope for government to influence economic decision-making: success meant profits; failure meant losses.
Corporations could exist only as long as free individuals willingly purchased their goods – and would go out of business quickly otherwise.
Capitalism became a world-beater in the 1800’s, when it developed capabilities for endemic innovation.
Societies that adopted the capitalist system gained unrivaled prosperity, enjoyed widespread job satisfaction, obtained productivity growth that was the marvel of the world and ended mass privation.
Now the capitalist system has been corrupted.
The managerial state has assumed responsibility for looking after everything from the incomes of the middle class to the profitability of large corporations to industrial advancement.
This system, however, is not capitalism, but rather an economic order that harks back to Bismarck in the late nineteenth century and Mussolini in the twentieth: corporatism.
In various ways, corporatism chokes off the dynamism that makes for engaging work, faster economic growth, and greater opportunity and inclusiveness.
It maintains lethargic, wasteful, unproductive, and well-connected firms at the expense of dynamic newcomers and outsiders, and favors declared goals such as industrialization, economic development, and national greatness over individuals’ economic freedom and responsibility.
Today, airlines, auto manufacturers, agricultural companies, media, investment banks, hedge funds, and much more has at some point been deemed too important to weather the free market on its own, receiving a helping hand from government in the name of the “public good.”
The costs of corporatism are visible all around us: dysfunctional corporations that survive despite their gross inability to serve their customers; sclerotic economies with slow output growth, a dearth of engaging work, scant opportunities for young people; governments bankrupted by their efforts to palliate these problems; and increasing concentration of wealth in the hands of those connected enough to be on the right side of the corporatist deal.
This shift of power from owners and innovators to state officials is the antithesis of capitalism.
Yet this system’s apologists and beneficiaries have the temerity to blame all these failures on “reckless capitalism” and “lack of regulation,” which they argue necessitates more oversight and regulation, which in reality means more corporatism and state favoritism.
It seems unlikely that so disastrous a system is sustainable.
The corporatist model makes no sense to younger generations who grew up using the Internet, the world’s freest market for goods and ideas.
The success and failure of firms on the Internet is the best advertisement for the free market: social networking Web sites, for example, rise and fall almost instantaneously, depending on how well they serve their customers.
Sites such as Friendster and MySpace sought extra profit by compromising the privacy of their users, and were instantly punished as users deserted them to relatively safer competitors like Facebook and Twitter.
There was no need for government regulation to bring about this transition; in fact, had modern corporatist states attempted to do so, today they would be propping up MySpace with taxpayer dollars and campaigning on a promise to “reform” its privacy features.
The Internet, as a largely free marketplace for ideas, has not been kind to corporatism.
People who grew up with its decentralization and free competition of ideas must find alien the idea of state support for large firms and industries.
Many in the traditional media repeat the old line “What's good for Firm X is good for America,” but it is not likely to be seen trending on Twitter.
The legitimacy of corporatism is eroding along with the fiscal health of governments that have relied on it.
If politicians cannot repeal corporatism, it will bury itself in debt and default, and a capitalist system could re-emerge from the discredited corporatist rubble.
Then “capitalism” would again carry its true meaning, rather than the one attributed to it by corporatists seeking to hide behind it and socialists wanting to vilify it.
This column was produced within the framework of the EC-funded “V4Aid” project.
The views expressed do not necessarily represent the view of the EU.
The terrorist attacks in America and the war against the Taliban have incited wide speculation about the relationship between culture and economic development.
Most pointedly, is the Islamic world thwarted from modernizing because its culture is trapped in the Middle Ages? Is poor economic development in much of the Middle East and Central Asia the result of cultural practices that are hostile to economic growth?
The usual charge is that the Islamic world missed the advances of the European Enlightenment, when the state and religion were separated, modern scientific ideas were adopted, and cultural attitudes towards women modernized.
As a result, it is alleged, the Islamic world cannot cope with the demands of modernization, either in technology or in cultural practices, such as the granting of rights to women, which is necessary for economic success in the modern world.
As always with crude generalizations, elements of truth are intermixed with a mass of confusion.
The truth is that certain cultural practices support economic modernization.
These include a tendency towards greater equality between men and women and their roles in society; a culture that rewards educational attainment with high social status; the secularization of many aspects of modern life, including the preeminence of modern science; and cultural practices that favor social mobility in the choice of occupations.
The falsehood is to believe that some cultures are static and inimical to change, while others are somehow uniquely modern.
In all parts of the world, cultures have had to adjust to the changes in economic organization, technology, and scientific knowledge of the past two hundred years.
In Western Europe and the US, for example, the cultural acceptance of social and economic equality between men and women has involved a long process of political struggle and evolving social norms.
The pace of change has varied markedly within regions and across cultural sub-groups.
The Islamic world, which stretches over 15,000 kilometers, dozens of countries, and more than 1 billion followers of the faith, is similarly subject to widespread cultural variation.
Islamic countries in the Mediterranean region (such as Morocco, Tunisia, Egypt, and Turkey) are culturally and politically distinct from Islamic countries in the Arabian Peninsula (such as Saudi Arabia, Yemen, and Oman), which differ from Islamic countries in Central Asia (such as Afghanistan, Pakistan, Tajikistan), Southeast Asia (such as Indonesia and Malaysia) and Sub-Saharan Africa (such as Mali and Chad).
Consider one example: the number of children per woman in society, known as the ``total fertility rate.''
In societies where women are not allowed to work and are expected to remain home and raise children, the number of children is very high.
Economic growth tends to suffer: when poor households have many children, the education given to each child also tends to be reduced.
In some parts of the Islamic world, most notably in the Arabian peninsula, the fertility rate remains very high.
A woman in Yemen will on average give birth to more than 7 children in her lifetime.
In Saudi Arabia, the average is over 6 children.
In other parts of the Islamic world, the fertility rate is far lower and has declined in recent decades, signaling a major shift in cultural norms.
In Tunisia, the average fertility rate has dropped from 6.2 in the 1970s to 2.3 today, just slightly above the 2.0 average in the US.
Similarly, in Turkey the fertility rate fell from 5.2 in the early 1970s to 2.7 in the late 1990s.
In Indonesia, the decline in fertility rates was about the same.
Women have entered the labor force in these societies in much greater number, delivering economic gains and improvements in their social status.
We can therefore note that in Islamic societies like Tunisia, Turkey, Indonesia, and Malaysia, economic growth and cultural change has proceeded rapidly in the past generation.
Some of these countries have been among the world's fastest growing economies in recent decades.
Islamic culture has neither been a barrier to growth, nor has it been static.
As in other parts of the world, culture in these countries has shown its vibrancy and also its capacity to adjust to changing conditions.
In the Arabian peninsula, cultural change has been slower, as has economic development.
Causation probably runs in both directions here: cultural factors may have impeded economic growth, while poor economic performance (say, bad economic policies and over-dependence on oil) may have slowed the adaptation of cultural practices to the needs of a modern economy.
In very remote places like Afghanistan or Chad, weak connections with the world economy also delayed the process of social change.
These examples should warn us away from three current tendencies.
The first is to give easy labels to complex and diverse societies.
The idea of a single conservative ``Islamic world'' is as mistaken as a single modern ``Western society.''
Diversity is very high; cultural practices vary widely.
Simplistic labels reflect more prejudice than understanding.
The second tendency is to believe that culture is somehow static and unchanging.
Cultures everywhere change in response to technological developments, economic growth, and - of course - globalization.
The third tendency is to believe that culture is the key to economic development.
Economic development is determined by many factors, including geography, politics, international relations, and culture.
Cultural differences across societies are often more the outcome than the cause of differences in economic development.
PRINCETON – Jesus said that we should give alms in private rather than when others are watching.
That fits with the commonsense idea that if people only do good in public, they may be motivated by a desire to gain a reputation for generosity.
Perhaps when no one is looking, they are not generous at all.
That thought may lead us to disdain the kind of philanthropic graffiti that leads to donors’ names being prominently displayed on concert halls, art museums, and college buildings.
Often, names are stuck not only over the entire building, but also on as many constituent parts of it as fundraisers and architects can manage.
According to evolutionary psychologists, such displays of blatant benevolence are the human equivalent of the male peacock’s tail.
Just as the peacock signals his strength and fitness by displaying his enormous tail – a sheer waste of resources from a practical point of view – so costly public acts of benevolence signal to potential mates that one possesses enough resources to give so much away.
From an ethical perspective, however, should we care so much about the purity of the motive with which the gift was made?
Surely, what matters is that something was given to a good cause.
We may well look askance at a lavish new concert hall, but not because the donor’s name is chiseled into the marble façade.
Rather, we should question whether, in a world in which 25,000 impoverished children die unnecessarily every day, another concert hall is what the world needs.
A substantial body of current psychological research points against Jesus’s advice.
One of the most significant factors determining whether people give to charity is their beliefs about what others are doing.
Those who make it known that they give to charity increase the likelihood that others will do the same.
Perhaps we will eventually reach a tipping point at which giving a significant amount to help the world’s poorest becomes sufficiently widespread to eliminate the majority of those 25,000 needless daily deaths.
That is what Chris and Anne Ellinger hope their Web site, www.boldergiving.org , will achieve.
The Web site tells the story of more than 50 members of the 50% League – people who have given away either 50% of their assets or 50% of their income in each of the last three years.
Members of the league want to change expectations about what is a “normal” or “reasonable” amount to give.
They are a diverse group of people.
Tom White ran a big construction company, and started giving millions to Paul Farmer’s efforts to bring health services to Haiti’s rural poor.
Tom Hsieh and his wife, Bree, made a commitment to live on less than the national median income, currently $46,000 a year.
As Hsieh, who is 36, earned more, they gave away more, mostly to organizations helping the poor in developing countries.
Hal Taussig and his wife have given away about $3 million, amounting to 90% of their assets, and now live happily on their social security checks.
Most donors see giving as personally rewarding.
Hsieh says that whether or not his giving has saved the lives of others, it has saved his own: “I could easily have lived a life that was boring and inconsequential.
Now I am graced with a life of service and meaning.” When people praise Hal Taussig for his generosity, he tells them, “Frankly, it’s my way of getting kicks out of life.”
The 50% League sets the bar high – perhaps too high for most people.
James Hong started www.hotornot.com , a Web site that allows people to rate how “hot” other people are.
It made him rich.
He has pledged to give away 10% of everything he earns over $100,000.
Hong’s Web site, www.10over100.org , invites others to do likewise.
So far, more than 3,500 people have. 
Hong sets the bar low.
If you earn less than $100,000, you don’t have to give away anything at all, and if you earn, say, $110,000, you would be required to give away only $1,000 – less than 1% of your income.
That is not generous at all.
Many of those earning less than $100,000 can also afford to give something.
Still, Hong’s formula is simple, and it starts to bite when earnings get really big.
If you earn a million dollars a year, you have pledged to give $90,000, or 9% of what you earn, which is more than most rich people give.
We need to get over our reluctance to speak openly about the good we do.
Silent giving will not change a culture that deems it sensible to spend all your money on yourself and your family, rather than to help those in greater need – even though helping others is likely to bring more fulfillment in the long run.
LONDON – I spent the New Year in Sydney, watching the fireworks above the iconic bridge welcome in 2009.
The explosions over Gaza that night were not intended to entertain, but rather to break Hamas and discredit it in the eyes of Palestinians.
It was the latest resort to terrible violence in order to resolve how to share in peace what Christians still like to call the Holy Land.
Mahatma Gandhi criticized the biblical justification of retribution, “an eye for an eye, a tooth for a tooth.”
Followed through to its end, he argued, it would mean that all were blind.
And so it has proved in Palestine and Israel.
Blind in Gaza, blind in Jerusalem.
Much of what has happened was predictable, as well over 1,400 men, women, and children have died and more than 4,000 have been injured.
First, the United States justified the Israeli assault and blamed everything on Hamas, just as it used to pin all responsibility for whatever went wrong on Yasir Arafat and Fatah.
Second, despite French President Nicolas Sarkozy’s welcome high-profile diplomacy, Europe has been irrelevant, if not quite invisible.
As Israeli officials point out, Europeans are always there for the photo opportunity.
The Quartet’s peacemaker, Tony Blair, is as unctuously nugatory as ever.
He appears on CNN , but has he actually visited Gaza since his appointment in the summer of 2007?
No.
Third, as usual, Israel has accused of anti-Semitism those who have dared to criticize its disproportionate response to Hamas’s indefensible rocket attacks and its collective punishment of Palestinians.
An Italian cardinal, who admittedly spoke intemperately, was accused of using the language of Holocaust denial.
By that standard, does my unqualified criticism of Hamas’s rocket attacks make me an Islamophobe?
Coincidentally, the deadly attack on Gaza came at the same time that a clutch of America’s most distinguished would-be Middle East peacemakers published books about how the task should properly be tackled.
It all sounded a bit like a series of job applications – the war for President Barack Obama’s ear.
One thing all these experts could agree on is that President George W. Bush was a disaster.
American policy might as well have been made in Likud’s headquarters.
Even at the end, when the United Nations Security Council voted on Gaza, Bush was happy to humiliate Condoleezza Rice at Israeli Prime Minister Ehud Olmert’s bidding.
These “wise men,” advisers one and all to President Bill Clinton and other presidents, all seem to concede that the failure of the proposed Camp David accord in 2000 could not, after all, be laid solely at Arafat’s door.
Former Israeli premier Ehud Barak should carry his share of the blame.
Moreover, they all criticize the Clinton-era practice of routinely clearing America’s policy positions first with Israel, which is hardly likely to win Arab confidence or support.
The American diplomats’ arguments about process did not on the whole carry over into disagreement about the content of a peace deal.
All more or less agree on this. Two states.
Security guarantees for Israel.
A Palestinian state within the 1967 borders, adjusted by agreement through mutual land swaps.
An end to most West Bank settlements.
No “right of return” for Palestinian refugees, but financial compensation for them.
Some system of joint or international sovereignty over Jerusalem’s holy places and the division of the city so that it can become the capital of two states.
Of course, this is what should happen.
And I suppose that it is conceivable that it could still happen with the help of welcome new mediators like Qatar and Turkey, whose prime minister called Israel’s attack “a serious crime against humanity.”
But I have begun to wonder whether it will really be possible to achieve peace on this basis.
Fatah, and Palestinian moderates like President Mahmoud Abbas, have been totally discredited.
Palestinians on the whole have been further radicalized.
Hamas, whose engagement and support is essential for any settlement, has sworn revenge.
Every day, new Palestinian sorrows strike heaven in the face.
The widows and the mothers of the dead weep and cry out for bloody justice.
Should we be surprised?
Had the British government pursued peace and the destruction of the IRA in Northern Ireland by bombing Catholic Derry, would that have alienated or won over Catholic opinion?
On the Israeli side, which political leaders really want a Palestinian state and are prepared to take the political risks associated with trying to establish one?
Which of them are strong enough to deal with the West Bank settlers?
There will be no peace settlement otherwise.
Which leaders will teach the facts of life to the more extreme members of the Jewish diaspora in America?
Who among Israel’s leaders understands that reconciliation is more important that retribution and revenge?
However tough things looked in the past, I have never felt such a sense of despair about Palestine and Israel.
Reason has been drowned in blood.
It seems as though the politics of hope have given way to the politics of the cemetery.
Poor Palestine.
Poor Israel.
Who is there now who can still light a candle in the dark?
As EU enlargement approaches, people across Western Europe fear a flood of job-seeking immigrants from the postcommunist accession countries.
Indeed, if all eight of the top East European candidates (excluding Bulgaria and Romania) join by the target date of 2004, the EU population's will soar by about 75 million people. 
When Spain and Portugal joined the EU two decades ago, emigration to existing member states was lessened by the fact that many immigrants had arrived from these countries during Europe's go-go 1960s.
But migration from Eastern Europe in those years was blocked by the Iron Curtain.
Now the income gap between eastern applicants and the EU is three times as large as the disparity with the Iberian peninsula was.
Munich's Ifo Institute expects about 2.5--3.3 million migrants to Western Europe during the 15 years following EU enlargement. 
These are big numbers, but there is little or no reason for fear-not if today's EU members prepare.
Unlike immigration from non-European countries, East European immigrants share a similar cultural background and will assimilate easily. 
In principle, with flexible labor markets, migration creates welfare gains for all countries.
Emigration countries gain because their nationals can earn an income in Western Europe that, for all but the most marginal migrant, is more than sufficient to compensate for the loss of domestic value added and the subjective and objective costs of migration.
Immigration countries gain because all but marginal migrants produce more value added than they get back in wages.
While blue-collar workers incur income losses, their losses will be overcompensated by the gains of landowners, capital owners, entrepreneurs and white collar workers. 
Sadly, today's EU labor markets are too inflexible to achieve this result.
If immigration countries suffer from chronic unemployment because wages are overly generous and rigid, as seems the case in most West European countries, migrants who find work will simply displace nationals from their jobs.
Here migration will result in a welfare loss.
Migrants gain.
So, too, family members staying home who receive money transfers.
But migrants produce no additional value added for the countries into which they immigrate, but incur migration costs and their contribution to domestic value added is missing. 
The EU wants to solve this problem by limiting migration for a transition period of up to seven years.
This is a second-best solution.
The best solution is to make Western labor markets flexible by opening the system of collective wage bargaining, dismantling labor market regulation, and reforming the welfare state. 
If workfare replaces welfare, wages will become more flexible enabling EU labor markets to absorb immigrants more efficiently.
But even with these measures, social benefits may artificially increase the incentive to migrate. 
If immigrants gain welfare benefits in addition to wages, more will be lured into coming than necessary, and marginal migrants would create welfare losses for the EU equal to the benefits.
Given that immigrants usually enter countries that redistribute resources from above-average to below-average incomes, such benefits are likely even if immigrants work and pay taxes and social security contributions.
Excluding taxes and contributions paid and transfers and public goods received, the Ifo Institute reckons that the average immigrant to Germany receives a net 2,300 euros annually. 
One way to curtail this problem is to delay full integration of immigrants into the welfare system of a host country for a few years-a reform advocated by the Scientific Advisory Committee to Germany's Federal Finance Ministry.
Immigrants could come and work, pay taxes and social contributions, and gain free access to the public goods of the host country.
They could also receive the full contribution-financed social transfers that the welfare state provides. 
But they would not be granted tax-financed social benefits.
Temporary exceptions could include supplemental social assistance, housing benefits or the "export" of family benefits to children living in the home country.
The exceptions would have to be tailored by each country so that the net cost of all transfers of public resources to and from immigrants is zero. 
Politicians and lawyers may dislike this solution, because it undermines the EU's principle of social inclusion for employment and resembles arrangements that currently apply to EU citizens who live in other member countries without working there.
Instead, bureaucrats and politicians prefer a quota system, whereby bureaucrats, not the market, select who immigrates. 
Such a system may formally fit better with the idea of social inclusion, but violates the basic right of free migration granted in the Treaty of Rome.
Only people that bureaucrats deign to select are fully included, while others who want to come but are not allowed to do so face discrimination. 
A policy of partial, delayed integration is preferable to quotas, not only in view of the Treaty of Rome but also on economic grounds.
It allows for fine-tuning and self-selection of migration flows, yielding far better results than even the most well-meaning bureaucrats could ever achieve.
Moreover, it would reduce the fiscal burden on taxpayers in immigration countries, thereby preventing a competitive dismantling of West European welfare states driven by the aim of warding off expensive immigration. 
Partially delayed integration rather than transition periods or quotas is a market-oriented solution that can maintain Europe's welfare states and enable it to grow and develop to its true potential. 
“Multiculturalism” has become a suspect term almost everywhere in the world nowadays, and particularly in Europe.
People say things like: “I used to be for openness and toleration of difference, but now I see where it’s leading.” But where is it leading?
Almost every reason for toleration’s apparent fall into disrepute concerns Islam.
Even simple requests, like that of schoolgirls to wear headscarves in class, are suddenly freighted with immense political significance and treated as issues that must be resolved at the highest level of government.
People – and their elected leaders as well &#45;&#45; often have the feeling that such seemingly innocent proposals are in fact part of an ominous “hidden agenda.”
That agenda is “Islam,” which many imagine to include all the terrible things that we can read about in the press every day: the stoning of adulterous women under Sharia law in northern Nigeria, the amputation of thieves’ hands in Saudi Arabia, honor killings of women who refuse arranged marriages in Pakistan (or even northern English cities like Bradford and Manchester), the willingness to justify suicide bombings.
If you reply that the girls who want to wear headscarves to school aren’t living in Nigeria or Saudi Arabia, and almost certainly don’t share the extreme Wahhabi views found in those countries, you will be met with a look of almost indulgent pity, a look of the type reserved for the terminally naïve.
Or you will be told stories about how Saudi trained imams are twisting the girls’ arms, turning them into unwilling stalking-horses for “Islam.”
Indeed, it is virtually impossible nowadays to talk about headscarves as an issue in its own right.
All the sociological evidence about the girls’ motives, which are in fact very varied, is swept aside as irrelevant.
All that matters is the threat posed by Islam.
This is a classic example of what I call “block thinking,” which seems to have made huge strides in Europe in recent years.
John Bowen’s recent book Why the French Don’t Like Headscarves documents this shift.
Block thinking fuses a varied reality into one indissoluble unity, and in two ways.
First, different manifestations of Islamic piety or culture are seen as alternative ways of expressing the same core meaning.
Second, all Muslims are then seen as endorsing these core meanings.
The possibility that a girl wearing a headscarf might in fact be rebelling against her parents and their kind of Islam, and that others might be deeply pious while being utterly revolted by gender discrimination or violence, is lost from view.
Block thinking is an age-old phenomenon, and we all do it to some degree.
But, while in another age we might have been indulgent about its consequences, today it has explosive potential, because people who think in this manner are prime recruits for seeing the world in terms of Samuel Huntington’s theory of the “clash of civilizations.”
What’s worse, the way such people then act tends to edge us closer to Huntington’s nightmare scenario.
By treating all the varied segments of Islam as nothing more than parts of a unified threat to the West, they make it harder for Muslims to stand out and criticize their own block thinkers – people like Osama bin Laden, who are building their own unified enemy, composed of “Christians and Jews.”
Block thinkers on each side give aid and comfort to block thinkers on the other side, and with each exchange they pull us closer toward an abyss.
So how can we stop this madness?
Block thought persists in part because its critics on each side are unknown to those on the other side.
Indeed, how many times does a critic of European block thought meet this kind of response: “But where are the Muslims who are criticizing extremist Islam?”
Of course, one isn’t likely to meet them in the drawing rooms of Paris journalists or the wider European professional political class.
But explaining that to block thinkers will never have the impact of a real connection to the multi-faceted discourse that is actually taking place on the other side.
The real question, then, is this: Where are the crossover figures who can provide that urgently needed connection?
LONDON – The race for the leadership of the British Labour Party isn’t normally a world-shaking event.
But the recent contest between two brothers – David and Ed Miliband – not only provided the material for a riveting family drama; it also illustrated some peculiarities of democratic cultures that often go un-noted – and the strange relationship between the personal and the political that is built into the   hierarchy of democratic protocol.  
Politics, or at least the exercise of power, was traditionally a family affair.
Kings typically hankered after male heirs, because power was vested through filial lineage, and distributed through tribal affiliations.
Hereditary power did not necessarily make for warm and open family relations.
Henry VIII was willing to execute two wives and overturn Christendom in pursuit of a son.
There are examples, in polygamous societies, of royal concubines murdering each other’s children in order to assure the predominance of their genetic line.
The Ottomans introduced the practice of “judicial royal fratricide,” supposedly to prevent civil war.
Whether it involved absolute loyalty or murderous rivalry, traditional politics was rarely divorced from personal passion.
Not so in modern Western democracies, where personal passions are, at least in theory, supposed to be completely separate from the impersonal representation of group interests.
Democracy, in its Greek origins, began with the creation of a public sphere distinct from the family and its intense emotions.
But modern democracies – especially those conducted on the Anglo-Saxon model – take this further, by attempting to separate not only the private from the public, but the person from the politician.
The division is in a sense inscribed in the democratic spectacle.
After presidential debates in the United States or Britain, the contenders, who may have been accusing each other of the most unforgivable of sins, shake hands vigorously and give each other genial and encouraging smiles.
No matter how much Barack Obama may have loathed the views of George W. Bush, he had to be initiated into state secrets by the former president, in a confidential – and undoubtedly genial – meeting.
In parliamentary debates, fierce ideological battles may be the order of the day, but ad hominem attacks are off limits.
This is undoubtedly to the good, and necessary to the conduct of orderly democratic life; but to those not used to it, the ability to combine enmity with bonhomie can seem counterintuitive.
Indeed, it may be that the transition from passionate to impersonal politics is one of the most difficult challenges facing democratizers everywhere.
In pre-1989 Eastern Europe, for example, politicians’ ideological positions were seen as inseparable from their moral, or human, self.
Those who were on the wrong side of the political divide were not only guilty of erroneous views; they were seen as wrong in their essence, and therefore to be condemned and hated.
The idea that you could treat political enemies jovially, and perhaps have a drink with them after hours – or enter into a coalition government with them – can seem not only unnatural, but even a bit indecent, in such circumstances.
Indeed, in some young democracies, or more volatile cultures, the suspension of personal feeling is not always successfully maintained.
Just last year, one could witness fistfights in parliaments ranging from Iraq to Taiwan, Turkey, and, most spectacularly, Ukraine.
To us, such behavior looks untoward, or even uncivilized; to the participants, it is probably experienced as a natural overflow of righteous feeling.
Clearly, parliamentary brawls are not a desirable modus operandi.
But how far can the separation between person and politician be taken – and to what extent do we really give it credence?
The Miliband race was an extreme example of what might be called counter-nepotism – the attempt to abstract the politician from all private attachments.
As the two brothers sat on platforms together, challenging each other’s views, they tried to maintain the double fiction that, on the one hand, there was no special bond between them, and, on the other, that their sometimes fierce disagreements did not taint their fraternal affections.
For a while, everybody played politely along; but the tricky double-think involved in this was exposed when the younger brother, Ed, won the leadership, by a razor-thin margin, in a last-minute upset.
Suddenly, this didn’t seem quite right.
In the media, comparisons to Esau’s theft of Jacob’s birthright and to various Shakespearean tragedies began to abound.
David Miliband’s decision to retreat from front-line politics made it evident that a symbolic beheading had taken place – and one wonders if Ed Miliband won’t be haunted, and therefore hampered, à la Macbeth, by the psychological violence he committed.
In judging candidates for high office, we are encouraged to eschew “personality politics,” and to disregard such aspects of politicians’ identities as their spiritual lives, their private behavior (unless obvious transgressions are committed), and their appearance and aesthetic tastes.
In practice, few of us can manage to compartmentalize our perceptions – and, perhaps, doing so would not be desirable.
We may not want politicians to be driven by self-interest, but we need to acknowledge that they have selves, which are formed by a multitude of factors – and passions.
In other words, if we do not want to reduce our vision of politics to policy processing, we need to remember – if only for the sake of fuller and more realistic judgment – that politicians are human, too.
PRINCETON – Former US President Bill Clinton gave one of the best speeches of his life at the recent Democratic National Convention.
One of the biggest rounds of applause came when he said that President Barack Obama’s appointment of Hillary Clinton as his Secretary of State after she had been his principal political rival proved that “democracy does not have to be a blood sport.”
That applause reflected the view of the majority of American voters that US politics has become much too partisan, and that rivals are more interested in attacking each other – “drawing blood” – than they are in focusing on political issues.
But what President Clinton was really saying was that Secretary Clinton’s ability to go to other countries and work with her former political rival in pursuit of the national interest is a powerful example of the way democracy is supposed to work.
That is an important point to make, because in far too many countries democracy remains – literally – a blood sport.
The value of the ballot is to seize power and then harass, detain, or even kill your opponents.
As the slogan goes: “One man, one vote, one time.” Indeed, the National Endowment for Democracy in the US describes some countries as “electoral dictatorships.”
Many fear precisely such an outcome for the Arab awakening, with popular movements toppling despots, only to install new dictators via elections.
The only way to avoid it is to be more committed to the process of electing a government freely and fairly than to the leader or party that is elected, even when the victor is frankly inimical to your interests.

That is also the conundrum of US policy in the Middle East in the midst of ongoing revolution.
For 30 years, the US government supported secular rulers who justified their iron grip on power by insisting that the choice was between them and “the Islamists” – whom they portrayed as religious zealots bent on taking their countries back to the Middle Ages.
Now the US must convince skeptical populations that it is prepared to do business with elected Islamist governments.
People who have come to believe in US omnipotence and determination to pursue its interests in their region cannot easily believe that its government is suddenly prepared to endorse an outcome that it did not want. Indeed, some Coptic Christian and liberal parties protested against Hillary Clinton during her visit to Egypt this past June, because, in their view, the US must have wanted the Muslim Brotherhood to come to power.
Future US policy must embody a simple but powerful principle: America will engage with and support (through various kinds of foreign assistance) any government chosen through internationally monitored free and fair elections that then governs according to a popularly ratified national constitution, with compliance overseen by an independent judiciary.
Americans do not believe that liberal democracy is the best form of government because what “the people” want is automatically right or good, but because it pits interest against interest.
As James Madison wrote in The Federalist Papers, “It is of great importance in a republic not only to guard the society against the oppression of its rulers, but to guard one part of the society against the injustice of the other part.”
A genuinely representative assembly in the twenty-first century will not establish a polity that tolerates political prisoners, censorship, oppression of minorities and women, torture, disappearances, or detention without trial.
Governments that live by their constitutional principles, even when they are imperfectly interpreted and applied, should avoid slipping back into dictatorship and are likely to be self-correcting over time.
As long as governments operate within these broad parameters, the US should look to itself before passing judgment on others. Vice President Joseph Biden also gave a powerful speech at the Democratic convention, in which he quoted a line from Obama’s inaugural address: the US should lead in the world not by “the example of our power, but by the power of our example.”
Unfortunately, in terms of democratic practice, that example is badly tarnished at the moment.
The US Supreme Court has interpreted the US Constitution in a way that vitiates all restrictions on campaign spending, essentially allowing wealthy American individuals and corporations to buy elections.
The support of a multi-millionaire now counts vastly more than that of an ordinary citizen, making a mockery of the principle of “one man, one vote.”
Moreover, both major US parties routinely use their power when they win to redraw electoral districts’ lines to favor themselves and hurt their opponents. And, in some states, the Republican Party is openly trying to impede voting by requiring citizens to show official photo identification, which can be difficult and expensive to obtain.
These requirements are a new version of the poll tax, which Democrats in the American South used for years to disenfranchise African-American voters.
Democracy can work properly only if all citizens’ operative principle is: “I may hate what you stand for, but as long as you are elected fairly and govern constitutionally, I will defend to the death your right to compete and win.”
If democracy is to be any sport at all, all players must abide by the rules of the game.
PARIS – Could Europe be a Democratic “blue state” and Asia a Republican “red state”?
American presidential elections provide a near perfect test to understand the difference between European and Asian worldviews, even if the two continents are far from united internally.
If you want America to lead by the power of example, you favor Barack Obama; if you want to be reassured by the continuation of America’s power in a traditional security sense, you probably prefer John McCain.
Whereas a majority of Europeans – with the exception of those who for historical and geographic reasons are obsessed with the return of the “Russian bear” – support Obama, a majority of Asians, particular among the elite, seem to support McCain.
This difference stems above all from strategic considerations, but it probably also contains a cultural dimension.
In Asia, Indonesia may look “European” in its Obama craze, but it essentially constitutes an anomaly, easily explainable by Obama’s brief Indonesian upbringing.
Otherwise, and for very different reasons, a majority of Asian elites are awaiting the growing possibility of an Obama victory with some bewilderment and even apprehension.
For example, Japanese elites tend to favor continuity over change.
In their mind, the hard power of the United States is more important than its soft power, and their vision of an America “bound to lead” is largely unchanged.
For them, the US is above all the strategic counterweight needed to balance China.
But the Chinese, too, may very likely be favoring McCain, for the opposite reason.
The decline of America’s image and influence in the world does not annoy them.
As Asia’s leading power, China has seized the mantle of “hope” from the US.
America could regain it under Obama, but not under McCain.
Why favor change, when continuity works so well for you?
Indian elites reach the same conclusion for different reasons.
The Bush years are seen positively, for they coincide with the consolidation of India’s international status and emergence as America’s key diplomatic partner in Asia.
In Singapore, ideological considerations reinforce strategic interests.
A very conservative regime naturally tends to prefer a Republican candidate over a Democrat.
But, beyond strategic considerations, something else must be mentioned (with prudence).
It is too early to say that the “yellow man’s burden” is about to replace Rudyard Kipling’s “white man’s burden” in world history.
Asians are slow to acknowledge that power entails international responsibility.
But Asians who have more than caught up with the West may have difficulty adjusting to the idea that the US would for the first time in history not be headed by a white president.
How can you define yourself to the West, when the West has so spectacularly and visibly changed its appearance, if not its essence?
In Europe, the reverse is true.
The complex essence of Barack Obama is an absolute plus.
For the former colonial countries, who have no equivalent to Obama, to support him fully is a sort of exorcism, if not redemption.
America is once more paving the way for what Europeans should be able to achieve one day with their own minorities: a land of dreams made possible.
In a more classical sense, the depth of anti-Bush sentiment in Europe explains the depth of pro-Obama feeling and Europeans’ relative distancing from McCain’s candidacy.
Europeans have felt oppressed by America’s excessive demonstration of hard power.
They would not mind an America that was more modest abroad and more ambitious at home.
They are in fact secretly wishing that in these tough economic times, at least part of the “culture of hope” incarnated by Obama would reverberate on them and transform them for the better.
They do not want the US only to protect them, but to transform them.
The perception that Obama can transform the view that the US and the West have of themselves is an important factor in the emotional gap that may exist between Asia and Europe on the eve of America's presidential election.
On that count, Asia tends to be a status quo continent, while Europe is a revisionist one.
For many Europeans, a reinvention of America is Europe’s last hope.
It is a noble hope, but also a dangerous one, for dreams can easily turn into nightmares.
That might very well happen if America’s next president fails to redress the financial and economic threats facing his country, and thus the rest of the world.
Bolivia is not a typical Latin American country by any definition.
But for Haiti, it is the poorest nation in the Western Hemisphere, and it is even less stable, with a history of more than two hundred coups since independence.
In a region with a strong indigenous past but a scattered and isolated present, Bolivia is, alongside Guatemala, perhaps the only country in Latin America where indigenous peoples make up a majority of the population.
Its topography and ethnic distribution are generating autonomist and even secessionist forces that threaten national unity in more menacing ways than anywhere else.
And, of course, it is, with Paraguay, the only land-locked nation on the sub-continent.
So it would be highly imprudent to extrapolate Bolivia’s current crisis to the rest of Latin America.
It is far too simple to generalize: institutions elsewhere are much stronger, poverty – and particularly extreme poverty – have been diminishing, and the battle over natural resources has been largely settled.
Even in places like Venezuela, with both huge oil reserves and a traditional-minded nationalist government, the status quo allowing for foreign investment in energy resources has survived nearly eight years of President Hugo Chavez.
While the existence of indigenous movements is a reality in many countries, from Chiapas to “Araucania,” from Amazonia to Ayacucho, nowhere in Latin America have they posed a genuine threat to national integrity.
So Bolivia is not a premonitory crisis; nor does the hoary old “domino theory,” to which both Lyndon Johnson and Che Guevara subscribed in the case of Bolivia, seem valid or even half-way reasonable.
Yet Bolivia’s current crisis does point to the “democratic deficit” that plagues Latin America today.
Elected leaders have fallen for one reason or another in Bolivia, Ecuador, and Haiti.
Democracy is either defective or missing in Cuba, Mexico, and Nicaragua, and it is threatened by one cause or another in Venezuela and Colombia.
None of these cases are identical to the others; they include varying degrees of danger, harm, or reconciliation.
The question is what can be done about this state of affairs, which contrasts starkly with the encouraging outlook that prevailed just a few years back.
At the last Organization of American States assembly in Fort Lauderdale, Florida, the United States delegation took a good idea from others and, by its support, essentially sank it.
The story began a couple of years ago, when former Argentine Foreign Minister Dante Caputo and the United Nations Development Program were charged with drafting the Latin American Democracy Report.
They concluded that an early warning system for democratic crises in the region would help generate action before matters got out of control, as in Bolivia today.
Caputo and the UN team then convinced Chilean President Ricardo Lagos to take up the initiative and to promote it with several of his colleagues.
He did, but the initiative did not get very far.
In fact, The UNDP/Latin America Democracy Report, published in 2004, barely mentioned it.
The US and the new Chilean Secretary General of the OAS, Jose Miguel Insulza, resurrected the plan during the OAS meeting in Florida, but it was shot down by Latin Americans’ reasonable fears that the idea was directed against Venezuela, mingled with Latin Americans’ anachronistic fears of violating the sacrosanct principle of non-intervention.
Despite the continent’s failure to agree on the principle, the idea of an early-warning system deserves attention.
Today there may be little that the hemispheric community can do about the situation in Bolivia, and yet it is fraught with danger for everyone.
Evo Morales, the leader of the opposition and of the coca-leaf growers, may be an honest, if misguided, democratic leader, but are his followers untainted by authoritarian desires?
Hugo Chavez may not be financing Morales and Bolivia’s other dissidents, but are Venezuela and Cuba really not tempted to meddle in the country where Che Guevara died leading a guerrilla war nearly 40 years ago?
Bolivia’s Santa Cruz business community may not carry out its threat to secede, but will they prefer to share their region’s oil and gas reserves with the indigenous highland peoples rather than with Brazilian industrialists from São Paulo?
Before events reached these extremes, it might have been a good idea for the OAS (not the US) to get involved.
The region continues to need that involvement – on time, on message, and on a proper democratic platform, one that is distinct from both traditional US intervention and Latin America’s traditional indifference.
In April 2002, violent demonstrations known as the "water war" in Bolivia forced President Hugo Bánzer to cancel the contract with the only international corporation interested in taking on the most ambitious water project ever proposed in the country.
Recently, another major popular upheaval ended a project to export natural gas to Mexico and the United States through a Chilean seaport.
This was the "gas war," which its leaders used to overthrow President Sánchez de Lozada and hold back the modernization process of strengthening institutions, opening markets, and integrating Bolivia into the global economy.
These so-called "wars" are part of the same conflict that prompted the peasant blockades of September 2000, the continuing protests by coca growers against efforts to eradicate their crops because of their role in the cocaine trade, and the withdrawal earlier this year of a progressive tax project.
In essence, these are all part of an ongoing conflict between democracy and populism, with Bolivia's future caught in the crossfire.
Neither side trusts the other, so social wars have replaced meaningful political progress.
As the violence of the social mobilizations and the level of discontent have grown, Bolivia's intellectuals and politicians remain in a state of shock, afraid of contradicting the masses.
For their part, the populists can rouse the masses but fail to offer alternatives.
They are nostalgic for the past and fearful of globalization.
As the two sides collide, the country suffers: the outcome of the water war has meant that the poor still use the same dirty and expensive water, while the result of the gas war could mean that we remain without new export revenues.
Bolivia needs leaders who can move the country beyond social wars that translate into stagnation.
To move forward, both sides need to be realistic about Bolivia's past.
The level of poverty--more visible with Bolivia's urbanization--is enormous, but it was worse before modernization efforts began.
In fact, almost all indicators point to substantial progress made in the 21-year history of Bolivian democracy.
Infant mortality has been cut in half, more citizens than ever enjoy educational opportunities, and electric, telephone, and sanitation services have expanded to serve a greater number of people.
Moreover, the channels leading to higher social and political participation have multiplied.
These advances are the result of audacious institutional reforms and the government's sustained and increased investment in social programs.
They are part of the modern democracy.
None of this progress, however, has been accompanied by the strengthening of our citizens' sense of responsibility to their nation.
In fact, while Bolivians demand the right to the many benefits of democracy, we fail to take seriously any obligation to contribute to the public good.
Many evade or reject paying taxes, in part by appealing for compassion towards the poor.
Leaders of the poor prefer to romanticize the past.
Thus, while ethnic inequities have been dramatically reduced over the past 50 years, the historical memory remains vivid to new generations of the now urban Aymaras and Quechuas people.
They rightly contest the degradation of their ancestors, but also idealize their rural, communitarian nature.
The current state of affairs fails to meet their expectations, especially when contrasted with an idealized version of the past or the new patterns of consumption portrayed in the media.
So expectations outpace reality, with politicians contributing to this by promising more than they can deliver--and thus losing the trust of their constituents.
Malaise has grown ever more acute after many Bolivian political leaders and their supporters, worn down by the regional crisis of the 1990's, expressed doubts over the modernization process.
Institutional reforms meant the government could no longer use public resources with the same discretion as before.
As a result, political parties and social organizations alike attacked reform efforts.
Presidents Bánzer, Quiroga, and Sánchez de Lozada found their authority dwindling while movements against them grew ever more robust.
After the political rebellion and lootings of this past February, Bolivia's Catholic bishops made real and consistent efforts to create a harmonious space for dialogue.
But the most radical indigenous groups rejected the initiative, and the group organizing the coca growers took advantage of the situation, stirring up nationalist sentiments.
This was easily accomplished, given Bolivia's memory of its losses: the loss of its seacoast to Chile in the War of the Pacific in 1879, of coca crops to the US eradication program, and the country's mineral wealth to transnational corporations.
Populists effectively converted these memories into a political force that rejected efforts leading to globalization and an open society.
This conflict continues.
In Bolivia, the populist/communitarian movement is in the saddle, but is failing to do much more than shelve reform projects.
For the underlying conflict to be resolved, Bolivians must become convinced that reform is the right track, the only one, indeed, that leads to progress and authentic development.
PARIS – As the United States and the world mark the fifth anniversary of the invasion of Iraq, debates are raging about the consequences – for Iraq, the Middle East, and America’s standing in the world.
But the Iraq war’s domestic impact – the Pentagon’s ever mushrooming budget and its long-term influence on the US economy – may turn out to be its most lasting consequence.
The US Defense Department’s request for $515.4 billion in the 2009 fiscal year dwarfs every other military budget in the world.
And this huge sum – a 5% increase over the 2008 military budget – is to be spent only on the US military’s normal operations, thus excluding the wars in Iraq and Afghanistan.
Since he took office in 2001, President George W. Bush has increased America’s regular military budget by 30%, again not taking into account the cost of the wars he launched.
Last year, America’s entire military and counterterrorism expenditures topped $600 billion.
One can assume that next year’s total spending on military affairs will be even bigger.
Adjusted for inflation, US military spending has reached its highest level since World War II.
Is there any limit to this spending boom?
The US is allocating more money for defense today than it did during the war against Hitler or the Cold War.
The Bush administration seems to think that today’s military threats are graver.
Talk about the so-called “peace dividend” that was supposed to come with the fall of the Berlin Wall has been silenced.
Of course, because the US economy has grown faster than military spending, the share of GDP dedicated to military expenditures has fallen over the years.
The US spent 14% of its GDP on the military during the Korean War (1950-1953, the Cold War’s peak), 9% during the Vietnam War and only 4 % nowadays.
Yet, given the sheer scale of military spending today, one can wonder if it is rational.
The US economy is probably in recession, clouds are gathering over its pension and health-care systems, and its military budget may not make sense even in strategic terms.
America alone accounts for around 50% of the world’s military expenditures, which is historically unprecedented for a single country.
Most other countries don’t come anywhere close.
Indeed, the second-ranked country in terms of total annual military spending, the United Kingdom, lags far behind, at $55 billion, followed by France ($45 billion), Japan ($41 billion), and Germany ($35 billion).
China and Russia, which can be considered strategic rivals of the US, spend $35 billion and $24 billion, respectively (though these figures probably underestimate expenditure, the true amount is certainly still far below the US –level).
Iran, depicted by the Bush administration as a major threat, is a military dwarf, spending $6.6 billion on its military.
Some voices in America are calling for even bigger increases.
Indeed, the Pentagon wants to enlarge the Marine Corps and Special Operations forces.
Since it is increasingly difficult to recruit and retain soldiers, to do so will probably require raising their wages and improving their quality of life.
Disabled soldiers also will cost a lot of money, even if the Pentagon won’t automatically pay everything for them.
But fulfilling the ostensible rationale for this seemingly interminable spending orgy – success in the so-called “war on terror” – does not seem anywhere within reach.
Mike McConnell, America’s Director of National Intelligence, recently admitted to a US Senate panel that al-Qaeda is gaining strength and steadily improving its ability to recruit, train, and even attack the US.
That assessment is stunning, yet few American leaders – Democrats and Republicans alike – appear to be wondering if military power is the best answer to security issues.
Indeed, by relying mainly on military solutions to political problems, the US seems to be increasing rather than reducing the threats it faces.
After all, the dangers that America faces today do not come from nation states, but from non-states actors against whom nuclear weapons and aircraft carriers are useless.
It would be less expensive and more fruitful for America to tackle the Israeli-Palestinian conflict, return to a multilateral approach, and respect the moral principles that it recommends to others.
Likewise, only by adopting such a strategy can the US start to compress the Pentagon’s inflated budget and begin to address its many domestic woes.
The $82 billion “emergency supplemental” bill to finance American military operations in Iraq and Afghanistan leaves the United States spending more money on military power than is needed on a yearly basis to permit every child in the world to receive, within one decade, both primaryandsecondary education.
Clearly, the question is not whether universal education is affordable, but whether America and the world can afford to neglect the political, economic, social, and health benefits of educating the roughly 380 million children around the globe who currently do not attend school.
Education, no less than military might, is a security imperative, for it helps the world – both individuals and societies – to escape the consequences of widespread poverty, rapid population growth, environmental problems, and social injustices.
Education strengthens social and cultural capital, which contributes to strong and stable polities.
It improves human health, increases life expectancy, and lowers fertility rates.
Aside from these obvious benefits, education is also a widely accepted humanitarian obligation and an internationally mandated human right.
But this right is unrealized for the 28% of the world’s school-age children who are not enrolled in school.
Most are illiterate and live in absolute poverty.
The majority of these children are female.
Of those who enter primary school in developing countries, more than one in four drops out before attaining literacy.
Moreover, enrollment does not necessarily mean attendance, attendance does not necessarily mean education, and education does not necessarily mean good education.
In 2000, the global community pledged to achieve universal primary education (UPE) by 2015.
Many poor countries are wildly off track when it comes to meeting this goal.
At the current rate of educational expansion, an estimated 118 million children will be absent from primary school in 2015.
Nearly twice that number will not attend secondary school.
The World Bank, UNICEF, and UNESCO have estimated that achieving UPE by 2015 will entail annual expenditures of between $6.5 billion and $35 billion, on top of the approximately $82 billion that developing countries spend each year on primary education.
These funds will be needed for schools, teachers, teacher training, materials and equipment, administration, and assessments.
Based on a five-year project that we led at the American Academy of Arts and Sciences, we believe that the UPE goal is not ambitious enough: the world should aim for, and can achieve, high-quality, universalsecondary education, as well as universal primary education.
Developing countries spend approximately $93 billion per year on secondary education.
If a gradual approach is taken between now and 2015, the annual additional cost of extending secondary education to every child will likely be between $27 billion and $34 billion.
Creating the necessary space to accommodate universal enrollment will require significant investment.
These funds would at best ameliorate – not eliminate – prevailing global disparities in educational access and quality.
Not included is the cost of other improvements needed to encourage children to attend school, such as meals, tuition subsidies, and more effective, dynamic, and knowledgeable teachers.
Nor does this include the cost of improving national governments’ capacity to collect data and to implement and oversee educational reforms.
Though more money is essential, it is not sufficient.
In some regions, cultural barriers inhibit schooling of girls and of linguistic, religious, and ethnic minorities.
The political energy required for expanding and reforming education is difficult to muster in the world’s wealthiest nations.
Ensuring high-quality education for all children requires an open discussion of educational goals, an international commitment to improving its effectiveness and economic efficiency, recognition of the need to extend secondary education to all children, and acknowledgment of educational diversity and the need to adapt aid policies to local contexts.
None of these tasks is possible without supplementing the funding already provided by developing countries.
The world, or even the US by itself, has the ability to provide the additional funds needed.
As the G8 leaders gather in Scotland, it is hard to imagine them coming up with a better investment in our common future.
NEW YORK – This global economic crisis will go down in history as Greenspan’s Folly.
This is a crisis made mainly by the United States Federal Reserve Board during the period of easy money and financial deregulation from the mid-1990’s until today.
This easy-money policy, backed by regulators who failed to regulate, created unprecedented housing and consumer credit bubbles in the US and other countries, notably those that shared America’s policy orientation.
The bubble has now burst, and these economies are heading into a steep recession.
At the core of the crisis was the run-up in housing and stock prices, which were way out of line with historical benchmarks.
Greenspan stoked two bubbles – the Internet bubble of 1998-2001 and the subsequent housing bubble that is now bursting.
In both cases, increases in asset values led US households to think that they had become vastly wealthier, tempting them into a massive increase in their borrowing and spending – for houses, automobiles, and other consumer durables.
Financial markets were eager to lend to these households, in part because the credit markets were deregulated, which served as an invitation to reckless lending.
Because of the boom in housing and stock market prices, US household net wealth increased by around $18 trillion during 1996-2006.
The rise in consumption based on this wealth in turn raised house prices further, convincing households and lenders to ratchet up the bubble another notch.
This has all come crashing down.
Housing prices peaked in 2006, and equity prices peaked in 2007.
With the collapse of these bubbles, paper wealth of perhaps $10 trillion, or even as much as $15 trillion, will be wiped out.
Several complex things are now happening simultaneously.
First, households are cutting back sharply on consumption, since they feel – and are – vastly poorer than they were a year ago.
Second, several highly leveraged institutions, such as Bear Stearns and Lehman Brothers, have gone bankrupt, causing further losses of wealth (of these failed institutions’ shareholders and creditors) and a further loss of credit that these firms once supplied.
Third, commercial banks also lost heavily in these dealings, wiping out much of their capital.
As their capital declines, so, too, do their future loans.
Fourth, and finally, the failure of Lehman Brothers and near failure of the insurance giant AIG, incited a financial panic, in which even healthy firms are unable to obtain short-term bank loans or sell short-term commercial paper.
The challenge for policymakers is to restore enough confidence that companies can once again obtain short-term credit to meet their payrolls and finance their inventories.
The next challenge will be to push for a restoration of bank capital, so that commercial banks can once again lend for longer-term investments.
But these steps, urgent as they are, will not prevent a recession in the US and other countries hit by the crisis.
The stock and housing markets are unlikely to recover any time soon.
Households are poorer as a result, and will cut back sharply on their spending, making a recession inevitable in the short run.
The US will be hardest hit, but other countries with recent housing and consumption booms (and now busts) – particularly the United Kingdom, Ireland, Australia, Canada, and Spain – will be hit as well.
Iceland, which privatized and deregulated its banks a few years ago, now faces national bankruptcy, because its banks will not be able to pay off foreign creditors who lent heavily to them.
It is no coincidence that, with the exception of Spain, all of these countries explicitly adhered to the US philosophy of “free-market” and under-regulated financial systems.
But, whatever the pain felt in the deregulated Anglo-Saxon-style economies, none of this must inevitably cause a global calamity.
I do not see any reason for a global depression, or even a global recession.
Yes, the US will experience a decline in income and a sharp rise in unemployment, lowering the rest of the world’s exports to the US.
But many other parts of the world that still grow.
Many large economies, including China, Germany, Japan, and Saudi Arabia, have very large export surpluses, and so have been lending to the rest of the world (especially to the US) rather than borrowing. 
These countries are flush with cash, and are not burdened by the collapse of a housing bubble.
Although their households have suffered to some extent from the fall in equity prices, they not only can continue to grow, but they can also increase their internal demand to offset the decline in exports to the US.
They should now cut taxes, ease domestic credit conditions, and increase government investments in roads, power, and public housing.
They have enough foreign-exchange reserves to avoid the risk of financial instability from increasing their domestic spending, as long as they do it prudently.  
As for the US, the current undeniable pain for millions of people, which will grow next year as unemployment rises, is an opportunity to rethink the economic model adopted since President Ronald Reagan came to office in 1981.
Low taxes and deregulation produced a consumer binge that felt good while it lasted, but also produced vast income inequality, a large underclass, heavy foreign borrowing, neglect of the environment and infrastructure, and now a huge financial mess.
The time has come for a new economic strategy – in essence a new New Deal.
NEW YORK – The recent death of Norman Borlaug provides an opportune moment to reflect on basic values and on our economic system.
Borlaug received the Nobel Peace Prize for his work in bringing about the “green revolution,” which saved hundreds of millions from hunger and changed the global economic landscape.
Before Borlaug, the world faced the threat of a Malthusian nightmare: growing populations in the developing world and insufficient food supplies.
Consider the trauma a country like India might have suffered if its population of a half-billion had remained barely fed as it doubled.
Before the green revolution, Nobel Prize-winning economist Gunnar Myrdal predicted a bleak future for an Asia mired in poverty.
Instead, Asia has become an economic powerhouse.
Likewise, Africa’s welcome new determination to fight the war on hunger should serve as a living testament to Borlaug.
The fact that the green revolution never came to the world’s poorest continent, where agricultural productivity is just one-third the level in Asia, suggests that there is ample room for improvement.
The green revolution may, of course, prove to be only a temporary respite.
Soaring food prices before the global financial crisis provided a warning, as does the slowing rate of growth of agricultural productivity.
India’s agriculture sector, for example, has fallen behind the rest of its dynamic economy, living on borrowed time, as levels of ground water, on which much of the country depends, fall precipitously.
But Borlaug’s death at 95 also is a reminder of how skewed our system of values has become.
When Borlaug received news of the award, at four in the morning, he was already toiling in the Mexican fields, in his never-ending quest to improve agricultural productivity.
He did it not for some huge financial compensation, but out of conviction and a passion for his work.
What a contrast between Borlaug and the Wall Street financial wizards that brought the world to the brink of ruin.
They argued that they had to be richly compensated in order to be motivated.
Without any other compass, the incentive structures they adopted did motivate them – not to introduce new products to improve ordinary people’ lives or to help them manage the risks they faced, but to put the global economy at risk by engaging in short-sighted and greedy behavior.
Their innovations focused on circumventing accounting and financial regulations designed to ensure transparency, efficiency, and stability, and to prevent the exploitation of the less informed.
There is also a deeper point in this contrast: our societies tolerate inequalities because they are viewed to be socially useful; it is the price we pay for having incentives that motivate people to act in ways that promote societal well-being.
Neoclassical economic theory, which has dominated in the West for a century, holds that each individual’s compensation reflects his marginal social contribution – what he adds to society.
By doing well, it is argued, people do good.
But Borlaug and our bankers refute that theory.
If neoclassical theory were correct, Borlaug would have been among the wealthiest men in the world, while our bankers would have been lining up at soup kitchens.
Of course, there is a grain of truth in neoclassical theory; if there weren’t, it probably wouldn’t have survived as long as it has (though bad ideas often survive in economics remarkably well).
Nevertheless, the simplistic economics of the eighteenth and nineteenth centuries, when neoclassical theories arose, are wholly unsuited to twenty-first-century economies.
In large corporations, it is often difficult to ascertain the contribution of any individual.
Such corporations are rife with “agency” problems: while decision-makers (CEO’s) are supposed to act on behalf of their shareholders, they have enormous discretion to advance their own interests – and they often do.
Bank officers may have walked away with hundreds of millions of dollars, but everyone else in our society – shareholders, bondholders, taxpayers, homeowners, workers – suffered.
Their investors are too often pension funds, which also face an agency problem, because their executives make decisions on behalf of others.
In such a world, private and social interests often diverge, as we have seen so dramatically in this crisis.
Does anyone really believe that America’s bank officers suddenly became so much more productive, relative to everyone else in society, that they deserve the huge compensation increases they have received in recent years?
Does anyone really believe that America’s CEO’s are that much more productive than those in other countries, where compensation is more modest?
Worse, in America stock options became a preferred form of compensation – often worth more than an executive’s base pay.
Stock options reward executives generously even when shares rise because of a price bubble – and even when comparable firms’ shares are performing better.
Not surprisingly, stock options create strong incentives for short-sighted and excessively risky behavior, as well as for “creative accounting,” which executives throughout the economy perfected with off-balance-sheet shenanigans.
The skewed incentives distorted our economy and our society.
We confused means with ends.
Our bloated financial sector grew to the point that in the United States it accounted for more than 40% of corporate profits.
But the worst effects were on our human capital, our most precious resource.
Absurdly generous compensation in the financial sector induced some of our best minds to go into banking.
Who knows how many Borlaugs there might have been among those enticed by the riches of Wall Street and the City of London?
If we lost even one, our world was made immeasurably poorer.
As more time passes with neither the value of the dollar declining sharply nor market forces beginning to shrink America’s current-account deficit – which may well reach $1 trillion this year – two diametrically opposed reactions are emerging.
Most international finance economists are becoming increasingly frightened that a major international financial crisis could erupt.
Indeed, they fear that the scale of that potential crisis is becoming larger and larger.
Others – especially managers of financial assets – are becoming increasingly convinced that economists don’t know very much, and that what they do know is of no use to traders like themselves.
They see little reason to believe that current asset values and trade flows are not sustainable.
After all, they (or some of them) argue, the real GDP of the United States is growing by $400 billion per year, with about $270 billion going to labor and $130 billion to capital.
Even after depreciation, that $130 billion of extra annual income is capitalized at about $1.5 trillion of wealth, so the current-account deficit, even at $1 trillion, is not overwhelmingly large.
We Americans can sell off two-thirds of the increment to our wealth to finance imports and still be $500 billion better off this year than we were last year.
Moreover, the annual interest charged on the extra $1 trillion per year that Americans borrow from the rest of the world is about $50 billion – just one-eighth of annual economic growth, while the trade deficit is financed out of the growth of the value of capital.
So what’s unsustainable?
Why can’t the US current-account deficit remain at its 2006 value indefinitely?
The counterargument hinges on the difference between the current-account deficit and the trade deficit.
The current-account deficit is equal to the trade deficit plus the cost of servicing the net international asset position: the net rent, interest, and dividends owed to foreigners who have invested their capital in the US.
As time passes, deficits accumulate.
As deficits accumulate, the cost of servicing the net international asset position grows.
Thus, in order to keep the current-account deficit stable, the trade deficit must shrink.
And the only way for the trade deficit to shrink substantially is for net imports to fall, which requires either a relatively sharp decline in the value of the dollar, thereby raising import prices, or a depression in the US.
Both outcomes would weaken demand for foreign goods by making Americans feel that they are too poor to buy them.
As a result, holders of dollar-denominated assets should be looking forward to two alternative scenarios.
In one, the value of the dollar will be low; in the other, the US will be in a depression.
In neither scenario does it make sense to hold huge amounts of dollar-denominated assets today.
Therefore, foreign speculators should, any day now, dump their dollar-denominated assets onto the market, and so bring about the dollar decline that they so fear.
But foreign-currency speculators and international investors are not looking forward to either of these scenarios.
They continue to hold very large positions in dollar-denominated assets, which they would not do if they thought the US faced a choice between a cheap dollar and a deep depression.
So, what alternative does the market see?
And why is it so different from the possible scenarios that international financial economists see?
The answer appears to be that there is nobody in the financial centers of New York, London, Tokyo, Frankfurt, and Hong Kong who thinks it is their business to bet on a future flight from the dollar.
Especially in times of crisis – and a sharp fall in US imports would imply a much more severe crisis for Asian and European exporters than it would for the US – the dollar is a currency that you run to, not from.
George Soros can bet on a run on the British pound.
Thai import-export firms can bet on a run on the baht by accelerating their dollar receipts and delaying their dollar payouts.
Everyone can bet on a run on the Argentine peso – a favorite sport of international financial speculators for a century and a half. But not the dollar.
Not yet.
In other words, the market is betting that the dollar will fall gradually in the next five years, and that the US current-account deficit will narrow without a financial crisis.
That is what happened in the late 1980’s, and in the late 1970’s, too.
After all, God, it is said, protects children, fools, dogs, and the United States of America.
But the odds on a soft landing are lengthening with each passing day.
WASHINGTON, DC – Today’s conventional view of the eurozone is that the crisis is over – the intense, often existential concern earlier this year about the common currency’s future has been assuaged, and everything now is back under control.
This is completely at odds with the facts.
European bond markets are again delivering a chilling message to global policymakers.
With bonds of “peripheral” eurozone nations continuing to fall in value, the risk of Irish, Greek, and Portuguese sovereign defaults is higher than ever.
This comes despite the combined bailout package that the European Union, International Monetary Fund, and European Central Bank created for Greece in May, and despite the ECB’s continuing program of buying peripheral EU countries’ bonds.
Heading into its annual meetings in a few weeks (followed by the G-20 summit in Seoul in November), the IMF is bowing to pressure to drop ever-larger sums into the EU with ever-fewer conditions.
Indeed, official rhetoric has turned once again to trying to persuade markets to ignore reality.
Patrick Honohan, the governor of Ireland’s central bank, has labeled the interest rates on Irish government bonds “ridiculous” (meaning ridiculously high), and IMF researchers argue that default in Ireland and Greece is “unnecessary, undesirable, and unlikely.”
This is disconcertingly reminiscent of the spring – when Jean-Claude Trichet, the ECB president, lashed out at a skeptical bond market and declared a Greek default unfathomable.
But markets today think there is a 50% chance that Greece will default within the next five years – and a 25% chance that Ireland will do so.
The reason is simple: both Greece and Ireland are likely insolvent.
While the Greek fiscal fiasco is now common knowledge, Ireland’s problems are deeper and less widely understood.
In a nutshell: Ireland’s policymakers failed to supervise their banks, and watched (or cheered) from the sidelines as a debt-fueled spending binge generated the “Celtic miracle,” whereby Ireland grew faster than all other EU members and Dublin real estate became some of the most expensive in the world.
By the end of 2008, Ireland’s three main banks had lent more than three times the country’s national income.
The crash came in 2009, as Ireland’s real estate boom turned to bust, leaving the country with large insolvent banks, a collapse in budget revenues, and Europe’s largest budget deficit.
Ireland’s banks financed their rapid growth by borrowing from other European banks, so the health of Europe’s financial system has become entwined with the survival of these insolvent banks.
It is no surprise that the ECB is now Ireland’s largest creditor – through buying up its government bonds.
In the latest data (through the end of August), despite being two-thirds the size, Ireland received more ECB financing than Greece – totaling 75% of Irish GNP and growing rapidly.
The quid pro quo for this easy ECB money is that the Irish government must protect European creditors who would otherwise face large losses.
The ensuing massive bank bailout, plus continued budget deficits and declining nominal GNP, means that Ireland’s debt is ballooning, while its capacity to pay has collapsed.
Investors naturally respond to unsustainable debt by selling bonds until interest rates become “ridiculous.”
Those high interest rates strangle businesses and households, causing further economic collapse and making debt ever more unsustainable.
To halt this downward spiral, Ireland’s risk of insolvency needs to be put to rest.
Either banks need to default on their senior obligations, or the government will need to default alongside the banks.
In either case, new austerity measures are needed, and Ireland will require substantial bridge financing.
Irish and EU politicians should take the lead in making these tough decisions, but the current leadership will not.
Instead, the EU, the ECB, and Ireland have reached a Faustian bargain that keeps Ireland liquid (i.e., it gets euros), but does nothing to halt the growing likelihood of insolvency (i.e., its increasing inability to pay back those euros in the future).
The IMF, which should be standing up to this dangerous bargain, instead plans to open the spigots (with Chinese, American, and other countries’ funds) even more widely to insolvent nations.
On August 30, the Fund abolished ceilings on its “Flexible Credit Line” facility, which was introduced in 2009 to provide rapid funds to countries in temporary crisis.
Moreover, the IMF announced a new financing program called a “Precautionary Credit Line,” which will provide funds more quickly and with even fewer conditions – even to countries without “sound public finance” and “effective financial supervision.”
The Fund is also hoping to establish a new “Global Stabilization Mechanism” to provide credit lines to regional groupings (like the EU).
A European politician heads the IMF, its board of directors is far more weighted towards Europe than is justified by Europe’s economic relevance, and it is rushing to ease lending conditions to Europe just as EU members are suffering deep insolvency problems.
There is a better solution, pioneered after commercial banks in the United States loaned too much to Latin America in the 1970’s.
Sovereign debt was eventually restructured through the creation of “Brady bonds.”
The trick was to offer banks the opportunity to swap their claims on (insolvent) Latin American countries into long-maturity, low-coupon bonds that were collateralized with US Treasuries.
The good collateral meant that banks could hold these debts at par on their balance sheets.
At the same time, this swap reduced troubled countries’ debt-payment obligations – allowing them to get back on their feet.
Europe could take this route.
Rather than continuing to pile new debts onto bad debts, the EU stabilization fund could be used to collateralize such new par bonds.
Creditors could be offered these par bonds, or a shorter-term bond with a higher coupon – but with debt principal marked down.
The new bonds could be known as Trichet or Merkel/Sarkozy or Honohan bonds – whatever works to build consensus.
Societies that take in "brain drained" scientists and others benefit enormously.
Innovative and entrepreneurial French Huguenots contributed mightily to the launch of the Industrial Revolution in Britain.
American universities benefited mightily from refugee German Jews fleeing Adolf Hitler.
Today's Silicon Valley would not be what it is without its brilliant Chinese and Indian entrepreneurs. 
The Swiss Federal Institute of Technology in Zurich (ETH) has the highest number of Nobel Prize winners of any institution in the world, no doubt partly due to the fact that 35% of its faculty is foreign.
From Cordoba 1000 years ago to California today, the most intellectually stimulating places are crossroads for bright people from different cultures. 
Societies that fail to attract foreign brains stagnate.
Take Japan.
Japan's homogeneity helped create the economic nationalism that drove the country for several decades, but today most of Japan's universities, research institutes and laboratories, think-tanks and elite publications, suffer from sclerotic inbreeding.
Japan's current lethargy is due, in part, to the in-bred languor of Japanese intellectual life. 
But aren't countries that export their "brains" impoverished by the process?
It depends.
Spain, for example, saw its best minds drained away for five centuries, notably following Fascism's victory in the Spanish Civil War.
When Franco died in 1975, Spain's future path was not obvious, as evidenced by the attempted coup of February 1981. 
Poor, dictatorial, marginalized from Europe, Spain's experience during the last quarter- century is one of history's most successful transition stories, as it became a prosperous, thriving democracy and ceased being a major exporter of brains.
Indeed, many of Spain's best minds have returned home.
More importantly, foreign brains now drain to Spain! 
Historically, a big exporter of people, per inhabitant, has been Ireland.
Poverty and the rigid social control of a reactionary Roman Catholic Church made the country inhospitable to intellectual life -- to Britain's and America's great advantage, because both received many bright Irish fleeing the stultifying intellectual life of their homeland.
As generally happens, the less intellectually endowed remained behind. 
Yet, from Third World poverty levels two decades ago, Ireland has surpassed its former colonial master in GDP 
per capita.
Becoming a committed European player, fostering foreign direct investment, including venture businesses, promoting financial services and IT resulted in a formidable brain drain reversal for Ireland. 
After Chiang Kai-shek retreated to Taiwan in 1949 to form the Republic of China in opposition to Mao's People's Republic, he sought to maintain his dictatorial regime but was made to recognize the importance of building Taiwan's economy so as to strengthen the island.
Thanks to generous US aid --Taiwan was for several decades second only to Israel in the amount of American aid received --Taiwan could send its best university students, especially engineers, to study abroad. 
Now Taiwan has the highest proportion of engineers to total population in the world.
Many Taiwanese engineers studied in prestigious American universities, with the result that in Boston people sometimes refer to M.I.T. as "Made in Taiwan" rather than the Massachusetts Institute of Technology.
As late as the 1980s, only two out of ten Taiwanese who studied in the US returned home, due to its bleak social, intellectual and political environment. 


Then Taiwan did several things: by establishing science parks, it provided a good environment for R&amp;D; by deregulating, it provided opportunities for entrepreneurs; last, but emphatically not least, by ending the dictatorship and ushering in democracy, it provided the basis for that universal desire of people to pursue their individual freedom and happiness.
In the 1990s, thanks to its returning brains, Taiwan became a high-tech powerhouse. 
South Korea's story over the last 50 years parallels Taiwan's story.
The military dictatorship established by Park Chung-hee in 1962 adopted an aggressive economic development policy, partly to contain North Korea.
The Park government recognized the importance of investing in education, including primary, secondary and tertiary. 
The problem for a dictator in building universities is that students are needed, and students often protest!
Once Korean students overthrew the dictatorship of Park's successor, Chung Doo-hwan, Korean scientists, engineers, economists, and others, returned home 
 en masse
 , bringing knowledge acquired in the US with them. 
So a brain drain can be a good thing for recipient countries and also for brain exporting countries.
Good, that is, if the drain is reversed one day.
Most people everywhere prefer to stay home, or return home, rather than live in permanent exile. 
 Kimchi
 is simply not as good in Los Angeles as in Pusan, nor is 
 chapathi
 as good in Manchester as in Hyderabad. 
Brain drains put enormous pressure on brain exporting countries to improve their governance, their institutions, and their economic and their social freedoms.
Such improvements are the ultimate test of a successful society.
For this reason especially, but also for many others, the more brains that are drained, the better! 
CAMBRIDGE – A huge struggle is brewing within the G-20 over the future of the global financial system.
The outcome could impact the world – and not only the esoteric world of international finance – for decades to come.
Finance shapes power, ideas, and influence.
Cynics may say that nothing will happen to the fundamentals of the global financial system, but they are wrong.
In all likelihood, we will see huge changes in the next few years, quite possibly in the form of an international financial regulator or treaty.
Indeed, it is virtually impossible to resolve the current mess without some kind of compass pointing to where the future system lies.
The United States and Britain naturally want a system conducive to extending their hegemony.
US Treasury Secretary Timothy Geithner has recently advanced the broad outlines of a more conservative financial regulatory regime.
Even critics of past US profligacy must admit that the Geithner proposal contains some good ideas.
Above all, regulators would force financiers to hold more cash on hand to cover their own bets, and not rely so much on taxpayers as a backstop.
Geithner also aims to make financial deals simpler and easier to evaluate, so that boards, regulators, and investors can better assess the risks they face.
While the rest of the world is sympathetic to Geithner’s ideas, other countries would like to see more fundamental reform.
Russia and China are questioning the dollar as the pillar of the international system.
In a thoughtful speech, the head of China’s Central Bank, Zhou Xiaochuan, argued the merits of a global super-currency, perhaps issued by the International Monetary Fund.
These are the calmer critics.
The current president of the European Union’s Council of Ministers, Czech Prime Minister Mirek Topolanek, openly voiced the angry mood of many European leaders when he described America’s profligate approach to fiscal policy as “the road to hell.”
He could just as well have said the same thing about European views on US financial leadership.
The stakes in the debate over international financial reform are huge.
The dollar’s role at the center of the global financial system gives the US the ability to raise vast sums of capital without unduly perturbing its economy.
Indeed, former US President George W. Bush cut taxes at the same time that he invaded Iraq.
However dubious Bush’s actions may have been on both counts, interest rates on US public debt actually fell.
More fundamentally, the US role at the center of the global financial system gives tremendous power to US courts, regulators, and politicians over global investment throughout the world.
That is why ongoing dysfunction in the US financial system has helped to fuel such a deep global recession.
On the other hand, what is the alternative to Geithner’s vision?
Is there another paradigm for the global financial system?
China’s approach represents a huge disguised tax on savers, who are paid only a pittance in interest on their deposits.
This allows state-controlled banks to lend at subsidized interest rates to favored firms and sectors.
In India, financial repression is used as a means to marshal captive savings to help finance massive government debts at far lower interest rates than would prevail in a liberalized market.
A big part of Russia’s current problems stems from its ill-functioning banking system.
Many borrowers, unable to get funding on reasonable terms domestically, were forced to take hard-currency loans from abroad, creating disastrous burdens when the ruble collapsed.
Europe wants to preserve its universal banking model, with banks that serve a broad range of functions, ranging from taking deposits to making small commercial loans to high-level investment-banking activities.
The US proposals, on the other hand, would make universal banking far harder, in part because they aim to ring-fence depository institutions that pose a “systemic risk” to the financial system.
Such changes put pressure on universal banks to abandon riskier investment-bank activities in order to operate more freely.
Of course, US behemoths such as Citigroup, Bank of America, and JP Morgan will also be affected.
But the universal banking model is far less central to the US financial system than it is in Europe and parts of Asia and Latin America.
Aside from its implications for different national systems, the future shape of banking is critical to the broader financial system, including venture capital, private equity, and hedge funds.
The Geithner proposal aims to rein in all of them to some degree.
Fear of crises is understandable, yet without these new, creative approaches to financing, Silicon Valley might never have been born.
Where does the balance between risk and creativity lie?
Although much of the G-20 debate has concerned issues such as global fiscal stimulus, the real high-stakes poker involves choosing a new philosophy for the international financial system and its regulation.
If our leaders cannot find a new approach, there is every chance that financial globalization will shift quickly into reverse, making it all the more difficult to escape the current morass.
Since 1978, reproductive biologists have helped couples overcome infertility by using increasingly sophisticated techniques for generating and manipulating human embryos in the laboratory.
At the same time, molecular biologists have been working to overcome human disease by deciphering the entire sequence of the human genome and constructing tools to correct genetic and cellular defects.
While reproductive and molecular biologists focus on unrelated medical problems - infertility and disease - combining their technologies produces 
 reprogenetics
 , which will allow us to design ourselves. 
Reprogenetics
 will enable prospective parents to give their children genes that they themselves do not carry, thereby increasing their offspring's chances for health, longevity, happiness, and success - an appalling prospect for many bioethicists.
But is reprogenetics simply a new and more powerful vehicle to repeat the abhorrent eugenic practices of the past?
Or are reprogenetics and eugenics fundamentally different from one another in terms of both control and purpose? 
Eugenics embodies the desire and attempts of a society's leaders to control the breeding practices of its citizens, including the forcible sterilization or murder of those deemed as carrying undesirable genes.
Reprogenetics, by contrast, is concerned with the question of what genes an individual child will receive, not with the vague, unscientific goal of improving a society's gene pool.
Moreover, it gives control to individual prospective parents.
While eugenic practices led to a restriction of reproductive freedom and worse, reprogenetics can do the opposite.
It could help parents have children with a higher likelihood of being healthy, without bringing direct harm to anyone else. 
Reprogenetics can be understood as an extension of parents' fundamental motivation and desire: to protect their children and give them all possible advantages in life.
Parents in affluent societies already provide environmental advantages to their children after birth; reprogenetics could allow them to pursue the same objectives before birth. 
Of course, neither environmental nor genetic advantages guarantee healthier, happy, successful children.
But the lack of guarantees does not prevent parents from spending $140,000 to send their children to the elite private university where I teach.
If democratic societies allow people to spend money to buy environmental advantages for children, how can they prohibit parents from buying genetic advantages?
If reprogenetics is used to increase chances of health, happiness and success, what could be wrong with it? 
Once issues of technical safety are resolved, a fundamental objection to reprogenetics is its inherent unfairness to families unable to afford it.
All modern democratic societies must balance individual autonomy and social justice.
In the US, individual autonomy is of paramount importance.
In most other Western countries, social solidarity looms much larger. 
Most European countries try to realize it by providing equal healthcare and educational opportunities to all children.
But the argument that genetic enhancements are immoral because not all children can receive them is flawed.
Children are not biologically equivalent to begin with.
Everyone is born with advantages or disadvantages across a whole range of physical characteristics as well as innate abilities.
Life is not fair. 
So, in the future the critical question will be this: "Who decides how genetic advantages are distributed?"
Who decides which child will get the HIV resistance gene and who will be born susceptible to AIDS?
Who will decide which child will have superior protection against cancer and heart disease? 
Should the decision be left to the randomness of nature, as it is now?
Should it be determined by the parents' affluence?
Or should it be controlled by a benevolent state that doles out life-enhancing genes to all its newly conceived children? 
Unfortunately, provision and regulation of genetic enhancement technology will not be easy.
Unlike healthcare, there are almost no limits to genetic enhancements.
There can always be stronger resistance to disease, greater longevity, more physical prowess, and higher mental capacity.
Furthermore, the innate desire to provide for one's children is so powerful that affluent citizens may buy reprogenetics elsewhere even if their society bans or limits its use.
Today, for example, Europeans travel to the US to purchase human eggs from young women chosen on the basis of their presumed genetic characteristics. 
It is, however, possible to envisage an alternative scenario to that of a growing gap between "haves" and "have-nots."
Although such a gap may emerge initially, the cost of reprogenetics is likely to drop sharply over time.
Like computers and advanced telecommunications, it could become affordable to the majority in developed countries. 
Ultimately, hyper-human genetic enhancements will become feasible, too, and the economic and social advantages that wealthy countries maintain could be expanded into a genetic advantage.
The divide between wealthy and poor nations could widen further with each generation until a common humankind no longer exists.
A severed humanity could be the ultimate legacy of unfettered global capitalism. 
The only alternative to this bleak possibility seems remote today and may never be viable: a single global state in which all children are provided with the same genetic enhancements and the same opportunities for health, happiness, and success.
While this sounds like political fiction in a world where children still die from starvation, reprogenetics sounded like science fiction only thirty years ago.
The course of political development is, for good or bad, far more difficult to predict. 
The biggest hidden story in international development these days may be Brazil's economic takeoff.
Two years ago, Brazil's economy was left for dead, and the election of Worker Party candidate Luiz Inácio "Lula" da Silva as President was widely expected to trigger financial collapse.
Instead, Lula has governed with remarkable prudence, and Brazil is poised for rapid growth.
But something more fundamental is at play: Brazil may finally be overcoming some of the deepest obstacles to its economic development, obstacles that held the country back for decades.
If so, it could mark not only Brazil's economic ascendancy but also the recovery of other parts of South America.
In January 2002, American right-wingers were terrified of a leftist revolution in Brazil.
Foreign investors were panicking over the prospect that Brazil would fail to roll over its foreign debts.
The IMF, for a change, did a good job, providing interim financing and throwing its political backing behind Lula after the elections.
In turn, Lula adopted orthodox macroeconomic policies and moved to get the budget deficit under control, breaking the panic.
Market projections for Brazil's growth are around 4% for 2004.
But something deeper is at play than the usual waves of euphoria and panic in international financial markets.
Much of the credit for Brazil's turnaround belongs not to Lula but to his predecessor, Fernando Henrique Cardoso, who was Brazil's President from 1992 to 2000.
I credit FHC, as he is widely known, with making four key contributions.
· First, under his leadership, Brazil firmly embraced human rights, not only in the sense of democratic elections, but in terms of economic justice for African-Brazilians and indigenous Brazilians, people who had long been discriminated against.
Like most of Latin America, Brazil was born in the crucible of conquest and slavery.
Even during the 20 th century, neither the indigenous populations nor the African-Brazilian slave descendants had much chance in the economic and social order.
That is changing fast.
Public education is becoming universally available, including for groups that faced harsh discrimination in the past.
Remarkably, indigenous groups also won a hard-fought struggle for land rights in their traditional Amazon homelands.
· Second, Brazil is finally embracing the global knowledge economy.
For most of the 20 th century, Brazilian elites thought that they could get by on natural resources - cattle ranches, coffee plantations, fruit juices, and soybean farms.
Now they know that universal secondary education and extensive university-level training is also needed.
Under FHC's reforms, enrolment rates in secondary education soared, from 15% in 1990 to 71% in 2000.
Equally important, Brazilian universities are seeing an increase in quality and attendance as well.
Most of Latin America, including Brazil, ignored public investments in R&D for decades, while East Asian countries invested heavily.
FHC appointed a series of outstanding Ministers of Science and Technology, and the government finally began spending more on research and development.
Brazil is becoming known not only for orange juice, but for aircraft exports like the Embraer jets that now compete with American and European producers for the regional commuter market.
· Third, Brazil is coming out of its economic shell, competing in world markets rather than protecting national markets.
For decades, due to rampant protectionism, the ratio of Brazil's exports to GNP was one of the lowest in the world.
That is finally changing.
The export/GNP ratio has risen from 8% in 1990 to 13% in 2001, a sign that Brazil is beginning to seek out world markets.
Lula is traveling widely to promote Brazilian exports, another sure sign that Brazil's political economic orientation has become far more international.
· Fourth, Brazil is focusing on the health and productivity of its people.
Under FHC, Brazil pioneered an effective response to the AIDS epidemic by guaranteeing access to antiretroviral medicines and to widespread counseling and viral testing.
The hero of this effort, Dr. Paulo Teixera, is now at the World Health Organization helping to lead the global effort against AIDS.
Brazil has also dramatically improved child health, with mortality rates of young children falling sharply, from 60 per thousand in 1990 to 36 per thousand in 2001.
Brazil's total fertility rate (average number of births per woman) has come down sharply as well, from 2.7 in 1990 to 2.2 in 2001.
With more children surviving to adulthood, poor families are choosing to have fewer children, and to invest more in their health and education.
Population growth pressures are falling, providing a powerful long-term boost to Brazil's economic development.
Brazil's economic turnaround may have powerfully positive effects on its neighbors, especially the struggling countries of the Andean region.
This is the most likely scenario, but it is too early to declare victory.
Brazil still faces huge challenges.
Lula will have to build on the work of FHC.
Macroeconomic stability must be consolidated, with budget deficits brought decisively under control.
The political consensus in favor of universal education, outward-oriented trade, health for all, and a science-and-technology oriented economy must be strengthened.
Brazil must also pay more attention to environmental management, especially in the fragile yet critical Amazon region, if it wants long-term, sustainable economic development.
For Brazil to play a bigger role as regional economic leader, greater cooperation with its neighbors in suitable infrastructure projects and expanded markets will be needed.
Great challenges, indeed, but Brazil seems to be in the mood to meet them.
The International Monetary Fund (IMF) came through last week with a larger rescue package for Brazil than world financial markets expected.
This should have eased fears about Brazil's future.
So far, it hasn't.
After an initial rally, Brazilian interest rates have settled at levels incompatible with long-term solvency.
Its benchmark "C bonds" now yield around 22% in dollar terms.
Brazil's debt equals 60% of GDP, of which 35% falls due within a year.
The IMF has required that Brazil run a "primary surplus" (i.e. interest on government debt is excluded in the budget calculations) of 3.75% on its budget.
But this will clearly not be able to prevent a big further deterioration in the country's debt/GDP ratio, especially as high interest rates push Brazil into recession.
The fact that this package failed to bring relief indicates that something is fundamentally wrong with the international financial system.
Brazil's problems cannot be blamed on anything Brazil has done wrong; responsibility falls squarely on international financial authorities.
Admittedly, Brazil may soon elect a president that global financial markets do not like; but if international financial markets take precedence over democratic choice, the system is undoubtedly flawed.
Under the influence of market fundamentalism, the IMF does not benefit all of its members sufficiently.
In recent years, the so-called "Washington consensus" as espoused by the IMF and World Bank has put its faith in the self-correcting nature of financial markets.
That faith was and is misplaced.
Ever since financial capital began moving freely around the globe, crisis has followed crisis, with the IMF called upon to put together rescue packages of ever larger size.
Market fundamentalists blame this state of affairs on the moral hazard created by IMF bailouts.
In the aftermath of Asia's crisis of 1997, the IMF switched from bailouts to "bail-ins" that shifted more of the risk back to international lenders.
By doing so, the true risks of investing in emerging markets were revealed.
What is the result?
Capital flows have reversed.
Instead of capital flowing to economies on the world's periphery, it is leaving them and flowing to economies at the center.
If stability is to be preserved, financial markets need regulators and a lender of last resort.
But there can be no lender of last resort without a modicum of moral hazard.
Every developed country learned this lesson domestically decades ago, but the world has yet to learn it internationally.
The system we have in place is lopsided.
It is designed to preserve international financial markets, not the stability of emerging economies on the periphery.
That is what rendered the risk/reward ratio of investing in emerging markets so unfavorable.
Once we recognize the problem, solutions can be found.
The Washington Consensus starts by asking how big a budget surplus is needed in order to keep indebtedness within bounds; the higher the interest rates, the bigger the required surplus.
In the case of Brazil, with 22% interest and 4% growth, the primary surplus would have to be 4.8% to keep the debt/GDP ratio from rising - an obvious impossibility.
The right question to ask is this: what level of interest rates can be reconciled with reasonable growth?
A primary surplus of 3.75 % then becomes the maximum, not the minimum, that can be exacted, and it can support real interest rates of not more than 10%.
So the question then becomes: how do you bring interest rates down to that level?
This may require some international credit enhancements or guarantees.
The world's task is to find instruments that can minimize the possibility of moral hazard and yet keep the level of real risk within tolerable bounds.
I suggest that Instead of a traditional IMF package, the central banks of the developed countries should open their discount windows for Brazilian government debt.
Brazilian bonds would rally and confidence would return at the sight of a lender of last resort.
The risk would be minimized by not raising the amount the central banks are willing to lend in line with the rise in market prices.
Commercial banks would soon reinstate their lines of credit for Brazil, which would help ensure a recovery of exports.
(Lifting of the bulk of US tariffs on Brazilian steel would also help here.)
The crisis would then dissolve into thin air.
My proposal would achieve what the recently announced package failed to achieve, and at no higher a price.
It is not too late to adopt it.
Once it is in place, Brazil's incoming president (no matter who he is) would have no reason to contemplate interfering with Brazil's normal debt servicing commitments.
As things now stand, he would be justified in demanding greater international support rather than allow his country to bleed to death as Argentina is now doing.
In political conditions such as those that now prevail in Brazil, markets are right to take into account the possibility of a debt reorganization or even of a default.
But once they do, their actions soon become a self-fulfilling prophecy.
This is why financial markets cannot be left to their own devices.
London – I feel a little sorry for President Bush.
Whatever his other many failings, he has a pretty good record on aid to poor countries, particularly in healthcare.
True to form, he recently announced a big increase in US food aid – good for the hungry poor and good for American farmers.
This was a faster response than some other countries have made to the global food crisis.
After falling for more than 30 years, food prices have recently soared. The Economist’s food price index has risen to its highest level since it was started in 1845.  As has happened throughout history, rocketing prices and shortages have caused riots from Bangladesh to Bolivia.
The word for bread in Egypt is “aish,” which also means life.
Threats to life bring crowds on to the streets.
What made me feel a little sorry for Bush was the reaction to his announcement.
Bush referred to the reasons for shortages and price hikes.
He did not dwell on the diversion of American corn from food to heavily subsidized bio-fuels.
Nor did climate change feature prominently in his argument, although many experts suggest that this may be the cause of the droughts and floods that have ruined wheat harvests in Australia and vegetable oil production in Indonesia and Malaysia.
Bush pointed his finger primarily elsewhere.
Food prices had responded to growing demand.
In Asia, economic growth had stimulated food consumption.
The Chinese and Indians were eating more and eating better.
Over a 20-year period, for example, the Chinese had doubled the amount of meat they eat.
What Bush said is of course true.
But it is only part of the truth.
Globalization has benefited India and China, and the rest of us, too.
One key of the principal reasons for the world’s economic growth from 2000-07, despite wars and terrorist atrocities, was that India and China joined the world economy.
Hundreds of millions of people were lifted out of poverty.
But many Indians are still wretchedly poor.
Too many.
They have a miserable diet – not least when compared with Bush’s Texan neighbors.
Grain consumption per head in India has remained static, and is less than one-fifth the figure for the US, where it has been rising.
I do not imagine you will find too many vegetarians in Crawford, Texas, and the meat consumed by the average American is way ahead of the figure for any other country.
Think of all those T-bone steaks.
Bush’s partial explanation of the world food crisis, accurate as far as it went, brought the anger of India’s media and of many politicians down on his head.
According to India’s Defense Minister, A.K. Anthony, presumably an expert on butter as well as guns, Bush’s statement was “a cruel joke.”
The parliamentary opposition urged Prime Minister Monmahan Singh, who wisely kept his head down, to join in the populist America-bashing.
Later in the “cruel joke” week, Bush’s White House compounded the sin.
According to Bush’s press spokesman, the growth in world demand for oil – in Asia, for example – was one of the causes of the high price of filling the tanks of gas-guzzling Sports Utility Vehicles, as well as more modest family cars, at America’s pumps.
Meanwhile, the US government papered over the fact that Americans, who make up less than 4% of the world’s population, own and drive 250 million of the world’s 520 million cars.
More outrage around the world at American double standards.
Now, all this is more than the knock-about of international politics.
One day soon, Bush and Cheney will be out of office.
But we will still be left with the most difficult global issue we have ever faced: as more of us prosper, how do we deal fairly with some of the economic and environmental consequences?
What do we do about the bottom billion in the world who remain in grinding poverty while the rest of us live better and longer lives?
How do we deal with equity on a global scale when we cannot even deal with it country by country?
This conundrum will lie at the heart of the diplomacy next year to find a successor to the Kyoto agreement.
Can we prevent a calamitous increase in global warming in a way that is fair, that takes account of past and present responsibility, and that does not thwart legitimate hopes for a better life everywhere?
We have never faced a more difficult political task.
Meanwhile, there is a food crisis to solve.
We have already seen many examples of how not to deal with it.
Stopping food exports is stupid.
If we restrict market forces, there will be less food and higher prices.
We should also avoid the cheap political trick of holding down what we pay to poor farmers in order to benefit poor city dwellers.
Why do governments do this?
The answer is obvious: city dwellers riot; in the countryside, people just starve.
The best way to deal with the problem is to subsidize food for the poor; we should not cut the price we pay farmers for growing it.
Having enjoyed a few days of Bush-bashing, India got on with the job of bowing to pre-election political pressures.
The government announced that it was suspending trading in futures markets for a number of farm products.
India has the most economically literate triumvirate of politicians in the world in charge of its economy.
They must know that this measure will have as much effect on food inflation as rain dancing has on the weather.
But politics, alas, is politics.
The Franco-German axis is proving a nightmare for European unity.
Within a single month, Gerhard Schroeder's Germany and Jacques Chirac's France first destroyed the EU's Stability Pact and endangered European monetary union by demanding--and receiving--special status for French and German fiscal deficits.
Now the axis has crushed hopes of passing a new European constitution in Brussels by demanding the so-called "double majority" rule, which would seriously weaken medium-size and smaller countries' voting power by comparison to what was agreed three years ago in Nice.
European integration can't afford further defeats.
Trust has been decimated.
Anger overflows.
Small and medium-sized EU countries feel tricked.
Will these countries continue to sacrifice for the common European good when, time after time, the big countries tell them to go to the back of the bus and be grateful for the ride?
It's time for a pause in European integration efforts if only to avoid a complete, irreparable rupture of relations between nations that are supposed to be uniting.
The Germans, in particular, need a time out to reflect upon the wisdom of their recent bullyboy tactics.
Gerhard Schroeder is providing disastrous leadership for Germany.
The country's "new nationalism" will end in tears for both Germany and Europe.
Have today's Germans really forgotten that Europeanism is not the best alternative for Germany--it is the only alternative?
Yet, after last week's Brussels summit ended in failure, the Germans and their French allies are talking up a "two-speed" Europe, with the so-called "pioneer group" of Germany, France, Italy, and the Benelux countries--Belgium, the Netherlands, and Luxembourg--going faster and pursuing deeper integration projects than the others.
A "two-speed" Europe is, however, a euphemism for abandoning or opting out of European integration by Europe's big three.
It would decisively split Europe by allowing the big countries and their satellites to go their own way.
(The Dutch never would go along with this.) A "two-speed" Europe means the end of the EU as we know it.
Of course, if the big countries are not willing to sacrifice any measure of national sovereignty for the overall European good, then a united Europe is doomed.
That is why the debate over the Stability Pact was so important--and why its demise is so disconcerting: the Germans and the French proved willing to sacrifice little, if anything, for the common European interest.
Now, after the failure to endorse the draft EU constitution, Schroeder bitterly complains that "some nations are representing their national interests and have left the European idea behind."
Take a good look in the mirror, Gerhard.
But, notwithstanding recent defeats, it is far too early to give up on an integrated Europe.
Chirac and Schroeder--and the current weaknesses in France and Germany that created them--will not last forever.
Perhaps improved economic growth will give these countries the strength to throw off their present leaders.
Until France and Germany do change, Europe's game must be a waiting game.
Time can solve Europe's problem. That's why a pause now makes good sense.
The smaller EU countries also could benefit from a time out.
Even though the big countries are trying to marginalize them at almost every turn, the small countries cannot unite to fight the common enemy.
This is because they often see themselves having more in common with the big countries than the other small ones.
Belgium, for example, is virtually a satellite of France.
The same is true of Luxembourg.
Austria is closer to Germany than Finland, and so on.
Unless the small countries unite on a common front, they will continue to prove easy targets of the big nationalistic players.
On the issue of big versus small countries, Europe has a lot to learn from the United States.
Big states comfortably co-exist with small states in the US because America has a bicameral system in which the House of Representatives is based on population, but each state elects two members of the Senate.
The system is very elastic, and has shown itself able to accommodate an increasing number of states.
The coming accession of ten new members to the EU would be made much simpler were Europe to find its own equally flexible system.
LONDON – On July 9, the leaders of the world’s largest economies will meet in L’Aquila, Italy, at the Major Economies Forum (MEF) to discuss progress towards a new global climate agreement.
In six months, a deal is supposed to be struck in Copenhagen, so the MEF meeting comes at a vital moment.
When many of the same leaders met in April to address the economic crisis, they rightly pledged to do “whatever is necessary.”
The same spirit needs to animate the L’Aquila meeting.
There is enormous good will to do so.
The new US administration is supporting strong American action.
China is setting ambitious targets for reducing energy intensity and making massive investments in renewable energy.
India has put forward its own action plan.
Europe has set a goal of cutting emissions by 30% below 1990 levels by 2020 if there is an ambitious global agreement.
Japan has published its proposals for major carbon reductions.
Across the world, commitments are forthcoming.
But practical challenges remain.
What is being asked is that global emissions be less than half their 1990 levels by 2050, having peaked before 2020.
Since emissions from the developing countries are on the whole lower than those of the developed world – and will need to continue to rise in the short-term as they maintain economic growth and address poverty – it has been proposed that developed countries cut emissions by at least 80% relative to 1990 by 2050, with major steps towards this goal over the next decade.
Developing countries will also need to play their part, significantly slowing and peaking emissions growth in the coming decades.
For the US, such commitments would mean cutting emissions to around one-tenth of today’s per capita level, while for China it would mean creating a new low-carbon model of economic development.
For all countries, this is a major challenge – a revolution that implies a huge shift in policy.
The good news is that if we focus on clear, practical, and achievable goals, major reductions can be made in order to ensure that, whatever the precise interim target, the world will fashion a radical new approach within a manageable timeframe.
A new report from the “Breaking the Climate Deadlock” project, a strategic partnership between my office and The Climate Group, shows how major reductions even by 2020 are achievable if we focus action on certain key technologies, deploy policies that have been proven to work, and invest now in developing those future technologies that will take time to mature.
Perhaps the most interesting fact to emerge is that fully 70% of the reductions needed by 2020 can be achieved by investing in three areas: increasing energy efficiency, reducing deforestation, and use of lower-carbon energy sources, including nuclear and renewables.
Implementing just seven proven policies – renewable energy standards (e.g., feed-in tariffs or renewable portfolio standards); industry efficiency measures; building codes; vehicle efficiency standards; fuel carbon content standards; appliance standards, and policies for reduced emissions from deforestation and forest degradation (REDD) – can deliver these reductions.
All seven policies have already been successfully implemented in countries around the world, but they need scaling up.
While cap-and-trade systems or other means of pricing carbon emissions can help provide incentives for businesses to invest in low-carbon solutions, in the short term at least, these seven policy measures – and direct action and investment by governments – are needed to achieve the targets.
In the longer term, we also need technologies such as carbon capture and storage (CCS), expanded nuclear power, and new generations of solar energy, together with the development of technologies whose potential or even existence is still unknown.
The important thing for Copenhagen is that decisions are taken now for investments that will yield benefits later.
For example, the overwhelming majority of new power stations in China and India – necessary to drive the industrialization that will lift hundreds of millions out of poverty – will be coal-fired.
That is just a fact.
So developing CCS or an alternative that allows coal to become clean energy is essential for meeting the 2050 goal.
But we need to invest now, seriously and through global collaboration, so that by 2020 we are in a position to scale up CCS or be ready to deploy other alternatives.
Renaissance of nuclear power will require a big expansion of qualified scientists and engineers.
Electric vehicles will need large adjustments to infrastructure.
Smart grid systems can enable big savings in emissions, but require a plan for putting them into effect.
These measures will take time, but require investment now.
Meanwhile, in the short term, low energy lighting and efficient industrial motors may sound obvious, but we are nowhere near using them as extensively as we could.
So we know what we need to do, and we have tools available to achieve our goals.
MEF leaders can therefore have confidence in adopting the interim and long-term targets recommended by the scientific community: keeping warming to below two degrees Celsius; peaking emissions within the next decade; and at least halving global emissions by 2050 versus 1990.
Developed countries will be able to commit to reducing their emissions by 80% versus 1990 by mid-century, as many have already done, and provide the necessary financial and technology support for developing countries’ adaptation and mitigation efforts.
With that support, developing countries in turn will need to design and implement “Low-Carbon Growth Plans” that significantly slow and eventually peak their emissions growth.
By making these commitments, the MEF leaders, whose countries account for more than three-quarters of global emissions, would lay a firm foundation for success in Copenhagen.
Between L’Aquila and Copenhagen, there will undoubtedly be difficult discussions over interim targets for developed countries.
While such targets are important, what matters most is agreement on the measures that ultimately will set the world on a new path to a low carbon future.
For years, the emphasis has rightly been on persuading people that there must be sufficient “will” to tackle climate change.
But leaders, struggling to cope with this challenge even amidst economic crisis, need to know that there is also “a way.”
Only by combining the two will we succeed.
Fortunately, such a way – immensely challenging but nonetheless feasible – exists.
For 25 years, the so-called “Washington Consensus” – comprising measures aimed at expanding the role of markets and constraining the role of the state – has dominated economic development policy.
As John Williamson, who coined the term, put it in 2002, these measures “are motherhood and apple pie, which is why they commanded a consensus.”
Not anymore.
Dani Rodrik, a renowned Harvard University economist, is the latest to challenge the intellectual foundations of the Washington Consensus in a powerful new book titled One Economics, Many Recipes: Globalization, Institutions, and Economic Growth .
Rodrik’s thesis is that though there is only one economics, there are many recipes for development success.
Rodrik has rendered a major service by stating so openly the claim of “one economics.”
A critic who made the same claim that economics allows only one theoretical approach would be dismissed as paranoid, whereas Rodrik’s standing creates an opportunity for a debate that would not otherwise be possible.
The “many recipes” thesis is that countries develop successfully by following eclectic policies tailored to specific local conditions rather than by following generic best-practice formulas designed by economic theorists.
This challenges the Washington Consensus, with its one-size-fits-all formula of privatization, deregulated labor markets, financial liberalization, international economic integration, and macroeconomic stability based on low inflation.
But, while the many recipes thesis has strong appeal and empirical support, and suggests a spirit of theoretical pluralism, the claim of “one economics” is misguided, for it implies that mainstream neoclassical economics is the only true economics.
Part of the difficulty of exposing this narrowness is that there is a family split among neo-classical economists between those who believe that real-world market economies approximate perfect competition and those who don’t.
Believers are identified with the “Chicago School,” whose leading exponents include Milton Friedman and George Stigler.
Non-believers are identified with the “MIT School” associated with Paul Samuelson.
Rodrik is of the MIT School, as are such household names as Paul Krugman, Joseph Stiglitz, and Larry Summers.
This split obscures the underlying uniformity of thought.
The Chicago School claims that real-world market economies produce roughly efficient (so-called “Pareto optimal”) outcomes on which public policy cannot improve.
Thus, any state intervention in the economy must make someone worse off.
The MIT School, by contrast, argues that real-world economies are afflicted by pervasive market failures, including imperfect competition and monopoly, externalities associated with problems like pollution, and an inability to supply public goods such as street lighting or national defense.
Consequently, policy interventions that address market failures – as well as widespread information imperfections and the non-existence of many needed markets – can make everyone better off.
None of this is about fairness, which is a separate issue.
Indeed, neither the Chicago School nor the MIT School say that market outcomes are fair, because actual market outcomes depend on the initial distribution of resources.
If that distribution was unfair, current and future outcomes will be unfair, too.
Chicago economists seem to believe that real-world outcomes are acceptably unfair and, more importantly, that attempts to remedy unfairness are too costly, because tampering with markets causes economic inefficiency.
They believe that government intervention tends to generate its own costly failures because of bureaucratic incompetence and rent-seeking, whereby private interests try to steer policy to their own advantage.
MIT economists tend to espouse the opposite: fairness is important, the real world is unacceptably unfair, and government failure can be prevented by good institutional design, including democracy.
These differences reflect the intellectual richness of neo-classical economics, but they provide no justification for the claim that there is one economics.
On the contrary, heterodox economists like Thorsten Veblen and Joseph Schumpeter long ago raised many of today’s cutting-edge issues in neoclassical economics, including the role of social norms and the relationship between technological innovation and business cycles.
Heterodox economics includes core theoretical concepts that are fundamentally incompatible with neoclassical economics in either of its two contemporary forms.
These concepts result in significantly different explanations of the real world, including income distribution and the determinants of economic activity and growth.
Moreover, they often result in different policy prescriptions.
The late Robert Heilbronner – one of Schumpeter’s most renowned students – viewed economics as “worldly philosophy.”
Just as philosophers are divided on the nature of truth and understanding, economics is divided on the workings of the real world.
Paradigms should co-exist in economics, just as in other social sciences.
Yet, in practice, the dominance of the belief in “one economics,” particularly in North America and Europe, has led increasingly to a narrow and exclusionary view of the discipline.
This reality is difficult to convey.
One reason is that liberal neo-classical economists like Stiglitz and Krugman share values with heterodox economists, and shared values are easily conflated with shared analysis.
Another reason is that heterodox and MIT School economists also often agree on policy, even if their reasoning is different.
Finally, most people are incredulous that economists could be so audacious as to enforce one view of economics.
The “many recipes” thesis enriches neo-classical economics’ contribution to the development debate, and many of its policy proposals will find support from heterodox economists.
However, it fails to engage the deep intellectual divisions regarding economic development, trade, and globalization, because it refuses to admit the legitimacy of such disagreements.
By repeating the claim of “one economics,” Rodrik inadvertently reveals the censorship embedded in contemporary economics.
The great challenge is not to admit that there are many recipes, but rather to create space for other perspectives on economic analysis and policy.
Kyoto – As 2009 commences, Microsoft is previewing its next-generation operating system, Windows 7, which is remarkable only in that it is almost the same as every previous version.
Stagnation in computer design is not surprising, considering that familiarity is so comfortable. 
But it can also stifle development.
Military intelligence depends on ever-improving communication, so it is one area in which system design is constantly changing.
Some of those innovations will eventually trickle into the mainstream, so a glimpse at current experiments can reveal what the future of ordinary computer interaction could look like, and what would be gained.
For the lay user, technology is encountered mostly as an interactive interface.
People rarely consider that the tangible features assumed to be intrinsic to the “computer” were imitations of other objects, with keyboards inherited from typewriters and screens from television.
Inside the computer screen is a virtual 1950’s office, with paper documents, filing cabinets, and a garbage can.
This page-window format is known as Window-Icon-Mouse-Pointer, or WIMP, which, due to monopoly forces, has been the universal paradigm since the 1980’s – ancient history in computer years.
These formats are taken for granted, just as we accept telephone keypads and car dashboards, which are also user interfaces.
It is easy to forget that, years ago, telephones had no buttons or dial – you had to pick up the handset and ask an operator to make the connection.
The telephone dial didn’t appear until 1919, when the first group of self-designated “user interface scientists” at Western Electric considered what the most intuitive form should be.
When improving a computer interface, form is the key.
We’ve seen hints of a new paradigm in Apple’s iPhone, which allows gestural finger motions, but in the intelligence community, concept visualization can be so radical that most ordinary users might barely recognize what it was.
Designs are inspired by cognitive science, the arts, even science fiction.
Ironically, a recent trend reaches far into the past, to a traditional Japanese concept known as 
 katachi
 , which is emerging as an international movement.
“Katachi” literally means “form” in Japanese, but the concept has complex connotations that do not exist in other languages.
The word is a composite of two terms, “kata” (pattern) and “chi” (magical power), so it includes nuances such as “complete assembly” and “shape that tells an attractive story.”
This richer notion stems from ancient Japanese culture, which perceived the overlap between geometry and meaning.
The Chinese symbol for “form” carries some of the same reasoning, due to its use of ideograms.
Four thousand years ago, China developed a writing system that conveyed concepts both as idea and picture.
Notions such as “wooden structure” and “beauty” were indicated by symbols which, when combined, could create a new concept, such as “form.” 
Governments in countries colonized by China were forced to adopt this pictographic writing system in order to receive political regulations, but the pronunciation of the characters was not controlled.
The colonized were able to maintain aspects of their local culture through different aural versions of the same written “word” because the common meaning existed only in the shape.&#160; 
Modern user interface scientists are interested in katachi because it can reveal how form facilitates human interaction.
A traditional example is the tea ceremony, which was developed in Japan in the late sixteenth century.
The format is simple – a host serves tea with some sweets, the guests drink it and then express thanks; that’s all.
Foreigners are often mystified as to why such a minimalist event can require years of training.
But the motivation for this art is common to every culture: imagine a talented host from any country whose manner is so easy that guests are wrapped in a mood of quiet happiness.
In the tea ceremony, this ability has been refined into a skill that combines materials, meaning, and mood.
Those with high ability know how the guests’ experience can be improved with careful preparations of tools, reflective conversations, and natural yet well-controlled body motions.
Physical movements embody the intended meaning of the event, so the whole environment becomes a signifier.
Small innovations are often introduced into the style of hospitality to suggest the personality of the host. 
An operating system based on katachi’s insights would harness this overlap between shape, sense and environment.
It might allow you to feel the “form” of a concept with your hands.
Or it could indicate the reliability of data based on whether it was laid out neatly or had a scrambled appearance, so it could be assessed at a glance.
Perhaps future interfaces will allow us to communicate across language barriers by immersing us in assemblies of pictures – a hybrid between movies, architecture and email. 
Expressive icons represent thought, but can only communicate complex subtleties and situations if they allow multiple levels of understanding.
Computer scientists might be in a unique position to enable richer communication, and perhaps a more stable future as a consequence.
For this reason, let us hope that more developers explore this so-called “disruptive” side of technology during the coming year.
NEW YORK – Let us assume, for the sake of argument, that Geert Wilders, the Dutch politician who is convinced that Europe is “in the final stages of Islamization,” is right: Anders Breivik, the Norwegian mass murderer, is mad.
Wilders tweeted: “That a psychopath has abused the battle against Islamization is disgusting and a slap in the face of the worldwide anti-Islam movement.”
This assumption is not so far-fetched.
Murdering more than 60 innocent young people at a summer camp with an assault rifle, after bombing a chunk of central Oslo, is, to put it mildly, morally eccentric – something most sane people would never dream of doing.
The same is true, naturally, of a group of young men who decide to commit suicide and mass murder by flying commercial airliners into large public buildings in New York and Washington.
But neither Breivik, nor the terrorists of September 11, 2001, killed without reason, in the way some nihilistic American shooters do.
Islamists view their acts of random mass murder not as a personal publicity stunt, but as a tactic in a holy war against the decadent, sinful West.
Breivik is, in his own mind, a warrior for the other side.
His aim was to protect the West from Islamization.
His enemies are not just Muslims, but the liberal Western elites, and their children, who were destroying Europe from within through “multiculturalism” and “cultural Marxism.”
In fact, what Breivik wrote in his rambling manifesto, entitled A European Declaration of Independence, is more or less what populists, such as Geert Wilders, have been saying.
Of course, there was much else in the manifesto – fantasies about reviving the medieval Knights Templar, for example – that suggests a more bizarre disposition, and Wilders was quick to distance himself from Breivik’s violent methods.
Indeed, only one right-wing European politician, Francesco Speroni of the Italian Northern League, which is part of Silvio Berlusconi’s government, was prepared to defend Breivik.
Speroni claimed that Breivik’s “ideas are in defense of western civilization.”
So, how seriously must we take the ideological reasons that killers like Breivik and the September 11 terrorists invoke to justify their murders?
A few years ago, the German writer Hans Magnus Enzensberger wrote a fascinating essay about the “radical loser.”
Radical losers are mostly young men who are so enraged by their own lack of social, economic, and sexual self-esteem and the indifference of the world around them, that they long for a suicidal act of mass destruction.
Anything can trigger such an act: rejection by a girl, being fired from a job, failing an examination.
And sometimes the killers reach for ideological justifications: building pure Islam, struggling for communism or fascism, or saving the West.
The particular ideals might be unimportant – simply those that happen to be available, owing to fashion or other historical circumstances.
Once a radical loser is in the mood to kill, any reason will do.
Perhaps.
But does this mean that there is no link at all between the stated views of radical clerics or politicians and the acts committed in the name of those opinions?
For all the finger pointing at Wilders, just because Breivik professed to admire him, the acts of a deranged killer, others caution, should not be used to discredit what he stands for.
After all, there is nothing irrational, or murderous, about claiming that multiculturalism is a flawed ideal, or that Islam conflicts with modern Western European views of gender equality or gay rights, or that mass immigration will cause serious social conflicts.
These claims began to be made by respectable conservatives, and even some social democrats, in the 1990’s.
They reacted against a rather smug liberal establishment that tended to dismiss all critical thought about immigration or non-Western faiths and traditions as racism and bigotry.
But, while there was nothing intrinsically wrong with discussing the social consequences of large-scale immigration from Muslim countries, some populists in Holland, Denmark, France, Germany, Belgium, Britain, and other countries, went much further.
Wilders, in particular, likes to speak in apocalyptic terms of “the lights going out over Europe,” and “the sheer survival of the West.”
And the problem is not just a particular strain of violent revolutionary Islam, but Islam itself: “If you want to compare Islam to anything, compare it to communism or national socialism – a totalitarian ideology.”
This is the language of existential war, the most dangerous kind.
Indeed, the terminology of World War II is being deliberately revived.
Those who oppose radical hostility to all forms of Islam are “appeasers” of, or “collaborators” with, “Islamofascism.”
For some, September 11, 2001, was analogous to 1938, or even 1940.
The very survival of Western civilization is at stake.
Is it really so surprising that certain people might mistake this rhetoric for a call to arms?
To be sure, neither Geert Wilders, nor even rabidly anti-Islamic bloggers in the United States, such as Scott Spencer and Pamela Geller (both of whom were quoted extensively in Breivik’s manifesto), have called for physical violence.
But their writings and statements have been sufficiently hysterical and hateful to incite a person with an unbalanced mind.
Indeed, Breivik’s interpretation of their words is, in an odd way, more rational than the idea that a war for our very survival can be fought with words alone.
BUCHAREST: Perhaps only our greatest playwright, Eugene Ionesco, could have gotten this story right.
Ionesco’s genius was to portray a world in which the absurd is triumphant.
Imagine the scene: Bucharest, le petit Paris, a city of three million people with wide boulevards and grand bourgeois villas, stands now a city half in ruins.
Poverty runs rampant, orphanages overflow with abandoned children, countless packs of wild dogs roam the streets.
All of this excites little or no interest in the West.
Romania’s politicians appear to be equally indifferent; they have wasted the last ten years in endless fights, while our postcommunist neighbors reinvented their societies and made themselves ready for membership in the EU.
Then Bucharest’s mayor, Traian Basescu, proposes a plan to control the dogs: the city government will put to sleep any dog without an owner.
Suddenly, the West’s interest is kindled.
Not to help us, of course – at least not to help the city that contains armies of feral dogs, making it appear at times like a ghost town in a Sergio Leone cowboy movie.
No, Brigitte Bardot – we still anticipate the arrival of Gerard Depardieu any day now – and other celebrities, people unable to shed a tear for our unwanted orphans or for the mass poverty left behind by Ceausecu, fly into Bucharest (undoubtedly by first class) to protect the wild dogs and denounce our mayor.
Our reality, I suspect, would challenge even Ionesco’s sense of the absurd.
Middle-aged, greying, Bardot arrived in Bucharest not to remind men, high and low, of her charms but to prevent what she called a “canine genocide.”
Yet, despite the harsh rhetoric, when Miss Bardot and Mayor Basescu met, they parted with a kiss. “For 30 years I waited for this,” the Mayor blushed.
Unwilling to discriminate between parties, Miss Bardot later kissed our president, Ion Iliescu.
Her celebrity recognized, the public’s adoration bestowed, she then departed, leaving the wild dogs, and our broken society, to their fates.
The feral dogs of Bucharest are a tawdry legacy of communism, like the many half-built and abandoned blocs of flats dotted across the city and throughout the country.
Decades ago, Bucharest held many tiny houses, with courtyards and small gardens. People kept watchdogs to protect their properties.
In the 1970s and 1980s, however, most of these homes were forcefully demolished by Ceausescu.
The dictator wanted all socialist citizens to live in socialist flats.
As tens of thousands of people were moved into tiny, standard issue apartments, many dogs were abandoned.
Like Romania’s people, they survived only by daily cunning.
Since 1990, successive mayors promised to tackle the problem of these hundreds of thousands of feral dogs.
But even bigger problems – housing and street crime – also existed, so nothing was done about them.
Besides, many people opposed killing the street dogs.
Every now and then a few were caught, sterilised and released.
But the packs multiplied and multiplied.
Mayor Basescu wants to be the next leader of the Democratic Party (now led by former Prime Minister, Petre Roman) and is said to be preparing to run for president in 2004.
Success as Mayor of Bucharest will boost his chances, and what better way is there for a politician to promote himself than by “cleaning up” some seemingly intractable problem – particularly one that symbolizes ten years of incompetence and despair.
So, all street dogs, the mayor promised, would be caught and quarantined.
The old and sick would be killed by euthanasia; the rest sterilised and vaccinated.
Meanwhile, people would be asked to adopt as many dogs as possible.
Those not adopted would share the fate of the sick and old.
Even before the Bardot visit, demonstrators besieged City Hall in opposition to the plan.
A human rights defender, Gabriel Andreescu, compared the looming fate of the street dogs with the Holocaust and Gulag.
A leading journalist, Cristian Tudor Popescu, reproached animal rights defenders for their moral relativism and insensitivity to human suffering.
Our politicians usually shout at each other, but Basescu cleverly disarmed his critics by talking to representatives from animal rights groups.
He told them that he rejected cruelty to animals, but insisted that it was his duty to promote the interests of people before dogs.
He asked them (many of the representatives were well-to-do women) to set a personal example by adopting a street dog.
Ionesco was no moralist, but even he would not deny one moral to be drawn from this story: when societies avoid taking necessary measures, things only get worse.
For just as the wild dogs of Bucharest multiplied over the years, so too did Romania’s unsolved problems.
Vast social problems demand an entire community’s commitment, not just resolution from above.
Of course, you cannot “adopt” abandoned factories or the unemployed masses in the way that dogs can be adopted.
Nonetheless, a community must and should assume and share its burdens.
One day, Romania might actually learn this lesson.
I doubt, however, that celebrities like Miss Bardot will ever recognize the absurdity of their misplaced priorities – to come to a country where millions live in despair and dire conditions, and show concern for only the wild dogs.
A quiz for history buffs.
Twenty years ago – on June 4, 1989 – three events shaped a fateful year.
Which do you remember most vividly, and which most changed the world?
a) The bloody denouement of the protests on Tiananmen Square.
b) The death of Iran’s revolutionary cleric, Ayatollah Ruhollah Khomeini.
c) The Polish elections.
Few would answer c).
The victory of the famed opposition trade-union movement, Solidarity, in Eastern Europe’s first free election since 1946 was eclipsed by the violent crackdown in Beijing and Khomeini’s tumultuous passing.
Yet no single event did more to bring down communism in Europe – and thus to re-shape the post-war international order.
The next few months will bring all sorts of commemorations of communism’s end, particularly of the fall of the Berlin Wall in November 1989.
To many, it was a glorious moment, emblematic of the West’s victory in the Cold War, and one that seemed to come out of the blue.
But if you watched the Eastern Bloc’s disintegration from the ground, you would know that the process was far longer and more complex than most people realize.
The Polish election was a point of no return, the moment when forces for change became irreversible.
They gathered momentum after a summer of labor strikes, when Poland’s communist chief, General Wojciech Jaruzelski, concluded that the country’s economic troubles were too grim to face alone.
Why not enlist the help of Poland’s opposition, he reasoned, if not to solve the problems, then at least to share the blame for them?
And so, after six months of bargaining, a historic deal was struck. Poland would hold free and fair parliamentary elections, and Solidarity would compete.
It never occurred to the ruling communists (or to Solidarity) that they might lose.
Never in their wildest dreams did they imagine being driven from power altogether.
Yet that is what happened.
In retrospect, it is astonishing that there should have been any doubt.
Solidarity’s campaign was all chutzpah.
An iconic campaign poster captured the public mood: a picture of a gun-slinging Gary Cooper as the sheriff in the classic western High Noon .
June 4 was the day of reckoning in Dodge City East.
On that bright Sunday morning, as spring turned to summer, voters wasted little time in dispatching Poland’s communists to the abattoir.
On their dying day, Poland’s communists managed one last perversity, a final and unwitting act of utter self-humiliation.
They devised an electoral system whereby Poles would not vote for candidates of their choice, but would cross out those they did not want – which is to say, each and every communist.
Everywhere you looked, people were excising hated autocrats.
Here, at long last, was Poland’s long-awaited popular uprising, revenge for December 1980, when Jaruzelski declared martial law, banned Solidarity, and threw its leaders in jail.
Revolution by deletion!
The pen, at last mightier than the sword, became a weapon of glorious retribution, wielded with style. Some voters slashed their ballots boldly, decapitating the old regime with flourishing strokes.
Others savored the moment, perhaps puffing a cigarette as they reveled in this or that deletion. “Oh yes, he jailed my cousin.”
Pfft! “Oh, that sponging apparatchik, living high on our penury.”
Pfft! Pfft!
By contrast, the communists’ campaign was all but invisible.
In all of Warsaw, only a couple government candidates bothered to put up posters.
Most counted on the party’s media monopoly to carry their message, such as it was: “Vote Lezek, a good communist.”
To their credit, the regime accepted its inevitable loss with remarkable grace. At three p.m. on the day after the vote, Jaruzelski summoned top party officials.
“Our defeat is total,” he told them.
“A political solution will have to be found.” By that, he meant no violence and no doctoring the ballot count.
The communists would have to live with the result.
Twenty years later, I remain mystified.
Those of us covering Eastern Europe knew that Solidarity would win.
We knew, too, that its peaceful victory would be a lesson for the rest of the bloc.
For anti-communists everywhere, the Polish election was extraordinarily encouraging.
Thanks to Poland, what only days before had seemed impossible was, suddenly, possible.
There were other signs.
In May, Hungarian reformers began tearing down the fence along their border with Austria – a hole in the Iron Curtain.
In Moscow, Mikhail Gorbachev spoke of a “Common European House” and repudiated the interventionist Brezhnev Doctrine.
Yet when the Wall tumbled down, experts and world leaders alike were unanimous. “We never saw it coming,” they confessed.
The Cold War had lasted so long that change seemed unimaginable until freedom burst forth.
Strasbourg – The European Union recently embarked on a policy of “constructive engagement” with Belarus.
None too soon.
Previously, EU policy was to isolate Belarus, which itself was seeking isolation.
That policy achieved almost nothing, save for bolstering the country’s authoritarian leader, President Aleksander Lukashenko.
Belatedly and somewhat reluctantly, EU leaders have now accepted that they need to deal pragmatically with Lukashenko if they want to promote reform in Belarus and shift the country from its tight orbit around Russia.
This realization does not mean that Europe should turn a blind eye to the nature of Lukashenko’s regime.
EU members are rightfully concerned about human rights in a place dubbed by some “the Cuba of the east.”
Political repression and press restrictions remain common in Belarus.
But the same – and perhaps worse – can be said about China, yet the EU has invested much political capital in a strategic, multifaceted partnership with its rulers.
Belarus is the missing link in Eastern Europe’s post-Soviet democratization and reintegration.
European officials have been at pains to prevent the EU’s enlargement from creating new dividing lines between Belarus and its neighbors to the west and north – Poland, Lithuania, and Latvia – that joined the Union in 2004.
In fact, these countries are the biggest advocates of improving relations with Belarus, because of their shared historical, commercial, and familial links.
The EU has also suddenly awakened to the need for a common external energy-security policy, not least to diversify away from Russian supplies.
Given that 20% of Russian gas destined for Europe passes through Belarus, a stable and structured relationship with its government has become a priority.
In turn, Lukashenko has decided for economic reasons that his country needs EU support and can no longer depend exclusively on Russia without paying a heavy political price.
But the thaw in EU-Belarus relations needs to be based on reciprocal, permanent steps.
After all, no EU strategic partnership is unconditional.
But the EU must be ready to respond to the perceptible momentum in Belarus in favor of domestic reform, greater openness, and respect for fundamental democratic rights.
For example, the recent release of political prisoners in Belarus removed at a stroke one of the key reasons for the EU’s hostility towards Lukashenko.
This gesture, together with the free publication of an opposition newspaper, is precisely the kind of move that will entice EU interest in an enhanced relationship.
Similarly, Belarus must, in turn, respond positively to the EU’s steps to normalize relations, one of which should be rescinding travel restrictions against Lukashenko and other senior officials.
Of course, releasing political prisoners does not excuse Lukashenko’s past excesses.
But the political opposition to Lukashenko is hopelessly divided, plagued by infighting, and incapable of mounting any serious challenge to his rule.
Moreover, Lukashenko appears to be genuinely popular.
The country’s rural and elderly population – like those in other former Soviet countries – appears to prize economic stability and social order over democratic development.
Some observers believe that Lukashenko is making cynical overtures to the West in order to elicit more support from Russia, particularly at a time of economic crisis.
But, although Lukashenko is probably playing a divide-and-rule game, he must eventually make a choice.
The closer he moves to the EU, the greater the alarm in the Kremlin.
Russia is hypersensitive about challenges to its influence in what it calls its “near abroad” of former Soviet satellites.
Last summer’s war in Georgia, and the Kremlin’s habitual efforts to destabilize Ukraine’s pro-Western government, serve as warnings for what Lukashenko can expect if he moves precipitately.
With Belarus’s economy crumbling and its export markets withering, Russia could exploit Lukashenko’s vulnerability.
The Kremlin is considering a request from Belarus for $2 billion of credit, but, if this money is forthcoming, Belarus can expect to pay a heavy political price.
Lukashenko may have to adopt the Russian ruble, at least as a reserve currency.
Russia could also insist on greater military cooperation, including the deployment of Russian missiles in Belarus in response to America’s planned missile shield in Poland and the Czech Republic.
Prime Minister Vladimir Putin and President Dmitry Medvedev may also insist on Belarus recognizing the independence, declared following last summer’s war, of Georgia’s Abkhazia and South Ossetia regions, knowing that this would make the EU shrink from further commitments to Belarus.
Belarus’s reliance on cheap energy supplies from Russia could also be used as leverage.
But, with Russia’s economy contracting, Belarus is perhaps in a stronger position than it realizes.
The country needs greater access to global markets and eventual support for admission to the World Trade Organization, which is one of the EU’s greatest selling points and one of Russia’s fundamental weaknesses.
Now is the time for EU leaders to present Lukashenko with a clear alternative to dependence on Russia.
The first step in this process was the inclusion of Belarus in the EU's Eastern Partnership, a new framework for relations with six ex-Soviet republics in Eastern Europe and the Caucasus.
It is premature to invite Lukashenko to the opening summit of this initiative in Prague on May 7.
But, after years of atrophy, EU-Belarus relations finally offer some promise for the future.
Much responsibility rests with Lukashenko, but the EU must make every effort to coax Belarus into the family of European nations, where it belongs.
BRUSSELS – The European Union’s core countries these days, besides the original six founders, are the 15 member states that make up the European Monetary Union.
They have converging economies and coordinated monetary and fiscal policies.
The big outsider is the United Kingdom.
British EMU membership remains very desirable.
If the EU is to progress beyond the limits of a common economic and monetary policy and develop a defense and security policy along with a common foreign policy, the UK must be on board.
Exchange-rate fluctuations between sterling and the euro disturb market forces among member states, and at times even have a negative impact in London.
In the long run, the UK risks serious isolation if the euro zone starts to exert even greater power.
But other European countries must also understand British arguments in favor of the UK maintaining its own currency, given London’s importance as an international financial center as well as its privileged relations with more than 50 Commonwealth countries.
The euro zone should therefore offer the UK an honorable compromise in which Britain would be allowed to become a full member of the EMU and take a seat in all of its institutions like the European Central Bank and the ministerial Eurogroup, while also being able to keep the pound in its relations with third countries. 
The euro would, however, have to be accepted as legal tender in the UK, alongside the pound, and in the commonwealth countries, and this would demand close cooperation between the Bank of England and the ECB.
Such a compromise would increase the EMU’s weight both inside and outside Europe.
A Europe built around such a core corresponds to what I call a “Saturn model,” with a huge planet in the middle, surrounded by rings, converging sooner or later in the center.
The outer circles are the transition countries, while the rings around the center would be EU countries that still refuse to join the EMU, or do not yet fulfill all the conditions, like Romania and Bulgaria, or eventually the western Balkan countries and Turkey.
The Saturn model puts the present fierce debate on enlargement and the borders of Europe into a totally different context, because the core countries would no longer find themselves being asked to accept a Europe divided into different classes of member states.
The positioning of EU countries on the rings around the core would be transitory, with the aim being to facilitate overall convergence.
Given the impact of globalization and the direct challenge to the EU implied by competition from countries like China and India, the European economy needs to become more innovative.
Economic and social reform policies throughout Europe would be strengthened if the EU authorities were able to coordinate them, and EU enlargement, together with the further development of its internal market of almost half a billion consumers, could powerfully stimulate economic activity.
The accession of Spain and Portugal was a vivid example of that in the 1980’s, and it is an argument that should be considered with respect to such a populous country as Turkey.
Europe has been unifying gradually for 50 years now, and we can reasonably look forward to further inter-continental cooperation and integration, not least because of scientific and technological developments.
At the same time, we can expect a growing Atlantic community as successive rounds of trade liberalization make it easier to develop a free-trade area between the EU and the United States.
Europe’s own experience has taught us that a customs union must be the first step, and that sooner or later the more intense economic cooperation that a customs union imposes will compel its members to establish an economic community that has all the characteristics of a unified internal market.
But, of course, this can only function smoothly if exchange-rate fluctuations between its members’ currencies have been eliminated.
Although an Atlantic Monetary Union (between the US and the EU) is a long-term prospect, it should be considered as a grand design for the future.
Europe’s leaders and their voting publics now have a choice between the Europe of the past and of the future.
The Europe of the past began with the Schuman Plan, which sowed the seeds of today’s EU, and concluded when the Cold War ended.
It was an era of integration based on the heroic drive to reconcile post-war Germany and France and establish a 
 Pax Europea
 , as well as the threatened expansion of the Soviet Union.
But after the implosion of communism, the situation in Europe was more or less reversed: the defensive demarcation of borders has been replaced by the removal of frontiers across the Continent.
However, while General de Gaulle once spoke of a Europe stretching from the Atlantic to the Urals, defining Europe in purely geographical terms omits other criteria – including the European social model and the scale of values on which it is based – of what it means to “belong” to Europe.
Instead, the vocation of Europe in the course of the twenty-first century should be to become the lever of step-by-step inter-continental convergence and unification.
Europe must be reinvented for this purpose, and broadening the EMU’s reach is the right place to start.
CAMBRIDGE: Many life and death issues facing developing countries can only be addressed by international joint action.
No lone African country, for example, can overcome the crushing burden of malaria, a disease that claims perhaps 1million lives per year, and which causes around 800 million episodes of illness per year.
Current scientific knowledge is simply inadequate to face the challenge.
The world, instead, relies on the World Health Organization (WHO) to address challenges such as this.
In recent years, however, the United States and other governments have squeezed the budget of the WHO to a point where it can not effectively carry out its global mission.
It is desperately important that the world's governments now recommit to raise the budget of the WHO, as one of the most important steps available in the cause of global development and justice.
Start with two points.
First, many of the crucial barriers to economic development are scientific rather than purely economic.
All of the IMF-World Bank missions in the world are not going to overcome the problems of malaria, or drug-resistant tuberculosis, or even low agricultural productivity in the arid regions of Africa.
These problems simply require new scientific and technical approaches.
Second, the needed science will not emerge from the poorly financed laboratories and universities of developing countries.
It now takes around $300 - $500 million to develop a new vaccine, for example, a malaria vaccine.
Only the major pharmaceutical companies, working in conjunction with basic and applied research centers around the world, can mobilize the necessary funding.
The developing world, alas, contributes only a tiny fraction of worldwide scientific advance, and the major drug companies generally lack the market incentives to invest in diseases afflicting the poor people of the developing world.
Here enters the critical role of the World Health Organization.
As the only international body charged with looking after global health, including the health of the world's poorest people, the WHO is uniquely placed to create a framework in which the needed research and development can take place.
The WHO identifies the areas of highest priority, and then mobilizes the international community to appropriate actions.
It did this most famously in the case of smallpox, where the WHO led the successful campaign on global eradication of that long-dread disease.
It's now time that the WHO lead a similar effort on malaria, tuberculosis, AIDs, and other afflictions of the developing and developed world.
Fortunately, under the dynamic management of the new Director General of the WHO, former Norwegian Prime Minister Gru Brundtland, the WHO is gearing up to meet these new global challenges.
But it currently lacks the resources to match the WHO's will-power, the urgency of the problems, and the operational capabilities of the organization.
In a blindly mechanical way, the U.S. had taken the view that all major UN agencies should keep their budgets unchanged in nominal (current-dollar) terms, leading to a drop in real spending because of inflation.
This tight budget is supposed to force shake-ups in UN management.
On the contrary, it is starving the ability of key units such as the WHO to carry out their job, and to attract and keep the expertise that they need. Such a simple-minded budget policy as an across-the-board freeze in nominal budgets should be ended immediately.
Of course, in the end, success in malaria control, or AIDs control, will require a partnership between the WHO, the private pharmaceutical companies, academic research establishments, and the world's governments.
For example, the WHO and the rich-country governments could promise to purchase an effective malaria vaccine in order to distribute it (below cost) in Africa, thereby guaranteeing the drug companies that they will have a market for a new vaccine if these companies spend the time and money to develop one.
Such creative approaches could spur a tremendous amount of research and development on behalf of the world's poor, and do much more good than yet another IMF-World Bank mission.
The WHO can lead such valuable efforts, and has already proposed to lead dynamically and creatively if given the chance.
For the sake of the world, let's give the new WHO team the chance to make good on this commitment.
TOLEDO, SPAIN &#45;&#45; With President George W. Bush’s grand strategy for the Middle East in ruins, his administration has, however hesitantly, begun to put greater emphasis on resolving conflicts by peaceful means.
The settlement reached with North Korea, whereby it will dismantle its nuclear program, and the Annapolis conference for an Israeli-Palestinian peace – with the participation of Syria, a pivotal member of the region’s “axis of evil” – are two key examples of this trend.
The United States’ staunchest ally since 2001, Great Britain, has already gone down this path, divorcing itself from its servile alliance with a Bush administration that focused on war and confrontation.
Though only a miniature version of America’s imperial predicament, Britain’s current policy, as its new prime minister, Gordon Brown, is defining it, may anticipate the direction taken by the next American president.
Tony Blair’s endorsement of Bush’s Middle East designs showed that an imbalance of power in an alliance always causes the weaker partner to become subservient.
Britain joined America’s Iraq adventure with the same inflated perceptions of its military capacity and diplomatic clout that trapped Bush.
But Britain’s military contribution to the war effort was not indispensable, so Bush did not have to heed Blair’s advice.
As a result, Britain could not serve as a bridge between a doubtful Europe and a belligerent US, as Blair believed, and Britain’s capacity to be a force for good on the world stage was severely damaged.
Like America, Britain has learned the hard way the limits of what sheer military power can achieve, and also the devastating implications of its misuse for its reputation in the Muslim world and beyond.
The scope and virulence of anti-British sentiment in the Muslim world are now second only to that facing the US.
Restoring Britain’s reputation in the region will take years of hard work.
Blair’s legacy has thrown Brown into a confusing oscillation between Britain’s transatlantic tradition and its European connections.
No longer an independent global power, yet unhappy with the London-Washington axis that Blair forged, Brown’s government continues to waffle in its commitment to a united Europe.
Indeed, Brown, for whom America remains “Britain’s most important bilateral relationship,” recently blocked his foreign secretary, David Miliband, from delivering a speech that he considered excessively pro-Europe.
But such uncertainty, common in times of transition, should not overshadow what the end of the Blair-Bush era in Britain holds in store.
Unilateralism and pre-emptive wars are to be replaced by what Brown defines as “an agenda for a hard-headed internationalism,” based on cooperation with multilateral agencies and alliances – the United Nations, NATO, the European Union, and the British Commonwealth.
The new policy seems to shift emphasis to “soft power” strategy aimed at projecting Britain as a global economic and cultural hub.
The City of London, the British Council, Oxfam, and the BBC are now expected to restore the prominence of Britain’s enduring values.
Conspicuously, it is no longer the British, but France’s government under President Nicolas Sarkozy, that is carrying the torch of a possible attack on Iran’s nuclear installations.
But, for Brown’s policy to succeed, it must promote social change and political reform in the Arab world.
That means abandoning Blair’s strategy of confronting the “arc of extremism” with putative “moderates” who, besides offering lucrative markets for arms sales, are in fact autocrats whose conduct has helped fuel the growth of radical Islam.
The “extremists” versus “moderates” language has served only to revive colonial memories in the region and divide it even more deeply.
Post-Blair Britain is becoming a country for which wars that lack international legitimacy can only presage defeat and moral decay.
Of course, international legitimacy can be a vacuous concept when not backed by the capacity to use effective force.
Now incapable of intimidating anyone, Britain has opted for developing its potential to inspire.
Unfortunately, inspiration, too, requires the threat of effective military power to be an effective force for change.
Notwithstanding its many setbacks in recent years, the US remains the only power capable of leading a global strategy that consists in balancing soft and hard power.
May the next American president pursue this course.
LONDON – With Labour trailing the Conservatives slightly in opinion polls, the British election on May 6 could well produce a “hung” parliament, in which neither major party obtains a majority and the Liberal Democrats hold the balance of power.
Depending on which party wins more seats, either Labour’s Gordon Brown or the Conservatives’ David Cameron will become prime minister with the Liberal Democrats’ support.
The surprise is that the Conservatives are not polling far ahead of Labour.
After 13 years in power, Labour started the election with a huge disadvantage: the legacy of Tony Blair.
From being Labour’s most potent asset in 1997, Blair turned into the party’s greatest liability after the Iraq war, and had to be practically forced out in 2006.
His successor, Chancellor of the Exchequer (finance minister) Gordon Brown, was well described by Blair as “clunking.”
A man of charm and humor in private life, he is relentlessly dour in public.
In Britain’s first ever “presidential” television debate the youthful Nick Clegg stole the show for the Liberal Democrats with his freshness and directness.
David Cameron was polished but vague, and the jowly Brown came across as gun loaded with statistics.
But the statistics were not as good as they should have been.
Brown’s reputation for fiscal prudence evaporated with the Great Recession.
Nevertheless, it is the Great Recession that keeps Labour in contention, particularly in the light of the Conservatives’ pledge to start cutting public spending the moment they take power.
This makes people anxious for their jobs.
Most people – bankers and many “experts” excepted – are instinctive Keynesians, even if they have never heard of John Maynard Keynes.
At some level, they understand what Keynes called the “paradox of thrift”: if households and firms are forced to reduce their expenses, and the government simultaneously cuts spending, unemployment will rise, because one person’s spending is another’s income, and the outcome will be less spending and less income all around.
Moreover, now is not the time for a political party to be seen to be in cahoots with the bankers.
Although there is no real British equivalent of the American revolving door between Washington and Wall Street, the Conservatives are widely considered to be friends of the City of London and soft on rich tax evaders like Lord Ashcroft and Zak Goldsmith.
Although the MPs’ expenses scandal – parliamentarians claiming reimbursement for dubious expenses – hit both main parties, the most egregious cases involved wealthy Conservative MPs.
And even though inequality of wealth and income in Britain increased in the 13 years Labour has been in power, this is thought to be something that a left-wing party might seek to correct, whereas there is no similar expectation for a party of the right.
In short, when the power of money is under attack, a party that represents money will have a harder time.

Labour has an obvious interest in fighting the election on their handling of the economic crisis.  The Conservatives would have done better to support them on this, while focusing their attack on the government’s economic record as a whole –especially Labour’s addiction to centralization and over-regulation.  But this is going to be difficult to do because their naïve Shadow Chancellor, George Osborne, seems determined to put “cutting the deficit” at the heart of the Conservative program.
Spending cuts, he argues, would restore credibility to Britain’s public finances, thereby quelling the anxieties of businesses, investors, and consumers about future tax increases and inflation.
A more certain future would restore confidence, boosting private investment and ensuring a robust recovery.
Public spending cuts come more naturally to Conservatives, and they have – despite their lack of candor – attempted to make a virtue out of this necessity.
The Conservative manifesto ‘An Invitation to Join the Government of Britain’ is merely a grandiloquent way of saying that under a Conservative government the people will have to look after themselves.
Labour, by contrast, argues that immediate spending cuts would wreck the recovery – that the hole in the economy, not the government budget deficit, is the problem needing most attention.
In practice, both parties are afraid of their convictions.
The Conservatives’ pledge to start cutting the deficit immediately amounts to only a 1% reduction in the coming year.
Any promise of deeper cuts would, they feel, be electoral suicide, even though their model of the economy tells them that the government should be smaller, and that the deficit is unnecessary and even damaging.
Labour’s model of the economy implies maintaining the deficit for as long as needed, and even increasing government spending if the recovery appears to be flagging.
But Labour is too afraid of the markets to say so openly.
So, like St. Augustine, they promise virtue, but not until next year.
In other words, neither major party can afford to blurt out the awkward truth: how much deficit reduction any government can achieve will depend on what happens to the economy over the next five years, and no one can say anything for certain about that.
So the main parties vie with each other in their promises not to cut public services.
Labour will not cut spending on unspecified “front-line services.”
The Conservatives will not cut spending on health, international aid, and defense, similarly leaving unclear just where the cuts will be made.
Only the Liberal Democrats are committed to a big cut: scrapping Britain’s nuclear submarines.
Finally, all the parties promise big constitutional changes.
The Conservatives want to reduce the size of the House of Commons by 10%.
Labour wants to reduce the House of Lords’ membership by half and hold referenda on making it wholly elected and on changing the voting system.
The Liberal Democrats want MPs to be elected by proportional representation.
In a hung parliament, Britain’s ancient constitution would become a pawn among the parties as they haggle for a share of power.
In that case, voters would get both more and less than they bargained for.
NEW DELHI – In July, I was among 30 men and women from around the world – government ministers, bureaucrats, technologists, and strategic thinkers – who gathered at the International Telecommunications Union (ITU) in Geneva to discuss how broadband can transform the world for the better.
This “Broadband Commission” met under the Chairmanship of Rwanda’s President Paul Kagame and the Mexican communications mogul Carlos Slim.
The ITU, a United Nations body, established the Commission in partnership with UNESCO, and the joint chairmanship was no accident.
The UN recognizes that if the information revolution is to advance further, it will take a public-private effort.
As ITU Secretary-General Hamadoun Touré has put it, “In the twenty-first century, affordable, ubiquitous broadband networks will be as critical to social and economic prosperity as networks like transport, water, and power.”
The Swiss writer and playwright Max Frisch once dismissed technology as “the art of arranging the world so that we need not experience it.”
Today, however, technology is essential to effective participation in our world.
And, although mankind cannot live by technology alone, the information revolution has liberated millions of people.
Information is liberating in the traditional political sense of the term: the spread of information has had a direct impact on the degree of accountability and transparency that governments must deliver if they are to survive.
It is also liberating economically.
Information technologies are a cost-effective form of capital.
Estonia and Costa Rica are well-known examples of how information-access strategies can help accelerate output growth and raise income levels.
Some of the least developed countries, such as Mali and Bangladesh, have shown how determined leadership and innovative approaches can, with international support, connect remote and rural areas to the Internet and mobile telephony, thereby helping to liberate subsistence farmers who were previously tied to local knowledge and local markets.
Likewise, mobile networks are delivering health services to the most remote areas of India.
One successful UNESCO initiative is the creation of multipurpose community telecenters throughout the developing world, providing communication and information facilities – phone, fax, Internet, computers, audio-visual equipment – for a wide range of community uses.
India’s Unique Identification Number project, under the capable stewardship of information-technology pioneer Nandan Nilekani, will enable access to government, banking, and insurance services at the grass-roots level.
There is no doubt that the Internet can be a democratizing tool.
In some parts of the world – and certainly in most of the West – it already is, since large amounts of information are now accessible to almost anyone.
But the stark reality of today’s world is that you can tell the rich from the poor by their Internet connections.
Indeed, economic development nowadays requires more than thinking only of the poverty line; one must also think of the high-speed digital line, the fiber-optic line – indeed, all the lines that exclude those who are not plugged into the possibilities of our world.
But the digital divide is no immutable gap.
On the contrary, the technology gap between developed and developing countries, measured by levels of penetration by personal computers and information-technology and communications services, has narrowed markedly over the course of the past decade, with rapid growth in mobile phone and Internet use.
The average level of Internet and mobile-phone penetration in the rich world in 1997  – 4.1 Internet users and 10.7 mobile phones per 100 inhabitants – was reached in developing countries only five years later.
By contrast, the average level of fixed-line telecommunication penetration in developing countries is nearly 50 years behind the levels of the West.
Not surprisingly, it was in Africa – not Europe or America – where the cell phone first overtook the housebound handset.
More Africans have become telecommunications users in the last four years than in the entire twentieth century.
The Indian story is even more remarkable.
When I left India in 1975 for graduate studies in the United States, the country had roughly 600 million residents and just two million land-line telephones.
Today, India holds the world record for the number of cell phones sold in a month –20 million – and for the most telephone connections made in a single month in any country in the history of telecommunications.
The growth in mobile-telephone technology demonstrates that the digital divide is shifting, and the focus of development efforts must change with it.
India, for example, has 525 million mobile phone users and fewer than 150 million people with Internet access, so using mobile-phone technology as a tool of e-governance has become vital.
This calls for creative means of effecting information transfer and making and receiving official payments by telephone.
Security is a key area of concern today in e-governance – both physical security, in an age of terrorism, and cyber security.
Using technology to deliver security will become even more important in areas such as information sharing, disaster management, and data-privacy standards.
Information and communications technology is a powerful tool to address underdevelopment, isolation, poverty, and the lack of political accountability and political freedom.
But people need access first and foremost.
High-speed broadband Internet access can improve everything from transport management, environmental protection, and emergency services to health care, distance education, and agricultural productivity.
Delivering these benefits to ever more people will require resources, international cooperation, and political will.
PRINCETON – In 2000, the world’s leaders met in New York and issued a ringing Millennium Declaration, promising to halve the proportion of people suffering from extreme poverty and hunger by 2015.
They also pledged to halve the proportion of people without safe drinking water and sanitation; move toward universal and full primary schooling for children everywhere – girls as well as boys; reduce child mortality by two-thirds and maternal mortality by three-quarters; and combat HIV/AIDS, malaria, and other major diseases.
These pledges, reformulated as specific, measurable targets, became the Millennium Development Goals (MDGs).
Last month, ten years on from that meeting, world leaders returned to New York for a United Nations summit that adopted a document called Keeping the Promise, which reaffirmed the commitment to meeting the goals by 2015.
The UN press release called the document a “global action plan” to achieve the MDGs, but it is more an expression of aspirations than a plan.
What chance do we really have of keeping the promises made in 2000?
As the Yale philosopher Thomas Pogge has pointed out, the task has been made easier by moving the goal posts.
Even before 2000, the World Food Summit, held in Rome in 1996, pledged to halve the numberof undernourished people by 2015.
By contrast, the corresponding MDG was to halve the proportion of the world’s people who are suffering from hunger (as well as of those living in extreme poverty).
Because the world’s population is rising, halving the proportion of people suffering from hunger (and extreme poverty) means that the number will not be halved.
But worse was to come.
When the Millennium Declaration was rewritten as a set of specific goals, the baseline for calculating the proportion to be halved was set not at 2000, but at 1990.
That meant that progress already made could contribute to the achievement of the goal.
And the goal became halving “the proportion of people in the developing world,” which makes a big difference, because the developing world’s population is growing faster than the population of the world as a whole.
The net effect of all these changes, Pogge calculates, is that, whereas world leaders pledged in 1996 that by 2015 they would reduce the number of undernourished people to no more than 828 million, now they are pledging only to reduce the number in extreme poverty to 1.324 billion.
Since extreme poverty is responsible for about one-third of all human deaths, this difference effectively means that – if the final promise is actually honored – each year about six million more people will die from poverty-related causes than would have died had the original promise made in Rome been kept.
In any case, according to a recent World Bank/International Monetary Fund report, we are not on track to meet even the scaled-back global target of halving the proportion of hungry people in developing countries.
Rising food prices – possibly related to climate change – have reversed past progress and last year briefly pushed the number suffering from hunger above the one-billion mark.
That this should happen while developed nations waste hundreds of millions of tons of grain and soybeans by feeding them to animals, and obesity reaches epidemic proportions, undermines our claims to believe in the equal value of all human life.
The target of halving the proportion of people in extreme poverty is within reach, but mainly because of economic progress in China and India.
In Africa, after economic stagnation in the 1990’s, a decade of encouraging economic growth is reducing the proportion of the population living in extreme poverty, but not quickly enough to halve it by 2015.
There is better news on achieving gender parity in education, a key to reaching other goals, including lower infant mortality, which often comes about because educated women have fewer children.
We also have a good chance of meeting the target of reducing by half the proportion of people in developing countries without safe drinking water – but to achieve the same with sanitation is proving more difficult.
On health goals, however, we are not even close.
Maternal mortality is falling, but not fast enough.
More people with HIV/AIDS are getting inexpensive anti-retroviral drugs and their life-expectancy has increased, but universal access is still far off, and the disease is still spreading, if more slowly than before.
Progress has been made in reducing malaria and measles, and the rate of child mortality has fallen partly as a result, but the goal of a two-thirds reduction will not be met.
For a long time, rich countries have promised to reduce poverty, but have failed to match their words with adequate action.
Of course, some important progress has been made.
Millions of lives have been saved, but millions more could be saved.
To make sustainable progress in reducing extreme poverty will require improvements in both the quantity and quality of aid.
Just a handful of countries – Denmark, Luxembourg, the Netherlands, Norway, and Sweden – have met or exceeded the UN’s modest target of  0.7% of GDP for foreign development assistance.
But, without trade reform and action on climate change, more and better aid will not suffice.
For now, it looks very much as if, come 2015, the world’s leaders will have failed to keep their (watered-down) promises.
That means that they will be responsible for permitting the needless deaths, every year, of millions of people.
PRINCETON – Ten years after its birth, Google is threatening to re-open the “Browser Wars” of the 1990’s, when Microsoft’s Internet Explorer eliminated its rival, Netscape’s Navigator.
This time, however, it is Google’s Chrome that promises to transform the economics underlying the entire software industry, and not only because of its technical innovation in linking very different kinds of software to an Internet browser.
In doing so it eliminates the need for a program such as Windows, which previously controlled access to every kind of software.
Google’s new technology is impressive, and will no doubt prove convenient for many consumers once the initial security problems are resolved.
But the fundamental innovation lies elsewhere.
Chrome is a breakthrough because it offers a completely novel approach to a dilemma created by the legal and regulatory regime of competition policy in the world’s two major legal jurisdictions, the United States and the European Union.
Between 1995 and 1997, Explorer almost completely eradicated Navigator, although Navigator had initially opened up the World Wide Web for most users and its dominance appeared unassailable.
The major advantage of Explorer was not so much a technical one, but rather that Microsoft’s Windows provided the operating software for the overwhelming majority of personal computers.
As a result, an Internet browser – and, indeed, other media software – could be integrated into the Windows framework as an entire software package.
The ability to have operating systems and software bundled together made life much easier for the average consumer.
You simply got everything you wanted (and probably much more) with the purchase of a computer.
But this also reduced the possibility of choice, of selecting and combining different software.
Microsoft’s critics have complained endlessly about this, claiming that the browser’s integration into the operating system drove out inherently superior software solutions.
For instance, many users preferred the word-processing program WordPerfect to Microsoft’s Word, but the ease of having a bundled solution meant that Word had the advantage of being used more widely, and thus drove its rival into extinction.
Microsoft’s advantage, and its business model, goes back to another protracted legal struggle.
Computer software was originally not a commodity to be bought, but a service.
IBM built up a massively dominant position because it leased a carefully custom-designed and individualized package.
It did not sell anything, computers or software.
IBM’s leasing model seemed to challenge the entire legal philosophy of US competition policy that was established in the New Deal era.
President Franklin Roosevelt had originally wanted to control American business by setting price levels, but when the US Supreme Court rejected this approach, his administration started to use competition policy to challenge the positions of market-dominant companies.
Competition policy, however, faces great difficulty in dealing with industries in which technical breakthroughs can create apparently instant monopolies.
In line with the philosophy of challenging dominant positions, the US Department of Justice in 1969 started a major investigation of IBM, which had just revolutionized business computing with its 360 line.
The case dragged on until it was dismissed in 1982 as being “without merit.”
But so long as the anti-trust case remained a threat, IBM was nervous, and began to back away from its business model.
Microsoft’s current position is a direct outcome of the old anti-trust case pushed against IBM.
When IBM launched its personal computer, it could easily have bundled it together with its own operating software, and in this way maintained its dominance.
But, worried that the US authorities would accuse it of attempting to control a new market, IBM left the Disk Operating System (DOS) for the new PCs to a tiny new company that no one saw as a threat: Microsoft.
Of course, Microsoft ran into its own legal troubles when it took over IBM’s former dominant position, waging long drawn-out court cases on both sides of the Atlantic.
The EU, which has looked increasingly to the US model for competition law, began proceedings against Microsoft in 1993.
The US started only after Microsoft’s victory in the browser wars, with a case beginning in 1998.
Initially, both cases went decisively against Microsoft, with a US ruling in 2000 that would have required the company’s break-up, although this was subsequently overturned on appeal.
Google’s position is so interesting and so powerful because the legal philosophy that challenges any ascendant position, even in an industry that seems naturally to produce monopoly, remains in place.
Leasing software and hardware, as IBM initially did, is problematic.
But so is selling computer services on a one-time basis, in the manner of Microsoft.
By contrast, on the face of it, there cannot be anything wrong with offering services or products for free, and then simply using the resulting advertising possibilities.
Google’s model is a neat example of what might be termed “post-modern economics.”
The amazing story of technical innovation is that it was, and remains, hard for innovators to benefit from radical technological breakthroughs.
Industrial Revolution-era cotton makers in England did not make a great deal of money, even though their products revolutionized personal life and hygiene, and even extended life expectancy. 
In our own time, air travel has become much cheaper, but airlines lose money; telephoning is no longer unaffordable, but the telecommunications companies lost fortunes by over-bidding for mobile telephony rights.
Google has taken the logic of loss-making technology to its ultimate culmination of not charging at all for its product.
NEW HAVEN – People frequently ask me, as someone who has written on market speculation, where the next big speculative bubble is likely to be.
Will it be in housing again?
Will it be in the stock market?
I don’t know, though I have some hunches.
It is impossible for anyone to predict bubbles accurately.
In my view, bubbles are social epidemics, fostered by a sort of interpersonal contagion.
A bubble forms when the contagion rate goes up for ideas that support a bubble.
But contagion rates depend on patterns of thinking, which are difficult to judge.
Big speculative bubbles are rare events.
(Little bubbles, in the price of, say, individual stocks, happen all the time, and don’t qualify as an answer to the question.)
And, because big bubbles last for many years, predicting them means predicting many years in the future, which is a bit like predicting who will be running the government two elections from now.
But some places appear a little more likely than others to give rise to bubbles.
The stock market is the first logical place to look, as it is a highly leveraged investment – and has a history of bubbles.
There have been three colossal stock-market bubbles in the last century: the 1920’s, the 1960’s, and the 1990’s.
In contrast, there has been only one such bubble in the United States’ housing market in the last hundred years, that of the 2000’s.
We have had a huge rebound from the bottom of the world’s stock markets in 2009.
The S&amp;P 500 is up 87% in real terms since March 9 of that year.
But, while the history of stock-market prediction is littered with too much failure to try to decide whether the bounceback will continue much longer, it doesn’t look like a bubble, but more like the end of a depression scare.
The rise in equity prices has not come with a contagious “new era” story, but rather a “sigh of relief” story.
Likewise, home prices have been booming over the past year or two in several places, notably China, Brazil, and Canada, and prices could still be driven up in many other places.
But another housing bubble is not imminent in countries where one just burst.
Conservative government policies will probably reduce subsidies to housing, and the current mood in these markets does not seem conducive to a bubble.
A continuation of today’s commodity-price boom seems more likely, for it has more of a “new era” story attached to it.
Increasing worries about global warming, and its effects on food prices, or about the cold and snowy winter in the northern hemisphere and its effects on heating fuel prices, are contagious stories.
They are even connected to the day’s top story, the revolutions in the Middle East, which, according to some accounts, were triggered by popular discontent over high food prices – and which could themselves trigger further increases in oil prices.
But my favorite dark-horse bubble candidate for the next decade or so is farmland – and not just because there have been stories in recent months of booming farmland prices in the US and the United Kingdom.
Of course, farmland is much less important than other speculative assets.
For example, U.S. farmland had a total value of $1.9 trillion in 2010, compared with $16.5 trillion for the US stock market and $16.6 trillion for the US housing market.
And large-scale farmland bubbles are quite rare: there was only one in the US in the entire twentieth century, during the great population scare of the 1970’s.
But, farmland, at least in certain places, seems to have the most contagious “new era” story right now.
It was recently booming, up 74% in real terms in the US in the decade ending with its price peak, in 2008.
And the highly contagious global-warming story paints a scenario of food shortages and shifts in land values in different parts of the world, which might boost investor interest further.
Moreover, people nowadays easily imagine that the housing and farmland markets always move together, because prices in both boomed in recent memory, in the early 2000’s.
But, from 1911 to 2010 in the US, the correlation between annual real growth of prices for homes and farmland was only 5%, and the latest data on farm prices have not shown anything like the decline in home prices.
By 2010, real farm prices in the US had fallen only 5% from their 2008 peak, compared to the 37% decline in real home prices since their peak in 2006.
The housing-price boom of the 2000’s was little more than a construction-supply bottleneck, an inability to satisfy investment demand fast enough, and was (or in some places will be) eliminated with massive increases in supply.
By contrast, there has been no increase in the supply of farmland, and the stories that would support a contagion of enthusiasm for it are in place, just as they were in the 1970’s in the US, when a similar food-price scare generated the century’s only farmland bubble.
Still, we must always bear in mind the difficulty of forecasting bubbles.
And, for daring investors, it is not enough to find a bubble to pile into.
They must also try to determine when to cash out and put their money elsewhere.
The future of the housing boom, and the possible financial repercussions of a substantial price decline in coming years, is a matter of mounting concern among governments around the world.
I learned this first-hand while attending this year’s Jackson Hole Symposium in the remote wilderness of Wyoming, where, ironically, there are almost no homes to buy.
The howls of coyotes and bugling of elk rang out at night.
But, by day, everyone was talking about real estate.
This conference has grown to be a major international event for government monetary policymakers, with governors or deputy governors of 34 central banks attending this year.
Roughly two-thirds of these countries have had dramatic housing booms since 2000, most of which appear to be continuing, at least for the time being.
But there was no consensus on the longer-run outlook for home prices.
Of all these countries, the United States appears to be the most likely to have reached the end of the cycle.
According to the Standard &amp; Poor’s/Case-Shiller US National Home Price Index, US home prices increased 86% in real, inflation-corrected, terms from 1996 to 2006, but have since fallen 6.5% – and the rate of decrease has been accelerating.
That looks like the beginning of the end of the boom, though, of course, one can never be sure.
I presented a bearish long-run view, which many challenged, but no one obviously won the argument.
Nevertheless, an outside observer might have been struck by the weight given to the possibility that the decade-long boom might well suffer a real reversal, followed by serious declines.
There seems to be a general recognition of substantial downside risk, as the current credit crisis seems to be related to the decline in US home prices that we have already seen.
The boom, and the widespread conviction that home prices could only go higher, led to a weakening of lending standards.
Mortgage lenders seem to have believed that home buyers would not default, because rising prices would make keeping up with their payments very attractive.
Moreover, the boom resulted in a number of financial innovations, which may have been good ideas intrinsically, but which were sometimes applied too aggressively, given the risk of falling prices.
Mortgage-backed securities were urged onto investors for whom they were too risky.
As with homebuyers, all would be well, the reasoning went, on the premise that home prices continue to rise at a healthy pace.
At the Jackson Hole conference, Paul McCulley of PIMCO, the world’s largest bond fund, argued that in the past month or two we have been witnessing a run on what he calls the “shadow banking system,” which consists of all the levered investment conduits, vehicles and structures that have sprung up along with the housing boom.
The shadow banking system, which is beyond the reach of bank regulators and deposit insurance, fed the boom in home prices by helping provide more credit to buyers.
Bank runs occur when people, worried that their deposits will not be honored, hastily withdraw their money, thereby creating the very bankruptcy that they feared.
It is no coincidence that this new kind of bank run originated in the US, which is the clearest example of falling home prices in the world today.
When home prices stop rising, recent homebuyers may lose the enthusiasm to continue paying their mortgages – and investors lose faith in mortgage-backed securities.
The US Federal Reserve is sometimes blamed for the current mortgage crisis, because excessively loose monetary policy allegedly fueled the price boom that preceded it.
Indeed, the real (inflation-corrected) federal funds rate was negative for 31 months, from October 2002 to April 2005.
The only precedent for this since 1950 was the 37-month period from September 1974 to September 1977, which launched the worst inflation the US has seen in the last century.
What then helped produce a boom in consumer prices now contributed to a boom in home prices.
But loose monetary policy is not the whole story.
The unusually low real funds rate came after the US housing boom was already well underway.
According to the Standard &amp; Poor’s/Case-Shiller US National Home Price Index, home prices were already rising at almost 10% a year in 2000 – a time when the Fed was raising the federal funds rate, which peaked at 6.5%.
The rapid increase thus appears to be mostly the result of speculative momentum that occurred before the interest-rate cuts.
Alan Greenspan, the former Fed chairman, recently said that he now believes that speculative bubbles are important driving forces in our economy, but that, at the same time, the world’s monetary authorities cannot control bubbles.
He is mostly right: the best thing that monetary authorities could have done, given their other priorities and concerns, is to lean against the real estate bubble, not stop it from inflating.
The current decline in home prices is associated just as clearly with waning speculative enthusiasm among investors, which is likewise largely unrelated to monetary policy.
The world’s monetary authorities will have trouble stopping this decline, and much of the attendant problems, just as they would have had trouble stopping the ascent that preceded it.
One goal of the recent war in Iraq was to build a lasting market democracy that could serve as an example for the Middle East.
While progress towards this goal has been stymied by the mundane practicalities of restoring law and order, the coalition must eventually take it up.
When it does, it will also have to face the fact that the current distribution of economic power in Iraq is not conducive to democracy or markets, and that outside interim administrations tend to make matters worse.
Start first with the distribution of economic power.
Years of dictatorship and sanctions decimated Iraq's business and professional classes.
Estimates suggest that over 60% of Iraqis depend for their income on government, which will obtain the bulk of its revenues from oil for the foreseeable future.
But when an easily extractable, government-controlled resource accounts for a large share of national output, democracy can suffer.
Consider Venezuela.
Hugo Chavez's government faced a widespread opposition strike, whose intent was not only to demonstrate popular opposition, but also to starve the government of revenue.
Without revenue, such a government cannot pay the army or thugs who keep it in power.
Although it seemed that Chavez would fall, oil saved him.
Few people are needed to extract oil.
With the help of some loyal (and foreign) engineers and enough new workers to replace strikers, the government kept the oil flowing, securing the resources needed to maintain the loyalty of mercenary forces who would otherwise have gone over to the opposition.
The strike is all but over, and the Chavez government is now taking action against its leaders.
It was the same with Saddam Hussein.
Even with Saddam deposed, what is to prevent a successor regime from using oil power to oppress Iraq's people?
Democracy is stable only when it is accompanied by a wide diffusion of economic power, which gives the citizenry the ability to keep a government from becoming arbitrary and tyrannical.
The conditions under which democracies flourish are also the conditions under which free markets prosper.
When people do not fear that a rapacious government will expropriate their wealth, and when an elite that owes its success to the government does not determine market rules, opportunities percolate to everyone.
So how to build the economic basis for a stable democracy in post-war Iraq?
Douglas MacArthur's partially successful policies in Japan after the Second World War offer some guidance.
Japan was perhaps easier to transform because it did not have an abundance of easily extractable natural resources.
But land holdings were concentrated and a few large combines called "Zaibatsus" held industrial power.
MacArthur attacked concentrated economic power under the assumption that large landholders and large firms become pawns of government.
Subsequent reforms expanded and widened the land-owning class, fostering an agricultural revival and making Japanese democracy more stable.
But MacArthur did not have enough time to finish the job.
The need for reliable suppliers during the Korean War forced a compromise with the Zaibatsus.
This partly explains why Japan's domestic market remains uncompetitive despite its vibrant democracy.
Some suggest that Iraq's oil "problem" be dealt with by distributing shares in the state oil company to the people.
This is no solution, because the government will still control oil revenues and determine the dividend.
Without adequate governance, oil revenues will be wasted on grandiose projects, corruption, or rearmament.
Even if the government-owned oil industry is broken up and privatized, whether to foreigners or not, there is no guarantee that a future government cannot regain control.
The best hope for an enduring market democracy in countries like Iraq lies in building the countervailing economic power of professionals and entrepreneurs.
Such people abound in Iraq, however decimated by years of sanctions.
A priority for any interim administration must be to restore and improve educational and healthcare institutions so that they can recover lost ground.
Another priority is to wean people from dependence on government.
Reconstruction could revive the entrepreneurial classes if small contractors and businesses are given opportunities.
The danger is that the interim administration may hand out contracts to those well connected in Washington or the rich westernized Baghdad elite that gets cozy with whatever government is in power.
As Russia's recent experience shows, creating a politically sycophantic business oligarchy makes the prospect of a market democracy more remote.
It is far wiser to distribute contracts widely and ensure that more Iraqi businesses gain access to credit.
Clearly, many old financing institutions are compromised.
The easiest fix is to let foreigners in so that they can channel foreign capital into domestic private ventures.
New domestic financial institutions should also be encouraged.
Such policies would mirror those followed by Napoleon III in France in the 1850's.
Destroying the financial power of the Ancien Regime laid the foundations for the vibrant market democracy France became.
All this will not happen overnight.
Economic institutions must be built, repaired and strengthened.
The interim administration must undertake a delicate balancing act: Iraqis will have to be prevented from choosing how they will be ruled until the economic preconditions are in place for that choice to be genuinely free.
At the same time, Iraqis need to be convinced that the interim administration has their best interests at heart, rather than the interests of American or British businesses.
Success in this balancing act requires leadership, transparent policies, and good communication.
America provided this in postwar Europe and Japan.
It must rise to the challenge again.
The euro is now six years old.
It is past time to consider how it is performing, and whether it has lived up to the expectations that accompanied its birth.
Those expectations were not modest.
By reducing transaction costs and removing exchange-rate uncertainty, the single European currency was expected to lead to fully integrated product and financial markets.
This, in turn, would bring greater gains from trade, stronger competition, larger cross-border capital flows, lower borrowing costs, and more opportunities for sharing risk, all of which were expected ultimately to boost investment and productivity.
Reality has disappointed.
Compared to the five years before the euro’s launch in 1999, productivity growth has since slowed in Italy, Germany, Spain, and the Netherlands, while over the same period it accelerated or remained constant in Denmark, Sweden, and the UK, the European Union members that remained out.
Indeed, with the main exception of France, the euro does not seem to have been a blessing for the countries that adopted it. 
Why this disappointment?
Have the expected benefits of the new currency failed to materialize?
Several recent economic studies addressed this question, looking at a variety of indicators. 
Here is what emerges:
· The single currency 
 has
 boosted international trade within the euro area, by about 10%.
Although a larger effect was expected, it remains too early for a complete assessment.
In any case, this is an important positive outcome, because international trade is generally regarded as a key determinant of faster growth and higher efficiency.
· The euro was expected to increase price transparency, thereby strengthening competition in product markets.
No evidence exists that this happened.
Prices did converge during the implementation of the Single Market program, in the early 1990’s, but then price convergence stopped.
· Cross-border investment towards the euro area has increased, although here it is more difficult to disentangle the effect of the single currency from other concomitant events (such as privatizations or corporate mergers).
· Money and bond markets are now fully integrated in the euro area, implying a reduction in the cost of capital for large corporate borrowers.
Retail banking, however, remains segmented by national borders, so that households and smaller producers have not been much affected.
· The euro was expected to acquire an international role, eventually improving Europe’s resilience in the face of economic shocks.
There has been a surge in euro-denominated international bonds, but the liquidity of foreign-exchange markets is no higher for the euro compared to the national currencies it replaced, and the euro remains a long way from challenging the supremacy of the dollar.
Of course, the euro was never just an economic project.
One of its backers’ main motives was to boost Europe’s political integration.
Indeed, the euro has quickly become a symbol of European unity.
When asked, “What does the EU mean to you personally,” 50% of citizens in the 15 countries that were EU members before enlargement in May 2004 say “the euro” – the second most common response (just behind “the ability to travel, study, and work anywhere in the EU”).
Yet, this symbol has not made the EU or the euro area any more popular.
Support for EU membership within the pre-enlargement EU-15 remains where it was in the mid-1990’s (and below the peak reached in 1990), while support for the euro is no higher now than it was in 1997.
To be sure, the introduction of the euro was a true revolution, and we cannot yet see all its effects.
But what is clear is that the revolution took place on shaky national economic foundations, transforming the upper floors of the European economy – financial markets and macroeconomic policy institutions – while leaving intact the 
 ancien
 underpinnings of supply-side distortions induced by misguided national policies in the 1970’s and 1980’s. 
These distortions, not any shortcomings of the single currency, account for the euro area’s dismal economic performance.
The countries that adopted the euro had poor labor-market institutions, bloated pension systems, high taxes on labor income, and inefficient service sectors in the late 1990’s, and they still do now.
The more fundamental problem with the euro is that its adoption has not pushed countries to address these underlying deficiencies.
It was expected that full integration of product and financial markets would expose inefficiencies, steering investment flows away from laggards towards the more efficient countries.
Yet, while reform efforts intensified throughout Europe in the late 1990’s both inside and outside of the euro area, there is little evidence that “ins” enacted more far-reaching and significant supply-side reforms than the “outs.”
Larry Summers, the former US Treasury Secretary and now president of Harvard University, once called the single European currency a “distraction” from the serious supply-side reforms Europe needed to confront.
This judgment may be too harsh, because we do not know whether the EU and the single market would have survived without the single currency.
But one thing is certain: Europe cannot afford other “distractions.”
Overhauling Europe’s shaky supply-side foundations is the key challenge facing the euro revolution, and it is a challenge that needs to be addressed at its national-level roots.
The world is a study in contrasts nowadays.
We are haunted by images of terror and warfare.
Yet every region of the globe has experienced some of the strongest economic growth seen in years, inflation remains subdued despite surging oil prices, and financial markets are doing well.
Several economies that recently faced financial crises are rebounding strongly.
At the same time, much more needs to be done to help prevent future crises and reduce poverty.
What do these contrasts mean for the future?
The answer depends crucially on how each country and the international community respond to key policy challenges: addressing global imbalances through macroeconomic policies and long-overdue reform; meeting the costs of aging populations; strengthening defenses against economic and financial crises; and delivering on the pressing imperatives of poverty reduction.
Recently, financial leaders from 184 countries met in Washington at the Annual Meetings of the IMF and World Bank.
This year marks the sixtieth anniversary of the Bretton Woods Conference that established those two organizations as pillars of international economic cooperation.
As IMF Managing Director, my message was one of vigilance and action.
Simply put, the international community must take advantage of the current recovery to broaden efforts to ensure financial and economic stability, and help those countries with limited prospects.
Periods of strong economic growth allow countries to put in place defenses to reduce the likelihood and severity of future downturns.
But such opportunities are all too easy to squander.
In an era of globalized financial markets, when countries can find it hard to cope with rapid cross-border capital flows, there is no time for complacency. A lesson of the 1990's is that vulnerabilities must be dealt with before they become crises.
The world's rapid economic growth in 2004 shows that the efforts to shore up our defenses since the 1990's has paid off.
But growth has been unbalanced: Europe and Japan - despite some recent gains - are far from reaching their potential, and the United States and China have continued largely to drive the world economy.
One priority is to reduce global payments imbalances.
The US must move to reduce its budget deficit in the medium-term.
Europe and Japan can increase their growth by stepping up the pace of structural reform.
Moves toward increased exchange rate flexibility in China and other Asian countries, supported by financial sector reform, will have domestic and global benefits.
Emerging market countries elsewhere have made considerable reform progress of late, but they must sustain the momentum to guard against potential shocks.
Other challenges loom.
Issues that we once regarded as "medium-term" are becoming more urgent.
Aging populations are forcing many countries to address pressures on their budgets and social security systems.
The problem is imminent in North America, the Euro Area, and Japan.
But, before long, many developing countries will also have to face up to it, and in many cases without a cushion of affluence.
Then there is the energy issue.
High oil prices have resurrected an old vulnerability.
Countries need to reformulate their energy policies - including by boosting production and refining capacity, diversifying energy sources, and giving new impetus to conservation.
A better balance between production and consumption would avoid large swings in oil prices.
The IMF focuses on crisis prevention, and in the past decade encouraged greater transparency and stronger financial systems.
The Fund also actively monitors capital market developments, and is implementing a more systematic assessment of debt sustainability.
There will always be ways to strengthen our work so that we provide well-articulated advice based on a clear understanding and the best analysis of each country.
We need to communicate our positions clearly to policymakers and reinforce incentives for countries to take appropriate corrective actions.
But in the end, the effectiveness of our advice hinges on countries' willingness to act on our recommendations.
Poverty also threatens economic stability.
For all the successes of recent decades, the fact remains that 20% of the world's population still lives on less than $1 a day, while HIV/AIDS and other communicable diseases are ravaging many societies.
Other social indicators offer a bleak picture.
Indeed, most developing countries are likely to fall short of the international community's target of halving poverty by 2015.
In 2002, at the Monterrey Conference, the international community agreed on a framework for reaching that goal.
Developing countries would implement sound economic policies accompanied by good governance.
Industrial countries would increase aid levels and lower trade barriers.
The IMF and World Bank would offer advice, expertise, and financing, with the Fund concentrating on the macroeconomic and financial stability that is crucial to fostering durable growth and poverty reduction.
Some progress has been made on this "Monterrey Consensus."
But international support is falling far below promised levels.
Strong political commitments are needed to provide the aid that is needed to accelerate progress, and to secure success for the Doha trade round that is so crucial for developing countries' longer-term prospects.
The resilience of the global economy in the face of political and economic shocks demonstrates the central relevance of the reform process - and underlines the importance of continuing along this path.
Governments and institutions like the IMF must keep this in mind as they seek to ensure a durable economic recovery that will benefit all of the world's people.
PYONGYANG: Is the Cold War's last glacier beginning to melt?
The summit between South Korean President Kim Dae Jung and North Korea's "Dear Leader" Kim Jong Il raised hopes on both sides of the Korean peninsula that 55 years of hot and cold war may diminish.
Because Korea remains the world's most heavily armed flash point and with the risk of nuclear weapons and missile proliferation still high in North Korea, the whole world may benefit from a loosening of tensions. For that to happen, however, more than the two Korean governments must act imaginatively and responsibly.
Kim Dae Jung's visit to North Korea provided Kim Jong Il with a historic opportunity to convey the message that North Korea is breaking out of self-imposed isolation.
By shaking hands with and embracing the South Korean president so publicly and so dramatically, Kim Jong Il demonstrated that he was seriously committed to beginning the process of normalizing political and economic relations between the two Koreas.
The warmth of his greeting showed the world that North Korea was indeed opening up; and it showed North Korea's own people that their government was going to change -- how is still unclear -- in order to survive in a rapidly globalizing world.
Kim Jong Il's actions also projected a new image of himself as a serious and reasonable leader, not the sinister recluse frequently depicted in newspapers.
The two Kims agreed in principle to work toward reunification by making joint efforts "independently" of outside influence, and to find common ground between the South's idea of a North-South "commonwealth" or confederation, and the North's idea of Alow-level federation".
They promised to help families separated by the Demilitarized Zone for half-a-century meet and to promote exchanges in various fields including economic cooperation.
Regular government to government meetings will tackle these matters.
Although some of this may sound like the normal hot air of goodwill found at the end of all summits, the very public commitments of the two leaders will provide real impetus to move ahead.
A real test of how far the process can go, and how quickly, will occur when and if Kim Jong Il actually pays a return visit to Seoul, as he agreed to do "at an appropriate time."
Is Kim Jong Il really signaling a fundamental change?
Is he prepared to pull his troops back from the Demilitarized Zone and dismantle the tens of thousands of artillery that are capable of reaching Seoul?
Is he ready to maintain today's freeze on developing nuclear weapons and to assure that North Korea does not export, develop, or deploy ballistic missiles?
So long as the danger of nuclear and missile proliferation in North Korea remains, the peninsula will remain a potential source of conflict.
North and South Korea remain technically at war even now.
Against this background, it is premature to talk about withdrawing American troops.
Although these knotty issues remain, they can now be addressed with more confidence because doubt as to who is really in charge in North Korea was put to rest. Kim Jong Il rules in North Korea.
His fingerprints are everywhere to be seen, not only in the summit's events, but it now appears clear that he was fully behind the policy of engagement initiated by President Clinton and the Japanese government after North Korea test-fired a medium range ballistic missile in August 1998.
By beginning to normalize relations with South Korea, Kim Jong Il gains leverage in his dealings not only with South Korea, but also in negotiations with the US, Japan, China, and Russia.
If this effort is to bear real fruit for him, however, he must continue to transform North Korea's Arogue state" image into that of a normal state.
That the US welcomed the steps taken so far was indicated by the Clinton administration's decision to actually implement its previously announced intention to lift trade sanctions on North Korean exports.
So building on the summit is not only a job for the two Kims.
The first task facing South Korea's government is to bring the US on board for a policy of increasing "Koreanization" of affairs on the peninsula.
Given a rising trend of big power rivalry over Korea in recent years, this may be no straightforward thing.
But it is vitally important to decouple the Korean peace process from Sino-American and Russo-American rivalries, particularly on the emerging hot button issues of national missile defense(NMD) and theatre missile defense(TMD) programs that America is contemplating.
China and Russia, too, have been building their stakes in North Korea.
Beijing hosted a secret visit by Kim Jong Il at the end of May, perhaps to talk him into hosting the summit as a wedge to replace Washington as the major player on the peninsula.
Russian President Vladimir Putin is poised to visit Pyongyang in July in search of support for his objections to America's proposed anti-missile shield.
And just as these two Asian land powers cultivate Kim Jong Il, Washington is seeking talks over missiles with Pyongyang and Tokyo is eager to reestablish diplomatic relations with the North.
America and Japan helped push North Korea to talk with South Korea.
It is incumbent upon South Korea to keep both governments closely informed of its efforts to secure some control over North-South reconciliation.
Because China's role is rising, it is crucial that the US and China restore their strategic dialogue and cooperate by decoupling the North Korean missile issue from the fractious issue of missile defense.
The two Kims have moved the Korean peninsula closer to peace than anyone dared hope one week ago.
Their efforts must be supported and sustained by the other powers with interests in the Koreas.
JERUSALEM – As President Barack Obama’s special Middle East envoy, former US Senator George Mitchell, learned during his visit to the region, America’s efforts at Israeli-Palestinian peace-making are running up against three major obstacles.
They will, no doubt, also arise in Obama’s upcoming meetings with the region’s leaders.
The first obstacle – indeed, the issue that stands front and center today – is the ongoing Palestinian civil war, with Hamas controlling the Gaza Strip in defiance of Abu Mazen’s Fatah-led Palestinian Authority.
The Palestinians’ basic failure at nation-building makes any meaningful peace talks with Israel – let alone an agreement – almost impossible at the moment.
With Palestinians unable to agree among themselves on a minimal national consensus, how can peace be established between them and Israel?
Second, with Likud’s Benjamin Netanyahu as prime minister, Israel now has a government which is far less likely to be willing – or able – to make major concessions and evacuate hundreds of thousands of Israeli settlers from the West Bank.
Third, and most significantly, the 1993 Israel-PLO agreement has until now failed to achieve its aim.
Attempts to revive the Oslo peace process – the “Road Map” and the Annapolis process – have similarly failed to achieve more than vacuous declarations and hollow photo opportunities.
The causes of these 15 years of failure should be considered, so that Mitchell’s mission does not become another stillborn effort.
Both the Palestinians and Israel can easily and rightly be blamed for the failure of the Oslo process.
But there is a more fundamental cause at stake, and it should not be overlooked.
The Oslo process tried to build a Palestinian state from the top down: create a Palestinian national authority, hand over territory to it, give it increasing power, arm it and finance it, hold elections, and a Palestinian state would emerge.
Instead, the consequence was a corrupt, militarized Palestinian Authority, with competing security services proved incapable of providing security.
Nor could it conduct credible negotiations with Israel or deliver necessary services to ordinary Palestinians.
Two reasons for this failure stand out: the institutional weakness of Palestinian civil society, which lacks the infrastructure necessary for nation-building; and the impossibility of simultaneous nation-building and peace-making.
There is no precedent anywhere in the world that suggests that such a two-tier process can succeed.
A fundamental change of paradigm is needed: the effort should shift to building a Palestinian state from the bottom up, for which there are encouraging signs, even in the midst of the failure of the top-down process.
In the last two years, former British Prime Minister Tony Blair and US General Keith Dayton have succeeded in effective institution-building in three West Bank districts – Jenin, Bethlehem, and Hebron – turning them into the most peaceful areas in the West Bank, with a minimal Israeli military presence.
Local authorities were supplied with adequate funding and advice; independent chambers of commerce became the backbone of a local commercial middle class, which is interested in keeping the region peaceful, even absent an overall agreement; local police were trained (in Jordan), and now function effectively as police forces, not armed militias; and business relations with adjacent Israeli regions have been renewed.
This empowerment of an effective local leadership was done with much persistence – and little fanfare. But these nuts-and-bolts projects created – for the first time – the building blocks necessary for effective Palestinian nation-building.
Admittedly, this process will take time and patience.
But, until now, it has been the only approach proven to succeed, while everything else has failed.
As Blair recently put it, such a bottom-up process may even go hand-in-hand with Netanyahu’s goal of an “economic peace,” though it would eventually have to go beyond it.
That such an approach would have to include a total halt to Israeli settlement activities goes without saying.
If carefully crafted, it may even be implicitly accepted, albeit without much enthusiasm, by the Israeli government.
The Oslo process has failed; an attempt to revive it – say, by way of the Beirut Arab peace initiative – will merely bring into the open all of the existing disagreements between the two sides, and will not overcome the Palestinian failure at nation-building.
After all the breakdowns in efforts to create a Palestinian state from the top down, only the old-fashioned way – from the bottom up – remains viable.
MANILA – One of the main sources of tension in Asia nowadays are the Spratly Islands in the South China Sea, where the Philippines, Vietnam, China, and others have conflicting claims.
In Chinese media reports, the heightened “unfriendliness” in the region has allegedly arisen from “bad rumors and speculations” on the part of Filipino commentators.
But the reality is starker: the intrusions by Chinese aircraft into Filipino airspace in May; Chinese patrol boats cruising in March in the Recto (Reed) Bank, 85 miles west of the Filipino island of Palawan; and, most serious of all, a Chinese missile frigate firing at Filipino fishing boats in February near Palawan’s Quirino atoll.
Will armed conflict result from these recurring – and, it seems, escalating – disputes between the Philippines and Vietnam on one side, and China on the other?
War, of course, is in no one’s interest.
But the risk posed by these disputes is growing, because China’s relations with both the Philippines and Vietnam are at their lowest point in decades.
Given these tensions, it is no surprise that the issue of disputed sovereignty in the South China Sea is almost certain to claim center stage at this month’s ASEAN Regional Forum, and at the East Asia summit in Bali that will follow it.
Last June, I gave the keynote speech at the celebrations marking the 36th anniversary of the establishment of Philippines-China diplomatic relations and the 10th anniversary of Philippines-China “Friendship Day” in the presence of 5,000 of my countrymen and a smattering of Chinese officials.
Yet on that same day, the headlines in Chinese papers were blasting the Philippines for its historic claim to ownership of the Spratly Islands.
Of course, the governments of both countries recognize the need to maintain the stability and cooperation that have made East Asia the world’s fastest growing region.
The same is true of Vietnam’s government and that of the United States.
But there is no institutionalized means to discuss and resolve the dispute, which is taking on greater significance almost daily, owing to the belief that vast mineral and energy resources lay on the sea bed around the Spratlys.
Now is the time for China, the Philippines, Vietnam, other claimants, and the US to take action to begin to diminish these tensions.
What is needed, above all, is a covenant among the leaders of the Asia/Pacific region that will make peaceful dispute resolution binding on all stakeholders, big or small.
Only such a pledge can provide the type of certainty that investors – any investors – will need if the Spratly resources are to be developed.
Certainly, China’s leaders talk as if this is their goal.
In April, at this year’s Boao Forum (the Asian Davos) on Hainan Island, Chinese President Hu Jintao asserted: “Peace and development remain the overriding themes of the times.
The world needs peace, countries deserve development, and people want cooperation....China will always be a good neighbor, good friend, and good partner of other Asian countries.”
It is past time to make those sentiments a reality; more than a pledge to resolve disputes peacefully is needed.
Asia’s governments must also begin to adhere to a far more expansive idea of open regionalism, which means that countries like India should have a voice in Asia/Pacific affairs, and they must respect the Asian interests of countries beyond the region.
The US, for example, should be made welcome to participate – or continue to participate – in peacekeeping and security cooperation.
But how is Asia to reach consensus on this point?
Ever since 1994, when Vietnam’s President Le Duc Anh held the presidency of ASEAN, I have proposed to ASEAN leaders that the Spratlys be demilitarized as a first step toward building trust.
The UN Convention on the Law of the Sea (UNCLOS) and associated international commitments must become the basis for productive dialogues leading to binding covenants.
Joint exploration and development of the resources within and beneath the archipelago could then begin.
More broadly, the urgent task for Asian statesmen over the next 5-10 years will be to replace the region’s Pax Americana, which has guaranteed regional stability for decades, with a more comprehensive Pax Asia-Pacifica that is built on inclusiveness and burden-sharing.
But such an Asia-Pacific peace will be durable only if it is based on a balance of mutual benefits rather than on the balance of power.
Clearly, this concept implies burden-sharing by all Asia-Pacific countries to ensure the region’s harmony and security.
Pax Asia-Pacifica’s institutions will need to be built, as Europe’s peace was built after World War II, on strong, cooperative undertakings among the most powerful countries and regional blocs – the US, China, Japan, India, South Korea, Russia, and the ASEAN 10.
The region’s continued economic growth and progress require that we Asians contain our rivalries and avoid the arms buildups that, unfortunately, now seem to be underway.
VIENNA – The greatest challenge of the current global financial crisis is the seeming impossibility of comprehending and managing its diversity.
Indeed, the way problems are proliferating appears almost uncontrollable.
Plans to meet the crisis, in country after country, have been revamped and restructured time and again.
The old models about how to understand the economy have had their day.
Across the globe, governments are facing fundamental decisions about the future nature of their economies and societies.
The sub-prime crisis in the early summer of 2007 developed first into a financial crisis and ultimately into a recession.
New economic problems soon rushed in to add to the existing ones: energy and food prices rose and then fell like a yo-yo; the dangers of climate change became ever more clear; and the mal-distribution of global political power demanded action.
The recent social unrest in Greece, Latvia, and Lithuania has shown that political stability is now vulnerable even in the European Union.
Indeed, around the world, from Mexico to Indonesia and even China, the social fabric is being stretched to the point of fraying.
This anxiety is reinforced by the general lack of funds among large groups of people who had nothing to do with creating today’s crisis but are bearing the pain of it.
These social anxieties are not being addressed because financial-sector bailouts, stimulus packages, and help for distressed industries with strong lobbies are testing many governments’ financial limits.
That the advocates of unconditional privatization are now crying out for state support would be cause for cynical laughter if the danger were not as big as it is.
For the brutal question governments must now face is this: is there an alternative to the Icelandic crash course?
In the past, when state economic decision-making reached such an impasse, wars and/or revolutions were the inevitable result.
As we face the type of turning-point decisions not seen since the darkest days of the 1930’s, can we avoid such an outcome?
If we are to avoid the worst, fundamental change is not only necessary, but unavoidable.
So politicians everywhere must do their duty and exercise responsible leadership.
A combination of steely calm and bold experimentation is the only way that political and social harmony will be preserved.
To make the European Central Bank a lender of last resort for all of the euro-zone countries, for example, would give distressed European governments some added breathing space.
But it will require global monetary reform of a fundamental order to right the imbalances between surplus and deficit countries, between happy savers and those who lived beyond their means, and between rich and poor.
Achieving this will not come without suffering.
Some of those who brought the world to this perilous point with their toxic financial instruments and unscrupulous speculation may even turn out to profit from these reforms.
So be it: a moral, and perhaps legal, reckoning must await the return of economic growth.
As governments move into uncharted territory, they will need to question themselves constantly.
All assumptions will need to be assessed and reassessed, starting points found and re-found, and new tools developed and perfected.
The mechanics of the welfare state will need to be strengthened; public policy must stop deferring to the financial sector, regardless of the need for bailout packages.
As governments embark on their necessary and bold experiments, they must remember to take their citizens with them.
For, unless these experiments in economic rejuvenation are transparent, they will lead to domestic political fights.
There is a wide difference between pragmatic and opportunistic politics, and governments had better keep this distinction in mind in the months and years ahead.
That domestic transparency and pragmatism will need to be carried over into international economic diplomacy.
For, unless today’s global imbalances are redressed, the next crash will be upon us before we have recovered from this one.
Today’s globalized markets need rules that take into account the public good in every country and region of the world.
That much is clear.
But the decision we are actually faced with is much more fundamental: global monetary and economic reform, or war and revolution.
Twenty years after the world supposedly reached “the end of history,” we are instead at another historical turning point.
Either we will write this history ourselves, or we will suffer through a dark era that could have been avoided.
BERKELEY – In the mid-2000’s, the United States had a construction boom.
From 2003-2006, annual construction spending rose to a level well above its long-run trend.
Thus, by the start of 2007, the US was, in essence, overbuilt: about $300 billion in excess of the long-run trend in construction spending.
When these buildings were constructed, they were expected to more than pay for themselves.
But their profitability depended on two shaky foundations: a permanent fall in long-term risky real interest rates, and permanent optimism about real estate as an asset class.
Both foundations collapsed.
By 2007, therefore, it was reasonable to expect that construction spending in the US would be depressed for some time to come.
Since cumulative construction spending was $300 billion above trend, it would have to run $300 billion below trend over a number of years in order to return to balance.
So, in 2007, everyone expected a construction-led slowdown.
And, starting that year, construction spending did indeed fall below trend.
But we were expecting a minor decline: a fall in construction spending below trend of $150 billion a year for two years or $100 billion a year for three years or $75 billion a year for four years.
Instead, spending fell $300 billion below trend in 2007 alone, and has remained depressed for four years.
Moreover, there is no prospect of anything like a rapid return to normal levels.
Therefore, when this construction cycle has run its course, the US will first have spent an excess $300 billion, and then fallen short of trend by a cumulative $2 trillion of spending not undertaken.
The net effect will be a construction shortfall in the US of at least $1.7 trillion.
That is a lot of unbuilt houses, apartment buildings, offices, and stores – and it is a truly radical disconnect between the size of the recent construction boom and the size of the current construction bust.
Indeed, this radical disproportion makes nonsense of all arguments that the current distressed state of the overall US economy is in some sense necessary, deserved, or an inevitable consequence of over-exuberant building in the desert between Los Angeles, California and Albuquerque, New Mexico in the mid-2000’s.
Otherwise, the construction-led economic slowdown would not be today’s $1 trillion in annual lost production.
The slowdown would be one-tenth the size of the one the US is now enduring, and it would be largely confined to the construction sector.
And, in that alternative universe, having worked off the entire burden of overbuilding, we would by now have returned to trend levels of production, employment, and demand.
There is one silver lining as we contemplate our macroeconomic wreckage: when incomes, production, and employment in the US return to their trend levels, Americans will demand an extra $1.7 trillion worth of buildings to live in.
And, because those buildings will not be there, construction demand will come roaring back.
If America does recover to the previous long-run trend, the next decade will likely witness a construction boom that puts the mid-2000’s boom in the shade.
But that is not now.
And it is not for some years to come.
There is another lesson here.
The economists Kenneth Rogoff and Carmen Reinhart argue that recovery after a financial crisis is almost always slow.
But there is at least one important sense in which America’s current construction bust suggests that they are wrong.
One factor behind slow post-financial-crisis recovery is that nobody knows how the division of labor will be rearranged.
But right now we know a lot about that.
We know that when Americans become confident again – when they believe that they could find new jobs if they lost their current ones, and when they can no longer tolerate doubling-up with their in-laws – they will demand more dwellings than the country has today.
If incomes and demand were normal, we would want a lot more new construction then we do now.
But, even though we can see the magnitude of the construction shortfall and understand how large it will be when recovery is complete, that does not help right now.
Right now, incomes are slack, households have become crowded, and there is a surplus of housing on the market – all because nominal demand is still far below trend.
In 20 years, historians will interview the then-aged monetary, banking, and fiscal policymakers of the 2000’s.
They will ask them why they did not take more aggressive steps to return nominal incomes and demand to trend levels when they were sitting in the hot seats.
I already wonder what their excuses will be.
When Bulgaria joined the European Union this past January, I believed that my country had finally left its repressive past behind.
But the recent arrest and threatened deportation of Annadurdy Hadjiev, a dissident from Turkmenistan who sought refuge here, suggests that some things never change.
If Bulgaria sends this man back to Turkmenistan – where he faces certain torture and the threat of a brutal death – our claim to be part of a democratic, rights-respecting Europe will ring hollow.
Moreover, the EU’s image as a defender of human rights around the world will be tarnished by its inability to hold member states to its own standards.
The case evokes memories of the days when the KGB’s influence was pervasive, and dissidents across Eastern Europe and Soviet lands like Turkmenistan lived in fear.
Hadjiev and his family fled to Europe in 2001, escaping one of the world’s most repressive regimes: the absolutist dictatorship of the late Saparmurat Niyazov, who fancied himself “Turkmenbashi,” the father of all Turkmen.
A former deputy chairman of the Central Bank of Turkmenistan and later an outspoken critic of Turkmenbashi’s government, Hadjiev, a senior member of the exiled Watan (Republican) Party, received “humanitarian parole” – a protected category of individuals that falls short of refugee status – when he reached Bulgaria.
But he has since been subjected to violent and arbitrary reprisals in this supposed “safe haven.”
And, although Turkmenbashi died in December, his successor, Gurbanguly Berdymukhammedov, has continued to imprison dissidents, stifle freedom of expression, and scoff at democracy, as February’s rigged elections demonstrate.
Bulgaria’s persecution adds to the anguish and injustice that has befallen Hadjiev and his family.
Last summer, Hadjiev’s brother and sister were arrested after they collaborated on a documentary about Turkmenistan, and were tried on trumped-up charges of weapons possession.
After a perfunctory closed trial, they were sentenced to seven and six years in prison, respectively.
Hadjiev’s sister, the journalist Olgusapar Muradova, died in prison several weeks later, under suspicious circumstances.
Her grown children, who viewed her body, told relatives that they saw evidence of torture and that she had sustained a severe head wound.
(A state-controlled autopsy implied that she had committed suicide.)
Hadjiev’s two other brothers, as well as his brother-in-law and sister-in-law, have been in Turkmenistan’s notorious penal gulag since 2002, when they were sentenced to lengthy prison terms.
In 2003, his elderly father-in-law was beaten by police agents and forced into internal exile.
On February 19, the Bulgarian police arrested Hadjiev with the intention of sending him back to face a similar fate.
This is not the first time he has been arrested in Bulgaria.
After first arriving, Hadjiev and his wife were arbitrarily detained for several days, leaving their 13-year-old daughter without supervision or access to her parents.
The police arrested Hadjiev again in 2002, in response to a Turkmen extradition request.
After the Varna City Court refused to allow the extradition, ruling that the charges were politically motivated, the Bulgarian authorities threatened to deport him.
In 2005, the Hadjievs’ car was incinerated by a bomb-like device, which they interpreted as a warning to cease their defiant challenges to the Bulgarian – and possibly Turkmen – authorities.
The authorities that arrested Hadjiev last month made no pretense of due process: they offered no arrest warrant, and have repeatedly refused him access to relatives and legal counsel.
Moreover, the court has given no explanation of why it is allowing him to be tried on the same embezzlement charge that of which he was acquitted in 2003.
Fortunately, Hadjiev is a fighter.
Since the beginning of his travails in Bulgaria, he has battled the system by confronting the government branches responsible for his persecution.
Indeed, he has sued the very prosecutor in whose hands his current extradition now rests – an act that may be jeopardizing his right to a fair hearing.
My government has pledged its willingness live up to the legal norms that are the core of European Union membership.
By releasing Annadurdy Hadjiev from jail and withdrawing the threat of extradition to Turkmenistan, Bulgaria would unequivocally demonstrate its commitment to fulfilling its obligations.
By granting him political asylum, we can make a resounding statement that authoritarian regimes can no longer count on support within Europe’s borders.
NEW DELHI – As stage-managed elections ratify the consequences of three decades of military rule in Burma, the perspective from its neighbor India may help explain why there is continued international acceptance of the country’s long-ruling junta.
Burma was ruled as part of Britain’s Indian Empire until 1935, and the links between the two countries remained strong after Burma gained its independence in 1947.
An Indian business community thrived in Burma’s major cities, and cultural and political affinities were well established.
India’s nationalist leader and first prime minister, Jawaharlal Nehru, was a close friend of the Burmese nationalist hero Aung San, whose daughter, the Nobel laureate and opposition leader Aung San Suu Kyi, studied in New Delhi.
For many years, India was unambiguously on the side of democracy, freedom, and human rights in Burma – and in ways more tangible than the rhetoric of the regime’s Western critics.
When the generals suppressed the popular uprising of 1988, nullified the overwhelming election victory by Aung San Suu Kyi’s National League for Democracy (NLD) in 1990, shot students, and arrested the newly-elected leaders, India’s government initially reacted as most Indians would have wanted.
India gave asylum to fleeing students and a base for their resistance movement (along with some financial help), and supported a newspaper and a radio station that propagated the democratic voice.
But then reality intruded.
India’s strategic rivals, China and Pakistan, began to court the Burmese generals.
Major economic and geopolitical concessions were offered to both suitors.
The Chinese even began developing a port on the Burmese coast, far closer to Calcutta than to Canton.
And the generals began providing safe havens and arms to a motley assortment of anti-Indian rebel movements that would wreak havoc in India’s northeastern states and retreat to sanctuaries in the newly-renamed Myanmar.
All this was troubling enough to Indian policymakers, who were being painfully reminded of the country’s vulnerability to a determined neighbor.
The clincher came when large deposits of natural gas were found in Burma, which, it was clear, would not be available to an India deemed hostile to the junta.
India’s rivals were gaining ground in its own backyard, while Indian businesses were losing out on new economic opportunities.
The price of pursuing a moral foreign policy simply became too high.
So India turned 180 degrees.
When Pakistan’s President, Pervez Musharraf traveled to Myanmar to celebrate his country’s new relationship with his fellow generals, India’s Foreign Minister Jaswant Singh soon followed.
The increasingly forlorn resistance operations staged from Indian territory were shut down in the hope of reciprocation from the Burmese side.
And India sweetened the generals’ tea by providing military assistance and intelligence support to their own never-ending counter-insurgencies.
India’s journey was complete: from standing up for democracy, India had graduated to aiding and abetting the military regime in Rangoon (now Yangon).
When monks were being mown down on the streets of Yangon in 2006, the Indian government called for negotiations, muttered banalities about national reconciliation, and opposed sanctions.
India also sent its minister for oil to negotiate an energy deal, making it clear that the country’s real priorities lay with its own national economic interests, ahead of its solidarity with Burmese democrats.
(At the same time, Indian diplomats intervened discreetly from time to time on behalf of Suu Kyi, though their effectiveness was limited by India’s unwillingness to alienate the junta.)
All of this was in fact perfectly understandable.
Officials in New Delhi were justified in reacting acerbically to Western critics of its policy.
India needed no ethical lessons from a United States and a Britain that have long coddled military dictators in India’s South Asian neighborhood, notably in Pakistan.
Any Indian government’s primary obligation is to its own people, and there is little doubt that the economic opportunities provided by Burmese oil and gas are of real benefit to Indians.
There is also the strategic imperative of not ceding ground to India’s enemies on its own borders.
India confronts an inescapable fact of geopolitics: you can put your ideals on hold, but you cannot change who your neighbors are.
India’s government cannot be blamed for deciding that its national interests in Burma are more important than standing up for democracy there.
The member countries of the Association of South East Asian Nations, on Burma’s eastern flank, have made similar calculations.
But many Indians are asking themselves what such a policy does to India as a civilization.
If that idealistic democrat Nehru had not been cremated, India’s stance toward Burma might cause him to turn over in his grave.
It is a policy that is governed by the head rather than the heart, but in the process India is losing a little bit of its soul.
PRAGUE – On November 7, when Burma’s first general election for almost two decades is to be held, a well-rehearsed script will play out.
The country’s ruling generals will twist what is meant to be a democratic process, whereby the people get to express their will, into a mockery of free expression in which people vote in fear and without hope.
The international community must judge Burma’s generals by their actions, not their words and promises.
The facts on the ground in Burma speak the truth more loudly than all the proclamations from the generals about a free ballot and a democratic transition.
More than 2,100 political prisoners remain in jail in Burma.
Many have been tortured, kept in horrific conditions, and denied medical care.
Attacks against the country’s ethnic minorities continue, with the deliberate targeting of civilians, including children, by the Burmese military and police.
The country’s media remains censored, freedom of expression denied, and the most popular political party in the country, the National League for Democracy, which won elections in 1990, has been forced to disband because it decided not to register for the November elections.
In such conditions, free and fair elections will be impossible.
This so-called democratic transition, a process designed solely by dictators and with input only from the regime’s loyalists, will result in continued dictatorship.
Before Burma’s fate is sealed in a new-model dictatorship, the United Nations must immediately and vigorously embark on a fresh process designed to deliver national reconciliation and democracy to that troubled country.
The international community, East and West, must unite behind a UN-led initiative to start genuine dialogue.
But, for this dialogue to have any real legitimacy, it must include the Nobel Peace Prize laureate Daw Aung San Suu Kyi, who has endured decades of house arrest, and her party, the NLD.
Other democratic opposition groups, and genuine ethnic-minority representatives, also need to be given a voice in the process.
Pressure must be brought to bear to bring Burma’s generals to a negotiating table where real negotiations take place.
All the tools at the disposal of the international community should be used to bring this about.
But responsibility for assisting Burma does not lie solely at the door of the UN.
The pressure on Burma’s generals must also be bilateral and multilateral – and should be reinforced by carefully calibrated economic measures, including targeted financial and banking sanctions.
Action must also be taken to end the impunity with which the Burmese generals have ruled.
The dictatorship stands accused of committing war crimes and crimes against humanity, mostly against the country’s minorities, who chafe at decades of oppression, ostracism, and military misrule.
The UN General Assembly should follow the UN Special Rapporteur‘s recommendation to establish a Commission of Inquiry into war crimes and crimes against humanity in Burma.
Moreover, the UN Security Council should impose an arms embargo against Burma, as it has in other countries similarly afflicted by conflict and serious human rights abuses. Those countries supplying arms to Burma expose themselves to charges of complicity in the war crimes and crimes against humanity committed by the dictatorship.
Dictatorship and human rights abuses will continue in Burma after November 7.
We do not need to wait until after the election to know this.
So there is no excuse for continued inaction.
Now is the time for the world to unite behind the people of Burma, and to help bring them peace and dignity at last.
YANGON – Here in Myanmar (Burma), where political change has been numbingly slow for a half-century, a new leadership is trying to embrace rapid transition from within.
The government has freed political prisoners, held elections (with more on the way), begun economic reform, and is intensively courting foreign investment.
Understandably, the international community, which has long punished Myanmar’s authoritarian regime with sanctions, remains cautious.
Reforms are being introduced so fast that even renowned experts on the country are uncertain about what to make of them.
But it is clear to me that this moment in Myanmar’s history represents a real opportunity for permanent change – an opportunity that the international community must not miss.
It is time for the world to move the agenda for Myanmar forward, not just by offering assistance, but by removing the sanctions that have now become an impediment to the country’s transformation.
So far, that transformation, initiated following legislative elections in November 2010, has been breathtaking.
With the military, which had held exclusive power from 1962, retaining some 25% of the seats, there were fears that the election would be a façade.
But the government that emerged has turned out to reflect fundamental concerns of Myanmar’s citizens far better than was anticipated.
Under the leadership of the new president, Thein Sein, the authorities have responded to calls for a political and economic opening.
Progress has been made on peace agreements with ethnic-minority insurgents – conflicts rooted in the divide-and-rule strategy of colonialism, which the country’s post-independence rulers maintained for more than six decades.
The Nobel laureate Daw Aung San Suu Kyi was not only released from house arrest, but is now campaigning hard for a parliamentary seat in April’s by-elections.
On the economic front, unprecedented transparency has been introduced into the budgetary process.
Expenditures on health care and education have been doubled, albeit from a low base.
Licensing restrictions in a number of key areas have been loosened.
The government has even committed itself to moving towards unifying its complicated exchange-rate system.
The spirit of hope in the country is palpable, though some older people, who saw earlier moments of apparent relaxation of authoritarian rule come and go, remain cautious.
Perhaps that is why some in the international community are similarly hesitant about easing Myanmar’s isolation.
But most Burmese sense that if changes are managed well, the country will have embarked on an irreversible course.
In February, I participated in seminars in Yangon (Rangoon) and the recently constructed capital, Naypyidaw, organized by one of the country’s leading economists, U Myint.
The events were momentous, owing both to large and actively engaged audiences (more than a thousand in Yangon), and to the thoughtful and moving presentations by two world-famous Burmese economists who had left the country in the 1960’s and were back for their first visit in more than four decades.
My Columbia University colleague Ronald Findlay pointed out that one of them, 91-year-old Hla Myint, who had held a professorship at the London School of Economics, was the father of the most successful development strategy ever devised, that of an open economy and export-led growth.
That blueprint has been used throughout Asia in recent decades, most notably in China.
Now, perhaps, it has finally come home.
I delivered a lecture in Myanmar in December 2009.
At that time, one had to be careful, given the government’s sensitivities, even about how one framed the country’s problems – its poverty, lack of rural productivity, and unskilled workforce.
Now caution has been replaced by a sense of urgency in dealing with these and other challenges, and by awareness of the need for technical and other forms of assistance.
(Relative to its population and income, Myanmar is one of the world’s smallest recipients of international assistance.)
There is much debate about what explains the rapidity of Myanmar’s current pace of change.
Perhaps its leaders recognized that the country, once the world’s largest rice exporter, was falling far behind its neighbors.
Perhaps they heard the message of the Arab Spring, or simply understood that, with more than three million Burmese living abroad, it was impossible to isolate the country from the rest of the world or prevent ideas from seeping in from its neighbors.
Whatever the reason, change is occurring, and the opportunity that it represents is undeniable.
But many of the international sanctions, whatever their role in the past, now seem counterproductive.
Financial sanctions, for instance, discourage the development of a modern and transparent financial system, integrated with the rest of the world.
The resulting cash-based economy is an invitation to corruption.
Likewise, restrictions that prevent socially responsible companies based in advanced industrial countries from doing business in Myanmar have left the field open to less scrupulous firms.
We should welcome Myanmar’s desire for guidance and advice from multilateral institutions and the United Nations Development Program; instead, we continue to limit the role that these institutions can play in the country’s transition.
Whenever we withhold assistance or impose sanctions, we need to think carefully about who bears the burden in bringing about the changes that we seek.
Opening up trade in agriculture and textiles – and even providing preferences of the kind that are offered to other poor countries – would likely benefit directly the poor farmers who make up 70% of the population, as well as create new jobs.
The wealthy and powerful can circumvent financial sanctions, though at a cost; ordinary citizens cannot so easily escape the impact of international-pariah status.
We have seen the Arab Spring blossom haltingly in a few countries; in others, it is still uncertain whether it will bear fruit.
Myanmar’s transition is in some ways quieter, without the fanfare of Twitter and Facebook, but it is no less real – and no less deserving of support.
ROME: "Get-rich-quick": for thousands of people around the world, that is what investing in the stock market means nowadays.
Old people invest their savings and pensions from home computers; young men and women give up working for salaries to seek a big pay-off in the stock options on offer from dot.com firms.
Given the global market tumult of the past ten days, examining the historical data about the performance of stock markets is a mandatory sobering experience for investors old and new and everywhere.
In the United States over the past 100 years, investments in stocks delivered an average 6% more than safe investments in short-term government securities.
This differential has been quite stable over time, although between 1947 and 1994 it was slightly higher at 8%.
The numbers are similar in other countries.
In Italy between 1961 and 1994, for example, stock investments brought an average return of around 6% more than investments in treasury securities.
Certainly, there have been extraordinary periods, such as the 1950s, when the differential between investing in the stock exchange in Milan and treasury securities climbed to over 22%.
But there were also unlucky periods; in the next decade (1961-1970), when the average differential was -2%.
Higher returns mean higher risks.
It is as simple as that.
If, instead of investing in the Standard & Poor index of 500 largest companies quoted on Wall Street, an investor put his savings in small, and often more innovative, companies (the so-called "small caps"), his return would have gone up in the last 50 years by 6% – i.e. by a mere15% over the return on ultra-safe government securities.
But the risks that investor faced would also have doubled, for the volatility of returns on short-term government securities was 3% during the same 50 years, but a whopping 17% for the S&P index, and 30% for small cap stocks.
This 30% figure means that, in any one year, the probability that the return on one's investment was going to be 30% higher than the return on government securities was equal to the probability that it would be 30% lower.
Given that in the same period American government securities brought, net of inflation, a little less than 2% return, this means that the return on small cap stocks had the probability, in any given year of delivering a +32% or -28% return.
In other words, long-term investments in stocks do yield more than investments in government securities, but the heightened volatility means that decades must pass before we can safely conclude that an average stock investment has indeed brought higher returns.
The history of "new economy" stocks is too short to allow anyone to say whether the extraordinary performance of the stock exchanges in more or less all countries over the last few years is a temporary speculative boom, or an irreversible result of the new economy.
Until now, even considering recent gyrations, almost all stock exchanges have been rising at breakneck speed.
Annuals return in Italy, for example, between Christmas and the end of the first quarter of this year was 120%.
But the greater volatility of the last few weeks saw the index of new European stocks lose at least 30% of its value.
Here is a powerful signal that the old relationship between returns and volatility is reasserting itself.
The fear now, however, is that a new generation of investors, including those who invest from their computers at home and who never experienced a negative performance of the market, is underestimating the risks.
In the United States, where the boom has lasted the longest, many observers have no doubt that the market is in a bubble.
Looking at price earning ratios on Wall Street, Robert Shiller, an economist at Yale University and one of the most convinced believers in the bull market, observed recently that stocks have never been more overvalued, not even in the summer of 1929, before the Great Crash.
The data, at least for the American economy, certainly shows that the new economy is generating extraordinary productivity increases.
But in light of historical experience, this may not be all that convincing.
Ours is not the first experience of a technological leap; at the previous turn of the century, the world saw the introduction of the electric engine and of the telegraph – clearly both inventions of comparable significance to the Internet.
Yet, during that period, the differential in returns between stocks and treasury securities was on the order of 6%.
In sum, the lesson of the new economy is not that one becomes rich without any effort, simply by speculating on the stock market.
The new economy teaches us that research, technological innovation, and entrepreneurial spirit in a competitive market – all things that are not plentiful in Europe – have a high payoff.
Europe has imported from the United States some of the negative aspects of the market, such as casino-like speculation.
But it has not yet moved toward the more important features of the American economy, such as deregulation of labor and product markets, and a reduction in the weight of the public sector on the economy.
Market falls in America might quickly be overcome because of the underlying strength of the American economy; Europe holds no such underlying strength in reserve.
For individual investors, stocks remain personal risks; for Europe as a whole, bursting any speculative bubble may risk economic stability.
BOSTON/ROME: Any reader of non-US newspapers could draw two conclusions about America’s electoral campaign: 1. that there is little difference between the two candidates; 2. that a mere detail – a slip of the tongue, a false step, a piece of gossip – could decide the election.
Both conclusions are wrong.
Start with the first.
Differences between Bush and Gore on economic policy are as deep as those between the right and left in France or Italy.
The cleavage lies in a very different visions about the state and it goes beyond questions about how to divide America’s budget surplus between increased spending or cutting taxes.
Bush’s Republicans favor increasing disposable family income (by reducing taxes) and more often leaving to the market, the production of goods and services now publicly provided and paid for by the taxpayer, rather than the user.
Gore’s Democrats prefer more traditional public management and control.
In public education, Bush favors a system of vouchers administered by individual states.
Through such vouchers, citizens are given a subsidy with which they “purchase” education either from a public or private school.
The idea is that market competition among different educational institutions will increase the quality of education.
Democrats oppose vouchers and prefer major federal investments in order to improve the quality of public schools.
On pensions, Bush advocates a mixed system of pensions, with a private component. The idea is to create more freedom for taxpayers to manage their pension funds, bringing incentives for the allocation of these monies into stocks and bonds.
Gore prefers to maintain the system essentially as it is and to use the budget surplus to eliminate the deficit in the pension system that will open in the second decade of this century, when a wave of baby boomers reaches retirement age.
In other words, Gore sees the pension system as a means to redistribute between rich and poor; Bush sees it more as a “private” system to accumulate individual pension savings.
A similar difference exists in health policy: Bush prefers fiscal relief for taxpayers so that they can buy private medical insurance; Gore prefers public management with more public intervention.
In sum, Americans are confronting fundamental differences about the right type of school, pension, and healthcare for the future.
The fact that in the weeks before the elections the candidates court undecided voters by trying to appear as centrist as possible should surprise no one.
The only area where there doesn’t seem to be much difference between the two candidates is foreign policy, and this is a good sign for the world, because it portends stability in America’s posture and, above all, cooperation between the two parties even if one of them were to control Congress and the other the Presidency.
Still, there are differences: Gore is more “interventionist”; Bush more cautious and less eager to engage American troops abroad.
The second point regards the way in which the vote will be decided.
The story of presidential elections in the twentieth century goes like this: if a foreign observer had only the following two pieces of data: 1. economic growth during the electoral year and 2. the name of the incumbent president, the observer could foresee with precision the results of presidential elections, independently of the entire campaign.
An incumbent president running for a second term (like Clinton in 1996) has an advantage; beyond that, strong economic growth in the electoral year favors the party of the incumbent president.
All the rest – scandals large and small, marijuana smoke, and errors of grammar – divert journalists but influence the results little.
Why, then, do candidates spend enormous amounts on campaigning?
For the same reason that Coca-Cola and Pepsi spend millions to compete – if both stopped advertising, their market shares would not change much, even if, obviously, it would change if only one of the two engaged in publicity.
In other words, conservative vote for Republicans and those on the left vote for Democrats on the basis of differences in the party programs, those in the middle go from one side to the other on the basis of the state of the economy and perceptions about the “competence” of the incumbent administration.
After WWII the only two incumbent presidents not reelected were Carter in 1980, who ran in the middle of a recession, and Bush (the father) in 1992, who paid for mediocre economic growth in 1990-1992.
(Had America’s economy come out of recession six months earlier, Clinton would probably not have won in 1992.)
It took the Watergate scandal in 1974 and Nixon’s resignation to make Gerald Ford (who became President upon Nixon’s resignation) lose in 1976.
Eisenhower in 1956, Johnson in 1964, Reagan in 1984, Bush in 1990, and Clinton 1996 (all incumbent presidents or vice presidents) with an economy in good shape would have won even if they hadn’t opened their mouth for the whole electoral campaign.
If this is so, given strong growth in America, Vice President Gore should win easily.
Instead Bush is holding his own.
Two factors work to Gore’s disadvantage.
Many think that the benefits of the “new economy” have little to do with who was in office.
If this is really a “new” economy maybe the economy’s impact on electoral results is also “new”.
The second factor is that the Republicans who control Congress are relatively “extremist” and might lose the legislative elections.
American voter tend to prefer a system that balances the President and Congress.
The expected new power of Democrats in Congress puts Gore at a disadvantage.
Having said all this, if Gore loses on November 7 he will confirm that he is one of the least liked politicians of the 20th century.
Note, indeed, that this is no “Clinton effect”: many polls indicate that Clinton would easily beat Bush.
In sum, an incumbent vice president who loses with an economy such as exists in America today should retire to private life.
If he wins by a hair’s breath, he better work very hard to have any hope in 2004.
The most shocking statement in the aftermath of Hurricane Katrina was President George W. Bush’s remark that “I don’t think anybody anticipated the breach of the levees” that protect New Orleans from flooding.
New Orleans is a city mostly below sea level, and must be protected by levees to keep water out.
Concern that the levees might break in the midst of a powerful hurricane was widespread among scientists, engineers, and emergency-preparedness experts.
Yet Bush apparently did not know of these concerns, even days after the hurricane destroyed the levees and flooded the city. 
There is a simple fact on display here, one that goes well beyond this particular hurricane, and even this particular president.
There is a deep disconnect in American politics between scientific knowledge and political decisions.
Bush bears much responsibility for this.
He has proven to be one of America’s least knowledgeable presidents when it comes to science – and one of the most ready to turn science into a political issue. 
In recent months, Bush undermined biological theories of evolution in favor of Christian fundamentalist dogmas.
He disdains climate science and public health science when it conflicts with the beliefs – and interests – of his core supporters.
Simply put, Bush’s record on science policy is miserable.
Climate scientists have warned for years that global warming caused by manmade emissions of greenhouse gases will generate more extreme storms.
While there is no scientific way to link a particular hurricane such as Katrina to the long-term trend – in the sense that Katrina might have been bad luck rather than a sign of manmade climate change – the energy of hurricanes throughout the world has been rising markedly.
Bush, alas, led an aggressive effort to discredit climate science rather than to respond to its findings.
He called for delays in reducing greenhouse gas emissions that cause global warming, which in turn causes the energy of hurricanes to rise.
According to the underlying science that Bush ignores, hurricanes take their energy from the warmth of seawater.
That is why hurricanes occur in hot tropical regions, and at the end of the summer months, when the sea surface temperatures are at their annual maximum.
Manmade global warming raises not only air temperatures, but sea-surface temperatures as well.
Higher sea-surface temperatures translate into more powerful storms in the world’s oceans.
Hurricanes are measured according to three dimensions: frequency, intensity, and duration.
The frequency of hurricanes has not changed much, if at all.
The big changes are in hurricanes’ intensity and duration.
Intensity measures a hurricane’s force, which includes wind speeds, and there has been some recorded increase.
The biggest change, however, has been in the duration of hurricanes: how many days each hurricane lasts.
Duration has risen markedly around the world.
The total energy of a hurricane is found by multiplying the intensity of the hurricane by its duration.
This, too, has risen sharply, and more is in store as temperatures rise.
Scientists and engineers who work on climate change stress that governments need to adopt two main responses.
The first, called “mitigation,” means reducing the amount of manmade climate change.
This can be done by changing the world’s energy system to limit emissions of carbon dioxide into the atmosphere – the main driver of manmade climate change.
One option is a shift to non-carbon energy sources, such as renewable energy (solar and wind power) and nuclear energy.
Another option is to combine carbon-based energy (coal, oil, and gas) with new technologies that prevent the emission of airborne carbon. 
The second response to climate change, called “adaptation,” requires that we ready ourselves for the climate change now underway and the increased climate change to come in future years.
This means preparing for hurricanes that are more powerful in both intensity and duration.
An attentive national government would surely have realized that the Gulf region of the United States is more vulnerable to high-energy hurricanes.
Indeed, Hurricane Katrina was the third most intense hurricane ever to make landfall in the US.
Such a government would have taken more action to strengthen levees.
The Bush administration’s negligence is especially shocking given the remarkable amount of scientific expertise that exists in the US.
Somehow, scientists have been pushed aside by political operators.
But the US government’s failings are matched in many parts of the world, and certainly in the poorest countries, where scientific expertise is scarce, and where many governments do not have scientific advisory councils to turn to for guidance.
Hurricane Katrina is a wakeup call, not only for the US but for the world.
We are entering a period when good science is vital for our survival.
On a crowded planet with threats to our climate, oceans, forests, food production, and water supply, and with global travel and high population densities increasing the risk of worldwide disease epidemics, we must turn to the best of our scientific and engineering knowledge to find a safe passage.
Two rulings of the United States Supreme Court this week rejected the sweeping wartime powers claimed by President Bush.
In the case of Yaser Hamdi, the court renounced the Administration's claim that military authorities could indefinitely hold a U.S. citizen as an "enemy combatant" without ever providing him with an opportunity to contest the basis for his detention before a neutral decision maker.
And in a case brought by fourteen foreign nationals, the court cast aside the government's argument that because the U.S. Naval Base at Guantanamo Bay is nominally under Cuban sovereignty, American courts lack jurisdiction to entertain legal claims brought by persons who had no say in where the U.S. military chose to detain them.
Although nowhere mentioned in either case, the scandalous treatment of Iraqi prisoners at Abu Ghraib and the revelations that high-level government lawyers prepared confidential memoranda authorizing torture, likely played a part in the Justices' reasoning.
The Administration essentially said, "trust us to do what's right."
Clearly, the court thought that such trust had not been earned.
Another unspoken consideration may have been at work in the Guantanamo Bay case, which has garnered considerable international attention.
In recent years, a majority of the Justices of the Supreme Court have articulated a multilateralist view of American law that stands in marked contrast to the unilateralism of the Bush Administration.
For example, in a 2002 Virginia case, the high court ruled that the execution of the mentally retarded is forbidden by the American Constitution as "cruel and unusual punishment."
While most of the Court's analysis focused on domestic considerations, the Justices also invoked a legal brief filed by the European Union that described the overwhelming disapproval of the practice in the world community.
Likewise, in last year's ruling striking down a Texas prohibition on same-sex sodomy, the Court cited a 1967 Act of the English Parliament and a 1981 ruling of the European Court of Human Rights.
Significantly, the six Justices in the majority in the Virginia and Texas cases also constituted the majority in the Guantanamo Bay case: the four dissenters from Bush v. Gore plus Ronald Reagan's two relatively moderate appointees, Sandra Day O'Connor and Anthony Kennedy.
These Justices regularly travel to colloquia on comparative constitutional law and see themselves as part of an international community of high court judges.
It cannot have escaped their notice that to uphold indefinite detention of foreign nationals without judicial process would have made them virtual pariahs on the conference circuit.
I do not mean to suggest that the Justices decided the Guantanamo Bay case as they did so that they would be toasted at their international cocktail parties.
I contend that their concern for world opinion-if that concern played the role I am suggesting it did-was for their country, not for themselves.
In less than four years, President Bush and his advisers have cast aside much of the longstanding bipartisan consensus under which the United States works through and with multilateral institutions like the United Nations.
Alarmed by this dramatic volte-face, the majority Justices in the Guantanamo Bay case may be trying to send assurances to the rest of the world that President Bush does not speak for all Americans, not even the ones who put him in office in the first place.
Of course, neoconservative critics of the high court will see in this explanation the confirmation of their worst fears.
Here are judges, they will say, who do not understand that they have no legitimate qualifications to act as agents of American foreign policy, a job committed by the Constitution to the President and (they may grudgingly admit) Congress.
Yet the high court has considered foreign policy implications before.
In the most celebrated American case of the twentieth century, Brown v. Board of Education, the Justices were probably influenced by a government brief explaining how racial segregation in the southern United States undermined American efforts to compete with the Soviet Union for the hearts and minds of people in developing countries.
By holding that American apartheid violated the constitutional command of "equal protection of the laws," the court struck a blow for justice at home and American strategic interests abroad.
To be sure, the Brown precedent is not entirely analogous, for there the Supreme Court gave weight to foreign policy considerations in just the way that the federal executive had urged.
In the Guantanamo Bay case, by contrast, the Bush Administration argued that a ruling for the detainees would undermine the war effort by diverting manpower and material from the battlefield to the courtroom.
But the majority opinion of Justice John Paul Stevens paid little heed to the Administration's parade of horribles.
A decorated World War II veteran, Justice Stevens may well have thought that he was at least as qualified as the civilians in the Bush Justice Department to forecast the impact of the court's ruling on military efficiency.
Or perhaps the Justices were simply reacting to the Administration's constant overreaching.
Yes, the existence of religious fanatics eager to kill large numbers of innocent American civilians warrants strong measures in response.
But the Supreme Court's rulings affirm the fundamental principle that even grave dangers do not warrant the sort of blanket deference to which the Bush Administration believes it is entitled whenever it utters the words "war" and "terrorism."
One of the more surreal sessions at this year’s World Economic Forum in Davos had oil industry experts explaining how the melting of the polar ice cap – which is occurring faster than anyone anticipated ­– represents not only a problem, but also an opportunity: vast amounts of oil may now be accessible.
Similarly, these experts concede that the fact that the United States has not signed the Law of the Sea, the international convention determining who has access to offshore oil and other maritime mineral rights, presents a risk of international conflict.
But they also point to the upside: the oil industry, in its never-ending search for more reserves, need not beg Congress for the right to despoil Alaska.
President George W. Bush has an uncanny ability not to see the big message.
For years, it has become increasingly clear that much is amiss with his energy policy.
Scripted by the oil industry, even members of his own party referred to an earlier energy bill as one that “left no lobbyist behind.”
While praising the virtues of the free market, Bush has been only too willing to give huge handouts to the energy industry, even as the country faces soaring deficits.
There is a market failure when it comes to energy, but government intervention should run in precisely the opposite direction from what the Bush administration has proposed.
The fact that Americans do not pay the full price for the pollution – especially enormous contributions to greenhouse gases – that results from their profligate energy use means that energy is under-priced, in turn sustaining excessive consumption.
The government needs to encourage conservation, and intervening in the price system ­­– namely, through taxes on energy – is an efficient way to do it.
But, rather than encouraging conservation, Bush has pursued a policy of “drain America first,” leaving America more dependent on external oil in the future.
Never mind that high demand drives up oil prices, creating a windfall for many in the Middle East who are not among America’s friends.
Now, more than four years after the terrorist attacks of September 2001, Bush appears to have finally woken up to the reality of America’s increasing dependence; with soaring oil prices, it was hard for him not to note the consequences.
But, again, his administration’s faltering moves will almost surely make matters worse in the immediate future.
Bush still refuses to do anything about conservation, and he has put very little money behind his continuing prayer than technology will save us.
What, then, to make of Bush’s recent declaration of a commitment to make America 75% free of dependence on Middle East oil within 25 years.
For investors, the message is clear: do not invest more in developing reserves in the Middle East, which is by far the lowest-cost source of oil in the world.
But, without new investment in developing Middle East reserves, unbridled growth of energy consumption in the US, China, and elsewhere implies that demand will outpace supply.
If that were not enough, Bush’s threat of sanctions against Iran poses the risks of interruptions of supplies from one of the world’s largest producers.
With world oil production close to full capacity and prices already more than double their pre-Iraq War level, this portends still higher prices, and still higher profits for the oil industry – the only clear winner in Bush’s Middle East policy.
To be sure, one shouldn’t begrudge Bush for having at last recognized that there is a problem.
But, as always, a closer look at what he is proposing suggests another sleight of hand by his administration.
Aside from refusing to recognize the importance of global warming, encourage conservation, or devote enough funds to research to make a real difference, Bush’s grandiose promise of a reduction of dependence on Middle East oil means less than it appears.
With only 20% of US oil coming from the Middle East, his goal could be achieved by a modest shift of sourcing elsewhere.
But surely, one would think, the Bush administration must realize that oil trades on a global market.
Even if America were 100% independent of Middle East oil, a reduction in supply of Middle East oil could have devastating effects on the world price – and on the American economy.
As is too often the case with the Bush administration, there is no flattering explanation of official policy.
Is Bush playing politics by pandering to anti-Arab and anti-Iranian sentiment in America?
Or is this just another example of incompetence and muddle?
From what we have seen over the past five years, the correct answer probably contains more than a little bad faith and sheer ineptitude.
Fifteen years ago, the United States was in the midst of what you could call its “Age of Diminished Expectations.”
Productivity gains had stalled, energy prices were high, the backlog of potential technologies that originated in the Great Depression had been exhausted, and waning benefits from economies of scale led nearly every economist to project that economic growth would be slower in the future than it had been in the past.
With productivity growth stagnating for almost two decades, it made sense back then to argue that the US government’s social-insurance commitments (Social Security, Medicare, and Medicaid) were excessive and so had to be scaled back.
That was then, this is now.
The intervening years have seen an explosion of technological innovation that has carried America’s general productivity growth back up to its pre-slowdown levels.
Indeed, today the US economy is standing on the brink of biotechnological and, perhaps, nanotechnological revolutions of vast scale and scope.
Yet the same calls to scale back America’s social commitments are heard.
Social Security’s actuaries may not have fully recognized the impact of today’s technological revolutions, but they have markedly boosted the scale of the system that the US government can afford.
Fifteen years ago, the consensus was that America's Social Security System was in huge trouble, that it needed the equivalent of an engine rebuild.
Today its problems look, as the Brookings Institution economist Peter Orszag says, much more like the equivalent of a slow tire leak: you have to fix it eventually, but it isn’t very hard to do and repair it isn’t terribly urgent.
So why is the Bush administration spending time and energy proposing radical changes to the Social Security System as its signature domestic policy initiative – indeed, as virtually its only policy initiative?
Everyone who worries about America’s weak fiscal position puts Social Security’s relatively small funding imbalance far down the list of priorities.
The highest priority problem is the overall budget’s medium-run outlook, as the Bush tax cuts have opened Reagan-size deficits that threaten to cripple US economic growth.
The second highest priority problem is figuring out what to do in the long term with Medicare and Medicaid.
America must decide the size of its public health programs and how to finance them.
In reality, this is more of an opportunity than a problem: if we did not expect that doctors and nurses will be able to do marvelous things in a generation or two that they cannot do now, we would not be projecting serious fiscal deficits arising from the health programs.
The third most serious problem is to put the US government’s General Fund budget on a sustainable basis, so that the non-Social Security government can finance itself and meet its commitments after the date – around 2020 – when it can no longer borrow from the Social Security Trust Fund.
The bottom line is that Social Security’s long-term funding difficulty, while real, is projected to be much smaller and much further in the future than any of the nearer, larger, and more significant fiscal problems currently facing the US government.
If Social Security is a slow tire leak, then the post-2020 General Fund is an urgent brake job, Medicare and Medicaid are a melted transmission, and the budget deficit is the equivalent of having just crashed into a tree.
What kind of driver, owning a car that has just crashed into a tree, has a burned-out transmission, and needs a brake job, says, “The most important thing is to fix this slow leak in the right rear tire?”
George W. Bush is that type of driver.
There are three theories as to why the Bush administration is focusing on Social Security.
The first is simple incompetence: Bush and his inner circle simply do not understand the magnitude and importance of the federal government’s other fiscal problems.
The second is ideology.
For some reason Bush and his people think it is important to undermine the successes of the New Deal institutions established under Franklin Roosevelt.
The third reason is bureaucratic capture: just as the principal aim of Bush’s Medicare Drug Benefit bill of 2003 was to boost pharmaceutical company profits, so the Bush administration’s Social Security proposal will most likely be tailored to the interests of Wall Street.
I don’t see any other, more pressing, reforms – such as raising income taxes to pay for national security – gaining any traction in the Bush regime.
If I had to bet on a cause, I would put my money on sheer incompetence.
After all, that seems to be the common denominator of every policy controlled by his White House.
PARIS – During a visit to the Middle East, Secretary of Defense Robert Gates warned that enemies of the United States should not use the power vacuum there to try to alter the status quo or to undermine the new American president’s objectives.
But the major challenge in this respect is now coming, ironically enough, from America’s main ally in the region, Israel.
Hardliners in Israel naturally regret the end of the Bush administration, for they know that, even if President Barack Obama does not dramatically change US policy toward Israel once he assumes power, he will not repeat Bush’s unconditional support.
Israeli hardliners saw the “war on terror” and the war in Iraq as their wars, supported Bush’s war-like rhetoric and isolation of Iran, and considered the neo-conservatives their ideological kin.
In particular, they shared the neo-cons’ conviction that military intervention is a legitimate and effective way of achieving political change.
This is what the Israeli government tried to achieve in Lebanon by “smashing Hezbollah” in 2006.
Now it is trying to do the same in Gaza.
In response to Hamas rockets, Israel is now using disproportionate force, just as it did in Lebanon.
The result will probably be the same: at the end of the campaign, Hamas will have increased its popularity in Palestine and in the Arab world.
Indeed, the current military operation follows Israel’s two-year blockade of Gaza, which was supposed to have damaged Hamas, but failed to do so.
It is likely that Obama will consider a Palestinian state to be in America’s fundamental interest.
He will see it as a precondition for altering perceptions of the US in the Arab and Muslim worlds, since restoring America’s credibility will be a major objective of the incoming administration.
Israeli hardliners cannot be sure that, at the end of the day, Obama will not find it necessary to change policies toward Israel in order to achieve this objective, for he considers it to be a strategic concern.
They also know, of course, that any serious engagement with the Palestinian question must imply engaging Hamas in the search for a two-state solution.
The Israeli government is, in short, using the Bush administration’s dying days to implement its military-first policy.
At the same time, it is trying to create a situation that will, in effect, make it more difficult for the new president to achieve his policies in the region.
News reports show that revulsion is spreading through the Arab world, where American and Israeli flags are burned side-by-side.
This war, therefore, will simply make it more difficult to engage with those countries at the very moment such talks are absolutely necessary.
One reason for international suspicion of Hamas has been the support that it receives from Iran.
Obama has vowed to change American policy toward Iran, opening diplomatic channels rather than merely issuing military threats.
Such a change would make it easier to end the isolation of Hamas as well.
America’s renewed engagement with Iran is clearly a policy that will have a far-reaching impact in the Middle East.
Although that strategic change in US policy is also in Israel’s best interests, most Israelis will not see it that way.
An American dialogue with Iran will be a serious blow to the interests of Israeli hardliners, and some of them dream of making it impossible.
Constraining American policy may, therefore, be one of the motivations behind Israel’s incursion into Gaza.
Yet it is a grave challenge to international peace and could spread instability throughout the region.
Were that to occur, Obama’s planned rapprochement with Iran would be strangled in the cradle.
In the days before Obama takes office, while a power vacuum persists in the US, the European Union has a unique role to play in international initiatives to end the violence and the unfolding humanitarian crisis.
For the EU to succeed, it must pursue the policy launched by the French Presidency, giving priority to stopping the war and distancing itself from Israel’s disproportionate use of force.
Negotiating a ceasefire between Israel and Hamas could be the first step toward a permanent end to hostilities and to the blockade of Gaza.
It could, in effect, pave the way for the new Obama administration to convene an international conference to implement the two-state solution for Palestine, which should follow the ceasefire.
Such initiatives should not become bogged down in tortuous negotiations, but should focus on implementing the basic principles for a two-state solution, along the lines proposed by the Clinton administration before it left office eight years ago.
Hamas has already engaged in ceasefire negotiations and should now be brought fully into the peace process, alongside Fatah, but it will, of course, have to abandon its own strategy of force, as expressed through the rockets it has rained down on Israel.
It is a policy that has proved to be ineffective, and that is illegal under international law because it targets Israeli civilians.
Israel, for its part, needs to recognize that, if it wants to act in ways that are consistent with its own democratic values, it must abandon its strategy of violence and disrespect for the basic human rights of the Palestinians, as well as the idea of “Great Israel.”
In short, it must accept a Palestinian state, through deeds as well as words.
Until this happens, dangerous days lie ahead until Obama’s inauguration, and the international community will need strong, level-headed politicians to see it through.
That a summit in Damascus of the Middle East’s “axis of evil” – Iran, Hezbollah, Syria, and Hamas – was convened immediately following President George W. Bush’s call for a conference of “moderates” to promote an Israeli-Palestinian peace demonstrates once again how intertwined the region’s problems are.
The Damascus meeting reflects Iran’s view of Israeli-Arab peace as a major strategic threat, because it would condemn it to isolation in a hostile Arab environment free of its conflict with Israel.
The Iranians also sought the meeting to forge an alliance against a possible US attack on their country’s nuclear installations.
America has always known that the Middle East’s problems are interconnected, but for years it got its priorities wrong, because it failed to see that if there was an Archimedean point to the Middle East problem, it was to be found in the Palestinian issue, not the “War on Terror,” Iraq, or the need for Arab democracy.
It took Bush six years of wrongheaded policies to finally admit that “Iraq is not the only pivotal matter in the Middle East.”
Bush’s initiative is a last-ditch effort to salvage America’s position in a region where it is on the defensive on all fronts.
It is especially ironic that, in stark contrast to his own rhetoric, Bush’s call for a Middle East peace conference is a call to wage war against the party, Hamas, that won a democratic election, and to make peace with the loser, Fatah.
Nevertheless, Bush’s initiative is not devoid of virtue.
He has finally acknowledged the failure of the “road map,” and hence the need to skip interim stages and move directly to a final settlement between Israelis and Palestinians.
Moreover, both he and Secretary of State Condoleezza Rice were unusually blunt in warning Israel that its future does not lie in “continued occupation of the West Bank.”
Bush also came as close as he could to endorsing former President Bill Clinton’s peace plan by affirming that “the borders of the past, the realities of the present, and agreed changes” will define his two-state solution.
But Bush’s strategy suffers from serious inconsistencies.
The conference ground rules exclude radical forces – Syria and Hamas – thus encouraging them to persist in their role as spoilers.
It is a fantasy to believe that peace can be concluded without the radicals’ participation.
As long as Hamas and Syria are left out of the United States-led peace process, they are condemned to Iran’s orbit.
The Saudis certainly have an interest in supporting this last ditch American attempt for an Israeli-Palestinian peace, especially now that, for the first time ever, Israel has refrained from opposing an arms deal between the US and Saudi Arabia. The common fear of Iran is a major consideration here.
However, Saudi Arabia’s willingness to participate in the conference might come with a price too high for Israel to pay: an endorsement of the Saudi peace initiative.
This is the reason Secretary of State Condoleezza Rice was cautious in her reaction to the Saudis’ ambiguous acceptance of their invitation to attend the conference.
Bush was right to call on friendly Arab states to contribute to an Israeli-Palestinian peace.
But how much leverage can he apply when they are so badly needed for his “War on Terror” and for containing Iran?
Though certainly a welcome new idea, Bush’s call for Egypt and Jordan to replace Israel as the gateway for Palestinian exports is most likely to be resisted.
For these “moderate” American allies, peace is about Israeli concessions, not about pulling Israel’s chestnuts out of the fire, certainly as long as it refuses to endorse the Arab peace plan.
The current American initiative sounds reasonable, but it is essentially unrealistic.
Tony Blair, the new envoy of the Quartet (the US, the European Union, the United Nations, and Russia), has called for a “conference with substance.”
But Israel will be required to engage in peace talks only if the Palestinians crack down on terrorism – that is, risk another Fatah-Hamas civil war – and eliminate corruption.
Such a sequence – and a conference whose harmless aim is “to review progress toward building Palestinian institutions, look for ways to support further reforms, and support the effort going on between the parties” – fits perfectly with the Israeli view.
But Palestinian militias have shown time and again that they will not give up the armed struggle before they see a Palestinian state along the lines of the 1967 borders, with Arab Jerusalem as its capital.
This is the fundamental pitfall of a strategy based on driving a wedge between Palestinian President Mahmoud Abbas’s “moderates” and Hamas’s “extremists.”
If Abbas is to prevail, it will not be through “gestures” or a process focusing on “institution building,” however important these may be.
Nothing less than a full-fledged peace agreement that meets the fundamental aspirations of Palestinian nationalism is likely to give him the popular legitimacy needed to confront the radicals.
Many around the world are surprised at how little attention the economy is receiving in President Bush's re-election campaign.
But I am not surprised: if I were President Bush, the last thing I would want to talk about is the economy.
Yet many people look at America's economy, even over these past three and half years, with some envy.
After all, annual economic growth - at an average rate of 2.5% - may have been markedly slower than during the Clinton years, but it still looks strong compared to Europe's anemic 1% growth.
But these statistics mask a glaring fact: the average American family is worse off than it was three and half years ago.
Median real income has fallen by over $1,500 in real terms, with American families being squeezed as wages lag behind inflation and key household expenses soar.
In short, all that growth benefited only those at the top of the income distribution, the same group that had done so well over the previous thirty years and that benefited most from Bush's tax cut.
For example, some 45 million Americans today have no health insurance, up by 5.2 million from 2000.
Families lucky enough to have health insurance face annual premiums that have nearly doubled, to $7,500.
American families also face increasing job insecurity.
This is the first time since the early 1930's that there has been a net loss of jobs over the span of an entire presidential administration.
Bush supporters rightly ask: is Bush really to blame for this?
Wasn't the recession already beginning when he took office?
The resounding answer is that Bush is to blame.
Every president inherits a legacy.
The economy was entering a downturn when Bush took office, but Clinton also left a huge budget surplus - 2% of GDP ­­- a pot of money with which to finance a robust recovery.
But Bush squandered that surplus, converting it into a deficit of 5% of GDP through tax cuts for the rich.
The productivity growth that was sustained through the downturn presented both an opportunity and a challenge.
The opportunity: if the economy was well managed, the incomes of Americans could continue to rise as they had done in the 1990's.
The challenge: to manage the economy so that growth would be robust enough to create the new jobs required by new entrants to the labor force.
Bush failed the challenge, and America lost the opportunity because of his wrong choices .
True, the economy was stimulated a little bit by Bush's tax cuts; it was probably stronger in the short run (though arguably not in the long run) than it would have been had there been no tax cuts.
But there were other policies that would have provided far more stimulus at far less cost.
Bush's objective, however, was not to maintain the strength of the economy; it was to push forward a tax agenda that shifted the burden away from those who could best afford to bear it.
Bush's failed policies have not only cost the economy dearly; they have left the economy in a far weaker position going forward.
The non-partisan Congressional Budget Office agrees that even without Bush's new expenditure initiatives and tax proposals, costing trillions of dollars, the deficit will not be eliminated in the foreseeable future - or even cut in half, as Bush has promised.
Expenditures on which America's future economic health depends - on infrastructure, education, health, and technology - will be crowded out, jeopardizing long-term growth.
Because fiscal policy did not stimulate the economy, a greater burden was placed on monetary policy.
Lower interest rates worked (a little), but for the most part by encouraging households to refinance their mortgages, not by stimulating investment.
The increased indebtedness of households is already leading to higher bankruptcy rates, and will likely dampen the recovery.
National debt, too, has risen sharply.
The huge trade deficit provides the spectacle of the world's richest country borrowing almost two billion dollars a day from abroad, contributing to the weak dollar and representing a major source of global uncertainty.
There might be some hope for the future if Bush owned up to his mistakes and changed course.
But no: Bush refuses to take responsibility for the economy, just as his administration fails to take responsibility for its failures in Iraq.
In 2003, having seen that its tax cuts for the rich had failed to stimulate the economy as promised, the administration refused to revise its strategies, but instead just prescribed more of the same medicine.
It now promises to make those tax cuts permanent.
The real risk is that this is one promise that Bush, if re-elected, will try to keep.
At the end of August, I joined nine other American Nobel Prize winners in economics in signing an open letter to the American public.
It is hard to get any two economists - let alone two Nobel Prize winners - to agree on anything.
But in this case our concerns were so grave as to overcome any disagreements.
We wrote: "President Bush and his administration have embarked on a reckless and extreme course that endangers the long-term economic health of our nation…. The differences between President Bush and John Kerry with respect to leadership on the economy are wider than in any other Presidential election in our experience.
President Bush believes that tax cuts benefiting the most wealthy Americans are the answer to almost every economic problem."
Here, as elsewhere, Bush is dead wrong, and too dogmatic to admit it.
George W. Bush’s economic policies have been based on an extraordinarily reckless gamble that reflects a political coalition of two major forces: the super-rich and evangelical Christians.
As those policies fail, global financial markets are reacting negatively, adding uncertainty to the world economy, and there is little relief in sight, because America is entering a period of prolonged political infighting and stalemate.
The super-rich had one over-riding objective in joining the Bush coalition: tax cuts that overwhelmingly benefited the wealthiest households.
Evangelicals were brought in on the basis of so-called “family values,” meaning opposition to abortion and gay marriage, and promises of active government support for religious activities, including direct payments to religious groups for social services that they provide locally and internationally.
The Bush team believed that they would eventually balance the tax cuts for the rich with reductions in government spending, but they never explained this to the public.
Instead, for four years they pretended that budget deficits were of little concern.
Only after being re-elected did they begin to explain that large budget deficits, caused mainly by lower tax revenues, would require sharp cuts in social security, health care spending, and other areas.
But the majority of Americans, having supported the tax cuts in Bush’s first term because it gave them a little extra cash, do not support the attack on basic government services that has followed.
This opposition extends to Christian evangelicals voters, who tend to live in working-class and middle-class households that depend on many kinds of government social services.
Despite the avowedly “free-market” beliefs of many Christian fundamentalists, as voters they support government-financed pensions, health care, and other public services.
Bush’s tax cutting was irresponsible from the start, but became much more so after September 11, 2001.
The Bush administration raised military spending sharply as it went to war in Afghanistan and Iraq, and as it increased spending on national security at home, without ever explaining to the American people how this would be financed.
The military-plus-security budget soared by more than 2% of GNP, while tax revenues fell by much more.
At the same time, Bush supported expenditure increases for popular items like education and prescription drug benefits, but paid for these services by borrowing the money rather than ensuring sufficient tax revenues.
No sooner did this strategy pay off with a narrow re-election victory – one that strengthened Republican control of Congress – than the dark realities of Bush’s fiscal recklessness started to be recognized.
The annual US budget deficit reached 5% of GNP, with an enormous part of the gap financed each year by Asian central banks, which now hold about $2 trillion in claims against America.
The problem is that Bush’s reckless gamble has now built up considerable political momentum.
As soon as he was re-elected, Bush started to propose cuts in popular government programs, but his own party is rejecting those cuts.
With the Republican-controlled Congress seeking to make the tax cuts for the rich permanent, the world is beginning to realize that America’s budget deficits are now entrenched, with no end in sight.
Because America’s economy is so large, and the dollar so central to global finance, chronic US budget deficits mean huge global repercussions.
The dollar is weakening, as financial markets understand that the US will need to borrow huge sums from abroad for years to come.
More ominously, the willingness of foreign central banks to lend to the US also looks likely to end.
After all, why should the central banks of China, Japan, South Korea, and other Asian countries accumulate vast holdings of US Treasury bills if the dollar is likely to lose value in the years ahead?
In a bizarre, but not unexpected way, America is lashing out at others for its problems.
Huge tax cuts and rising military spending have fueled an enormous rise in imports, and therefore a yawning trade deficit now accompanies America’s weak fiscal position.
But US politicians are blaming China and other countries for “unfair trade,” even threatening them with sanctions.
This response to homegrown problems plays well with voters, but it is ridiculous and ignorant, especially since the US has been depending on China to help finance the fiscal deficits.
In essence, the US is lashing out at its own banker, even as it asks the banker for yet more loans!
When Bush asked for spending cuts at the beginning of the year – including a social security reform that includes cuts in future benefits – world financiers expected that Bush would get his way, or most of it.
Little did they appreciate that American voters, having never actually supported spending cuts, would resist.
As that reality sinks in, economic prospects darken.
Foreigners will become less enthusiastic about continued lending to the US, weakening the dollar further, forcing up US interest rates, and threatening to undermine America’s stock market and consumer spending.
But as the storm clouds gather in the coming year, the political coalition that put Bush in power will stifle progress in undoing the fiscal mess.
Bush’s gamble was a loser from the start, generating costly results – mainly for the US, but for the rest of the world, too – for years to come.
Paris – The top-secret memoranda released by the Obama administration concerning torture practices in CIA prisons shed new light on a fundamental question: how is it that people acting in the name of the United States government could so easily accept the idea of torturing the detainees in their charge?
The newly published documents do not disclose the very facts of torture, which were already well known by whomever wanted to know them.
But they do reveal a great deal of information about how the torture sessions unfolded and how the agents involved perceived them.
What is most striking is the discovery of niggling little rules, outlined in CIA manuals and co-opted by the government’s legal executives.
One would have thought that torture was the result of blunders or unintentional excesses committed on the spur of the moment.
On the contrary, these memos make clear that torture was a tactic formulated in minute detail.
In the Bush administration’s “guidelines,” torture can be divided into three categories, of varying levels of intensity: “baseline” (nudity, dietary manipulation, sleep deprivation); “corrective” (hitting); and “coercive” (water-dousing, box confinement, water-boarding).
For a facial slap, the interrogator was supposed to hit with fingers slightly spread, at equal length between the tip of the chin and the bottom of the corresponding earlobe.
Dousing a naked detainee with water was to last 20 minutes if the water’s temperature measured 5 °C, 40 minutes at 10 °C, and up to 60 minutes at 15 °C. Sleep deprivation could not exceed 180 hours, but could start over again after eight hours rest.
Water immersion in a tub could last up to 12 seconds, no more than two hours a day, for up to thirty days in a row.
Waterboarding could last 40 seconds at most, though two prisoners were subjected to this torment a combined total of 286 times in a single month.
Confinement in a small box could not exceed two hours, but if the prisoner could stand in the box, it could continue up to eight hours at a time, 18 hours a day.
If an insect was introduced into the box, rules governed that, too.
How the torturers were trained is also disclosed.
Most methods were reverse-engineered from the training given to US soldiers preparing to face “long and extreme” situations (which somehow enabled executives to conclude that these ordeals are perfectly bearable).
In other words, the torturers had been tortured themselves.
An intense crash course lasting four weeks followed, enough to instruct them in their new jobs.
The Bush lawyers were the torturers’ necessary partners, whose work was intended to ensure legal impunity.
This was also a novelty: torture does not appear as a breach of a common standard, unfortunate but justifiable.
Instead, it has a legal standard.
Here, lawyers fell back on another series of techniques.
In order to circumvent the law, interrogation had to be conducted outside the US, even if that place was an overseas American military base.
The legal definition of torture implies the intentional infliction of severe suffering.
Torturers are thus advised to deny such an intention.
As a result, the goal of a facial slap is not to inflict physical pain, but to induce surprise and humiliation.
The purpose of confinement in a box is not to disorient someone, but to give the detainee a feeling of discomfort.
The torturer must always emphasize his “good faith,” “honest beliefs,” and the reasonable premise for them.
So euphemisms were systematically used: “enhanced techniques” for torture, “interrogation expert” for torturer.
Leaving material imprints is contra-indicated.
To that end, mental damage is preferable to physical injury.
Any video recordings of these sessions, not surprisingly, would be destroyed afterwards.
Various professional groups were involved with torture practices.
Thus, the contagion went well beyond the torturers’ limited circle.
Besides the lawyers legitimating the deeds, psychologists, psychiatrists, doctors (whose presence was mandatory at any session), and scholars also regularly provided moral, legal, or philosophical justifications.
And, while males inflicted torture, degradation in the presence of women enhanced the humiliation.
Who is to be held legally liable for this perversion of the law and basic moral principles?
The volunteer who carries out the task of torture is less liable than the high-ranking civil servant who justified and nurtured it.
And the latter is less liable than the political decision-maker who asked for it.
Friendly foreign governments, especially in Europe, can also be held responsible: although they knew about the torture, and took advantage of the information thus obtained, at no point have they expressed the slightest protest, or even signal their disapproval.
Their silence was tantamount to consent.
Should we therefore prosecute them?
The best democratic punishment for politicians is not to re-elect them.
As for unelected collaborators and enablers, we can hope that they will be sanctioned by their peers: who would like to study with a professor who advocated torture?
Who wants justice done by a judge who authorized brutality?
Who wants to be treated by a doctor who oversaw it?
If we are to understand why some Americans accepted administering torture so easily, we need not look for some ancestral hatred or fear of Muslims and Arabs.
No, the cause is far worse.
The memos that the Obama administration has disclosed teach us that anyone who complies with seemingly noble principles dictated by a “sense of duty” or by the necessary “defense of the homeland,” or who is urged by a basic fear for his own life and welfare, or the lives and welfare of his kin, can become a torturer.
Though triggered by the need to devise an exit strategy from the Iraqi quagmire, the Iraq Study Group’s grim report is a devastating indictment of the Bush administration’s entire foreign policy.
The report challenges the core principles of a faith-driven administration and of a president whose political gospel led him to a sharp departure from the culture of conflict resolution in favor of a crusade based on raw power.
A war that cannot be ended is sometimes worse than a war that is lost.
Therefore, the Iraq report is more than a plan to rescue Iraq; it is a road map for extricating America from the mayhem of an unwinnable war.
However much the study group shunned recommendations for a precipitous withdrawal, and avoided strict timetables for disengagement, their report is not only an unequivocal repudiation of Bush’s “stay the course” obsession, but also a counsel to cut and run.
Indeed, there is no realistic chance that the Iraqi army and police will be able to take over combat responsibilities and effective policing any time soon.
The entire security apparatus in Iraq is corrupt and infiltrated by insurgents.
Nor is it at all clear to what degree the Iraqis retain a stake in the idea of a united Iraqi state worth fighting for.
The report practically calls for ending all support to the Iraqi government if it fails to assume its responsibilities.
None of the Middle East’s problems has a military solution, and none can be solved through unilateral action.
The report is therefore right to challenge Bush’s insistence on discarding both Iran and Syria as interlocutors for a more stable regional order.
Iran has the most leverage inside Iraq, and Syria has become a vital crossing point for weapons and insurgents into the Iraqi battlefield.
There is simply no way that Iraq can be stabilized without America moving from a policy of disengagement to one of engagement with these two major regional spoilers.
The report thus stands as a rebuke to Bush’s entire “axis of evil” philosophy.
It refuses to ascribe to Iran’s secretive state an ideological rigidity that might not exist.
Indeed, Iran has shown its ability to behave with startling pragmatism more than once, not least in its links to Israel and the United States during its war against Iraq in the 1980’s, and in its assistance to the Americans in the war against the Taliban in Afghanistan.
But it is not only Iraq that requires regional support groups to reach a modicum of stability.
All the problems of the Middle East – Iraq, the Arab-Israeli dispute, the need for political reforms, and Islamic terrorism – are interconnected.
The interconnectedness of the problems in the outer circle of the region and those pertaining to the Arab-Israeli conflict in the inner circle was shown by the first Bush administration, which, in October 1991, following the first Gulf War, organized a major international conference aimed at securing an Arab-Israeli peace.
Neither the Israeli government nor its intimate ally in the White House can be expected to applaud the Iraq Study Group’s call for a repetition of that logic, for it contradicts everything the Bush administration has championed.
The report’s recommendation for an international conference in the style of the Madrid peace conference is not only a timely indication of the linkage between the Israeli-Arab conflict and the region’s other troubles; it is also a long overdue reminder that bilateral negotiations between the parties can not produce an agreement.
That realization prompted the all-Arab peace initiative of 2002, which established the conditions for an Israeli-Arab comprehensive settlement.
Alas, however bipartisan the Iraq Study Group’s report may be, it is too much to expect that Bush will endorse all of its recommendations and admit the bankruptcy of his entire foreign policy.
In fact, Bush has already expressed his objection to unconditional direct talks with Iran and Syria.
Nor does he seem eager to open a rift with Israel by dragging its government to an international conference, the way his father did with Prime Minister Yitzhak Shamir in 1991.
Bush will find it especially difficult to change his policy with respect to Iran.
In order to ensure that the US is too harassed to be able to threaten it, Iran has consistently obstructed Bush’s mission of regional transformation.
The report urges the president to understand that the spoilers will not cease to be spoilers as a precondition of negotiations, but only as a result of them.
At stake is a painful choice for Bush: to lead America into coexistence with what he considers a repugnant Islamic theocracy.
But Bush does not have many choices if he is to save his presidency from going down in history as an utter failure.
His was a suicidal brand of statecraft from the outset.
If he does not change course in Iraq and beyond, his presidency might draw the curtain on long decades of American hegemony in the Middle East – to the detriment of its closest allies in the region.
The Bush administration is once again committing a major policy blunder in the Middle East by actively supporting the Israeli government in its refusal to recognize a Palestinian unity government that includes Hamas.
This precludes any progress toward a peace settlement at a time when progress on the Palestinian problem could help avert conflagration in the greater Middle East.
The US and Israel seek to deal only with the president of the Palestinian Authority, Mahmoud Abbas.
They hope that new elections would deny Hamas the majority it now has in the Palestinian Legislative Council.
This is a hopeless strategy, because Hamas would boycott early elections, and even if their outcome would result in Hamas’s exclusion from the government, no peace agreement would hold without Hamas support.
Meanwhile, Saudi Arabia is pursing a different path.
In a February summit in Mecca between Abbas and Hamas leader Khaled Mashaal, the Saudi government worked out an agreement between Hamas and Fatah, which have been clashing violently, to form a national unity government.
According to the Mecca accord, Hamas agreed “to respect international resolutions and the agreements [with Israel] signed by the Palestinian Liberation Organization,” including the Oslo Accords.
The Saudis view this accord as the prelude to the offer of a peace settlement with Israel, to be guaranteed by Saudi Arabia and other Arab countries.
But no progress is possible as long as the Bush administration and Ehud Olmert’s Israeli government persist in refusing to recognize a unity government that includes Hamas.
Many of the causes of the current impasse go back to Israeli Prime Minister Ariel Sharon’s decision to withdraw from the Gaza Strip unilaterally, without negotiating with the then-Fatah-controlled Palestinian Authority.
This strengthened Hamas, contributing to Hamas’s electoral victory.
Then Israel, with strong US backing, refused to recognize the democratically elected Hamas government and withheld payment of the millions in taxes collected by the Israelis on its behalf.
This caused economic hardship and undermined the government’s ability to function.
But it did not reduce support for Hamas among Palestinians, and it reinforced the position of Islamic and other extremists who oppose negotiations with Israel.
The situation deteriorated to the point where Palestine no longer had an authority with whom Israel could negotiate.
This is a blunder, because Hamas is not monolithic.
Its inner structure is little known to outsiders, but, according to some reports, it has a military wing, largely directed from Damascus and beholden to its Syrian and Iranian sponsors, and a political wing that is more responsive to the needs of the Palestinian population that elected it.
If Israel had accepted the results of the election, that might have strengthened the more moderate political wing.
Unfortunately, the ideology of the “war on terror” does not permit such subtle distinctions.
Nevertheless, subsequent events provided some ground for believing that Hamas has been divided between its different tendencies.
No sooner had Hamas agreed to enter into a government of national unity than the military wing engineered the kidnapping of an Israeli soldier, which prevented such a government from being formed by provoking a heavy-handed Israeli military response.
Hezbollah then used the opportunity to stage an incursion from Lebanon, kidnapping several more Israeli soldiers.
Despite a disproportionate response by Israel, Hezbollah was able to stand its ground, gaining the admiration of the Arab masses, whether Sunni or Shia.
It was this dangerous state of affairs —including the breakdown of government
in Palestine and fighting between Fatah and Hamas—that prompted the Saudi initiative.
Defenders of the current policy argue that Israel cannot afford to negotiate from a position of weakness. But Israel’s position is unlikely to improve as long as it pursues its current course.
Military escalation – not just an eye for an eye but roughly ten Palestinian lives for every Israeli one – has reached its limit. After the Israel Defense Forces’ retaliation against Lebanon’s road system, airport, and other infrastructure one must wonder what could be the next step for the Israeli forces.
Iran poses a more potent danger to Israel than either Hamas or Hezbollah, which are Iran’s clients.
There is the growing danger of a regional conflagration in which Israel and the US could well be on the losing side.
With the ability of Hezbollah to withstand the Israeli onslaught and the rise of Iran as a prospective nuclear power, Israel’s existence is more endangered than at any time since its birth.
Both Israel and the United States seem to be frozen in their unwillingness to negotiate with a Palestinian Authority that includes Hamas. The sticking point is Hamas’s unwillingness to recognize the existence of Israel; but that could be made a condition for an eventual settlement rather than a precondition for negotiations.
Merely demonstrating military superiority is not sufficient as a policy for dealing with the Palestinian problem.
There is now the chance for a political solution with Hamas brought on board by Saudi Arabia.
It would be tragic to miss out on that prospect because the Bush administration is mired in the ideology of the War on Terror.
President George W. Bush’s declaration of “mission accomplished” in Iraq five years ago was as hubristic as his current assessment that the “surge” has “delivered a major strategic victory in the broader war on terror” is a fantasy.
The Iraq adventure is not only the longest and most expensive war in America’s history – the Nobel laureate economist Joseph Stiglitz has advanced a staggering estimate of $3 trillion – but is also the least conclusive.
The war has pulverized Iraqi society, dissolving it into an ethno-sectarian patchwork. The “surge” will end sooner or later, and the Iraqis, crippled by violence and corruption, will still be incapable of uniting their polity, and, with their military still unable to take over from the Americans, jihadi and inter-ethnic violence is bound to erupt again.
As Iraqi Colonel Omar Ali, the Iraqi battalion commander in Mosul, the main focus of the insurgency today, recently put it, “Without the Americans, it would be impossible for us to control Iraq.”
Wars, as Winston Churchill defined them, are always “a catalogue of blunders.”
History’s judgment of the Iraq war will therefore certainly dwell more on whether it has accomplished its strategic objectives of “reconstructing” a highly dysfunctional Middle East in America’s democratic image and consolidating America’s hegemonic position in the region than on its price in blood and money.
Strategically, the war was an utter failure.
A clear case of imperial overstretch, the war strained America’s military, undermined the America’s moral standing worldwide and its reputation in the Middle East, severely threatened its economy, and showed to both friends and foes the limits of American power.
The most serious unintended consequence of the war is the emergence of a powerful Shia challenge to the West’s Sunni allies in the Middle East.
America’s destruction of Iraq as a regional power handed hegemony in the Persian Gulf – whose centrality to Western interests cannot be overstated – to Iran’s Shia Islamist regime on a silver platter.
On the rubble of Saddam Hussein’s dictatorship, the Americans helped create in Iraq the first Shia-dominated Arab state, which may well become subservient to Iran’s regional ambitions – a calamity of historic dimensions for America’s Sunni allies.
President Mahmoud Ahmedinejad’s recent state visit to Iraq conveyed to the Americans an unequivocal message: the prospects of the United States ever reaching a modicum of stability in Iraq have become dependent on Iran-aligned forces.
America’s difficulties in Iraq and beyond contributed decisively to Iran’s nuclear ambitions.
The Iranians now see themselves as immune from an American attack on their nuclear installations, for America’s troubles in Iraq and the growing opposition to the war in the US are a signal to them that America’s strategy of pre-emptive wars has failed.
But, however radical the Iranian regime might be, it is not suicidal.
Hence, the threat of a nuclear Iran might consist less in its propensity to start a nuclear war with Israel than in its capacity to project its regional power effectively.
A nuclear Iran might even threaten America’s capacity to project conventional military force in the Gulf in times of crisis.
Nor should the possibility be ruled out that Iran might be tempted to back its regional ambitions by supplying nuclear material to proxy terrorist groups.
If anything, America’s debacle in Iraq has only emboldened the challengers of the status quo in the region.
That has also been the result of Bush’s ill-conceived democracy crusade in the Arab world.
Bush discovered to his dismay that any exercise in Arab democracy is bound to usher in anti-Western Islamists, be it the Muslim Brotherhood in Egypt, Shia parties in Iraq, or Hamas in Palestine.
The US eventually had to abandon its fantasies about Western-style Arab democracy, but it ironically left the Iranians carrying the torch of democracy in the region.
After all, Iran was quick to recognize that free elections are the safest way to undermine the Middle East’s pro-American regimes.
The Iraq war also meant that America ignored the Israeli-Palestinian peace process.
The chances that the Bush administration might be able to rally America’s Sunni “moderate” allies in the region to help salvage an Israeli-Palestinian peace are now hostage to an Iranian-led regional axis that includes Hamas, Hezbollah, and Syria.
All are united in their rejection of a Pax Americana in the Middle East, and all have so far shown remarkable resilience in ignoring America’s pre-conditions for a dialogue.
America’s inability to inspire the peoples of the Middle East, all ruled by US-backed autocracies, is not exactly stunning news.
What is news is that American power might also be losing its ability to intimidate them.
Last November’s Congressional elections dealt President George W. Bush a sharp rebuff over his Iraq policy.
Shortly after the election, the Iraq Study Group offered a bipartisan formula for the gradual withdrawal of United States troops.
But Bush rejected this, and persists in speaking of victory in Iraq – though it is unclear what that now means.
Perhaps because Iraq will define his legacy, he has proven reluctant to let go at a point when his policy appears to be a disaster.
Now Bush will increase the number of American troops in Baghdad and Anbar Province and try to stabilize both the rising sectarian civil war and the Sunni insurgency.
He has removed generals John Abizaid and George Casey, who were skeptical of a troop “surge,” and moved Ambassador Zalmay Khalizad, who was supposed to negotiate a political agreement in Iraq.
A number of the Democratic lawmakers who control the new Congress disagree with this approach.
Some Democratic activists seek an immediate withdrawal and are pressing for Congress to cut off funding for the war, but that is unlikely.
Congress is reluctant to be portrayed as failing to support troops in the field; while they will criticize, they will not block Bush’s plan.
Bush has long claimed that the number of troops in Iraq was a military decision and that he simply followed the advice of his generals, but now this is clearly not the case.
Ironically, there may once have been a point at which a large increase in troops might have made a difference.
In April and May 2003, polls showed a majority of Iraqis welcoming the overthrow of Saddam Hussein.
But the Bush administration failed to control rioting, disbanded the Iraqi army, and allowed the security situation to deteriorate.
In such chaos, it was difficult to do the reconstruction and development work that could have made Iraqi lives better and attracted support.
It is not easy for a marine or soldier to construct a school or clinic when he is being fired upon, or for Iraqi moderates to risk their lives by being supportive when they have no protection against insurgents.
Many military professionals foresaw this problem.
US Army Chief of Staff Eric Shinseki warned that although it would be possible to win the war with the 160,000 troops that Secretary of Defense Donald Rumsfeld used, it would take double that number to win the peace.
But because Rumsfeld wanted to prove a point about transforming American military strategy, and his neo-conservative advisors had ideological blinders that distorted their appraisal of Iraqi reality, Shinseki’s advice was rejected.
Deputy Secretary of Defense Paul Wolfowitz testified to Congress that Shinseki’s estimate of the number of troops required was “wildly off the mark.”
In fact, it turned out that Rumsfeld and Wolfowitz were the ones wildly off the mark.
Now both are gone, and Bush is turning to troop increases.
Too little, too late.
Is there any reason to believe that an additional five brigades will succeed in stabilizing Baghdad now when similar efforts have failed in the past?
The new American operational commander in Iraq, Lt. General Raymond Odierno, says that the new efforts will be more evenhanded among Sunni and Shiite neighborhoods, and American troops will stay alongside Iraqi troops in areas that have been cleared.
He hopes that with a few months, he can then withdraw American troops to the periphery of Baghdad and leave the policing of the capital to Iraqi forces.
But this assumes that Iraqi forces are up to the task, and that Prime Minister Nouri al-Maliki’s government, which rests upon Shiite militia support, can play a competent and evenhanded role.
Bush administration officials argue that the new plan is “not an open-ended commitment: we are putting real, specific requirements and expectations on the Iraqi government.” Among the political benchmarks are provincial elections, enactment of an oil law that distributes oil wealth in a way that benefits the Sunnis, and reform of the de-Baathifcation policy, which has been so costly to those who worked in the Iraqi government under Saddam.
But it may be too late for political compromise, and the Maliki government may not be capable of a broad non-sectarian policy.
If Bush’s new military plan is a temporary step to buy time to move in the direction of the Iraq Study Group’s proposals of training Iraqi forces and gradually withdrawing American forces, there may be something to be said for it as one last chance, but only if it is accompanied by the diplomatic advice that the study group also suggested.
It is too late to create a democracy in Iraq.
At best, the overthrow of Saddam removed a threatening dictator, and substituted a tyranny of the majority for the tyranny of a minority.
But the price has been high in terms of Iraqi lives lost in sectarian fighting.
The goal now is regional stability.
Each of Iraq’s neighbors has its own interests, but none will benefit from chaotic violence there, which would increase Iran’s influence, encourage Kurdish separatism to the worry of Turkey, and support Sunni terrorist movements that could spill back into Jordan, Kuwait, Syria, and Saudi Arabia.
The US cannot leave Iraq precipitously, but neither can it solve the problem on its own.
Establishing a contact group of Iraq’s neighbors to help set rules of the road for stabilization and containment will be an important step.
Iraq is not susceptible to a military solution.
Only more politics and diplomacy can salvage US policy.
President George W. Bush's administration has, on any objective basis, been a frightening thing to behold.
Strident and self-absorbed by narrow partisanship, administration officials have actually betrayed the conservative ideological cause, dismantling the tried-and-tested institutional foundations of America's economic prosperity and global security.
Start with economic policy and the deliberate unbalancing of the US government's long-term finances.
The aim clearly has been to sharpen the financial crisis of the social-welfare state and bring about a permanent reduction in government wealth re-distribution.
But broken eggs do not necessarily make an omelet: Bush's massive (and still growing) fiscal deficits have stimulated nothing but jitters about a prolonged slowdown in capital formation, household consumption, and economic growth.
Fiscal policy is, of course, only the tip of the iceberg.
Korean steelworkers might well ask whatever happened to the Republican Party's historic commitment to free trade.
African farmers should wonder how it could be Bush--not some left-wing Democrat--who reversed the archconservative Newt Gingrich's proudest achievement: the partial reform of agricultural subsidies.
The security policy of the Bush administration has been worse than frightening; it has been, to borrow one of the president's most frequent utterances nowadays, terrifying.
At the moment, administration insiders are trying to convince elite journalists that Bush did not deceive outsiders about Saddam Hussein's nuclear weapons program.
They are hoping that Americans will forget all the cocksure predictions of a military walkover and cheering crowds lobbing flowers at US and British troops.
Ignore all the lame excuses about the difficulties of assessing conflicting intelligence.
No one in this supposedly conservative administration had ever heard of Machiavelli's 500-year-old warning not to trust exiles? "Such is their extreme desire to return to their homes," Machiavelli wrote, apropos of Ahmad Chalabi and the Iraqi National Congress, "that they naturally believe many things that are not true, and add many others on purpose; so that, with what they really believe and what they say they believe, they fill you with hopes..."
The most terrifying aspect of the Bush administration's foreign policy is the motivating theory of the world that underlies it.
The Bush administration's intellectual allies call the Clinton administration "naïve" for believing that international relations form a positive-sum game in which all sides can win.
They speak explicitly about America's interest in preserving its relative , not just absolute, economic power.
As the University of Chicago's Dan Drezner puts it, the logic of Bush's National Security Strategy is to "prevent other great powers from rising, in order to ensure the long-term growth of freedom, democracy, and prosperity."
But what does it mean to "prevent other great powers from rising"?
What could it possibly mean other than "try to keep China and India desperately poor for as long as possible"?
After all, when China and India close even half the income gap separating them from the industrial core of the world economy, the sheer size of their populations alone will guarantee that they become very great powers.
It is certainly not in the interest of China or India to remain poor.
But it is not in America's national interest, either.
The history of the late 19th and 20th centuries teaches us that there is something uniquely dangerous to world peace and political sanity during the two generations in which cultures pass from a poor, rural, and agricultural economy to a rich, urban, and industrial (or post-industrial) way of life.
The aggressive foreign policy pursued by Wilhelmine Germany, the perverse suffering inflicted on Russia by Lenin and Stalin, the terrors of Mao, the dictatorships of Mussolini and Franco, and the monstrous Nazi regime all occurred during this transition.
So is it really in the interest of the US to try to "prevent other great powers from rising?"
Shouldn't America's leaders be trying to shorten the period that other societies are vulnerable to the evils that made the twentieth century the bloodiest in the history of mankind?
Wouldn't the rest of us rather minimize than maximize the time we might be faced with the problem of containing a Hindu Nationalist India, a Wilhelmine China, or a Weimar Russia?
It is long past time for a complete change of personnel at all levels of the Bush administration.
The world cannot afford to have pseudo-conservatives at high levels of the US government who do not work for global peace and prosperity, but instead for a dangerously wrongheaded geopolitical strategy.
There are many potential replacements for these officials in the Republican Party--sensible, deliberative statesmen who view America's national interest as being the promotion of global economic development, multilateral cooperation, and a world in which the US leads with its principles rather than dominates with its military power.
Such officials staffed the first Bush administration.
Where are they now?
Six long years of failed Middle East policies have finally brought President George W. Bush to recognize that the alliance of moderates in the region that he covets can only be forged through an Arab-Israeli peace.
Indeed, only by effectively addressing the Israeli-Arab dispute can he possibly salvage America’s standing in the region.
But the round of peacemaking that America has recently embarked upon not only comes too late in the political life of a lame-duck president who has been defeated at home and abroad; it is also ill-conceived and unconvincing.
Secretary of State Condoleezza Rice’s adamant resistance to engage the Syrians is not exactly wise policy.
The stakes for a peaceful regional order are too high for Israel and the United States to persist in refusing to put Syrian President Bashar al-Assad’s current peace offensive to the test.
The bones of contention that wrecked previous attempts to reach an Israeli-Syrian peace have realistic solutions, as was shown by the back-channel peace talks recently held between an Israeli ex-official and a Syrian with close connections to the regime.
Nor is Rice’s insistence on sticking to the failed “road map” for an Israeli-Palestinian settlement promising.
Susceptible to procrastination and evasion by both sides, the road map was stillborn.
Almost four years after it was first launched, neither of the parties has managed to muster the political will necessary to implement its primary provisions.
Not even the bizarre idea, reserved for the second stage, of a Palestinian state with “temporary borders” is enticing for the Palestinians.
This Gordian knot needs to be cut, not untied.
The concept of interim agreements has now become utterly obsolete, if only because the parties are incapable of paying the political price inherent in an open-ended, piecemeal process.
Instead, what is called for is a sweeping solution to all the core issues.
We now stand at the end of the peace process as we have known it.
From now on, our options will be a violent and unilateral disengagement, such as the one that ushered in the current war in Gaza, and a comprehensive peace plan that will have to be annexed to the road map and validated by an international peace conference.
Only such “reverse engineering,” starting at the end and working backward – and legitimized and monitored by strict international mechanisms – might yet save the prospects for an Israeli/Palestinian peace from ruin.
As the launch of the peace process at the 1991 Madrid International Peace Conference demonstrated, the prospects for peace in the Middle East always needed a concerted international push to exploit windows of opportunity.
Wars in the Middle East, especially those , such as Israel’s recent war against Hezbollah, that ended inconclusively, have almost invariably created the conditions for major political breakthroughs, because they taught the warring parties the limits of power.
Trapped in a momentous struggle between the forces of peaceful change and those committed to Doomsday, the Middle East is once again calling for a major international effort at peacemaking.
The initiators of the 2002 Arab peace initiative likewise understood that a strictly bilateral approach might be inadequate, and instead called to regionalize the solution to the conflict.
Loss of mutual trust between the parties, and their total incapacity to take even the smallest step towards each other, let alone to observe their commitments without prodding by third parties, made (and still makes) an international framework for peace the only way out of the dangerous impasse.
The end of bilateralism stems also from the dysfunctional political systems of both Palestine and Israel.
Today, Palestinian President Mahmoud Abbas is gasping for political air under the smothering control of Hamas.
On her recent trip to Israel, Rice had to listen to four different peace plans from the prime minister, the foreign minister, the minister for strategic threats, and the defense minister.
For both Israelis and Palestinians, achieving internal peace might prove as formidable a challenge as establishing peace with each other.
Any reformed peace process is doomed if it is guided by a road map within which, on the core issues, the parties have diametrically opposed views.
But there is no need to reinvent the wheel, because the solution to the Arab-Israeli conflict is embodied in the main peace plans that are already on the table: the Clinton peace parameters, and the all-Arab peace initiative.
Fifteen years after the Madrid Conference began a formal peace process between Israelis and Palestinians, the parties are wiser as to what is inevitable if this tortuous process is to lead to a permanent settlement.
In 1991, they convened on a platform of “land for peace.”
But the Israelis never believed they would have to give back all the land, while the Arabs did not think they might have to offer “all the peace.”
Today, at long last, everyone knows what is meant by “land,” and everyone knows what is meant by “peace.”
President Bush has asked that Americans not “play politics” at this moment of terrible national disaster.
But asking hard questions of our nation’s leaders is exactly what democracy demands when the government’s response to Hurricane Katrina is widely viewed as “a national disgrace.”
Katrina came with at least two days’ warning, but authorities waited to issue an evacuation order.
There was no transportation for people without cars or money, facilities to house and care for refugees were insufficient, there were no forces in place to deliver desperately needed supplies or to secure order, and there was nowhere near the number of boats, helicopters, and other craft necessary to rescue the stranded.
Hampered by a National Guard with 40% of its people in Iraq, the pace of getting military personnel to the hardest hit areas was inordinately slow.
For four days, there was simply no clear center of command and control.
As a result, countless people suffered and died.
Much of this failure is the result of the Bush administration’s policies, which effectively eroded the capacities of the Federal Emergency Management Agency (FEMA), the government agency primarily responsible for dealing with disasters.
Obsessed with the war on terror as well as an ideology of privatizing the functions of government, the administration systematically sapped FEMA’s long-term ability to prevent disaster or at least cushion the blows when prevention is not possible.
FEMA was downsized and downgraded from a cabinet position, then placed under the Department of Homeland Security.
Its mission of disaster planning and preparation was dropped entirely, and its focus was altered to fight terrorists.
Its leadership had no experience in disaster management.
The past director was one of Bush’s Texas political cronies, and the current director’s qualifications include a stint as commissioner for judges and stewards with the International Arabian Horse Association, where he was asked to resign for “supervision failures.”
Since 2001, billions of dollars were shifted from disaster relief to homeland security and the war in Iraq.
Key disaster mitigation programs were slashed and federal funding for post-disaster relief was cut in half.
The Army Corps of Engineers’ budget for levee construction in New Orleans was gutted, including funds specifically aimed at the Southeast Louisiana Urban Flood Control Project.
Preventive measures to protect people and property were not carried out despite FEMA’s own conclusion in 2001 that a major hurricane hitting New Orleans was one of the three “likeliest, most catastrophic disasters facing this country.”
Believing FEMA to be an “oversized entitlement program” and that the “business of government is not to provide services,” Bush’s first FEMA director instituted new outsourcing requirements as part of a major privatization effort.
This provoked a brain drain as experienced FEMA personnel moved into the private sector
Privatization also left poorer states and poorer communities especially vulnerable.
As money dried up and federal programs were contracted out to private firms at higher rates, only the richest and politically most important states and communities could compete successfully for the scarce federal grants necessary to pay for services.
For example, Florida (with 16 more electoral votes than Louisiana and where the president’s brother governs) received its requested funding to protect its wetlands.
By contrast, a more needy Louisiana (with its staggering 24% poverty rate) was denied its request for flood-mitigation funds in 2004.
With Louisiana’s ability to protect itself weakened and the center of disaster relief badly undermined, an inadequate government response and unnecessary destruction were almost inevitable – with the poor paying the price.
But the failure of this administration runs deeper than its chronic and intentional diversion of resources away from the types of policies that keep people safe from disaster.
Despite scientific evidence demonstrating that the increased intensity and frequency of hurricanes is related to climate change, the Bush administration systematically rejects participation in international climate-protection regimes.
Rather than continue a ban on wetlands development instituted by previous administrations, the Bush administration overturned it.
Because development-provoked erosion has brought the Gulf of Mexico 20 miles closer to land than it was in 1965, hurricanes are able to retain more strength, and their winds and waves pack more speed and destructive power.
Similarly, loss of wetlands threatened New Orleans’ levees, which were built on the assumption that they would have 40 to 50 miles of protective swamp as buffer between the city and the Gulf of Mexico.
Despite every major study showing that a massive coastal restoration program and higher levees were needed to protect New Orleans, the administration permitted federal agencies to stop protecting 20 million acres of wetlands, allowed developers to drain thousands of acres and in 2004 cut funding for holding back the waters of Lake Pontchartrain by more than 80%.
New Orleans is America’s canary in the mineshaft.
Ideologies of privatization that incapacitate effective government, permitting the privileged to save themselves while leaving the poor clinging to roofs, must now be challenged.
This disaster is a chilling reminder of what happens when government fails to protect its citizens, and it is imperative that Americans demand accountability.
Officials who did not do their jobs must be dismissed, and elected officials whose policies aggravated the devastation wrought by Katrina must be removed from office.
We owe this to the dead and to the survivors.
If you judge a government on the basis of its good intentions, those who support an American foreign policy that emphasizes the promotion of human rights internationally should cheer President George W. Bush’s reelection.
Indeed, no US president has spoken out more frequently and more forcefully about America’s mission to promote freedom in the world.
The National Security Strategy of the United States, published by the Bush administration in September 2002, is filled with strongly worded commitments to promote human rights. The Country Reports on Human Rights worldwide, published annually by the State Department, maintain the high standard of accuracy and comprehensiveness that they achieved during the Clinton administration.
Under President Bush, the US has taken robust stands on human rights conditions not only in pariah countries such as Burma, Cuba, and Syria, but also in strategically important countries like Egypt, Uzbekistan, and China.
Yet those who examine the impact of the Bush administration on human rights practices internationally often argue that Bush’s reelection will do long-lasting – perhaps irreversible – damage to the human rights cause.
What explains this apparent contradiction?
There are three principal reasons why the Bush administration’s impact on human rights is so much at odds with its stated intentions.
Iraq comes first.
After official US claims about weapons of mass destruction and about a connection to the terrorist attacks of September 11, 2001, became untenable, Bush increasingly emphasized the argument that America’s invasion was justified to remove a tyrant, Saddam Hussein, and thus to free the Iraqi people.
In essence, this is an argument that the war was justified as a means of promoting human rights.
To those in the other Arab countries of the Middle East and elsewhere who oppose the war, the impact is to make human rights seem a justification, or a pretext, for a projection of American power.
The effect is to increase their distrust of those who preach about human rights, making it much more difficult than ever before for the US to rally support for human rights in much of the world.
The second reason that Bush’s reelection is likely to hurt the human rights cause is that it constitutes an endorsement by the majority of Americans of an administration that is responsible for grave human rights abuses. America’s moral authority as an advocate of human rights depends on its own respect for human rights.
Under President Bush, that authority has largely evaporated.
The twin symbols are Guantanamo and Abu Ghraib.
Having practiced long-term detentions without charge, trial, or access to family or counsel; having sexually humiliated and tortured prisoners, some of them to death; and having failed to hold accountable any of the high-level officials responsible for the policies that led to those crimes, the US is now seen as a hypocrite when it calls on other governments not to engage in such abuses.
While the war in Iraq and abuses at American detention centers have damaged the cause of human rights in the Middle East and Asia, the third factor in the weakening of human rights – unregulated free trade – has been felt mostly in Latin America.
It is there that the Bush administration has most vigorously asserted its position that the freedom of capital movement is an aspect of human rights. In the National Security Strategy of September 2002, the Bush administration calls free trade not only a meritorious policy, but also a “moral principle.”
Many Latin Americans have lost faith in democracy because it has not benefited them economically.
They see the US as simultaneously the champion of democracy in the region and as the culprit in their economic woes because of its insistence on the sanctity of capital.
When protecting capital is elevated to a moral principle, or justified as a component of human rights in a region resentful over its sense of economic subjugation, the effect is to foster disillusion with human rights.
President Bush and many of his associates may be sincere in their commitment to the human rights cause.
But perhaps it is such certainty in their good intentions that makes them blind to the damage that they are doing.
BERLIN – Despite continuing tensions over Russia’s invasion of Georgia this August, the European Union will reopen talks with Russia on a new Partnership and Cooperation Agreement (PCA).
A PCA establishes a legal framework for negotiating specific agreements in such areas as trade, justice, and human rights.
The current talks aim to replace the expired 1997 PCA, which remains in force by mutual consent pending a new accord.
At an emergency meeting on September 1, EU leaders refused to continue the PCA talks until Russia removed its combat units from the Georgian separatist regions of Abkhazia and South Ossetia.
The heads of the 27 EU governments also characterized the Kremlin’s decision to recognize the independence of the two breakaway regions as “unacceptable.”
Since then, EU governments have moderated their conditions, describing a simple Russian military withdrawal from Georgian territories outside the two regions as sufficient to resume a dialogue on the PCA, energy security, and other issues.
The EU decision comes at a time when NATO has also sought to renew its engagement with Russia after the Georgia conflict led both parties to suspend many joint programs.
In a speech on September 18 at the Royal United Services Institute in London, NATO Secretary General Jaap de Hoop Scheffer argued that, despite differences over Georgia, Russia and the alliance should cooperate “wherever our interests converge.”
He specifically cited continued cooperation in Afghanistan, where Russia is providing logistical support for the NATO-led International Security Assistance Force, as “a clear indication that common interests can transcend disagreements in other areas.”
In order not to appear intimidated by Russia’s forceful dismemberment of Georgia, NATO governments have publicly reaffirmed their support for Georgia’s territorial integrity and the country’s desire to join NATO eventually.
In private, however, many allied officials have told the media that they are even less inclined than they previously were to deepen NATO’s ties with Georgia, given the risks of becoming entrapped in another Russian-Georgian war.
At present, it seems most Western governments have decided to concentrate on helping Georgia recover economically from the war rather than on punishing Russia directly.
At last month’s International Donors’ Conference in Brussels, they pledged billions of dollars of reconstruction aid.
The EU is also considering negotiating a free-trade area with Georgia and relaxing visa rules for Georgian citizens.
NATO has established a special NATO-Georgian Commission to help coordinate allied support for Georgia’s post-conflict reconstruction.
Even so, Russian and Western officials continue to spar over American plans to deploy ballistic missile defense systems in Poland and the Czech Republic.
In his speech in November to the Russian parliament on the state of nation, President Dmitry Medvedev warned that Russia would deploy short-range Iskander missiles in the Baltic Sea port of Kaliningrad “to neutralize if necessary the anti-ballistic missile system in Europe.”
Medvedev added that Russian electronic equipment would jam the American systems and that the Russian military was preparing additional countermeasures.
NATO and EU leaders denounced the threats, which seemed especially gratuitous coming one day after the American people had elected a new President who has expressed interest in improving relations with Russia.
Russia’s government has also sought to showcase its growing military potential.
In September and October, the country’s strategic forces engaged in their largest nuclear weapons-related exercises since the Soviet Union’s demise.
On October 12, the Russian Navy joined with the Strategic Rocket Forces to conduct a well-integrated exercise involving near-simultaneous testing of three long-range ballistic missiles from separate ground and submarine launch platforms.
Last month, Prime Minister Vladimir Putin also announced yet another increase in Russian defense spending.
Russian military expenditures have increased by double-digit figures in recent years.
This year, the Russian military will spend over $40 billion.
The figure for 2009 could exceed $50 billion.
Although superficially impressive, this surge obscures several key issues.
Much of the growth merely compensates for the exceptionally high inflationary pressures in Russia’s defense sector.
In addition, it will take years for the recent budget increases to translate into new equipment.
Although Russian designers can still develop first-class weapons, Russia’s defense companies, which have yet to recover from the traumatic disintegration of the Soviet military-industrial complex, remain unable to manufacture large numbers of the most advanced systems.
Russia’s military also must compete with foreign customers for those few warplanes, tanks, and other sophisticated weapons that are produced.
The long-term sustainability of Russia’s military revival is also unclear.
Russia’s government remains dependent on oil and gas exports for revenue, but the prices of these commodities are falling sharply.
Unlike the Soviet Union, Russia is tightly integrated into the world economy, rendering the country vulnerable to the current global financial crisis.
Medvedev recently warned that Russia’s “military-industrial complex is starting to be affected by credit problems,” stoking fears of a return to the paralyzing payment crises that plagued the defense sector during the 1990’s.
Russia’s continuing demographic problems will also make it difficult for the armed forces to become a fully professional military, one that does not depend on poorly motivated conscripts.
Although Medvedev and Putin have apparently adopted a viable power-sharing arrangement, Russia’s stunted political institutions lack the capacity to root out corruption and other inefficiencies.
Comprehensive security-sector reform remains off the political agenda.
Even in the high-priority defense sector, perhaps one-third of government spending is wasted or stolen – a condition that is not conducive to realizing Russia’s great power ambitions.
CAMBRIDGE – Spend in haste; repent at leisure. With minds concentrated by fears of another 1930’s-style Great Depression, America’s political leaders developed, virtually overnight, a $700 billion bailout plan to resuscitate the country’s rapidly deflating financial sector.
But, just as stunningly, rank-and-file members of the US House of Representatives have rejected it – at least for now.
Perhaps they were right to be skeptical.
The plan’s central conceit is that government ingenuity can disentangle the trillion-dollar “sub-prime” mortgage loan market, even though Wall Street’s own rocket scientists have utterly failed to do so.
To boot, we have been told that government is so clever that it might even make money on the whole affair.
Perhaps, but let’s not forget that a lot of very smart people in the financial industry thought the same thing until quite recently.
Just a year ago, the United States had five major freestanding investment banks that stood atop its mighty financial sector.
Collectively, their employees shared more than $36 billion dollars in bonuses last year, thanks to the huge profits these institutions “earned” on their risky and aggressive business strategies.
These strategies typically involve far more risk – and sophistication – than the activities of traditional commercial banks.
In mid-August, I had the temerity to predict that risks had come home to roost, and that a large US investment bank might soon fail or be forced into a highly distressed merger.
Little did I imagine that today, there would be no freestanding investment bank left on Wall Street.
Indeed, after years of attracting many of the world’s best and brightest into ultra-high paying jobs, collapsing investment banks are now throwing them out left and right.
One such victim, a former student, called me the other day and asked, “What am I supposed to do now, get a real job?”
This brings us back to the US Treasury’s plan to spend hundreds of billions of dollars to unclog the sub-prime mortgage market.
The idea is that the US government would serve as buyer of last resort for the junk debt that the private sector has not been able to price.
Who, exactly, would the Treasury employ to figure all this out?
Why, unemployed investment bankers, of course!
Let’s ponder this.
Investment bankers have been losing their cushy jobs because they could not figure out any convincing way to price distressed mortgage debt.
Otherwise, their firms would have been able to tap the trillions of dollars now sitting on the sidelines, held by sovereign wealth funds, private equity groups, hedge funds, and others.
Now, working for the taxpayer, these same investment bankers will suddenly come up with the magic pricing formula that has eluded them until now. 
Little wonder that academics across the political spectrum have expressed considerable skepticism.
True, the Treasury would take equity stakes in some firms, so there would be some upside potential.
But the main concern centers around the Treasury’s apparent intention to pay more than double the current market price (20-30 cents on the dollar) on the premise that its success in untangling the mortgage market would make any discount seem like a bargain.
Does such nitpicking fail to recognize the urgency of fixing the financial system?
Isn’t any plan better than none?
I, for one, am not convinced.
Efficient financial systems are supposed to promote growth in the real economy, not impose a huge tax burden.
And the US financial sector, in greasing the wheels of the real economy, has been soaking up an astounding 30% of corporate profits and 10% of wages.
Thus, unlike in the 1930’s, the US faces a hypertrophied financial system.
Isn’t it possible, then, that rather than causing a Great Depression, significant shrinkage of the financial sector, particularly if facilitated by an improved regulatory structure, might actually enhance efficiency and growth?
I am not suggesting that the government should sit on its hands.
It needs to provide an expanded form of deposit insurance during this time of turmoil, so that there are no more Northern Rock-style bank runs.
That was a big lesson of the 1930’s.
The government may also need to consider injecting funds more directly into the mortgage sector while the private sector reconstitutes itself.
Certainly, the government must also find better ways to help homeowners and their lenders work out efficient bankruptcy proceedings.
It makes no sense for banks to foreclose on homes when there are workout options whereby people could stay in their homes and banks could recover far more money.
Eventually, after further twists, turns, and huge expenditures, the US will emerge from its epic financial crisis.
The proposal that was defeated was not sufficiently targeted at pruning back insolvent banks, but it will almost certainly not be the last word, regardless of how Congress now proceeds.
The communist revolution that spanned the nineteenth and twentieth centuries was about concentrating government ownership of capital.
Then, in the closing decades of the twentieth century, a counter-revolution swept the world, pushing for just the opposite: disperse capital as widely as possible by getting everybody involved as owners.
Now the counter-revolution is being carried to its logical extreme: if everyone can be an owner, then everyone can be a capitalist, down to the barber, the waiter, and the trash collector.
A specter is haunting us again; this time it is the dream of truly democratizing capitalism.
But turning everyone into a capitalist may be as impossible as the communist dream of turning everyone into an inspired socialist worker.
Interest in the arcane principles of finance has always been an inclination particular to people who love to pore over numerical tables and study mathematical formulas.
These people sometimes make themselves rich, and it would seem nice if everyone could do that.
But the varying talents, foibles, and psychological predilections of men and women make this impossible.
The new spirit of democratic capitalism goes by different names and mobilizes a variety of symbols.
But, however we describe it, the idea that the masses should be owners is growing everywhere.
In Britain, for example, Tony Blair articulates a vision of “a nation of savers and asset-holders.”
His plans have been called “asset-based policies,” a term that has grown in popularity since Michael Sherraden’s 1991 book Assets and the Poor: A New American Welfare Policy .
In the United States, President George W. Bush calls his dream the “ownership society.”
In China, the National People’s Congress in 2004 re-defined entrepreneurs and individual proprietors as “builders of the socialist cause,” and included them in the Patriotic United Front.
Governments around the world are spending money on regulating and monitoring their stock markets so that they are safer for individual investors, and so that investor interest in these markets will grow.
They are also trying to develop their housing finance in order to expand homeownership.
Some are talking about letting people own their social security contributions, in the form of personal retirement accounts, their health care through health savings accounts, and their education through educational savings accounts and school vouchers.
This is an attempt at a real revolution, not a return to an earlier capitalist past.
It is about experimenting with creative new economic institutions that have never been seen before.
The general concept of “ownership” is not by itself a roadmap to a successful new economy, and there are myriad interpretations of how to carry out the revolution.
Revolutions are always experiments, and they are always an adventure.
Some of the new policies seem exemplary.
Tony Blair’s Labor government is implementing a plan that, beginning in April, will establish a personal Child Trust Fund of £250 to £500 for every newborn.
Parents can then make contributions to their child’s trust fund which can grow tax-free, and can choose how to allocate the Fund among investments.
The purpose of the gifts is to “encourage parents and children to develop the saving habit and engage with financial institutions.”
This is a well-designed, small-scale plan that will cost the government fairly little: £500, even invested for twenty years, will not be enough to lift someone out of poverty.
The trust funds’ real promise will consist in educating citizens about investments.
That’s a good start, particularly if Blair’s policy is copied elsewhere.
But other proposals carry bigger risks, notably the privatization of retirement pensions, which is talked about in many countries, and that some – including Great Britain, Chile, Sweden, and Mexico – have already put in place, at least partly.
Bush’s plan to reform Social Security in the US – at least what is known of it – represents the ownership revolution’s cutting edge.
Young people in the US who opt for it would see most of the traditional pension benefit replaced when they retire decades from now with proceeds from personal accounts that they would be free to allocate among a range of investments, including stocks.
Whatever traditional benefit remains would not be enough to live on; retirees would be at the mercy of the markets for the bulk of their income.
The outcome of any such experiment is impossible to foresee, because other countries’ experience can never be a perfect guide to a new system – the situation is never exactly the same in a different environment.
A privatized social security system like the one Bush proposes might turn out very well, assuming that people behave sensibly and/or the stock market keeps going up.
But there is also a higher risk of disaster, owing to a seemingly inborn human tendency to extrapolate past returns.
Investors could create a stock-market bubble, encouraging even more naïve investors to concentrate their personal retirement accounts in the stock market – and leaving them dangerously exposed when it crashes.
There is also a related risk that private accounts would cause a further drop in the personal saving rate.
The saving rate is the lifeblood of any economy, because foreigners cannot be expected to finance capital investment forever.
But all the talk of wondrous returns could spur what psychologists call “wishful thinking bias,” leading people to believe that their personal accounts will be so valuable in the future that outside saving is unnecessary.
Encouraging widespread capital ownership could potentially give rise to good policies.
But do we really want to extend such policies to areas like pensions, health care, and education?
After all, owning capital – whether it is stocks or real estate – entails risks, and the need to insure against these risks is why capitalist countries built traditional safety nets in the first place.
Revolutions are exciting, but we must make sure that we still have a home to return to when the barricades come down and the dust settles.
Under dramatically inauspicious circumstances, Mexico has finally got itself a new president last Friday.
Felipe Calderón has taken the oath of office, braving the wrath of his left-wing opposition, out-smarting the Partido de la Revolución Democrática (PRD) and its leader, Andrés Manuel López Obrador, but nonetheless paying a high price.
Every TV news show and front-page headline in the world ran the same headline: “New Mexican President inaugurated in chaos and fisticuffs.”
Mexico’s institutions withstood – just barely – the onslaught of a virtually insurrectional left-wing opposition, bent in vain on stopping Calderón’s inauguration, and of a resentful Partido Revolucionario Institucional (PRI), increasingly dedicated to allowing Calderón to take office, and then fail miserably.
Calderón impressively overcame apparently insurmountable obstacles on the way to the presidency, yet the struggle to govern and transform Mexico has just begun.
Most Mexican commentators believe that it should be relatively easy for Calderón to improve on the largely self-inflicted failure of outgoing President Vicente Fox’s term.
Mexico needs to grow at roughly twice the rate that it did under Fox (a meager 2% per year).
If Calderón can strengthen law and order, and use his considerable political skills to reach agreement with the PRI on structural economic reforms, he will succeed.
But this view is simplistic.
Fox’s term, along with the four last years of former President Ernesto Zedillo’s mandate, were hardly a failure.
Not since the 1960’s had Mexico undergone ten consecutive years of economic stability, low inflation, low interest rates, a stable currency, and constant, though mediocre growth.
For the first time ever, mortgages, automobile loans, and consumer credit became available to the lower middle class: this year more homes were built and sold, and more cars were bought, than ever before.
Likewise, while Fox can be criticized for not clamping down on protesters and a disruptive, extremist opposition, he never resorted to the bloody repression for which most of his predecessors came to be known.
Moreover, he dragged Mexico out of its archaic foreign policy cocoon, and placed immigration and human rights at the heart of Mexico’s new international agenda.
Nor is Calderón finding it easy to negotiate with the PRI, failing to build a coalition government, which he has repeatedly proclaimed as the solution to the gridlock that has cursed Mexico since 1997.
Whatever the advantages of a cabinet comprising solely members of his Partido Acción Nacional (PAN), this is not what Calderón sought.
Similarly, no deal with the opposition was possible regarding the inauguration ceremony – thus the chaotic, depressing scenes of congressmen fighting it out in their chamber, while Calderón was ushered in through the back door for a rushed ceremony.
Mexico’s economic problems might be similarly more intractable than many commentators seem to believe.
Mexico experienced a “cold-turkey” economic opening under former President Carlos Salinas in 1988-1994; a belated but successful political opening under former President Zedillo in 1994-2000; and, at long last, a true rotation in power thanks to Fox.
But the foundations of the old PRI-corporativist system created in the 1930’s remain untouched, and represent the main and most formidable obstacles to Mexico’s growth and success.
The first pillar of this system is the public and private economic monopolies that dominate the country.
The state-owned oil (Pemex) and electric power (Federal Electricity Commission) companies face no competition.
The private virtual monopolies in telecommunications (Telmex), television (Televisa), cement (Cemex), bread and tortilla manufacturing (Bimbo and Maseca, respectively), banking (Banamex/Citigroup and Bancomer/Banco de Bilbao) may face competition abroad, but not at home.
These monopolies are stronger than ever, and prices, supply, service, and quality all suffer.
The second pillar is formed by the unions that have controlled the Mexican labor movement since the 1930’s.
They enjoy “closed shop” hiring and firing prerogatives, leadership elections by acclamation, mandatory dues without transparency, and immense political power.
The teachers’ union is the largest in Latin America, the oil workers’ union is the richest in Latin America, and the social security employees union has thwarted any attempt at pension or health reform for years.
The third pillar of the system is political monopoly.
For 70 years, the PRI had a complete lock on Mexican politics; now three parties do, and no one else can enter the political arena or gain access to the enormous public subsidies – more than $500 million last year – handed out to these parties without their consent.
The main parties write their own anti-trust legislation, vote their own subsidies, and choose their own elected officials.
The absence of consecutive re-election at any level reinforces the party machines’ power: they pick candidates, whom voters merely ratify at the polls.
So Mexico’s challenges boil down to liberating the labor movement, breaking up the private monopolies and opening the public monopolies to competition, and lowering entry barriers that restrict access to the political arena.
These may not be sufficient conditions for success, but they are certainly necessary ones.
Calderón must strengthen his presidency from the outset.
Taking on the powers that be is perhaps the only way to achieve this, however risky it might appear.
Elected with only 35% of the vote, lacking a majority in Congress, and taking office on the eve of an economic slowdown in the United States, things would be difficult anyway.
Given that roughly a third of the electorate does not think he won fairly, and in view of the precariousness of the rule of law in the country, Calderón’s position is even less enviable.
Caution and patience might not be his best advisors.
Berkeley – While the new Obama administration is commanding global attention, America’s future may be written – as so many times before – in and by its largest state.
Once the lodestar for American optimism and achievement, California now illustrates the difficulties confronting the United States – and how much more can still go wrong domestically.
The most populous and wealthiest of America’s 50 states, California has long been a beacon of opportunity for talented and enterprising people from all over the world.
One in every four California residents was born in a foreign country.
California’s two most famous industries, Silicon Valley and Hollywood, depend on infusions of talent from abroad.
Its robust agricultural sector is a massive exporter of food, benefiting from the growing appetites of consumers in developing countries.
Yet California’s technological and entrepreneurial might – standing alone, the state would be the world’s eighth largest economy – coexists with a dysfunctional political system that has brought it to the edge of fiscal bankruptcy.
On May 19, the state’s voters, in a special election, rejected an array of tax increases and spending cuts required to balance its budget.
Now, California faces either an embarrassing federal bailout or a prolonged period of rule by judges, who under California law have the power to vacate labor agreements, abrogate contracts, and generally restructure the state’s financial commitments.
For President Barack Obama, California’s crisis imperils his own reform agenda.
Because other American states also face tough fiscal conditions, the political price of bailing out California may be bailing out dozens of other states too.
A massive state bailout, while adding enormously to pressure on Obama’s government, would expose the weak link in the US system of governance.
So-called “unitary” nations such as Britain, France, China, or Kenya, essentially have a single set of government obligations: one national police force, one employer for all public school teachers, one overall pension system, etc. By contrast, the US has an “asymmetric” form of government, which allows many overlapping government entities – 7,000 in California alone – to incur debts, hire and fire employees, and impose taxes.
Making sense of these asymmetries is difficult.
When financial markets concentrate on the fiscal health of the federal government, they miss the extent of government obligations as a whole.
The complexity of American governance threatens the benefits of Obama’s decision to stimulate the economy through deficit spending.
While the national government expands, state governments, such as California’s, contract.
Moreover, California’s crisis is more than an economic one.
California is the most diverse US state; more than half of its 37 million people are non-white.
For believers in the benefits of diversity, California represents the largest social experiment in human history, bringing people of different backgrounds together in a way unimaginable in, say, Germany, China, or Brazil.
California’s governor, Arnold Schwarzenegger, was an immigrant (from Austria) before he was a movie star.
In his six years in office, he has repeatedly tried to bypass a polarized state legislature – even the annual budget requires a two-thirds majority – by appealing directly to voters.
Ballot initiatives were created 100 years ago to empower ordinary citizens, but in recent decades the process has been captured by self-serving elites.
Even as California’s roads fall apart and public institutions decline – the result of too little spending and public workers who are too expensive – the state continues to operate the finest set of public universities in the US.
But the secret of the University of California’s success is its ability to obtain ever-higher amounts of funding from private sources and the federal government.
Disengagement from the California polity also is true of the state’s economic engines.
Intel, the world’s biggest chip maker and a Silicon Valley mainstay, hasn’t built a factory in California for more than 20 years.
Hollywood shoots an increasing number of films elsewhere.
Agriculture relies heavily on illegal workers from Mexico, who live temporarily near the fields and take their earnings back home.
How to forge a single community out of a state so diverse remains an elusive challenge.
Some influential people, including Schwarzenegger, say the state needs a new constitution that would restrict ballot initiatives and make budgets easier to pass.
More radical thinkers insist that California is ungovernable and should be broken into two or even three states.
Creating more Californias would of course require the approval of the federal government in Washington, where elected representatives from California – mainly from Obama’s Democratic Party – have more power today than at perhaps any time in US history.
Nancy Pelosi, the House majority leader, is from San Francisco.
Californians run the two most powerful House committees, Energy and Commerce and Education and Labor.
Two of the most influential senators also come from California.
Why these Washington politicians are idle while their state slides towards ruin says much about what’s broken in American politics.
Schwarzenegger is a Republican, so Democrats privately wish him to fail.
There’s a deeper problem: politicians across the spectrum, beholden to special interests, are habituated to denying serious problems.
Obama will be forced to help craft a compromise to keep the state financially afloat.
Yet as a condition, he may insist that Californians, who are already among the most heavily taxed Americans, pay more.
If Californians refuse, Obama could face a widening revolt – against the idea of expanded government as the chief response to what ails America at home.
The People’s Bank of China and the Bank of Japan – as well as other central banks in Asia – are in trouble.
They have accumulated vast foreign exchange reserves, estimated at more than $2 trillion.
The problem is that almost all of it is in US dollars – a currency that is rapidly losing its value.
All policy options for Asia’s central banks appear equally unattractive.
If they do nothing and simply hold onto the dollars, their losses will only increase.
But if they buy more, in an attempt to prop up the dollar, they will only have a bigger version of the same problem.
If, on the contrary, they try to diversify into other currencies, they will drive down the dollar faster and create greater losses.
They are also likely to encounter the same sort of problem with other possible reserve currencies.
The euro has been touted as the replacement for or alternative to the dollar.
Some enthusiastic Europeans encouraged Asians to diversify their reserve holdings.
But the same scenario might well be repeated with the euro in a few years.
Large fiscal deficits and slow growth might convince foreign exchange markets that there is little future in the euro, fueling a wave of selling – and hence losses for central bank holders.
There is a historical parallel to today’s concern about the world’s major reserve currency.
The interwar economy, shattered by the Great Depression of the early 1930’s, offers a whole series of painful, but important, lessons for the present.
In the 1920’s, the world economy was reconstructed around a fixed exchange rate regime in which many countries held their reserves not in gold (as was the practice before the First World War) but in foreign exchange, especially in British pounds sterling.
During the course of the 1920’s, some of the official holders of pounds grew nervous about Britain’s weak foreign trade performance, which suggested that, like today’s dollar, the currency was over-valued and would inevitably decline.
Foreign central banks asked whether the Bank of England was contemplating changing its view of the pound’s exchange rate.
Of course they were told that there was no intention of abandoning Britain’s link to gold, and that the strong pound represented a deep and long commitment (in the same way that US Treasury Secretary John Snow today affirms the idea of a “strong dollar”).
Only France ignored British statements and substantially sold off its sterling holdings.
When the inevitable British devaluation came on September 20-21, 1931, many foreign central banks were badly hit and were blamed for mismanaging their reserves.
Many were stripped of their responsibilities, and the persons involved were discredited.
The Dutch central banker Gerard Vissering resigned and eventually killed himself as a result of the destruction wrought on his institution’s balance sheet by the pound’s collapse.
Some countries that traded a great deal with Britain, or were in the orbit of British imperial rule, continued to hold reserves in pounds after 1931.
During World War II, Britain took advantage of this, and Argentina, Egypt, and India, in particular, built up huge claims on sterling, although it was an unattractive currency.
At the war’s end, they thought of a new way of using their reserves: spend them.
Consequently, these reserves provided the fuel for economic populism.
Large holders of sterling balances – Nehru’s India, Nasser’s Egypt, and Peron’s Argentina – all embarked on major nationalizations and a public sector spending spree: they built railways, dams, steel works.
The sterling balances proved to be the starting point of vast and inefficient state planning regimes that did long-term harm to growth prospects in all the countries that took this course.
Could something similar be in store for today’s holders of large reserves?
The most explicit call for the use of dollar reserves to finance a major program of infrastructure modernization has come from India, which has a similar problem to the one facing China and Japan.
It will be similarly tempting elsewhere.
This temptation needs to be removed before the tempted yield to it.
Reserve holdings represent an outdated concept, and the world should contemplate some way of making them less central to the operation of the international financial system.
To be sure, reserves are important to smooth out imbalances in a fixed exchange rate regime.
But the world has moved since the 1970’s in the direction of greater exchange rate flexibility.
Reserves are also clearly important for countries that produce only a few goods – especially commodity producers – and thus face big and unpredictable swings in world market prices.
Dependency on coffee or cocoa exports requires a build-up of precautionary reserves.
But this does not apply to China, Japan, or India, whose exports are diversified.
Today’s big surplus countries do not need large reserves.
They should reduce their holdings as quickly as possible, before they do something really stupid with the accumulated treasure.
The UN's weapons inspectorate chief and Iraq have agreed on tentative terms for the conduct of weapons inspections, which in theory could begin as early as two weeks from now.
But the success of any such deal depends as much on the men who will carry out the inspections as on the details of when, where, and how they are carried out.
Hans Blix will head the UN arms inspectorate charged with searching for, finding, and destroying Saddam Hussein's weapons of mass destruction.
I have known Blix for over forty years.
In 1960 he was my deputy when I was a leader of the Swedish Liberal Youth organization.
Since then I have followed his career closely.
He became Sweden's foreign minister for a year and was later a director general of the International Atomic Energy Agency (IAEA) in Vienna.
Personally, Blix is amiable and has a sense of humor; politically he is weak and easily fooled.
I can think of few European officials less suitable for a showdown with Saddam Hussein.
Indeed, it is with utter disbelief that I watch television news about Blix's negotiations with the Iraqi dictator's henchmen.
The world has been amply warned about Blix's weaknesses because he has a track record of compounded failure.
When Blix headed the IAEA before the Gulf War of 1991, he blithely assured the world, after several inspections, that nothing alarming was happening in Iraq.
He delivered the clean bill of health that Saddam had hoped for when he began hiding his atomic factories and ambitions.
Since then, we have learnt all too unambiguously that Saddam is obsessed with procuring weapons of mass destruction - chemical and biological warheads as well as atomic bombs and the missiles to deliver them.
Former experts of Iraq's nuclear weapons program, who have fled Baghdad for the West, confirmed this.
They told us about determined and costly efforts to obtain doomsday devices.
Indeed, it is now clear that Saddam was but a year away from securing his first atomic bomb when the Gulf War broke out.
After that war, UN inspectors found and destroyed huge amounts of chemical and biological warheads as well as facilities to produce nuclear weapons.
Despite his grave failings as IAEA chief before 1991, Blix once again came to lead UN disarmament inspectors, this time in tandem with another Swede, Ambassador Rolf Ekéus.
Blix, naive and relatively ignorant about technical details -- his field is international law -- is easily mislead.
Even after the Gulf war, he failed to realize that the Iraqi officials, who were again assuring the UN that they were hiding nothing, were but consummate liars.
Indeed, Blix believed that Iraq had no program at all for nuclear arms.
David Kay, perhaps the most effective arms inspector, insisted that he did not trust them.
But Blix reproached Kay for his attitude.
You must believe in official information, Blix implied.
The turning point came when Kay initiated inspections of suspect buildings without notifying the Iraqis about his intentions in advance.
This new, aggressive inspection strategy had dramatic consequences: Kay discovered material which confirmed that Iraq was only 12 to 18 months away from producing a nuclear device.
This historic discovery ended up in a confrontation at a parking lot in Baghdad.
UN cars were surrounded by 200 Iraqi soldiers and a mob, ordered out to the scene by Iraqi officials.
For four days and nights the siege continued, as Kay and his colleagues used satellite telephones to fax crucial documents to the West.
Blix had opposed the raid.
Fortunately, Ambassador Ekéus backed it and supported the inspectors during the siege.
I have met a number of experts on Iraq's weapons of mass destruction, and they often compare the two Swedes: "Ekéus is brilliant," they say, "Blix is terrible."
When the current UN inspectorate was being put together in 1999, both Ekéus and Blix were among the candidates being considered to head the new group of inspectors.
Friends of Iraq in Paris and Moscow consulted Baghdad to see whom Saddam would prefer.
France and Russia then suggested Blix.
Surprisingly the Clinton administration accepted that decision.
Saddam's chemical and biological arms, and his determination to get nuclear weapons, are a threat to the world.
The dictator could use these arms himself or make them available to terrorist organizations.
And the issue of war and peace depends on a man repeatedly duped by the Iraqi regime.
The Bush administration probably understands Blix's weaknesses.
My guess is that the US will not allow Blix and the inspectors that he oversees to be deceived by Iraq again.
Regardless of how this crisis develops from this point, the UN has neglected its duties by asking a wimp to lead the inspectors who are supposed to stand up to the brute of Baghdad.
“Dollar denial,” that state of willful blindness in which bankers and central bankers claim not to be worried about America’s falling currency, seems to be ending.
Now even European Central Bank Governor Jean Claude Trichet has joined the chorus of concern.
When the euro was launched, the US dollar-euro ($:€) exchange rate stood at $1.16/€1.
At that price, the dollar was undervalued by roughly 10% relative to its purchasing power parity (PPP).
Initially, the dollar’s price rose, but since 2002, it has, for the most part, fallen steadily.
Every day seems to bring a new low against the euro.
In the face of the dollar’s ongoing fall, policymakers have seemed paralyzed.
The reasons for inaction are many, but it is difficult to avoid the impression that they are related to the current state of academic theorizing about exchange rates.
Simply put, economists believe either that nothing should be done or that nothing can be done.
Their so-called “rational expectations models” predict that exchange rates should not deviate from parity in any lasting way.
Believing that they have found a way to model how currency traders think, they see no need for intervention because, save for temporary deviations, markets always get currency values right.
“Behavioral economists,” by contrast, acknowledge that currencies can depart from parity for a long period.
But they attribute this to market psychology and irrational trading, not to the attempts of currency traders to interpret changing macroeconomic fundamentals.
This implies that intervention is not only unnecessary; it is ineffective: Faced with wide swings and trading volumes of $2 trillion per day, central banks are helpless to counteract traders’ irrational zeal.
But both the “rational expectations” and the “behavioral” models are flawed, because they seek to generate exact predictions of human behavior.
Both disregard the fact that rationality depends as much on individuals’ imperfect understandings of history and society as on their motivation.
If we place “imperfect knowledge” at the heart of economic analysis, the implications of our limited ability to predict market outcomes becomes clear.
When it comes to currency markets, parity levels based on international trade are merely one of many factors that traders consider.
In attempting to cope with imperfect knowledge, they are not irrational when they pay attention to other macroeconomic fundamentals and thereby bid an exchange rate away from its parity level.
In the euro’s rise against the dollar, euro bulls supposedly have been reacting to America’s current account deficit, the strong euro-zone economy, and rising euro interest rates.
What is irrational about factoring in such fundamentals when trading a currency?
Of course, persistent swings from parity do not last forever.
While movements in macroeconomic fundamentals may lead bulls to bid the value of a currency further from parity, doing so simultaneously fuels concern about a counter-movement back to parity – and thus capital losses – which moderates the desire to increase long positions.
Relating the riskiness of holding an open position in a currency market to the exchange rate’s divergence from parity levels suggests a novel way to think about how central banks can influence the market to limit departures from parity.
Although the exchange rate ultimately reverts back to its PPP benchmark, in a world of imperfect knowledge market participants might ignore this possibility in the near term.
But if central banks regularly announced their concern about significant departures from PPP, as they do now about inflation prospects, they would heighten traders’ concern that other traders will consider it increasingly risky to hold open positions that imply further movement away from parity levels.
This should moderate bulls’ willingness to increase their long positions, thereby limiting the magnitude of the swing.
To implement this “limit-the-swings” proposal, a central bank would announce its estimate of parity values every month, together with a comprehensive explanation of its estimates.
It would also make known to currency traders its concern about excessive departures from its estimated parity values and its readiness to intervene at unpredictable moments to impede further departures from PPP.
This policy would be even more effective if it were known that more than one central bank – say, the Fed and the ECB – were prepared to intervene.
This strategy does not imply a pre-specified target zone for exchange rates.
Given the size of currency markets, such targets almost always fail.
Instead, our limit-the-swings strategy implies that, as the exchange rate moves further away from parity, central banks should intervene.
The possibility of unpredictable interventions would reinforce the effect of the bank’s regular announcements of the parity values on traders’ perception of increased risk.
While this proposal shares some features with inflation targeting, it may actually achieve its goals more effectively.
Both involve announcing benchmark levels.
In both cases, central banks attempt to affect macroeconomic outcomes directly as well as by influencing market participants’ expectations.
As Milton Friedman emphasized, however, the links between monetary policy and inflation are “long and variable.”
By contrast, the link between official intervention and exchange rate movements is much more direct and potent.
Given massive trading volumes, direct intervention can alter supply and demand for currencies only on the margin.
But the limit-the swings policy may amplify intervention’s effects by diminishing market participants’ desire to push the exchange rate away from PPP.
Our proposal to reduce ­­– but not eliminate – swings from parity recognizes that price fluctuations may be crucial for markets to ascertain the price of assets with an uncertain payoff.
But currency swings, if too wide and protracted, can hurt competitiveness and require costly resource allocation.
These effects often lead to calls for protectionist measures, which may reduce the benefits from international trade and real economic activity.
Only by acknowledging the limits to knowledge can monetary and exchange rate policies have a better chance of succeeding.
BERKELEY – There has never been a question about the ultimate purpose of the Chiang Mai Initiative (CMI), the system of Asian financial supports created in 2000 in that Thai city.
That purpose, of course, is to create an Asian Monetary Fund, i.e., a regional alternative to the International Monetary Fund, whose tender ministrations during the 1997-98 financial crisis have not been forgotten or forgiven.
So far, however, the CMI has been all horse and no saddle.
Its credits and swaps have never been activated.
The distress following the failure of Lehman Brothers would have been an obvious occasion.
Yet, revealingly, the Bank of Korea, the central bank hit hardest, negotiated a $30 billion foreign-currency swap with the United States Federal Reserve, not with its ASEAN+3 partners.
Now, we are told, ASEAN+3 has achieved another great breakthrough, the so-called Chiang Mai Initiative Multilateralization (CMIM), aimed at turning its bilateral swaps and credits into a regional reserve pool.
The goal was set in 2005, and last month ASEAN+3 finance ministers negotiated the details. They specified contributions to their $120 billion pool, set down borrowing entitlements, and allocated voting shares.
The agreement on contributions is significant, it is said, because China and Japan will both contribute 32%.
In previous regional agreements, like capital subscriptions to the Asian Development Bank, China had always been treated as a second-rate power and asked to contribute less.
Indeed, China had shunned Japan’s 1997 proposal to create an Asian Monetary Fund precisely because it worried that it would play second fiddle.
That China is now acknowledged as a co-equal means that it will not stand in the way of further cooperation.
Also significant, we are told, is the agreement to make decisions by simple majority, with countries’ votes to be roughly in proportion to their contributions.
This means that no single country can block action, in contrast to the IMF executive board, which makes decisions by consensus, giving large countries like the United States de facto veto power.
But do these new rules really matter?
Disbursing more than 20% of the credits available to a country still requires that it first reach an agreement with the IMF, and 20% of a country’s entitlement is actually less than it contributes to the pool.
This would appear to nullify the very purpose of the arrangement, which is to free Asia from the IMF.
While there is a plan to raise and then eliminate the 20% threshold, this is left to some future, unspecified date.
The reason for the contradiction is straightforward.
Countries putting money on the barrelhead want assurances that their resources will not be used frivolously, and they want to know that they will be repaid.
But regional neighbors find it hard to criticize one another’s policies and demand course corrections.
Political sensitivities run especially high in Asia.
Even in Europe, with its long history of cooperation, surveillance and conditionality are outsourced to the IMF.
Revealingly, the Fund, not the European Union, has taken the lead in negotiating emergency assistance packages for Hungary and Latvia.
Delinking the CMIM from the IMF will require Asian countries to undertake hard-hitting reviews of one another’s policies and to demand difficult policy adjustments.
Here ASEAN+3 talks the talk.
Its May agreement included a commitment to establish a regional surveillance unit.
But there is no agreement on where to situate it or how to staff it.
It could be placed within ASEAN’s Secretariat in Jakarta.
It could be placed inside the Asian Development Bank in Manila.
It could be given to the “neutral” Northeast Asian country, Korea.
The outcome matters – which is why governments are fighting over it.
Recall how the fateful decision to situate the IMF in Washington, DC enhanced the influence of the US Treasury just down the street.
These dilemmas can be finessed by giving both surveillance responsibilities and the actual power to disburse funds to an independent board insulated from national politics.
Its members, with statutory independence and long terms in office, could function like the monetary policy committee of a central bank.
They could issue a Financial Stability Report that bluntly flags weak policies and financial vulnerabilities.
And they could demand policy adjustments as a condition for disbursing funds.
The IMF could then be shown the door.
This scheme wouldn’t solve all of Asia’s problems.
But it would at least head off one danger, namely the urge to accumulate even more reserves.
Recent volatility reinforces this temptation.
If Asian countries succumb, global imbalances and all their associated problems will return.
Pooling regional reserves as a way of making them go further is a better alternative.
But making this vision a reality requires further bold thinking.
MELBOURNE – Something new is happening at Harvard Business School.
As graduation nears for the first class to complete their Master of Business Administration since the onset of the global financial crisis, students are circulating an oath that commits them to pursue their work “in an ethical manner”; “to strive to create sustainable economic, social, and environmental prosperity worldwide”; and to manage their enterprises “in good faith, guarding against decisions and behavior that advance my own narrow ambitions but harm the enterprise and the societies it serves.”
The wording of the new MBA oath draws on one adopted in 2006 by the Thunderbird School of Global Management, based in Arizona.
Nevertheless, the fact that it has been taken up by the world’s most famous business school is significant.
As of this writing, about 20% of the Harvard graduating class have taken the oath.
That will, of course, prompt cynics to ask: “What about the other 80%?”  But those who have taken the oath are part of a larger turn toward ethics that has followed the recent flood of revelations of dishonesty and greed in the financial sector.
Interest in business ethics courses has surged, and student activities at leading business schools are more focused than ever before on making business serve long-term social values.
Business ethics has always had problems that are distinct from those of other professions, such as medicine, law, engineering, dentistry, or nursing.
A member of my family recently had an eye problem, and was referred by her general practitioner to an eye surgeon.
The surgeon examined the eye, said that it didn’t need surgery, and sent her back to the general practitioner.
That is no more than one would expect from a doctor who is true to the ethics of the profession, my medical friends tell me.
By contrast, it’s hard to imagine going to a car dealer and being advised that you don’t really need a new car.
For physicians, the idea of swearing an oath to act ethically goes back to Hippocrates.
Every profession will have its rogues, of course, no matter what oaths are sworn, but many health care professionals have a real commitment to serving the best interests of their clients.
Do business managers have a commitment to anything more than the success of their company and to making money?
It would be hard to say that they do.
Indeed, many business leaders deny that there is any conflict between self-interest and the interests of all. Adam Smith’s “invisible hand,” they believe, ensures that the pursuit of our own interests in the free market will further the interests of all. 
In that tradition, the economist Milton Friedman wrote, in his 1962 book Capitalism and Freedom :  “there is one and only one social responsibility of business – to use its resources and engage in activities designed to increase its profits so long as it stays within the rules of the game, which is to say, engages in open and free competition without deception or fraud.” For the true believers in this creed, the suggestion that the manager of a business should strive for anything except maximizing value for shareholders is heresy. 
But, while the global financial crisis did reveal fraud on a massive scale, the underlying cause of the crisis was not fraud but the failure of the market to knit together the self-interest of those who sold and resold sub-prime mortgages with the interests of the investors in financial institutions that bought them.
The fact that an even larger catastrophe would have resulted had governments not been willing to draw on taxpayer funds to bail out the banks was an additional blow to those who have told us to trust the unregulated market.
The MBA oath is an attempt to replace the Friedmanite view of the social responsibility of business with something quite different: a management profession that commits itself to promoting the long-term, sustainable welfare of all.
The sense of a professional ethic is conveyed by clauses in the oath that require managers to “develop both myself and other managers under my supervision so that the profession continues to grow and contribute to the well-being of society.”
Another clause stresses accountability to one’s peers, a hallmark of professional self-regulation.
As for the ultimate objectives of the managerial profession, they are, as we have seen, nothing less than “to create sustainable economic, social, and environmental prosperity worldwide.”
Can such a code really take hold in the competitive world of business?  Perhaps the best hope for its success can be glimpsed in a comment made to a New York Times reporter by Max Anderson, one of the pledge’s student organizers: “There is the feeling that we want our lives to mean something more and to run organizations for the greater good,” he said.  If enough business people would conceive their interests in those terms, we might see the emergence of an ethically-based profession of business managers.
The Bush administration provided three major rationales for going to war in Iraq.
Only one remains at all credible: the need to transform the Middle East through democratization and thereby undercut support for terrorists.
But does this argument really have any more basis in reality than the administration’s previous claims of an “imminent” threat from weapons of mass destruction or Saddam Hussein’s alleged support for al‑Qaeda?
With post-invasion inspectors concluding that no WMD stockpiles existed, and intelligence agencies now convinced that the Iraq war’s net effect has been to boost al‑Qaeda recruitment throughout the Islamic world, the Bush administration is understandably emphasizing the claim about democratization.
Indeed, it has become a dominant theme of Bush’s second term.
As Secretary of State Condoleezza Rice put it in a recent speech in Cairo, “Freedom and democracy are the only ideas powerful enough to overcome hatred, division, and violence.”
Cynics view this as merely an argument of convenience, one that has gained in prominence only because the other two rationales for the war collapsed.
More importantly, skeptics also doubt the validity of the administration’s argument linking democracy and reduction of terrorism.
After all, British citizens in one of the world’s oldest democracies carried out the recent terrorist attacks in London.
Similarly, an American citizen carried out the worst terrorist attack in the United States before September 11, 2001.
The skeptics have a point, but they go too far.
For one thing, it is still too early to judge the merits of the argument.
A full assessment of the Iraq war and its effects on the Middle East will take a decade or more.
Clearly, the January 2005 election there was a positive step for the region.
In the last six months, there have been national elections in Lebanon and local elections in Saudi Arabia.
Egypt has amended its constitution to allow it presidential election to be contested.
Further elections are scheduled in Iraq and the Palestinian Authority.
As Walid Jumblatt, the Lebanese Druze leader said, “It’s strange for me to say it, but this process of change has started because of the American invasion of Iraq.”
Perhaps that outcome shouldn’t seem so strange.
After all, as the columnist David Brooks recently observed, “If there is one soft power gift that America does possess, it is the tendency to imagine new worlds.” In other words, the invasion of Iraq, and the subsequent increase in the rhetoric of democracy in the Middle East, may have changed frames of reference about the status quo.
Democracy, however, is more than just elections.
It also requires tolerance of minorities and respect for individual rights, as well as the development of effective institutions for resolving political conflicts in divided societies.
If this occurs in Iraq, it may provide some post hoc legitimization for the war.
But such an outcome remains in doubt.
In the short run, the invasion of Iraq has created an intensifying insurgency and incipient civil war.
The presence of foreign troops creates a stimulus for nationalist and jihadist responses.
The future of Iraq, not to mention democracy there, remains uncertain at best.
Nevertheless, we can still conclude from the Iraqi experience that while the development of democracy can be aided from outside, it cannot easily be imposed by force.
While it is true that Germany and Japan became democratic after American occupation, it required their total defeat in a devastating war, and a seven-year occupation.
Moreover, Germany and Japan were relatively homogeneous societies with some prior experience of democracy.
It is hard to see such conditions repeated in today’s world.
The Bush administration may be correct in arguing that the extremely high costs and risks of promoting democracy are less than the costs and risks of allowing the authoritarian status quo in the Middle east to persist indefinitely.
But democracy is not the only instrument for a transformation that addresses the roots of terrorism.
The development of civil societies, economic growth, and openness to the world are equally important.
So is employing young men, educating young women, and addressing values of liberty and justice, which means ameliorating the sense of indignity in the region that stems from issues like the Israel-Palestine conflict.
Moreover, democracy alone will not convert the current crop of extremist jihadis to peaceful change.
If anything, too rapid a democratic transition may destabilize governments and enhance the extremists’ opportunities to wreak havoc.
But, in the longer term, the slow, steady progress of democratization can provide a sense of hope for moderates, creating a plausible vision of a better future – the essence of soft power – that undercuts the message of hate and violence promoted by the extremists.
Democratization can surely help remove some of the sources of rage that fuel terrorism, but it is only part of the solution.
Certainly, the diversity of forms of governance used over the centuries by Russia, Poland, Lithuania, and Austria-Hungary when they ruled what is now Ukraine make creating a classic "nation state," with one dominant culture, difficult to imagine.
Consider, for example, the robustness of the Russian language and the strength of the Orthodox Church- Moscow Patriarchate - in Donetsk that is in eastern Ukraine and the robustness of the Ukrainian language and the influence of the Ukrainian Greek Catholic Church in Lviv in the west.
Yet Spain, India, Belgium, and Switzerland are all consolidated democracies that do not fit the classic model of the nation state.
Indeed, multiple but complementary identities are the norm in all four countries.
These multiple identities emerged because the democratic state provided a "roof" of equal rights above all citizens, whatever their religion, language, or culture. This helped develop a strong sense of identity with the statewide political community.
These profoundly pluralistic countries are not classic "nation states," but rather what I call democratic "state nations."
During the recent presidential election, many suggested that reconciling the "two Ukraines" was impossible.
But polarization has not been a constant factor in the history of independent Ukraine.
On the contrary, Ukraine is closer to being a "state nation" than many people think.
Moreover, its prospects for becoming a consolidated democracy are enhanced by the fact that its political elites - and most ordinary Ukrainians - have eschewed the idea of being a classic "nation state."
Indeed, more than 80% of Ukraine's Russified eastern districts voted for independence in 1991, and the 1999 parliamentary and presidential elections did not split the country nearly as much as the 2004 presidential elections did.
A survey in 2001 of the two supposedly most polarized cities, Donetsk and Lviv, showed convergence in their approval of independent Ukraine, with only 1% of respondents in Lviv and 5% in Donetsk preferring that Ukraine be divided into two or more countries.
As in other "state nations," surveys in Ukraine indicate that common symbols have helped build elements of a common identity.
Both ethnic Russians and ethnic Ukrainians view the tenth-century feudal state known as "Kyiv Rus" very favorably.
Moreover, both groups share the seventeenth-century Cossack warrior Bohdan Khmelnytskyi as their most popular historical figure, and both revile Stalin due to the famines caused by his forced collectivization of agriculture in the 1930's (whereas most ethnic Russians in Russia view Stalin as the heroic state savior of WWII).
These shared attitudes toward Ukrainian symbols and statehood owe much to a recognition that independence will not be well protected by forging a classic nation state, that is, a "Ukrainian Only" state.
Thus, the country's declaration of independence 13 years ago was made in the name of "The people of Ukraine," and citizenship was offered to everyone who was born on the territory of Ukraine, regardless of nationality.
I was invited as an adviser to two constitutional committee meetings in Kyiv in the 1990's.
My impression from the discussions was that both Ukrainians and Russians in Ukraine were acutely aware of the need to avoid ethnic conflict.
In fact, an informal state-building alliance of convenience emerged between key non-communist Ukrainian nationalists and key pro-sovereignty, ethnic Russian communists.
The perception of "two Ukraines" emerged in the presidential election of 2004 partly due to the charge that Yushchenko would eliminate the constitutional guarantee that ethnic Russians could use Russian as their primary language of instruction in schools.
But during his campaign Yushchenko assured Russophones that he would uphold such rights.
Finally, much of what has been described as "secessionism" in the east is in fact regionalism.
Greater legally respected decentralization in Ukraine, especially in Crimea, would be a logical and overdue "state nation" policy.
The other major issue raised during the Orange Revolution concerns presidential powers.
Many Yushchenko loyalists are unhappy that, in exchange for the government agreeing to fairer election rules, Yushchenko agreed to transfer some presidential powers to the parliament.
Not withstanding the self-serving intentions of outgoing President Leonid Kuchma, this historic pact may in the long run produce positive results for Ukraine's democracy and prospects for joining the European Union.
The Ukrainian Constitution of 1996 adopted a model of governance close to the French style semi-presidentialism created by Charles de Gaulle for the Fifth Republic: a directly elected president with significant executive powers and a prime minister responsible to parliament.
This system works best when the president and the prime minister come from the same political party or coalition.
But, as in Russia under President Vladimir Putin, Kuchma vastly increased presidential powers in Ukraine.
Indeed, no real democracy in the world has such unchecked presidential authority.
A look at the eight postcommunist countries just admitted to the European Union is instructive.
Four - Hungary, the Czech Republic, Estonia, and Latvia - are parliamentary.
The other four - Slovenia, Poland, Lithuania, and Slovakia - have directly elected presidents, but none comes constitutionally and politically close to Kuchma's Ukraine.
Like Portugal in the 1980's, they adopted semi-presidential systems that so reduce presidential authority and increase the parliament's powers that they are most accurately described as "parliamentarized semi-presidential" systems.
This is the model toward which Ukraine could be moving, however unwittingly.
If so, the presidency would most likely cease to be a potential source of ethnic polarization, thereby strengthening the common identity that both Ukrainian and Russian citizens are committed to upholding.
WASHINGTON, DC – Hosni Mubarak’s resignation as President of Egypt marks the beginning of an important stage in that country’s transition to a new political system.
But will the political transition ultimately lead to democracy?
We cannot know with certainty, but, based on the history of democratic government, and the experiences of other countries – the subject of my book, Democracy’s Good Name: The Rise and Risks of the World’s Most Popular Form of Government – we can identify the obstacles that Egypt faces, as well as the advantages it enjoys, in building political democracy.
Understanding any country’s democratic prospects must begin with a definition of democracy, which is a hybrid form of government, a fusion of two different political traditions.
The first is popular sovereignty, the rule of the people, which is exercised through elections.
The second, older and equally important, is liberty – that is, freedom.
Freedom comes in three varieties: political liberty, which takes the form of individual rights to free speech and association; religious liberty, which implies freedom of worship for all faiths; and economic liberty, which is embodied in the right to own property.
Elections without liberty do not constitute genuine democracy, and here Egypt faces a serious challenge: its best-organized group, the Muslim Brotherhood, rejects religious liberty and individual rights, especially the rights of women.
The Brotherhood’s offshoot, the Palestinian movement Hamas, has established in the Gaza Strip a brutal, intolerant dictatorship.
In conditions of chaos, which Egypt could face, the best-organized and most ruthless group often gets control of the government.
This was Russia’s fate after its 1917 revolution, which brought Lenin’s Bolsheviks to power and condemned the country to 75 years of totalitarian rule.
In the same way, the Muslim Brotherhood could seize power in Egypt and impose a far more oppressive regime than Mubarak’s ever was.
Even if Egypt avoids control by religious extremists, democracy’s two-part anatomy makes swift and smooth progress to a democratic system problematic.
While elections are relatively easy to stage, liberty is far more difficult to establish and sustain, for it requires institutions – such as a legal system with impartial courts – that Egypt lacks, and that take years to build.
In other countries that have become democracies, the institutions and practices of liberty have often emerged from the working of a free-market economy.
Commerce fosters the habits of trust and cooperation on which stable democracy depends.
It is no accident that a free-market economy preceded democratic politics in many countries in Latin America and Asia in the second half of the twentieth century.
Here, too, Egypt is at a disadvantage.
Its economy is a variant of crony capitalism, in which economic success depends on one’s political connections, rather than on the meritocratic free-market competition from which liberty grows.
Egypt suffers from another political handicap: it is an Arab country, and there are no Arab democracies.
This matters, because countries, like individuals, tend to emulate others that they resemble and admire.
After they overthrew communism in 1989, the peoples of Central Europe gravitated to democracy because that was the prevailing form of government in the countries of Western Europe, with which they strongly identified.
Egypt has no such democratic model.
Egypt is, however, better placed to embrace democracy than the other Arab countries, because the obstacles to democracy in the Arab world are less formidable in Egypt than elsewhere.
Other Arab countries – Iraq, Syria, and Lebanon, for example – are sharply divided along tribal, ethnic, and religious lines.
In divided societies, the most powerful group is often unwilling to share power with the others, resulting in dictatorship.
Egypt, by contrast, is relatively homogeneous.
Christians, who make up 10% of the population, are the only sizable minority.
The oil that the Arab countries of the Persian Gulf have in abundance also works against democracy, for it creates an incentive for the rulers to retain power indefinitely.
Oil revenues enable them to bribe the population to remain politically passive, while discouraging the creation of the kind of free-market system that breeds democracy.
Fortunately for its democratic prospects, Egypt has only very modest reserves of natural gas and oil.
The fact that the large protest movement that suddenly materialized has, until now, been a peaceful one also counts as an advantage for building democracy.
When a government falls violently, the new regime usually rules by force, not by democratic procedures, if only to keep at bay those it has defeated.
The cause of democracy in Egypt has one other asset, the most important one of all.
Democracy requires democrats – citizens convinced of the value of liberty and popular sovereignty and committed to establishing and preserving them.
The political sentiments of many of the hundreds of thousands of people who gathered in Cairo’s Tahrir Square over the last three weeks leave little doubt that they do want democracy, and are willing to work and even to sacrifice for it.  Whether they are numerous enough, resourceful enough, patient enough, wise enough, and brave enough – and whether they will be lucky enough – to achieve it is a question that only the people of Egypt can answer.
MILAN – Over the past two years, industrial countries have experienced bouts of severe financial instability.
Currently, they are wrestling with widening sovereign-debt problems and high unemployment.
Yet emerging economies, once considered much more vulnerable, have been remarkably resilient.
With growth returning to pre-2008 breakout levels, the performance of China, India, and Brazil is an important engine of expansion for today’s global economy.
High growth and financial stability in emerging economies are helping to facilitate the massive adjustment facing industrial countries.
But that growth has significant longer-term implications.
If the current pattern is sustained, the global economy will be permanently transformed.
Specifically, not much more than a decade is needed for the share of global GDP generated by developing economies to pass the 50% mark when measured in market prices.
So it is important to know whether this breakout growth phase is sustainable.
The answer comes in two parts.
One depends on emerging economies’ ability to manage their own success; the other relates to the extent to which the global economy can accommodate this success.
The answer to the first question is reassuring; the answer to the second is not.
While still able to exploit the scope for catch-up growth, emerging economies must undertake continuous, rapid, and at times difficult structural change, along with a parallel process of reform and institution building.
In recent years, the systemically important countries have established an impressive track record of adapting pragmatically and flexibly.
This is likely to continue.
With government policy remaining on course, we should expect a gradual strengthening of endogenous domestic growth drivers in emerging economies, anchored by an expanding middle class.
Combined with higher trade among them, the future of emerging economies is one of reduced dependence on industrial-country demand, though not a complete decoupling.
Distribution as well as growth matter.
Emerging economies still need to manage better their growing domestic tensions, which reflect rising income inequality and uneven access to basic services.
A failure on this front would derail their strengthening domestic and regional growth dynamics.
This is better understood today, with distributional aspects of growth strategy being firmly placed on emerging countries’ policy agendas.
While emerging economies can deal with the economic slowdown in industrial countries, the financial-sector transmission mechanism is more challenging.
Today’s low interest-rate environment is causing a flood of financial flows to emerging economies, raising the risk of inflation and asset bubbles.
The hiccups in Western banks have served to disrupt the availability of trade credits, and, if amplified, could destabilize local banks.
These risks are real.
Fortunately, several emerging economies continue to have cushions and shock absorbers.
Having entered the 2008-2009 crisis with sound initial conditions (including large international reserves, budget and balance-of-payments surpluses, and highly capitalized banks), they are nowhere near exhausting their fiscal and financial flexibility – and hence their capacity to respond to future shocks.
Overall, emerging economies are well placed to continue to navigate successfully a world rendered unstable by crises in industrial countries.
Yet, again, the decoupling is not complete.
A favorable outcome also requires industrial countries’ ability and willingness to accommodate the growing size and prominence of emerging economies.
The risks here are significant, pointing to a wide range of potential problems.
The flow of knowledge, finance, and technology that underpins sustained high growth rates in emerging economies is closely linked to an open, rule-based, and globalized economy.
Yet this global construct comes under pressure in an environment in which advanced countries have stubbornly high unemployment and bouts of financial volatility.
The location of growth in the global economy comes to be seen as a zero-sum game, leading to suboptimal reactions.
As a result, the continued openness of industrial-country markets cannot be taken for granted.
Political and policy narratives are becoming more domestic and narrow, while the international agenda and the pursuit of collective common global interests are having greater difficulty being heard.
These challenges will grow in the years ahead.
And then there is the issue of global institutions and governance.
Managing a growing and increasingly complex set of transnational connections is an even bigger challenge in a multi-speed world that is being turned upside down.
Such a world requires better global governance, as well as overdue institutional reforms that give emerging economies proper voice and representation in international institutions.
In the absence of such changes, the global economy may bounce from one crisis to another without a firm hand on the rudder to establish an overall sense of direction.
The result is what economists call “Nash equilibria,” or a series of suboptimal and only quasi-cooperative outcomes.
Where does all this leave us?
Emerging economies will be called on to play an even larger role in a multi-speed global economy characterized by protracted rehabilitation of over-extended balance sheets in industrial countries.
Left to their own devices, they are up to the task.
But they do not operate in a vacuum.
Emerging economies’ ability to provide the growth lubrication that facilitates adjustment in industrial countries is also a function of the latter countries’ willingness to accommodate tectonic shifts in the operation and governance of the global economy.
Let us hope that these global issues receive the attention they require.
CAMBRIDGE – Perhaps it is a pipe dream, but it is just possible that the ongoing BP oil-spill catastrophe in the Gulf of Mexico will finally catalyze support for an American environmental policy with teeth.
Yes, the culprits should be punished, both to maintain citizens’ belief that justice prevails, and to make other oil producers think twice about taking outsized risks.
But if that is all that comes out of the BP calamity, it will be a tragic lost opportunity to restore some sanity to the United States’ national environmental and energy policy, which has increasingly gone off track in recent years.
Why should there be any reason for hope, especially given that US environmental policy has been predicated on the unrealistic belief that relatively small subsidies to new energy technologies can substitute for tax-induced price incentives for producers and consumers?
The fact is, the BP oil spill is on the cusp of becoming a political game-changer of historic proportions.
If summer hurricanes push huge quantities of oil onto Florida’s beaches and up the Eastern seaboard, the resulting political explosion will make the reaction to the financial crisis seem muted.
Anger is especially rife among young people.
Already stressed by extraordinarily high rates of unemployment, twenty-somethings are now awakening to the fact that their country’s growth model – the one they are dreaming to be a part of – is, in fact, completely unsustainable, whatever their political leaders tell them.
For now, it may only be black humor (e.g., the New Orleans waiter who asks diners whether they want their shrimp leaded or unleaded).
But an explosion is coming.
Might a reawakening of voter anger be the ticket to rekindling interest in a carbon tax?
A carbon tax, long advocated by a broad spectrum of economists, is a generalized version of a gas tax that hits all forms of carbon emissions, including from coal and natural gas.
In principle, one can create a “cap-and-trade” system of quantitative restrictions that accomplishes much the same thing – and this seems to be more palatable to politicians, who will jump through hoops to avoid using the word “tax.”
But a carbon tax is far more transparent and potentially less prone to the pitfalls seen in international carbon-quota trading.
A carbon tax can help preserve the atmosphere while also discouraging some of the most exotic and risky energy-exploration activities by making them unprofitable.
Of course, there must be better (far better) and stricter regulation of offshore and out-of-bounds energy extraction, and severe penalties for mistakes.
But putting a price on carbon emissions, more than any other approach, provides an integrated framework for discouraging old carbon-era energy technologies and incentivizing new ones by making it easier to compete.
Advocating a carbon tax in response to the oil spill does not have to be just a way of exploiting tragedy in the Gulf to help finance outsized government spending.
In principle, one could cut other taxes to offset the effects of a carbon tax, neutralizing the revenue effects.
Or, to be precise, a carbon tax could substitute for the huge array of taxes that is eventually coming anyway in the wake of massive government budget deficits.
Why might a carbon tax be viable now, when it never has been before?
The point is that, when people can visualize a problem, they are far less able to discount or ignore it.
Gradual global warming is hard enough to notice, much less get worked up about.
But, as high-definition images of oil spewing from the bottom of the ocean are matched up with those of blackened coastline and devastated wildlife, a very different story could emerge.
Some say that young people in the rich countries are just too well off to mobilize politically, at least en masse.
But they might be radicalized by the prospect of inheriting a badly damaged ecosystem.
Indeed, there is volatility just beneath the surface.
Modern-day record unemployment and extreme inequality may seem far less tolerable as young people realize that some of the most cherished “free” things in life – palatable weather, clean air, and nice beaches, for example – cannot be taken for granted.
Of course, I may be far too optimistic in thinking that the tragedy in the Gulf will spur a more sensible energy policy that attempts to moderate consumption rather than constantly seeking new ways to fuel it.
A great deal of the US political reaction has centered on demonizing BP and its leaders, rather than thinking of better ways to balance regulation and innovation.
Politicians understandably want to deflect attention from their own misguided policies.
But it would be far better if they made an effort to fix them.
A prolonged moratorium on offshore and other out-of-bounds energy exploration makes sense, but the real tragedy of the BP oil spill will be if the changes stop there.
How many wake-up calls do we need?
ATHENS ­­– Even as the European Union and the International Monetary Fund lay the groundwork for a giant first-round bailout, debate is swirling about whether Greece can avoid sovereign default.
Some view Greece as Argentina revisited, noting the stunning parallels with the country that in 2001 set the record for the world’s largest default (in dollar terms).
Others, such as Greek Prime Minister George Papandreou, see the country’s problems as difficult but manageable, and complain of interference from ill-intentioned foreign speculators.
Avoiding default may be possible, but it will not be easy.
One has only to look at official data, including Greece’s external debt, which amounts to 170% of national income, or its gaping government budget deficit (almost 13% of GDP).
But the problem is not only the numbers; it is one of credibility.
Thanks to decades of low investment in statistical capacity, no one trusts the Greek government’s figures.
Nor does Greece’s default history inspire confidence.
As demonstrated in my recent book with Carmen Reinhart This Time is Different: Eight Centuries of Financial Folly , Greece has been in default roughly one out of every two years since it first gained independence in the nineteenth century.
Loss of credibility, if it comes, can bite hard and fast.
Indeed, the historical evidence slams you over the head with the fact that, whereas government debt can drift upward inexorably for years, the end usually comes quite suddenly.
And it can happen to any country, although advanced countries can usually tighten fiscal policy with sufficient speed and credibility that the pain comes mainly in slower growth.
Unfortunately, for emerging markets, adjustment is often impossible without help from the outside.
That is the precipice on which Greece stands today.
A debt crisis is not inevitable.
But the government urgently needs to implement credible fiscal adjustment, concentrating not only higher taxation, but also on rolling back some of the incredible growth in government spending – from 45% of GDP to 52% of GDP – that occurred between 2007 and 2009.
The government must avoid relying too much on proposals for tax increases, which ultimately feed back on growth and sustainability.
It would be far preferable to balance tax increases with some reversal of runaway government spending.
I have Greek friends who say that Greece is not alone.
And they are right.
Some countries are almost inevitably going to experience bailouts and defaults.
One of the more striking regularities that Reinhart and I found is that after a wave of international banking crises, a wave of sovereign defaults and restructurings often follows within a few years.
This correlation is hardly surprising, given the massive build-up in public debts that countries typically experience after a banking crisis.
We have certainly seen that this time, with crisis countries’ debt already having risen by more than 75% since 2007.
But, whereas we are likely to see a wave of defaults and IMF programs this time, too, fiscal meltdown does not have to hit every highly indebted country.
Indeed, what a country like Greece should be doing is pulling out all the stops to stay clear of the first and second wave of restructurings and IMF programs.
If it can, then perhaps watching other countries suffer will help convince the local political elite to consent to adjustment.
If not, Greece will have less control over its adjustment and potentially experience far greater trauma, perhaps eventually outright default.
There is an old joke about two men who are trapped by a lion in the jungle after a plane crash.
When the first of them starts putting on his sneakers, the other asks why.
The first answers: “I am getting ready to make a run for it.” But you cannot outrun a lion, says the other man, to which the first replies: “I don’t have to outrun the lion.
I just have to outrun you.”
Greece has yet to put on its sneakers, while other troubled countries, such as Ireland, race ahead with massive fiscal adjustments.
Greece’s new Socialist government is hampered by campaign promises that suggested the money was there to solve the problems, when in fact things turned out to be far worse than anyone imagined.
Unions and agricultural groups tie up traffic with protests every other day, hinting at possible escalation.
Most Greeks are taking whatever action they can to avoid the government’s likely insatiable thirst for higher tax revenues, with wealthy individuals shifting money abroad and ordinary people migrating to the underground economy.
Greece’s underground economy, estimated to be as large as 30% of GDP, is already one of Europe’s biggest, and it is growing by the day.
In the case of Argentina, a pair of massive IMF loans in 2000 and 2001 ultimately only delayed the inevitable harsh adjustment, and made the country’s ultimate default even more traumatic.
Like Argentina, Greece has a fixed exchange rate, a long history of fiscal deficits, and an even longer history of sovereign defaults.
Nevertheless, Greece can avoid an Argentine-style meltdown, but it needs to engage in far more determined adjustment.
It is time to put on the running shoes.
With one-third of the Palestinians’ Hamas-led government now under arrest by Israel, the escalation in Israeli-Palestinian relations has moved beyond military confrontation.
A far more fundamental question has come into view: can a Palestinian government that draws its authority from an agreement with Israel stay in power when it is led by an organization committed to the destruction of Israel?
The abduction of an Israeli soldier in the Gaza Strip, as well as the abduction and subsequent murder of an 18-year old Israeli civilian in the West Bank, have brought to the fore that question, which has haunted Israeli-Palestinian relations since Hamas won parliamentary elections in January.
The international community, led by the “Quartet” (the United States, the European Union, the United Nations, and Russia), has put three conditions to the Hamas government if it wishes to achieve international legitimacy and continue to be supported financially.
Hamas must recognize Israel’s right to exist, stop all terrorist activities, and commit itself to carry out all previous international agreements signed by the Palestinian Authority.
These look like reasonable conditions to any outside observer.
To Hamas, however, they appear to undermine its very raison d'etre.
After all, this is an organization committed to the destruction of Israel – its charter calls for a holy war against all Jews – and the establishment of an Islamic state in all of historical Palestine.
Indeed, Article 22 of that charter reveals that Hamas views the Jews (together with the Freemasons and other nefarious organizations like Rotary International and the Lions Club), as responsible for the French and Bolshevik Revolutions, World War I, and World War II.
So it is no great surprise that Hamas rejected the Quartet’s conditions.
At the same time, Palestinian President Mahmoud Abbas (Abu Mazen), who represents Fatah, which lost the January elections, has tried in vain to find common ground with Hamas through an ambiguous text known as “The Prisoners’ Document.”
This document was intended to serve as an implicit acceptance of Israel’s right to exist.
But nothing of the sort appears in the truncated text approved by Hamas.
On the contrary, the text legitimizes continuing attacks against Israeli civilians in the West Bank, making it unacceptable to Israel – and to the international community.
But the current crisis cannot be solved by words alone.
One of the paradoxical results of America’s almost messianic belief in elections as a panacea for all the ills of the Middle East is that Hamas – the winner of democratic elections – has gained a degree of legitimacy that it never had before.
On the other hand, Hamas’s history and current behavior clearly indicate that it regards elections as merely a political tool, and that it is devoid of any commitment to the norms and values underlying democracy.
Fascist and communist regimes of the past, which followed a similar instrumentalist approach to democracy, come to mind here.
Yet, at the same time, the US supports Abu Mazen, trying to undermine the Hamas government, thus casting a shadow on the credibility of its own commitment to democracy.
The current violence may escalate further, and could bring down the Hamas government.
On the other hand, diplomatic means may bring about the release of the Israeli soldier and put a stop to the firing of Qassam rockets from Gaza into Israel – a daily occurrence that has challenged the credibility of the new Israeli government under Prime Minister Ehud Olmert.
But the fundamental problem is that, until now, at every historical juncture, the Palestinians refused to accept a compromise and consequently failed in nation-building.
In 1947, they refused the UN partition plan, which called for the establishments of two states in British Palestine.
In 1993, after the Oslo agreements, the Palestinian Authority established under Yasir Arafat became another militarized authoritarian regime, very much like Syria and Egypt, and did nothing to alleviate the suffering of the Palestinian refugees.
It was this failure that brought Hamas to power.
The current crisis is obviously the first serious test for Olmert and his plans for further withdrawal from Israeli-occupied territories.
But it is an even greater test for the Palestinians: will they once again be led by a radical and fanatical leadership into another national catastrophe?
Or will they finally realize that a future of independence, sovereignty, and dignity is open to them – but only if they grant the Israelis what they rightly claim for themselves?
The international community can urge the Palestinians toward a decision.
But that decision, and its moral costs, remains in the hands of the Palestinians alone.
World oil prices crossed $40 a barrel in mid-summer, and have since climbed to the mid-$50's.
Today's oil prices are still only two-thirds the real peak reached during the Iranian Revolution of 1979, and future markets expect the oil price to fall back and settle at perhaps $45 a barrel.
But the current high level of oil prices has led forecasters to start reining in their expectations for economic growth.
"Higher oil prices are here to stay," says the American economic forecaster Allen Sinai. "[T]hat has to subtract growth and could cause core inflation to pick up."
Indeed, according to Sinai, higher oil prices are "the biggest risk...since the bursting of the stock-market bubble in 2000-2001."
Sinai is hardly alone.
If the oil price stays at $40 a barrel, expect it to have next to no effect on short-term world GDP growth.
But if the oil price remains at or near $60 a barrel, expect everyone's forecasts of GDP growth to be reduced by 1% per year.
High oil prices also threaten to slow long-term productivity growth.
With high - and volatile - oil prices, businesses will focus their investments less on boosting productivity and more on maintaining flexible energy usage.
At $40 a barrel, expect oil prices to slow the long-run growth rate of the world's potential output by 0.1% per year.
At $60 a barrel, expect the "measured" long-term rate of potential world output growth to slow by roughly 0.3% per year.
With most shocks to the world economy, we expect central banks to take steps to offset their effects.
When business investment committees become more cautious, we expect to see the Federal Reserve, the European Central Bank, the Bank of England, and others lower interest rates to make the numbers more attractive.
If consumers go on a spending binge, we expect the world's central banks to raise interest rates to cool off construction spending and free up the resources needed to prevent shortage-inducing inflation.
But this economic logic does not apply in the case of increases in oil prices.
Although high oil prices look like a tax on business activity that depresses aggregate demand, they also raise inflation, both directly and indirectly.
Central banks respond to lowered demand by reducing interest rates and to higher expected inflation by raising interest rates.
Because high oil prices both lower demand and raise inflation, central banks respond by doing little or nothing.
The effects of high oil prices thus flow through to the economy without being moderated by the world's central banks leaning against the wind.
Yet if we take a very long-term view, it is not so clear that high oil prices are bad for the world as a whole.
For example, if high oil prices were the result of taxes that were then redistributed to oil users, they would be unambiguously good.
To be sure, most taxes entail heavy "excess burdens": the cost is significantly greater than the value of the revenue raised because of potential taxpayers' myriad attempts at evasion and avoidance.
A tax on oil, however, does not entail excess burdens.
On the contrary, it implies excess benefits .
Shifts to more energy-efficient means of transportation ease congestion.
Attempts to shave costs by economizing on energy use reduce pollution.
Higher prices for oil substitutes spur research into other energy technologies - research that is much needed today if we are to tackle the problems of global climate change tomorrow.
A well-designed tax on oil would also reduce demand, thereby lowering the potential for windfall profits for those who rule or own the ground over the oil deposits.
A little more than a decade ago, Lloyd Bentsen, President Bill Clinton's first Treasury Secretary, tried to ensure precisely that, proposing to use a "BTU tax" to close America's fiscal deficit.
The Republican Party and the American Petroleum Institute sank that proposal.
A decade later, we have high oil prices, but they are not due to a well-designed tax, either in America or elsewhere.
As a result, the price boom is boosting windfall profits for the owners of oil deposits rather than improving countries' public finances.
For many years after independence in 1947, India remained a large and poor country.
Successive governments embraced policies that made the state the engine of growth and development, while severely restricting economic interactions with the rest of the world.
India's population is now much larger, and it is still poor--but not as poor as it might have been.
More than a decade ago, it embarked on a new course that has led to faster growth and lower poverty.
External trade was liberalized, and many government controls on domestic investment were removed.
Perhaps more significantly, the mindset of many intellectuals and policymakers changed in favor of a more market-oriented approach, including greater integration with the world economy.
This represents a crucial breakthrough for India's development.
As the Nobel laureate James Heckman points out in his recent analysis of the poor performance of the German economy after reunification, new opportunities in technology and trade have raised the cost of preserving the status quo. ``The winners in world trade in the next generation,'' Heckman argues, ``will be those countries that can respond flexibly with educated work forces.''
But how does a country of India's size and diversity go about achieving the flexibility that integration into the world economy requires?
Abdul Kalam, India's president since 2002, has stressed the need to build global competitiveness from the ground up--within each of the country's federal states.
By emphasizing the federal nature of India's polity, he is directly addressing an issue that has moved front and center in debates over economic reform in an era of globalization.
The fear is that some regions of a country might race ahead, while others languish in poverty.
It is a fear that prevails not only in India, but in China, South Africa, Mexico, and Brazil.
For example, in India, the cities of Bangalore and Mumbai might become enclaves comparable in attitude and achievement to the world's rich industrialized countries, capable of leading their respective states, Karnataka and Maharashtra, toward prosperity.
But states such as Bihar and Uttar Pradesh could well remain stagnant, falling ever deeper into relative deprivation.
Studies in the 1990's seemed to bear out this gloomy scenario: inequality of per capita output between India's states was increasing as they moved further apart in their performance.
If this trend persists, the existence and stability of India as a federal democracy will inevitably be called into question, because the laggard states have large populations and account for a majority of parliamentary constituencies.
Such a denouement, although worrisome, is not inevitable.
True, the economic reforms of the 1990's gave state governments more freedom to set their own policies, and their choices varied dramatically.
Moreover, one of the main consequences of economic openness and globalization at the subnational level has been fierce competition between state governments for foreign direct investment, which has been regionally concentrated.
But growing inter-state inequality may not be fatal to India's survival, for several reasons:
The output data are not conclusive in showing any long-run divergence (although clearly capital flows--domestic as well as foreign--matter for growth);
Internal labor mobility may well have some countervailing effects, which is not seen in data on output, but would be seen in figures on state incomes, if these were available;
Indian states differed in their responses to reform, mostly because of disparities in their economic and social infrastructure--particularly education and health--at the time reforms were initiated.
But these differences can be reduced over time by appropriate policy.
Poor states that spend public money more wisely improved people's lives quite quickly: Madhya Pradesh and Rajasthan illustrate the value of better governance;
Other measures of development, such as the Indian Human Development Index (which includes literacy, infant mortality, access to safe water and durably constructed housing, as well as formal education, poverty ratios, and per capita expenditure), do not show increased inequality;
Exclusive focus on the states ignores problems that are concentrated at lower levels: available evidence, albeit limited, suggests that decentralizing policy-making power that is currently exercised at the state level could lead to further improvement in overall economic performance.
India's central government retains an important role to play in reaching out to the poor.
Transfers of government money to subnational governments express the entitlement of all citizens to a basic set of public services.
But to fulfill this promise, India's central government must liberalize more.
It must privatize state-owned enterprises that suck up public resources; clean up and privatize the financial sector, which remains so government-controlled that it makes fiscal discipline at the subnational level close to impossible; and streamline the system of intergovernmental transfers so that means and ends are clearer.
This is not an exhaustive list of reforms, but they would go a long way toward allowing the central government and the states, working together, to confront successfully the grave potential peril that globalization holds in store for India.
President Kalam was right to appeal for policies that ``develop competitive strengths for the states so that they can excel at the national level and the global level.''
Now India must deliver.
If history seems likely to rank Silvio Berlusconi as an inconsequential Prime Minister of Italy, it will surely remember him as an extraordinary – and extraordinarily bizarre – one.
Promising one thing and delivering another was not so much a weakness of his government as its organizing principle.
Given the erratic nature of Berlusconi’s rule, it is no surprise that, ever since the 2001 election that returned him to power, the center-left l’Unione coalition has won all subsequent elections – administrative, regional, and European.
Yet the left’s prospects in the upcoming parliamentary election are far from certain, and Berlusconi seems far from doomed.
Given the country’s economic conditions, one would think that Italy is ripe for decisive change.
For the last four years, average growth in incomes has been a mere 0.3%, compared to 1.5% in the European Union, and in the past two years public debt has again started to rise.
Moreover, the strategy of Berlusconi’s ruling center-right Casa della Libertà coalition has been to tread water and wait for Europe’s economy to pick up instead of tackling Italy’s structural difficulties.
As a result, the government is criticized not only by the unions, but also by the employers’ association, Confindustria, which in 2001 gave Prime Minister Berlusconi strong support.
Then there is the ongoing conflict of interests between Berlusconi-the-Premier and Berlusconi-the-magnate, who holds public licenses that make him a semi-monopolist in media and TV advertising.
During Berlusconi’s tenure in office, his enormous personal assets have tripled.
While his parliamentary majority has approved many laws that promote his personal interests and have eased some of his legal difficulties, at the beginning of March, Berlusconi was again accused of corruption and tax fraud.
Berlusconi’s ministers have scarcely behaved better.
Two were forced to resign within a month of each other.
Roberto Calderoli, a prominent official in Lega Nord, the third-largest government party, provoked riots in Libya by wearing a t-shirt printed with the infamous cartoons of the Prophet Mohammad.
Francesco Storace, the former Minister of Health and a leading member of Alleanza Nazionale, the second-largest government party, is suspected of organizing political espionage, in an Italian-style Watergate.
But, despite the government’s catastrophic economic and ethical record, opinion polls indicate a lead of only about four percentage points for l’Unione—too small, given the high number of undecided voters, to predict the election’s outcome.
So what is keeping Berlusconi and his coalition in the race?
Above all, Berlusconi’s electoral campaign is aimed, in the manner of President Bush’s 2004 re-election campaign, at energizing his hard-core supporters and mobilizing the growing number of voters who have abstained in recent years.
In doing this he has not hesitated to use his semi-monopoly over television to exalt his government’s alleged accomplishments.
His campaign rhetoric highlights anti-communism with an emphasis not seen in Italy since 1948, coupled with a defense of the family and values cherished by the Roman Catholic establishment, although the Church has so far resisted being drawn into the campaign.
The Berlusconi coalition also benefits from the weakness of l’Unione.
Its leader, Romano Prodi, obtained an extraordinary popular endorsement when more than four million people voted for him in Italy’s first-ever primary elections.
Yet Prodi continues to be a party-less leader of too many parties.
To be sure, the cohesiveness of l’Unione has strengthened: the two major parties (Democratici di Sinistra and Democrazia e Libertà - la Margherita) are united under the symbol of the olive tree, the other parties have endorsed a detailed 280-page government program, and the left-wing Partito della Rifondazione Comunista has given clear signs of moderation and loyalty to the coalition.
For voters, however, a perception of fragility remains.
Finally, the uncertainty of the outcome reflects not so much voters’ behavior, but a change in the electoral system.
During the past decade, Italy has used a majority electoral system corrected by a proportional quota.
Under this system, Casa della Libertà translated a small popular majority in 2001 into a decisive parliamentary majority.
But, with the same result on the horizon this year for l’Unione, the center-right parliamentary majority changed the electoral law just a few months before the end of its term.
This is reminiscent of an army that, fearing defeat on the battlefield, poisons the wells as it retreats.
A proportional system in the absence of individual preferences means that party secretaries, rather than citizens, will choose deputies, and, with no effective electoral threshold, the number of parties will proliferate.
Although the election ballot will be 40 centimeters long to accommodate all the symbols of the old and new parties, it won’t contain the name of even a single candidate.
But the worst problem is that the majority system for the Senate could lead to a different majority gaining control there than in the Chamber of Deputies (the lower house), which may well cause legislative paralysis.
Moreover, President Carlo Azeglio Ciampi’s mandate ends at the same time that parliament dissolves, which means that his successor, elected by the new parliament, would have to nominate a government without a majority in both houses.
Berlusconi and Prodi have ruled out a German-style grand coalition – an outcome that seems especially unlikely following an election campaign in which both contestants have strongly hinted that their opponent has no legitimate right to govern.
At the same time, holding another vote would leave the question of the electoral law unresolved.
The puzzle of Berlusconi’s survival reflects a wider European conundrum.
Many Europeans, not just Italians, are nervous and unsure of where the continent is going.
So it is no surprise that an opportunist and charlatan like Berlusconi continues to get a hearing.
Italians must decide upon the sort of Italy they want if they are to get leaders of the stature they need.
CAMBRIDGE: Leaders from the G8 countries left Cologne without agreeing on institutional reform for the world's financial system.
Before they begin to tinker they should ponder the following scenario.
Financial market deregulation in an un-named country sets off a credit boom and an explosion in equity and real estate prices.
Private sector debt, increasingly short-term, shoots up from 85% of GDP to 135% within five years.
As the currency appreciates in real terms, exports falter and the current account deficit widens, and the government balks at devaluation.
Soon, devaluation in a nearby country reveals how vulnerable the economy is to the loss of international confidence.
Suddenly, foreign creditors curtail short-term credit lines.
The central bank tries to hold the exchange rate, but eventually is forced to let the currency float.
The result is a currency collapse and a wave of bankruptcies.
The economy confronts its most severe economic crisis in many decades.
Is the country Mexico in 1994-1995?
Thailand or South Korea in 1997-1998? Actually, no.
The country in question is Sweden in 1992-1993.
Similarities between Sweden then and major developing economies recently are reminders that in a world of capital mobility financial crises can overwhelm all kinds of countries, regardless of their structural features.
Crony capitalism, corruption, weak rule of law, lack of transparency, inadequate financial regulation and prudential supervision, poor corporate governance, non-enforcement of bankruptcy procedures, an insufficiently open capital account, overly-ambitious industrial policies -- these were the features of Asian countries that supposedly precipitated the Asian financial crisis.
Yet they are hardly Swedish characteristics, or for that matter are they dominant in Finland and Norway (two countries that experienced severe financial turbulence in 1992-1993).
Nonetheless, the view that such structural elements played a key role in the crisis has come to enjoy widespread support in official circles.
The result is a remarkable development: the international community has now taken on the task of redesigning developing economies in East Asia and elsewhere.
To cite one example: the memorandum of economic policies submitted by the Korean government to the IMF (March 10th, 1999) contains one-and-a-half pages on macroeconomic policy, and twelve densely-packed pages on privatization, financial sector restructuring, prudential regulation and supervision, corporate restructuring, trade and capital account liberalization, and transparency, monitoring and data reporting.
An irony here is that conditionality on developing countries is being ratcheted up at precisely the moment when our comprehension of how the world economy works and what small countries need to do to prosper within it has been revealed to be sorely lacking.
As Alan Greenspan candidly acknowledged recently, "I have learned more about how this new international financial system works in the last twelve months than in the previous 20 years."
There are serious dangers in throwing at developing countries a Washington-consensus view of economic policy, even if this consensus is now refurbished with new international codes and standards and with "second-generation reforms."
First, the new set of external disciplines come hand-in-hand with a particular, neo-liberal model of economic development that remains untested, and will foreclose development strategies that worked in the past, and others that could work in the future.
The narrowing of national autonomy in the formulation of development strategy is a cost for which developing countries are unlikely to receive an adequate reward.
Second, it is doubtful that the new policy agenda will make the international financial system much safer.
As long as capital flows remain large relative to the liquid assets held by national governments and are easily reversible, the international economy will be hostage to spectacular boom and bust cycles.
Indeed, by focusing attention on internal structural reforms in the developing world, the risk is that the current approach will lead to complacency on short-term capital flows, increasing rather then reducing systemic risks.
Finally, the difficulties of implementing many of the institutional reforms under discussion are severely underestimated.
Today's developed countries did not acquire their institutions overnight.
It would be nice if third-world countries could somehow acquire first-world institutions, but the safe bet has to be that this will happen only when they are no longer third-world countries.
The fact that fashions in economic policy change should make us more humble in prescribing structural programs for developing countries - especially on those (in, say, East Asia) that have developed by rejecting conventional wisdom and espousing heterodox policies.
The reality is that our prescriptions often go beyond what can be supported by careful theoretical reasoning or empirical demonstration.
Ignorance calls for humility.
Back to Sweden in 1992.
How did the Swedes deal with their financial crisis?
To begin with, they enacted a general guarantee for the entire banking system to stem panic (providing blanket protection to all but the shareholders).
This was followed by a recapitalization of the banking sector.
They also pursued an expansionary monetary policy and let interest rates slide.
The budget deficit was allowed to increase.
Real GDP began to recover in 1994 after three years of decline.
Imagine now that Sweden had been an ordinary developing country and that the IMF had been called in.
What would the Fund have recommended?
Presumably bank closures, higher interest rates, and fiscal tightening to restore market confidence.
No doubt many structural reforms as well.
It wouldn't have escaped the Fund's attention that the Swedish public sector plays a significant role in the economic life of the country: taxes are high, public employment is large, and government spending is close to half of GDP.
What better candidate for structural reform than a dismantling of the Swedish welfare state?
Would the IMF have made its assistance conditional on significant reforms in labor markets and in the social insurance system?
Probably yes.
Would Sweden have been better off today as a result?
Not likely.
Would it have been a good idea for the IMF to extend its conditionality in this manner?
Almost certainly not.
CAMBRIDGE – In the 1950’s, many Americans feared that the Soviet Union would surpass the United States as the world’s leading power.
The Soviet Union had the world’s largest territory, the third largest population, and the second largest economy, and it produced more oil and gas than Saudi Arabia.
Moreover, the USSR possessed nearly half of the world’s nuclear weapons, had more men under arms than the US, and had the most people employed in research and development.
It detonated a hydrogen bomb in 1952, only one year after the US, and it was the first to launch a satellite into space, in 1957.
In terms of soft power, communist ideology was attractive in post-World War II Europe, owing to its anti-fascist credentials, and in the Third World because of its identification with popular national-independence movements.
Soviet propaganda actively fostered a myth of the inevitability of communism’s triumph.
Nikita Khrushchev famously boasted in 1959 that the Soviet Union would overtake the US by 1970, and by 1980 at the latest.
As late as 1976, Leonid Brezhnev told the French president that communism would dominate the world by 1995.
Such predictions were bolstered by reportedannual economic growth rates of 5-6% and an increase in the USSR’s share of global output, from 11% to 12.3%, between 1950 and 1970.
After that, however, the Soviet growth rate and share of global output began a long decline.
In 1986, Mikhail Gorbachev described the Soviet economy as “very disordered.
We lag in all indices.”
A year later, Foreign Minister Eduard Shevardnadze told his officials, “You and I represent a great country that in the last 15 years has been more and more losing its position as one of the leading industrially developed nations.”
What is surprising in retrospect is how wildly inaccurate Western assessments of Soviet power were.
In the late 1970’s, a “Committee on the Present Danger” argued that Soviet power was surpassing that of the US, and the 1980 American election reflected such fears.
Yet in 1991, the Soviet Union collapsed.
The end of the Soviet Union left Russia significantly shrunken territorially (76% of the USSR), demographically (50% of the USSR’s population), economically (45% of the USSR’s output), and in terms of military personnel (33% of the USSR’s armed forces).
Moreover, the soft power of communist ideology had virtually disappeared.
Nonetheless, Russia had nearly 5,000 deployed nuclear weapons, and more than one million armed forces, though its total military expenditure was only 4% of the world total (compared to 40% for the US), and its ability to project power globally had greatly diminished.
In economic resources, Russia’s $2.3 trillion GDP was 14% that of the US at independence, and its $16,000 per capita income (measured in terms of purchasing power parity) was roughly 33% that of the US.
Its economy was heavily dependent on revenue from oil and gas, with high-tech goods representing only 7% of its manufactured exports (compared to 28% for the US).
In terms of soft power, despite the attractiveness of traditional Russian culture, Russia has little global presence.
In the words of Russian analyst Sergei Karaganov, Russia has to use “hard power, including military force, because it lives in a much more dangerous world and has no one to hide behind from it, and because it has little soft power – that is, social, cultural, political, and economic attractiveness.”
Russia is no longer hampered by communist ideology and a cumbersome central-planning system, and the likelihood of ethnic fragmentation, though still a threat, has waned.
Whereas ethnic Russians comprised only 50% of the Soviet Union’s population, they now make up 81% of the Russian Federation.
The political institutions needed for an effective market economy are largely missing, and corruption is rampant.
Russia’s robber-baron capitalism lacks the kind of effective regulation that creates trust in market relationships.
The public-health system is in disarray, mortality rates have increased, and birthrates are declining.
The average Russian male dies at 59 – extraordinarily low for an advanced economy.
Estimates by United Nations demographers suggest that Russia’s population may decline from 145 million today to 121 million by mid-century.
Many Russian futures are possible.
At one extreme, some view Russia as an industrialized banana republic whose corrupt institutions and insurmountable demographic and health problems make decline inevitable.
Others argue that reform and modernization will enable Russia to surmount its problems, and that its leadership is headed in this direction.
Late in 2009, President Dmitri Medvedev issued a sweeping call for Russia to modernize its economy, wean itself from a humiliating dependence on natural resources, and do away with Soviet-style attitudes that he said were hindering its effort to remain a world power.
But, as Katinka Barysch of the Centre for European Reform argues, Russian leaders’ concept of modernization is overly statist, particularly given that public institutions function so badly. “An innovative economy needs open markets, venture capital, free thinking entrepreneurs, fast bankruptcy courts and solid protection of intellectual property,” she argues.
Instead there are “wide-spread monopolies, ubiquitous corruption, stifling state interferences, weak and contradictory laws.”
Dysfunctional government and pervasive corruption make modernization difficult.
Peter Aven, president of Alfa Bank, argues that, “economically, it looks like the Soviet Union more and more.
There is a huge dependency on oil, a need for capital, a need for serious reforms, while the social burden is very strong.
Stagnation is the main threat.” A Russian economist says flatly that, “there is no consensus in favor of modernization.”
Whatever the outcome, because of its residual nuclear strength, its great human capital, its skills in cyber-technology, and its location in both Europe and Asia, Russia will have the resources to cause major problems for or to make major contributions to a globalized world.
We all have an interest in Russian reform.
MOSCOW – Russia’s economy is collapsing, but the situation could be even worse.
The global economic crisis has finally forced the government to adopt sensible policies, thereby staving off disaster – at least for now.
Official forecasts for Russian GDP growth in 2009 remain positive, but most analysts, including government officials, are bracing for a severe recession – which, indeed, appears to have started in the fourth quarter of 2008.
The stock market’s collapse – its 72% fall is the largest of all major emerging markets – is only the most visible sign of this.
Even Russia’s oligarchs are pawning their yachts and selling their private jets.
Signs of political instability are mounting.
The approval ratings for Russia’s president and prime minister are heading south.
Mass street protests have started – not led by opposition political parties but by workers and middle-class families facing job losses and declining wages.
More importantly, protesters are demanding that the government resign –unthinkable just a year ago.
With oil prices plummeting 70% from their peak (and similar price declines for metals, Russia’s other major export), it is no surprise that Russia is facing severe economic challenges.
Growth is endangered, the ruble is weak, and the government budget is in deficit.
Nevertheless, up to now, Russia’s government and private sector have weathered the storm reasonably well.
Critics of Vladimir Putin’s regime argue that Russia’s political system is too centralized and risks collapse in today’s economic storm.
The regime’s ideology, after all, places the state and loyalty to the rulers ahead of private property and merit.
When the crisis hits with full force, the government would nationalize major banks and companies, with the resulting inefficiency then burying the Russian economy, just as it doomed the Soviet Union.
Russia’s government has, in fact, made serious mistakes in dealing with the crisis.
Taxpayers’ money was spent to purchase corporate stocks in a failed attempt to support collapsing stock prices.
The government is unlikely to recover its investment anytime soon.
The government was also too slow in depreciating the ruble.
While one can argue that one-off devaluation was risky – as it could have triggered a panic – gradual depreciation should have started earlier than it did.
In the last two months of 2008, the central bank allowed the ruble to weaken at a rate of 1% per week, then at 2-3% per week.
It probably still needs to fall another 10%.
In the meantime, the central bank hemorrhaged reserves defending this slow correction, while commercial banks have been holding on to dollars in anticipation of the ruble’s further decline.
The third mistake was to raise import duties, especially for imported cars.
This was not only economically foolish (as with many other import-competing sectors, the automotive industry will certainly be protected by the weakening ruble), but also politically dangerous.
Car owners are an affluent, socially active, and easily organized group.
Street protests against the import duties became the first serious popular uprising that Russia has seen in many years.
Yet these mistakes are relatively minor and reversible.
Indeed, Russia’s government, unexpectedly, has taken resolute and mostly correct economic decisions.
First, it prevented the collapse of the banking system.
Many Russian banks were heavily exposed in foreign markets, and therefore faced severe financial problems once the crisis hit.
A massive liquidity injection by the government ensured that no major bank collapsed, and minor bank failures were administered in a surprisingly orderly fashion.
Moreover, the crisis has – so far – not resulted in major nationalizations of private companies.
The government could have used the crisis to nationalize all banks and companies in financial distress.
It has not, despite its still awesome foreign reserves, which give it the wherewithal to buy out a significant portion of the economy at fire-sale prices.
Instead, up to now at least, the government has mostly been providing (high-interest) loans rather than engaging in massive equity buyouts.
Nor have the oligarchs been bailed out.
Of $50 billion in external debt owed by Russian banks and firms in 2008, the government refinanced only $10 billion.
Apparently, the terms offered by the government (LIBOR+5% and collateral) have turned out to be right on target.
How did reasonable economic policies prevail in this crisis?
The key factor is that, for the first time since Putin came to power, the Kremlin perceives a genuine threat.
The years of easy popularity are over.
All the ugly facts that Russians ignored during the years of fast economic growth are bubbling to the surface.
The regime knows that its survival depends on preventing economic collapse.
The crisis energized the system and shifted decision-making power to those who know about and can do something for the economy.
But did these policy changes come too late?
The ossified, corrupt, inefficient economy built in the fat years of the oil boom may be impossible to save.
So the central question that Russia confronts is whether even competent economic policy can prevent economic and political collapse.
Terrorism is likely to define the year 2006 as much as it has ever year since 2001.
Years from now, historians will likely label the opening years of the twenty-first century the “Age of Terrorism.”
As with any new era, we do not yet fully understand what is happening and why.
While most of the world recognizes the problem, there are very different views on its causes and cures.
This much we know: terrorism is fueled by anger and frustration.
Radicals use the inability to attain political objectives peacefully to inspire fanatical action and to justify forms of violence normally considered unacceptable.
Beyond this basic point, however, there is less agreement on why frustration and anger lead to terrorism in some cases but not in others.
Moreover, there are two broad schools of thought as to the appropriate response when they do fuel extremist violence.
One school believes that modern terrorism cannot be eradicated, or that the costs of doing so are unacceptably high.
For this group, the only logical policy is to “ride out the storm” by ending policies which increase anger and frustration, and improving intelligence and defenses.
The second school of thought contends that terrorism can be eradicated by addressing its root causes.
Ironically, its adherents include both George W. Bush and Osama bin Laden.
For bin Laden and those who share his ideas, anger and frustration in the Islamic world stem from outside repression and exploitation of Muslims.
If the repression ends, so, too, will terrorism.
Until then, all means are legitimate when fighting a powerful and wicked enemy.
Terrorism, for bin Laden and his allies, is the only method available to strike at the West effectively. “It is permissible,” according to bin Laden’s ally in Iraq, Abu Musab Zarqawi, “to spill infidel blood.”
Bush, in contrast, believes that terrorism is rooted in the absence of political and economic opportunity.
Rather than grappling with this, radicals like bin Laden blame outsiders, particularly the United States and Europe.
But the ultimate solution, according to Bush, is the creation of fair and open political and economic systems that can eliminate anger and frustration through peaceful means.
Extremists might still exist, but they would be marginalized, finding few recruits or supporters.
Unfortunately, every approach has shortcomings.
The belief that terrorism cannot be eradicated assumes that the ability to tolerate terrorist attacks – to “ride out the storm” – is greater than the willingness of terrorists to persist, or even escalate the attacks.
By taking an essentially passive position, this approach might merely prolong the Age of Terrorism needlessly.
Moreover, appeasement is based on the dangerous assumption that the extremists’ objectives are limited – that once they attain their stated goals by using violence, they will become responsible members of the world community.
Bin Laden’s position – that terrorism will end when the Islamic world expels outside influence – is ethically and analytically flawed.
On the one hand, it would condemn hundreds of millions to live in repressive Iranian- or Taliban-style theocracies.
On the other hand, the idea that poverty and repression in the Islamic world are engineered from outside simply does not stand up to scrutiny.
Finally, the belief that democracy and economic reform will undercut terrorism is based on a series of assumptions that may or may not prove accurate.
For instance, it assumes that terrorists and their supporters do not understand their own anger.
But extremists say explicitly that their anger is caused by the injustice of the global system and the repressive policies of powerful states.
Closed political systems and stagnant economies in the Muslim world, they contend, are symptoms, not causes.
The Bush position also assumes that fundamental political and economic change is feasible and affordable – that open political and economic systems can be sustained with only modest effort – because the desire for freedom and prosperity is universal.
While true, it is not clear that a willingness to tolerate the freedom of others, which democracy requires, is equally widespread.
In some societies, democracy is simply a way for the majority to repress the minority.
In others, stability or justice is more important than political freedom.
Finally, this perspective assumes that democracies will be willing or able to control radicalism and crack down on extremists.
But history suggests that new, fragile democracies are more likely to attempt to placate radicals than to eliminate them, and that terrorists can exploit democratic governments’ respect for civil rights and the rule of law.
The horrible truth is that failure to eradicate the root causes of terrorism is almost certain to extend the Age of Terrorism, it is not clear that they really can be eradicated.
To appease the extremists might be easy but may not work.
To allow them to win would be to accept the supremacy of evil.
To promote democracy and open government might be the ultimate solution, but it stands on a shaky conceptual foundation of untested assumptions about the nature of the world and diverse cultures.
Unfortunately, the world is at a point where it can see the danger from terrorism but not the cure.
Worse still, a cure may not exist.
TRIVANDRUM, INDIA – It is fashionable these days, particularly in the West, to speak of India and China in the same breath.
These are the two big countries said to be taking over the world, the new contenders for global eminence after centuries of Western domination, the Oriental answer to generations of Occidental economic success.
Indeed, two new books explicitly twin the two countries: Robyn Meredith’s The Elephant and the Dragon: The Rise of India and China and What It Means for All of Us and Harvard business professor Tarun Khanna’s Billions of Entrepreneurs: How China and India are Reshaping their Futures – and Yours .
Both books view the recent rise of India and China as shifting the world’s economic and political tectonic plates.
Some even speak of “Chindia,” as if the two were joined at the hip in the international imagination.
Count me among the skeptics.
It is not just that China and India have little in common, save for the fact that they occupy a rather vast landmass called “Asia.”
It is also that they are already at very different stages of development.
China started its liberalization a decade and a half before India, hit double-digit growth when India was still hovering around 5%, and, with compound growth, has put itself in a totally different economic league from India, continuing to grow faster from a larger base. 
Moreover, the two countries’ systems are totally dissimilar.
If China wants to build a new six-lane expressway, it can bulldoze its way through any village in its path.
In India, if you want to widen a two-lane road, you could be tied up in court for a dozen years over compensation entitlements.
When China built the Three Gorges dam, it created a 660-kilometer long reservoir that necessitated displacing two million people – all accomplished in 15 years without a fuss in the interest of generating electricity.
When India began the Narmada Dam project, aiming to bring irrigation, drinking water, and power to millions, it spent 34 years (so far) fighting environmental groups, human rights activists, and advocates for the displaced all the way to the Supreme Court, while still being thwarted in the streets by protesters.
That is how it should be: India is a fractious democracy, China is not.
But, as an Indian, I do not wish to pretend that we can compete in the global growth stakes with China.
But if we can’t compete, can we co-operate?
The two civilizations had centuries of contact in ancient times.
Thanks mainly to the export of Buddhism from India to China, Chinese came to Indian universities, visited Indian courts, and wrote memorable accounts of their voyages.
Nalanda received hundreds of Chinese students in its time, and a few Indians went the other way; a Buddhist monk from India built the famous Lingyin Si temple in Huangzhou in the fifth century.
Southwest India’s Kerala coastline is dotted with Chinese-style fishing nets, and the favorite cooking pot of the Malayali housewife is the wok, locally called the cheen-chetti (Chinese vessel).
But it has been a while since Indians and Chinese had much to do with each other.
The heady days of Hindi-Chini bhai-bhai (“Indians and Chinese are brothers”), the slogan coined by Nehru’s India to welcome Chou En-Lai in 1955, gave way to the humiliation of the 1962 border war, after which it was “Hindi-Chini bye-bye” for decades.
The border dispute remains unresolved, with periodic incursions by Chinese troops onto Indian soil and new irritants such as the anti-Chinese protests by Tibetan exiles who have been given asylum in India.
To speak of a bilateral “trust deficit” might be an understatement.
And yet, there is some good news.
Trade has doubled in each of the last three years, to an estimated $40 billion this year; China has now overtaken the United States as India’s largest single trading partner.
Tourism, particularly by Indian pilgrims to the major Hindu holy sites in Tibet, Mount Kailash and Lake Mansarovar, is thriving.
Indian information technology firms have opened offices in Shanghai and Hangzhou, and Infosys recruited nine Chinese this year for its headquarters in Bangalore.
There are dozens of Chinese engineers working in (and learning from) Indian computer firms and engineering companies, while Indian software engineers support the Chinese telecoms equipment manufacturer Huawei.
By and large, India is strong in areas in which China needs to improve, notably software, while China excels at hardware and manufacturing, which India sorely lacks.
So India’s Mahindra and Mahindra company manufactures tractors in Nanchang for export to the US.
The key operating components of Apple’s iPod were invented by the Hyderabad company PortalPlayer, while the iPod itself are manufactured in China.
Philips employs nearly 3,000 Indians at its “Innovation Campus” in Bangalore to write more than 20% of the company’s global software, which Philips’ 50,000-strong workforce in China then turns into brand-name goods.
In other words, the elephant is already dancing with the dragon.
The only question is whether political tensions could bring the music screeching to a halt.
There is no doubt that, whatever India’s legitimate differences with China’s Communist regime, cooperation is in the best interests of both peoples.
After all, one plus one doesn’t only equal two; put together properly, it can add up to 11.
NEW YORK – The Greek financial crisis has put the very survival of the euro at stake.&nbsp; At the euro’s creation, many worried about its long-run viability.
When everything went well, these worries were forgotten.
But the question of how adjustments would be made if part of the eurozone were hit by a strong adverse shock lingered.
Fixing the exchange rate and delegating monetary policy to the European Central Bank eliminated two primary means by which national governments stimulate their economies to avoid recession.
What could replace them?
The Nobel laureate Robert Mundell laid out the conditions under which a single currency could work.
Europe didn’t meet those conditions at the time; it still doesn’t.
The removal of legal barriers to the movement of workers created a single labor market, but linguistic and cultural differences make American-style labor mobility unachievable.
Moreover, Europe has no way of helping those countries facing severe problems.
Consider Spain, which has an unemployment rate of 20% – and more than 40% among young people.
It had a fiscal surplus before the crisis; after the crisis, its deficit increased to more than 11% of GDP.
But, under European Union rules, Spain must now cut its spending, which will likely exacerbate unemployment.
As its economy slows, the improvement in its fiscal position may be minimal.
Some hoped that the Greek tragedy would convince policymakers that the euro cannot succeed without greater cooperation (including fiscal assistance).
But Germany (and its Constitutional Court), partly following popular opinion, has opposed giving Greece the help that it needs.
To many, both in and outside of Greece, this stance was peculiar: billions had been spent saving big banks, but evidently saving a country of eleven million people was taboo!
It was not even clear that the help Greece needed should be labeled a bailout: while the funds given to financial institutions like AIG were unlikely to be recouped, a loan to Greece at a reasonable interest rate would likely be repaid.
A series of half-offers and vague promises, intended to calm the market, failed.
Just as the United States had cobbled together assistance for Mexico 15 years ago by combining help from the International Monetary Fund and the G-7, so, too, the EU put together an assistance program with the IMF.
The question was, what conditions would be imposed on Greece?
How big would be the adverse impact?
For the EU’s smaller countries, the lesson is clear: if they do not reduce their budget deficits, there is a high risk of a speculative attack, with little hope for adequate assistance from their neighbors, at least not without painful and counterproductive pro-cyclical budgetary restraints.
As European countries take these measures, their economies are likely to weaken – with unhappy consequences for the global recovery.
It may be useful to see the euro’s problems from a global perspective.
The US has complained about China’s current-account (trade) surpluses; but, as a percentage of GDP, Germany’s surplus is even greater.
Assume that the euro was set so that trade in the eurozone as a whole was roughly in balance.
In that case, Germany’s surplus means that the rest of Europe is in deficit.
And the fact that these countries are importing more than they are exporting contributes to their weak economies.
The US has been complaining about China’s refusal to allow its exchange rate to appreciate relative to the dollar.
But the euro system means that Germany’s exchange rate cannot increase relative to other eurozone members.
If the exchange rate did increase, Germany would find it more difficult to export, and its economic model, based on strong exports, would face a challenge.
At the same time, the rest of Europe would export more, GDP would increase, and unemployment would decrease.
Germany (like China) views its high savings and export prowess as virtues, not vices.
But John Maynard Keynes pointed out that surpluses lead to weak global aggregate demand – countries running surpluses exert a “negative externality” on their trading partners.
Indeed, Keynes believed that it was surplus countries, far more than deficit countries, that posed a threat to global prosperity; he went so far as to recommend a tax on surplus countries.
The social and economic consequences of the current arrangements should be unacceptable.
Those countries whose deficits have soared as a result of the global recession should not be forced into a death spiral – as Argentina was a decade ago.
One proposed solution is for these countries to engineer the equivalent of a devaluation – a uniform decrease in wages.
This, I believe, is unachievable, and its distributive consequences are unacceptable.
The social tensions would be enormous.
It is a fantasy.
There is a second solution: the exit of Germany from the eurozone or the division of the eurozone into two sub-regions.
The euro was an interesting experiment, but, like the almost-forgotten exchange-rate mechanism (ERM) that preceded it and fell apart when speculators attacked the British pound in 1992, it lacks the institutional support required to make it work.
There is a third solution, which Europe may come to realize is the most promising for all: implement the institutional reforms, including the necessary fiscal framework, that should have been made when the euro was launched.
It is not too late for Europe to implement these reforms and thus live up to the ideals, based on solidarity, that underlay the euro’s creation.
But if Europe cannot do so, then perhaps it is better to admit failure and move on than to extract a high price in unemployment and human suffering in the name of a flawed economic model.
Russia’s gradual inclusion in the G-8 was supposed to nurture the growth of democracy, foster creation of a free-market economy, and encourage constructive behavior in international relations.
Instead, Russia’s leaders have become more interested in consolidating state power at home and abroad than in promoting democracy, protecting human rights, and cooperating with the West.
The collapse of the USSR, President Vladimir Putin has proclaimed, was the greatest geopolitical catastrophe of the twentieth century.
Obviously, the USSR is not about to be resurrected.
But Putin has moved to reassert state control over strategic sectors of the economy, including oil and gas, communications, pipelines, electricity and banking, as well as limiting political rights, harassing independent groups, and strengthening control over the media.
Moreover, Russia is coming to the fore, firmly and confidently, to regain its Great Power status.
Putin continues to pursue a brutal military campaign in Chechnya while intervening politically in Soviet successor states like Ukraine, Georgia, Moldova, and Belarus and rejecting Western tactics aimed at curbing Iran’s and North Korea’s nuclear ambitions.
Putin’s position is reinforced by strong public support, as well as by the dramatically weakened position of major Western leaders.
George W. Bush and Tony Blair have lost the popularity they enjoyed before the Iraq war, and Blair, together with French President Jacques Chirac, will soon leave the political scene.
Angela Merkel in Germany and Romano Prodi in Italy are ruling with weak coalition governments.
In these circumstances, given Russia’s continuing failure to meet the G-8’s political and economic standards, the upcoming summit in St. Petersburg could produce a backlash, eroding the legitimacy, credibility, and relevance of the world’s most developed countries.
Indeed, Russia and the world may well see in the summit the G-8’s silent approval of Putin’s domestic and foreign policies.
Clearly, there are many who would endorse former Soviet President Mikhail Gorbachev’s recent call on Western countries to stop pressuring Putin over human rights.
According to Gorbachev, Western pressure merely strengthens Putin, “because in essence his position is very close to the aspirations of the people.” Bush has echoed that sentiment, telling CNN ahead of his trip to the summit that admonishing the Russian president in public on matters such as democracy and human rights would be counterproductive.
“No leader likes to be scolded publicly,” he said.
But can the West afford to remain aloof?
Russia started off its year as G-8 president with a crisis over gas supplies to Ukraine, and even threatened Europe with rerouting its gas exports to Asia.
Putin has placed energy security at the top of the summit’s agenda, but that does not mask Russia’s ambition to dominate European markets by controlling the pipelines that carry its oil and gas, the refineries that process it, and the retail outlets that sell it.
The dilemma facing the West is that it needs Russia’s backing not only on policy toward Iran and North Korea, but also in Afghanistan, Iraq, and the Middle East as a whole.
Unfortunately, Bush’s strategy of democracy promotion has mainly contributed to unease around the world and alienation from Western goals.
Especially in view of the Iraq experience, Putin has won substantial public sympathy by arguing that opposition to Western democracy promotion is resistance not to democracy itself, but to Western intervention against Russian “sovereign democracy.”
Clearly, an ostracized Russia is a dangerous Russia.
But to hold a G-8 meeting in St. Petersburg in an atmosphere of “business as usual” may be even more dangerous.
Bush and European leaders issued a statement after their recent meeting in Austria saying that Russia must honor “democratic freedoms, respect for human rights, civil society and transparency, and a responsible approach to energy security.”
But words alone are not enough.
Nor should it be the end of the story.
The G-8’s seven democratic countries should use the St. Petersburg summit as an opportunity to reaffirm their will to develop close and friendly relations with Russia.
But if their inclusion of Russia is to serve a useful purpose, they must also reaffirm the values that unite them.
When world financial leaders meet in Singapore this month for the joint World Bank/International Monetary Fund meetings, they must confront one singularly important question.
Is there any way to coax the IMF’s largest members, especially the United States and China, to help diffuse the risks posed by the world’s massive trade imbalances?
This year, the US will borrow roughly $800 billion to finance its trade deficit.
Incredibly, the US is now soaking up roughly two-thirds of all global net saving, a situation without historical precedent.
While this borrowing binge might end smoothly, as US Federal Reserve Chairman Ben Bernanke has speculated, most world financial leaders are rightly worried about a more precipitous realignment that would likely set off a massive dollar depreciation and possibly much worse.
Indeed, if policymakers continue to sit on their hands, it is not hard to imagine a sharp global slowdown or even a devastating financial crisis.
Although Bernanke is right to view a soft landing as the most likely outcome, common sense would suggest agreing on some prophylactic measures, even if this means that the US, China, and other large contributors to the global imbalances have to swallow some bitter medicine.
Unfortunately, getting politicians in the big countries to focus on anything but their own domestic imperatives is far from easy.
Though the comparison is unfair, it is hard not to recall the old quip about the IMF’s relative, the United Nations: “When there is a dispute between two small nations, the UN steps in and the dispute disappears.
When there is a dispute between a small nation and a large nation, the UN steps in and the small nation disappears.
When there is a dispute between two large nations, the UN disappears.”
Fortunately, the IMF is not yet in hiding, even if some big players really don’t like what it has to say.
The IMF’s head, the Spaniard Rodrigo Rato, rightly insists that China, the US, Japan, Europe, and the major oil exporters (now the world’s biggest source of new capital) all take concrete steps towards alleviating the risk of a crisis.
Though the exact details remain to be decided, such steps might include more exchange-rate flexibility in China, and perhaps a promise from the US to show greater commitment to fiscal restraint.
Oil exporters could, in turn, promise to increase domestic consumption expenditure, which would boost imports.
Likewise, post-deflation Japan could promise never again to resort to massive intervention to stop its currency from appreciating.
Europe, for its part, could agree not to shoot its recovery in the foot with ill-timed new taxes such as those that Germany is currently contemplating.
Will the IMF be successful in brokering a deal?
The recent catastrophic collapse of global trade talks is not an encouraging harbinger.
Europe, Japan, and (to a much lesser extent) the US, were simply unwilling to face down their small but influential farm lobbies.
The tragic result is that some of the world’s poorest countries cannot export their agricultural goods, one of the few areas where they might realistically compete with the likes of China and India.
Fortunately for Rato, addressing the global imbalances can be a win-win situation.
The same proposed policies for closing global trade imbalances also, by and large, help address each country’s domestic economic concerns.
For example, China needs a stronger exchange rate to help curb manic investment in its export sector, and thereby reduce the odds of a 1990’s style collapse.
As for the US, a sharp hike in energy taxes on gasoline and other fossil fuels would not only help improve the government’s balance sheet, but it would also be a way to start addressing global warming.
What better way for new US Treasury Secretary Hank Paulson, a card-carrying environmentalist, to make a dramatic entrance onto the world policy stage?
Similarly, the technocrats at the Bank of Japan surely realize that they could manage the economy far more effectively if they swore off anachronistic exchange-rate intervention techniques and switched whole-heartedly to modern interest-rate targeting rules such as those used by the US Federal Reserve and the European Central Bank.
With Europe in a cyclical upswing, tax revenues should start rising even without higher tax rates, so why risk strangling the continent’s nascent recovery in the cradle?
Saudi Arabia, with its burgeoning oil revenues, could use a big deal to reinforce the country’s image as a major anchor of global financial stability.
If today’s epic US borrowing does end in tears, and if world leaders fail to help the IMF get the job done, history will not treat them kindly.
Instead, they will be blamed for not seeing an impending catastrophe that was staring them in the face.
Let’s hope that on this occasion in international diplomacy, the only thing that disappears are the massive global trade imbalances, and not the leaders and institutions that are supposed to deal with them.
NEW DELHI – The target date for fulfilling the Millennium Development Goals is 2015, and the world knows it is not on course to meet those goals.
So world leaders are set to gather at the United Nations to undertake a comprehensive review, with the aim of agreeing on a roadmap and a plan of action to get to the MDG finishing line on schedule.
I was at the UN in September 2000, when world leaders met at the Millennium Summit and pledged to work together to free humanity from the “abject and dehumanizing conditions of extreme poverty,” and to “make the right to development a reality for everyone.”
These pledges include commitments to improve access to education, health care, and clean water for the world’s poorest people; abolish slums; reverse environmental degradation; conquer gender inequality; and cure HIV/AIDS.
It’s an ambitious list, but its capstone is Goal 8, which calls for a “global partnership for development.”
This includes four specific targets: “an open, rule-based, predictable, non-discriminatory trading and financial system”; special attention to the needs of least-developed countries; help for landlocked developing countries and small island states; and national and international measures to deal with developing countries’ debt problems.
Basically, it all boiled down to a grand bargain: while developing countries would obviously have primary responsibility for achieving the MDGs, developed countries would be obliged to finance and support their efforts for development.
This hasn’t really happened.
At the G-8 summit at Gleneagles and the UN World Summit in 2005, donors committed to increasing their aid by $50 billion at 2004 prices, and to double their aid to Africa from 2004 levels by 2010.
But official development assistance (ODA) last year amounted to $119.6 billion, or just 0.31% of the developed countries’ GDP – not even half of the UN’s target of 0.7% of GDP.
In current US dollars, ODA actually fell by more than 2% in 2008.
The UN admits that progress has been uneven, and that many of the MDGs are likely to be missed in most regions.
An estimated 1.4 billion people were still living in extreme poverty in 2005, and the number is likely to be higher today, owing to the global economic crisis.
The number of undernourished people has continued to grow, while progress in reducing the prevalence of hunger stalled – or even reversed – in some regions between 2000-2002 and 2005-2007.
About one in four children under the age of five are underweight, mainly due to lack of quality food, inadequate water, sanitation, and health services, and poor care and feeding practices.
Gender equality and women’s empowerment, which are essential to overcoming poverty and disease, have made at best fitful progress, with insufficient improvement in girls’ schooling opportunities or in women’s access to political authority.
Progress on trade has been similarly disappointing.
Developed country tariffs on imports of agricultural products, textiles, and clothing – the principal exports of most developing countries – remained between 5% and 8% in 2008, just 2-3 percentage points lower than in 1998.
The time has come to reinforce Goal 8 in two fundamental ways.
Developed countries must make commitments to increase both the quantity and effectiveness of aid to developing countries.
Aid must help developing countries improve the welfare of their poorest populations according to their own development priorities.
But donors all too often feel obliged to make their contributions “visible” to their constituencies and stakeholders, rather than prioritizing local perspectives and participation.
There are other problems with development aid.
Reporting requirements are onerous and often impose huge administrative burdens on developing countries, which must devote the scarce skills of educated, English-speaking personnel to writing reports for donors rather than running programs.
And donor agencies often recruit the best local talent themselves, usually at salaries that distort the labor market.
In some countries, doctors find it more remunerative to work as translators for foreign-aid agencies than to treat poor patients.
Meanwhile, donors’ sheer clout dilutes the accountability of developing countries’ officials and elected representatives to their own people.
We must change the way the world goes about the business of providing development aid.
We need a genuine partnership, in which developing countries take the lead, determining what they most acutely need and how best to use it.
Weak capacity to absorb aid on the part of recipient countries is no excuse for donor-driven and donor-directed assistance.
The aim should be to help create that capacity.
Indeed, building human-resource capacity is itself a useful way of fulfilling Goal 8.
Doing so would serve donors’ interest as well.
Aligning their assistance with national development strategies and structures, or helping countries devise such strategies and structures, ensures that their aid is usefully spent and guarantees the sustainability of their efforts.
Donors should support an education policy rather than build a photogenic school; aid a health campaign rather than construct a glittering clinic; or do both – but as part of a policy or a campaign, not as stand-alone projects.
Trade is the other key area.
In contrast to aid, greater access to the developed world’s markets creates incentives and fosters institutions in the developing world that are self-sustaining, collectively policed, and more consequential for human welfare.
Many countries are prevented from trading their way out of poverty by the high tariff barriers, domestic subsidies, and other protections enjoyed by their rich-country competitors.
The European Union’s agricultural subsidies, for example, are high enough to permit every cow in Europe to fly business class around the world.
What African farmer, despite his lower initial costs, can compete?
The onus is not on developed countries alone.
Developing countries, too, have made serious commitments to their own people, and the primary responsibility for fulfilling those commitments is theirs.
But Goal 8 assured them that they would not be alone in this effort.
Unless that changes, the next five years will be a path to failure.
During World War II, Allied soldiers occupied Iran, using the country as a way station to transport supplies from the Persian Gulf to the Soviet Union.
This was Iran’s first exposure to Americans. “They arrived in our country with a certain innocence,” said the respected Iranian historian Kaveh Bayat, “and without any colonial pretenses.”
The Americans’ supply train would regularly pass through my father’s ancestral village, Arak, then a scenic oasis of green gardens and fruit orchards. “Whenever we heard the train coming,” my father once told me, “all the young boys in the village would run as fast as we could through the apple orchard to greet the passing Americans.
They would smile and wave and throw us whatever gifts they happened to have – playing cards, chewing gum, lifesaver candies….For us they were like heroes from another world.”
So much has changed since then.
Iran’s 1979 revolution did away with the pro-American, undemocratic regime of the Shah, bringing in its place the anti-American, undemocratic regime of the clerics.
Relations between the United States and Iran have been officially non-existent since a group of radical students stormed the US embassy in Teheran – 25 years ago this week – taking sixty six Americans hostage for 444 days.
Sixty years ago, Arak was a humble village known to US troops for its grapes; today Pentagon officials hone in on it as an industrial city that is integral to Iran’s worrisome nuclear program.
And yet few countries have a more paradoxical relationship than the US and Iran.
While the Iranian regime continues to be belligerently anti-American, the Iranian people are overtly pro-American.
While the governments in Teheran and Washington appear to be strategic archrivals, in the words of former Secretary of State Henry Kissinger, “there are few nations in the world with which the United States has less reason to quarrel or more compatible interests than Iran.”
Indeed, Iran has likely benefited more than any other country from US-led regime changes in Afghanistan and Iraq, as both the Taliban and Saddam Hussein were the country’s sworn enemies.
But neither side seized the opportunity to build on this common ground, and today US-Iran relations are as antagonistic as they have been in years.
For the US, Iran’s nuclear ambitions, opposition to Israel, and support for extremist groups have become increasingly intolerable in the context of the war on terror.
Iran’s long-standing opposition to relations with the US is a bit more complex.
To be sure, many of Iran’s ruling elites came of age politically during the anti-imperialist and anti-colonialist agitations of the 1960’s and 1970’s, and still cling to that worldview.
Although their revolutionary zeal may have waned over the years, they still tend to share the outlook of the late Ayatollah Khomeini, who likened the relationship between Iran and the US to that “between a sheep and a wolf.”
Ideological rigidity alone, however, does not explain Iran’s often-gratuitous anti-Americanism.
For Iran’s political and military elite, any increased liberalization that would likely result from an opening of ties with the US represents a threat to their interests.
From their perspective, Iran is now a closed party – their party – and the less who join in, the merrier.
With America bogged down in Iraq and oil prices hitting record highs, regime hardliners see little reason to compromise these days.
On the other hand, some influential Iranians – led by former president Hashemi Rafsanjani – recognize that relations with the US are inevitable, given Iran’s need to re-integrate into the international community and face its economic deficiencies.
Moreover, the Iranian people are overwhelmingly in favor of rapprochement.
As author Afshin Molavi wrote in his incisive travelogue Persian Pilgrimages , Iranian youth today are not revolutionary idealists, like those of three decades ago.
Instead, they have concrete demands, like jobs and political and social freedom.
They are desperate to enter the global community and rid themselves of a damaged international reputation.
Today’s Iranian intellectuals have undergone a similar maturation process, dismissing the “utopianist” and “nativist” political ideals of their predecessors.
Referring to Jalal Al-e Ahmad’s 1962 book Gharbzadegi (“West-toxication”), which became one of the manifestos of the 1979 revolution, one secular intellectual in Teheran remarked to me that, “Nobody reads Al-e Ahmad anymore.
On the contrary, we long for interaction with the West.
If it can bring us more economic opportunities, as well as social and political freedoms, let us be ‘West-toxified.’”
Still, despite popular demand in Iran, and common strategic interests, it could be years before America and Iran sit down and make amends.
After 25 years of living without each other, reconciliation will not come immediately.
When it does, there is good reason to believe that Iranians will greet their long lost friends with the same friendliness and exuberance that they did sixty years ago in Arak.
PRINCETON – The small Himalayan kingdom of Bhutan is known internationally for two things: high visa fees, which reduce the influx of tourists, and its policy of promoting “gross national happiness” instead of economic growth.
The two are related: more tourists might boost the economy, but they would damage Bhutan’s environment and culture, and so reduce happiness in the long run.
When I first heard of Bhutan’s goal of maximizing its people’s happiness, I wondered if it really meant anything in practice, or was just another political slogan.
Last month, when I was in the capital, Thimphu, to speak at a conference on “Economic Development and Happiness,” organized by Prime Minister Jigme Y. Thinley and co-hosted by Jeffrey Sachs, Director of The Earth Institute at Columbia University and Special Adviser to United Nations Secretary-General Ban Ki-moon, I learned that it is much more than a slogan.
Never before have I been at a conference that was taken so seriously by a national government.
I had expected Thinley to open the conference with a formal welcome, and then return to his office.
Instead, his address was a thoughtful review of the key issues involved in promoting happiness as a national policy.
He then stayed at the conference for the entire two and a half days, and made pertinent contributions to our discussions.
At most sessions, several cabinet ministers were also present.
Since ancient times, happiness has been universally seen as a good.
Problems arise when we try to agree on a definition of happiness, and to measure it.
One important question is whether we see happiness as the surplus of pleasure over pain experienced over a lifetime, or as the degree to which we are satisfied with our lives.
The former approach tries to add up the number of positive moments that people have, and then to subtract the negative ones.
If the result is substantially positive, we regard the person’s life as happy; if negative, as unhappy.
So, to measure happiness defined in that way, one would have to sample moments of people’s existence randomly, and try to find out whether they are experiencing positive or negative mental states.
A second approach asks people: “How satisfied are you with the way your life has gone so far?” If they say they are satisfied, or very satisfied, they are happy, rather than unhappy.
But the question of which of these ways of understanding happiness best captures what we should promote raises fundamental questions of value.
On surveys that use the first approach, countries like Nigeria, Mexico, Brazil, and Puerto Rico do well, which suggests that the answer may have more to do with the national culture than with objective indicators like health, education, and standard of living.
When the second approach is taken, it tends to be the richer countries, like Denmark and Switzerland, that come out on top.
But it is not clear whether people’s answers to survey questions in different languages and in different cultures really mean the same thing.
We may agree that our goal ought to be promoting happiness, rather than income or gross domestic product, but, if we have no objective measure of happiness, does this make sense?
John Maynard Keynes famously said: “I would rather be vaguely right than precisely wrong.” He pointed out that when ideas first come into the world, they are likely to be woolly, and in need of more work to define them sharply.
That may be the case with the idea of happiness as the goal of national policy.
Can we learn how to measure happiness?
The Center for Bhutan Studies, set up by the Bhutanese government 12 years ago, is currently processing the results of interviews with more than 8,000 Bhutanese.
The interviews recorded both subjective factors, such as how satisfied respondents are with their lives, and objective factors, like standard of living, health, and education, as well as participation in culture, community vitality, ecological health, and the balance between work and other activities.
It remains to be seen whether such diverse factors correlate well with each other.
Trying to reduce them to a single number will require some difficult value judgments.
Bhutan has a Gross National Happiness Commission, chaired by the prime minister, which screens all new policy proposals put forward by government ministries.
If a policy is found to be contrary to the goal of promoting gross national happiness, it is sent back to the ministry for reconsideration.
Without the Commission’s approval, it cannot go ahead.
One controversial law that did go ahead recently – and that indicates how willing the government is to take tough measures that it believes will maximize overall happiness – is a ban on the sale of tobacco.
Bhutanese may bring into the country small quantities of cigarettes or tobacco from India for their own consumption, but not for resale – and they must carry the import-tax receipt with them any time they smoke in public.
Last July, the UN General Assembly passed, without dissent, a Bhutanese-initiated resolution recognizing the pursuit of happiness as a fundamental human goal and noting that this goal is not reflected in GDP.
The resolution invited member states to develop additional measures that better capture the goal of happiness.
The General Assembly also welcomed an offer from Bhutan to convene a panel discussion on the theme of happiness and well-being during its 66th session, which opens this month.
These discussions are part of a growing international movement to re-orient government policies towards well-being and happiness.
We should wish the effort well, and hope that ultimately the goal becomes global, rather than merely national, happiness.
Most of the discussion surrounding how to respond to Asia’s tsunami disaster has focused on government relief programs and official schemes to implement early warning systems.
Little discussion has focused on the promotion of private risk management institutions, notably insurance.
This is unfortunate.
Insurance companies provide professional, finely detailed risk management that respects the complexity of the dangers to be hedged and responds creatively to individual needs.
Promoting private insurance may seem an indirect response to the tsunami disaster, but it is a rational – and powerful – response.
Insurance companies have not penetrated many of the regions that suffered the greatest losses.
According to a study by the Insurance Information Institute, expenditures on non-life insurance in 2003 amounted to only 0.83% of GDP in Indonesia, 1.19% of GDP in Thailand, and 0.62% of GDP in India, compared with 5.23% of GDP in the United States.
Foreign aid is no substitute for insurance.
Charity inspires, reassuring us of our humanity, but it is often capricious.
You wouldn’t want to rely on it.
Indeed, when deciding how much disaster aid to offer, countries often seem to be influenced mainly by their leaders’ concerns about how others will view them.
Charity responds to attention-grabbing events, often neglecting less sensational disasters.
Insurance, on the other hand, is a reliable and venerable institution, its modern form dating back to the seventeenth century.
But insurance and other risk management institutions have been slow to develop, even in advanced countries.
In the US, most people still do not have flood or earthquake insurance.
In California, one of the world’s most unstable geological regions, only one in six homeowners buys earthquake insurance.
A fundamental problem is that insurance is not a concept that comes naturally to most people.
In fact, as psychologists Daniel Kahneman and Amos Tversky have shown, there is a systematic human tendency to downgrade the perceived probability of low-probability events, so that people go about their lives as if the probability of these events’ occurrence is zero.
Similarly, humans tend to accept large downside risks in order to avoid small certain losses, such as insurance premiums.
Insurance companies have faced a slow and difficult process in weaning the public from these tendencies.
Moreover, designing new risk-management products is not easy.
Insurance companies face inherent difficulties in measuring risks, and they must tailor their policies creatively around the human foibles that limit uptake.
Insurers must also be attentive to a wide array of possible moral hazards – perverse incentives to risky behavior – and to problems of selection bias in attracting clients.
To deal with disasters more effectively, countries must find the will to create an environment in which a much more developed private insurance industry can flourish.
In the US, the National Flood Insurance Program of 1968 made it mandatory for those financing construction or improvement of structures within Special Flood Hazard Areas to buy flood insurance.
If not made mandatory, insurance must at least be promoted effectively.
Otherwise, people will build on flood plains in the belief that their government, or the governments of the world, will feel obligated to bail them out, thereby insuring, in effect, bad risks that should not be taken.
Many of the worst outcomes in Asia occurred in tsunami-prone areas, such as the low-lying coastal areas of Sri Lanka.
Private insurance would discourage construction in the most dangerous locations, owing to prohibitively high premiums, while encouraging the adoption of tsunami-resistant building standards in marginal areas.
Fortunately, our international risk-management institutions are steadily improving.
Various catastrophe bonds, covering earthquakes and other disasters, and weather derivatives have begun trading on financial markets in recent years.
The Kyoto Protocol created a mechanism for trading carbon dioxide emissions, which promises to manage the risks of an even bigger potential disaster: global warming.
The markets for these products are still small, but they have strong growth potential, and their further development would enhance insurance companies’ ability to cover risks of major international disasters.
Consider the absence of an early tsunami warning system in the worst affected countries.
It is easy to blame people for lack of foresight, but none of the nine hardest hit countries had developed one.
They can’t all be bunglers.
The problem is not individual error.
The failure was caused by the absence of appropriate international institutions that would be alert to the broad spectrum of potential disasters.
Discussion of early warning systems for tsunamis has focused on government programs.
But early warning means more than ocean sensors and satellites; it also implies directing construction away from disaster-prone areas and prodding private businesses to develop effective safety and evacuation procedures.
These are normal activities of insurance companies.
Indeed, one of the more striking features of the tsunami disaster was that it caught some of the most glamorous vacation resorts completely unprepared.
The lesson is clear: even high-class businesses are only as professional as the existing institutional infrastructure permits them to be.
The ultimate reason for their lack of preparation is that our insurance industry was not covering their tsunami risks, and hence not offering up-to-date disaster-prevention guidance.
The insurance industry can, and should, respond to the tsunami disaster by accepting the moral imperative to take concerted action to expand risk coverage.
To the extent that governments are involved, they can promote better risk management through responsive regulation and even subsidization of experiments with new private insurance products.
MILAN – In the past two years, two dangerous episodes of financial instability and sudden changes in market dynamics have hit the world economy.
More are likely, because the global economy is out of balance in several respects as it emerges from the crisis, particularly in terms of sovereign debt and the structure of global demand.
Systemic risks drive most crises, and pose a challenge for several reasons.
First, they are not easy to detect with confidence, and are even more difficult to prove.
Second, predicting the exact timing of a break point (when bubbles burst, markets lock up, and credit freezes) is, and will likely remain, beyond our ability.
Finally, crises are highly non-linear events, which means that they occur without much warning.
Periodic outbreaks of instability impose high social costs on those who had the least to do with causing them.
If repeated, this pattern may erode confidence in financial markets and regulators, which could well lead to heavy-handed regulation, the expansion of the state, and retrenchment from globalization.
But the problem is even more serious.
The financial and economic crisis is morphing into a sovereign debt crisis in advanced countries.
Financial and economic imbalance can lead to dangerous fiscal imbalance, as tax revenues plunge and social insurance and bailout expenditures rise.
The International Monetary Fund suggests that as much as 75% of the “fiscal stimulus” in the advanced countries comprises non-discretionary counter-cyclical measures.
Undetected imbalances and systemic risk make fiscal policies seem prudent when they are not.
Spain, for example, was not running a fiscal deficit coming into the crisis.
But its revenues and expenditures were in part determined by a highly leveraged real-estate bubble.
Extreme fiscal imbalance can also lead to a growth trap in which fiscal consolidation has such a large negative effect on growth as to be self-defeating.
Greece is probably a case in point.
Eventually, the only way out is to reset the value of liabilities via restructuring or inflation.
If systemic risk can cause this kind of cascading sequential imbalance, then the “sovereign” needs to be alert, competent at identifying rising systemic risk, and able to take corrective action early.
We are about to get a comprehensive package of re-regulation focused on capital requirements and leverage, transparency, ratings and other sources of information, incentives, conflicts of interest and limits on the scope of financial firms, consumer protection, and resolution mechanisms.
The hope is that such reforms will reduce the likelihood and severity of systemic risk.
But that doesn’t deal with global imbalances and other contributors to and signs of instability.
In addition and as a complement to re-regulation, we need a comprehensive systemic risk monitor.
Some prominent policymakers and analysts, however, argue that oversight aimed at identifying and stemming systemic risk is futile.
With incomplete models of risk dynamics and a complex and constantly changing global financial system, detection is, they argue, either impossible or so prone to error that the effort would be counter-productive.
Asset bubbles are hard to identify with certainty.
If skeptics are right, then we should accept that we will periodically be out of financial and fiscal balance without knowing it in advance.
Thus, we should also accept the need for much more conservative fiscal positioning than was thought necessary even three years ago.
In statistics and the theory of decision-making under uncertainty, errors are inevitable.  There are two kinds.
One error is to reject a true proposition; the other is to accept a false one.
Let’s call them RWT (reject when true) and AWF (accept when false).
The issue can then be framed as follows: in the context of detecting and responding to systemic risk, which of the two types of errors has the higher expected costs?   
Opponents of prudential oversight of systemic risk take two different positions.
One is that the AWF error won’t occur, because there are no reliable ex ante signs of rising potential instability.
Looking for them is a waste of resources.
Instability just strikes like lightning.
This seems wrong.
In the 2008 crisis, for example, some analysts issued warning signs, and some investors noted and responded to them.
Admittedly, these warnings did not add up to an ironclad case, and they certainly didn’t predict the timing of the break.
But the signs were there.
A second position accepts that there are warning signs, but that they are so unreliable that responding to them would do more harm than good.
This implies that AWF has a higher expected cost than RWT, because there are a lot of false positives and/or the cure is worse than the disease.
One can accept that there are costs to AWF.
But RWT is costly, too, as we have seen, so the aggregate negative effect of the policy response to false positives (AWF) would have to be large to be convincing.
I am not convinced.
There may be a deeper bias at work.
In business and investing, choices under conditions of uncertainty are made all the time, and mistakes are routine.
By contrast, developed country policymakers’ default stance seems to be that proactive or preemptive measures require a high degree of certainty, owing to a deep-seated belief that financial markets are stable and self-regulating.
If one believes that market instability is rare, then it is reasonable to refuse to act unless there is a compelling case to do so.
In light of experience, the view that the financial system is only exceptionally unstable or on an unsustainable path seems at least questionable.  
Based on new theory and experience, we may eventually conclude that policy responses to systemic risk are impossible to devise, and that the costs of the AWF errors are higher than the RWT errors.
But we should at least conduct the experiment, assigning responsibility to a new or existing institution that has access to information, deep analytical talent in both financial and macroeconomic analysis, and is relatively free of conflicts of interest.
The analysis should be made public and could influence perceptions of systemic risk and market behavior, thereby increasing self-regulatory capacity of the system.
For the past three centuries, humans’ effects on the global environment have escalated.
Most importantly, our emissions of carbon dioxide may cause global climate patterns to depart significantly from their natural course for many millennia to come.
It seems appropriate to assign the term “Anthropocene” to the current, in many ways human-dominated, geological epoch, supplementing the Holocene – the warm period of the past 10–12 millennia.
The Anthropocene Period could be said to have started in the latter part of the eighteenth century, when analyses of air trapped in polar ice showed the beginning of growing global concentrations of CO2 and methane.
This date also happens to coincide with James Watt’s design of the steam engine in 1784.
Mankind’s growing influence on the environment was recognized as long ago as 1873, when the Italian geologist Antonio Stoppani referred to the “anthropozoic era,” defined by a “new telluric force, which in power and universality may be compared to the greater forces of earth.”
In 1926, V. I. Vernadsky similarly acknowledged the increasing impact of mankind on “[t]he direction in which the processes of evolution must proceed, namely towards increasing consciousness and thought, and forms having greater and greater influence on their surroundings.” Vernadsky and Teilhard de Chardin used the term “noösphere” – the world of thought – to mark the growing role of human brain-power in shaping its own future and environment.
Humans’ rapid expansion in terms of population and per capita use of Earth’s resources has continued apace.
During the past three centuries, the human population has increased ten-fold, to more than six billion, and is expected to reach 10 billion in this century.
As a result, 30–50% of the planet’s land surface is now exploited by humans.
At the same time, the methane-producing cattle population has risen to 1.4 billion, contributing to the increasing rate of destruction of tropical rainforests, which releases carbon dioxide and contributes to faster species extinction.
Land conversion for grazing (and construction), together with crop tillage, has also caused soil erosion at 15 times its natural rate.
Indeed, at its current pace, anthropogenic soil erosion would fill the Grand Canyon in 50 years.
Similarly, dam building and river diversion have become commonplace, as humans’ water consumption has risen nine-fold over the past century, to the point that mankind now uses more than half of all accessible fresh water – roughly two-thirds of it for agriculture.
Fisheries remove more than 25% of the primary production in upwelling ocean regions and 35% in the temperate continental shelf.
Moreover, energy use has grown 16-fold during the twentieth century, causing 160 million tons of atmospheric sulfur-dioxide emissions per year – more than twice the total of natural emissions.
Likewise, more nitrogen fertilizer is applied in agriculture than is fixed naturally in all terrestrial ecosystems, and nitric-oxide production from the burning of fossil fuels and biomass also surpasses natural emissions.
At the same time, of course, human consumption of fossil fuels, together with our agricultural activities, have caused substantial increases in concentrations of “greenhouse” gases – CO2 by 30% and methane by more than 100%.
Indeed, these concentrations are higher than at any point in the past 400 millennia, with more growth to follow, because so far these effects have largely been caused by only 25% of the world population.
The consequences are numerous and profound: acid precipitation, photochemical “smog” and global warming, among others.
Hence, according to the latest estimates by the Intergovernmental Panel on Climate Change (IPCC), Earth will warm by 1.4–5.8 °C during this century.
Many toxic substances are released into the environment, even some that are not toxic but nonetheless are highly damaging – for example, the chlorofluorocarbons that caused the Antarctic ozone hole (and which are now regulated).
Things could have become much worse: the ozone-destroying properties of halogens have been studied since the mid-1970’s.
If it had turned out that chlorine behaved chemically like bromine, the ozone hole would by then have been a global, year-round phenomenon, not just an event of the Antarctic spring.
More by luck than by wisdom, this catastrophic situation did not develop. 
Unless there is a global catastrophe – a meteorite impact, a world war, or a pandemic – mankind will remain a major environmental force for many millennia.
As a result, scientists and engineers face a daunting task during the Anthropocene era: to guide us towards environmentally sustainable management.
This will require appropriate human behavior at all levels, and may well involve internationally accepted, large-scale geo-engineering projects to “optimize” climate.
At this stage, however, we are still largely treading on 
 terra incognita
 .
PITTSBURGH – In 1971, President Richard M. Nixon launched a “war” against cancer.
But, nearly four decades later, the battle remains focused on highly profitable efforts to develop drugs and technologies to treat the disease while virtually ignoring environmental factors that cause it.
True, cancer deaths have dropped chiefly because of long-delayed – and still poorly supported – efforts to curb smoking.
Successes with screening and treatment of breast, colo-rectal, and cervical cancer have also helped.
But blacks and other minorities in the United States – and elsewhere in the world – do not share in these successes, and environmental factors appear to explain the disparity.
For example, while one in eight Americans is black, one in three is employed in sanitation or other blue-collar jobs.
Moreover, they have half the level of cancer-protective vitamin D as whites, and they are much more likely to live in polluted neighborhoods.
Indeed, cases of cancer that are not tied to smoking or aging are increasing.
Cancer is the leading cause of death in middle-aged persons and children (after accidents), and we can’t explain why, for most forms of cancer, death rates are higher for blacks than they are for whites. 
What we can say is that the disease itself is the wrong enemy.
Instead, we should be attacking known environmental carcinogens – not just tobacco, but also radiation, sunlight, benzene, solvents, and some drugs and hormones.
Modern cancer-causing agents like diesel exhaust, pesticides, and other air pollutants are not systematically studied.
When they are considered at all, they are deemed to be the inevitable price of progress. 
But most cancers are made, not born, arising from damage to our genes that occurs throughout our lives.
Despite having remarkably similar genes at birth, identical twins do not develop the same cancers.
By age 50, their chromosomal bands are profoundly different from one another.
America’s Centers for Disease Control and Prevention confirm that children’s blood today contains dozens of chemicals that did not exist two decades earlier, including many gene-damaging compounds known to cause cancer and a host of other diseases.
Men and women of child-bearing age now carry enough hormone-disturbing compounds in their bodies to impair their fertility.
Women exposed to higher levels of the pesticide DDT before the age of fourteen have a five times higher chances of developing breast cancer when they reach middle age.
Could such compounds play a role in unexplained and growing rates of childhood cancer, testicular cancer, and non-Hodgkin’s Lymphoma throughout the industrial world?   Should we wait to find out?
While we are phenomenally successful at keeping young people from dying of cancer today, that success comes as a Faustian bargain.
One of three young women treated with radiation to the chest to arrest Hodgkin’s disease will develop breast cancer by age 32.
Of course, many cancers might not have developed in the first place had these patients not been exposed to other cancer-causing agents in the environment.
Our dependence on many modern conveniences makes us the subject of vast uncontrolled experiments to which none of us is asked to consent.
For example, the long-term safety of mobile phones remains unproven.
Widely publicized studies in the early 1990’s touting their safety excluded business users.
Recent reports from France and Sweden find that those who have used mobile phones for ten or more years have double the risk of brain cancer.
Also troubling is the fact that the limit for microwave emission from mobile phones is 500 times lower in Switzerland and China than in the US. 
A way of looking is a way of not looking, runs a Chinese proverb.
The limited nature of evidence on some environmental cancer hazards should not be confused with proof that no harm has occurred: the research is hard to do, and, in the US, very little of it is now funded by the government and private sector.
Moreover, confusion about environmental cancer risks also results from longstanding, carefully cultivated, and well-financed disinformation campaigns inspired by the machinations of the tobacco industry.
We cannot afford to ignore the signs of the importance of the environment for our health.
To address the scourge of cancer, we must complement efforts to detect and treat cancer with new ways to keep people from developing the disease in the first place.
Across Europe and America, there is a groundswell of debate concerning the legalization of cannibas for personal use.
Indeed, Britain has, to all intents and purposes, practically decriminalized marijuana usage.
As a neuro-scientist, I am concerned about this debate. 
One common justification for legalization or decriminalization of cannabis centers around the idea that it does not involve a victim.
But at least four reports in major medical journals
 (Ramstrom, 1998; Moskowitz, 1985; Chesher, 1995; and Ashton, 2001), show the contrary.
In a study of pilots smoking only a single moderate joint, there was a difference between a placebo control group and those taking cannabis, 
 up to 50 hours
 after taking the drug.
Other costs to the community are accidents at work or at home, educational under-attainment, impaired work performance and health budget costs. 
Another argument for relaxing our attitude to cannabis is that it is non-addictive.
Of course, defining `addiction' is hard, but if one regards it as an inability to give up, then there is strong evidence that cannabis incites dependence.
Recent papers report many users in the US, UK and New Zealand now seek treatment for dependence.
Other papers show that 10% of users want to stop or cut down, but have difficulties doing so, whilst a paper in 1998 reported that 10-15% of users become dependants. 
Recently, it was shown that withdrawal symptoms were experienced after only three days of light use.
Heavy users confront a worse situation: Dr Bryan Wells, a rehabilitation expert, comments, ``for the first time I'm beginning to see something that resembles the withdrawal symptoms produced by hard drugs in heavy cannabis users.'' 
Another argument in favor of relaxed laws on cannabis are its supposed beneficial effects on pain.
So far, that evidence is anecdotal; it is hard to exclude placebo effects.
The results from clinical trials are awaited.
But distinctions should be drawn between recreational drugs and medicines, as they are for opiates.
If cannabis is a pain-killer, then it must have a huge impact on the physical brain. 
Indeed, widespread reports exist of the impact of cannabis on the brain, in particular areas concerned with memory (hippocampus), emotion (mesolimbic system), and movement (basal ganglia).
Cannabis affects a variety of chemical systems and it works via its own `receptor,' it's own molecular target.
The fact that there is a naturally occurring analogue of cannabis in the body, as there is for morphine, provides a basic reason to differentiate it from alcohol. 
For an agent that affects a variety of transmitter systems, is as though it were a transmitter itself.
Perhaps, not surprisingly, for cannabis has a clear effect on psychology: not only is there euphoria, but often overlooked effects of anxiety, panic and paranoia.
Disorders in psychological performance, attention impairments, and memory deficits are well known. 
More disturbing - and less acknowledged - is the fact that these effects can be long-term.
In one recent paper, a comparison of ex-users who used for 9 years and abstained from 3 months to 6 years, were compared with long-term users of 10 years, and short-term users of 3 years.
In all cases the frequency of use was 10-19 days per month.
In all cases, 
 all 
 users, irrespective of whether they had given up or not, had attention impairments compared to controls. 
Although those who stopped using cannabis partially improved over those continued using cannabis, they were below the level of controls, and this impairment was related to the duration of use.
Most disturbing was the fact that no improvement in performance occurred with increasing abstinence. 
No surprise, then, that because these long-term effects seem to be irreversible, there is an effect on brain pathology.
Because much of this data comes from work with isolated systems, and therefore on all brains, an obvious criticism is that you can't extrapolate from such data.
Yet, the evidence suggests that the long-term effects must have a physical basis. 
A counter-argument to such thinking is to challenge whoever thinks that there is a `safe' dose of cannabis, with no effect on the brain, to say what that dose might be.
Even a dose comparable to one joint, and analogous levels of the active THC ingredient to that in plasma, can kill 50% of neurons in the hippocampus (an area related to memory) within 6 days. 
People, moreover, are unaware that the THC in cannabis remains in the body for over 5 days.
For someone using cannabis routinely, the dose carried in the body is higher than imagined.
It is also easy to underestimate the dose being taken, because there is a wide variety in the strength of cannabis.
Individual variations in body fat and, worryingly, disposition to psychosis, means that you cannot predict how much will affect any person at any time. 
Cannabis could well be having a serious effect on the mind, which I define as the personalization of brain circuits that reflect an individual's experiences.
A transmitter-like substance, with such powerful effects, must affect those circuits.
So `blowing your mind' might be exactly what marijuana users do. 
BALTIMORE – As each new day brings word of another Wall Street bailout even more colossal than the last, one question presents itself with ever-increasing force: why does America’s economy perform so badly under Republican presidents?
The facts are hard to dispute; indeed, the historical record is now so stark that diehard Republicans are probably starting to wonder if there is a curse.
Over the period for which modern statistics are readily available, Democrats have outperformed Republicans by almost every traditional measure of economic performance (per capita GDP growth, unemployment, inflation, budget deficits).
Democrats have even managed to beat the Republicans on their own turf.
Thanks to the profligacy of the current Bush administration (and the prudence of the Clinton administration), average Federal spending as a proportion of GDP under Republican presidents now exceeds that under Democrats during the measured period.
The pattern of Republican deficiency holds up when the span of historical analysis is extended by using stock returns to measure economic performance.
On average, since the inception of the Standard and Poor’s composite stock index in 1926, the reward for putting your money in the market has been about 16 percentage points lower per presidential term under Republicans than under Democrats.
Republican underperformance remains a stubborn fact even when the Great Depression and World War II are left out of the analysis (in the fond hope that they will prove to have been unique experiences).
With the current presidential term lurching to such a calamitous close that the incumbent is probably worried about being remembered as George Herbert Hoover Walker Bush, the correlation between presidential party and economic outcome demands some kind of explanation.
The answer can’t be found in the specific policy proposals of Republicans or Democrats, which have evolved so much over the years that they defy meaningful generalization.
Nor are there clearly identifiable differences in doctrine that should translate into a reasonable expectation of better economic performance under one party than the other.
Perhaps the best explanation has to do with attitudes, not ideology.
Maybe capitalism works better when skeptics restrain its excesses than when true believers are writing, interpreting, judging, and executing the rules of the game.
The Democrats are surely the more skeptical of America’s two parties.
Some evidence can be found in those features of the American economy that we believe others should emulate.
There is now an overwhelming consensus that open, transparent, and accountable mechanisms of shareholder control are essential for the efficient functioning of public corporations.
Virtue is defined by good accounting rules.
But it is instructive to recall that many of those now-universally-admired rules were fiercely resisted when first proposed.
The options backdating scandal that recently caught Apple’s chairman, Steve Jobs, is a microcosm of innovation, prosecution, and reform; now that a rule has been written to prohibit backdating, this particular scam will not happen again.
Thus do accounting rules approach perfection.
What do we learn from this example?
It’s hard to say.
Maybe that capitalism works better when it is being held accountable to some external standard than when left to its own devices.
As the twentieth century recedes in the rear-view mirror, it increasingly seems that, for better or worse, our era’s defining manifesto has been Milton Friedman’s book Capitalism and Freedom .
But that book’s potency originally derived from its fierce independence from contemporary orthodoxies.
Friedman’s voice was a skeptical breath of fresh air at a time when the reigning viewpoint was a kind of smug pseudo-socialism that did not recognize the astounding power of markets to accomplish desirable aims.
Today, however, the reigning Republican orthodoxy is a kind of smug pseudo-Friedmanism that believes that markets left to themselves can do no wrong.
Perhaps it is time for another breath of fresh air.
The book for the new epoch has yet to be written, but I have a proposed title: Capitalism and Skepticism .
Skepticism might not be as bracing as freedom, but it’s something we could have used a bit more of in the past few years.
Europe's Enron-induced schadenfreude is kaput.
Last year's Vivendi and this year's Parmalat scandals have seen to that.
Europe, like America - indeed, like the entire capitalist world - must now become more hawkish in demanding prosecution and punishment of bosses who loot their companies.
American prosecutors in the Enron case have made important progress lately, with some important crooks, like Andrew Fastow, offering both guilty pleas and a willingness to testify against their former colleagues.
Mr. Fastow will go to jail for ten years; those he testifies against will face even longer sentences.
Italian prosecutors seem zealous to make those who looted Parmalat pay a similar price.
But these cases go beyond the companies robbed and the shareholders betrayed.
What is at stake is no less than the perception of the fairness of the market and political support everywhere for market-oriented policies.
Capitalist economies produce inequality, often large ones.
Up to a point, and to the extent that income differences are due to differences in ability, effort, investment in education, etc., they are necessary to providing the correct incentives to invest, work, innovate, and grow.
But the more tainted the market's reputation for fairness, the more average citizens will see income differences merely as the result of corruption, illegal activities, connections with public officials, and so on.
This will increase demands for more regulation and heavy government involvement in the economy, so as to bring unruly and untrustworthy capitalists under greater control.
Moreover, the more that wealth accumulation is viewed as "unfair" (i.e., the result of corruption and illegality), the more pressure for stiff taxation of "ill-gotten gains" will mount.
If any of these populist measures would make markets fairer and better functioning, we would say, "So be it."
Unfortunately, reacting to corrupt businessmen in this way sets in motion a vicious circle: more regulation may lead to even more corruption in order to avoid it; higher taxes on wealth will bring about even more tax evasion, making the system even more tainted.
Sadly, nowadays, things as disparate as highly paid executives, the Enron and Parmalat scandals, contested mergers and acquisitions, stock market volatility, "junk bonds," and asset-price bubbles are all lumped together under the snide heading "cowboy capitalism."
Europeans are particularly prone to see things this way - and to see a powerful government as the sheriff to keep the cowboys from shooting up the town.
This is especially worrisome because Europe has recently begun moving in the right direction by deregulating its markets.
With political support for these changes still shaky, the risk is that opponents may use Parmalat, Enron, Vivendi, and other cases as an excuse to reverse the process.
In many developing countries, weak regulators and a widespread perception of corruption often stand in the way of pro-market reforms; the left (populist or otherwise) can credibly argue that capitalism is "corrupt" and so must be taken under the wing of the government.
This is a big reason why market capitalism has such a hard time taking root in the developing word.
If capitalists are corrupt, how can you convince a poor peasant to believe in the market economy?
He will vote for populist policies.
The result is even more corruption and less growth in a sort of "corruption-induced" poverty trap.
The Parmalat scandal may have been a blow to global capitalism, but in Italy it is hoped that it might sound the death knell for an economic system traditionally based much more on "connections" amongst private groups - and between these groups and the public sector - than on competitive markets.
For Italy, the obvious solution is to strengthen the country's investigative and financial institutions, and improve the design of regulatory agencies, particularly the quality of their personnel.
This, however, will not happen overnight, and in the meantime the demand for more regulation may result in a structure that is heavy, ineffective, and in the end impedes, rather than corrects, market forces.
Supervision inside Italian firms should be strengthened by making sure that a sufficient number of non-executive directors sit on the boards of public companies.
A single independent director would probably have been enough to blow the whistle at Parmalat: there were none on its board.
Similarly, it might help to have accounting firms be selected by minority shareholders or paid by the stock exchange, rather than by a company itself.
Here, even the recent changes in the US have not gone far enough: they prevent accounting firms from also serving as advisors to a firm, but they still leave the decision about remunerating the accountants in the hands of the company, thus creating a perverse incentive to play fast and loose with financial reporting.
It is surprising that while the Italian government is busy redesigning the regulatory and supervisory structure of the country's financial institutions and financial markets, nothing is being said about independent directors and accounting firms.
After all, good sheriffs need active citizens to be in their posses and to serve on juries.
Clean capitalism needs the same sort of widespread engagement.
Recent revelations that many corporate executives have backdated their stock options, ensuring excessive compensation even when their companies perform poorly, are merely the latest in a stream of examples of bad business behavior.
In an era of evaporated pensions and benefits for the rank and file, piggish pay packets for CEO’s have led a cynical public to wonder where big business has gone wrong.
The answer may be quite simple: too many bosses have abandoned basic human values and embraced the credo famously uttered by Gordon Gekko in the movie 
 Wall Street
 : “Greed is good.”
But a growing body of research concludes that greed is 
 not
 always good, and that moral values are a necessary element in the conduct of business.
The Gordon Gekkos are predators who take the quick payoff.
Although they do serve a useful purpose by keeping other players on their toes and raising efficiency through competition, market participants for the most part avoid them, preferring to do business with the Warren Buffetts – hard-driving businessmen, but known for fair play and creating long-term value.
Consider the trip to the mall, where shoppers buy goods produced and shipped from around the world.
This decentralized delivery of goods relies on employees working for two weeks before receiving a paycheck, companies offering each other lines of credit, and banks offering bridge loans.
Even though humans have engaged in exchange since before the birth of civilization, the impersonal system of trading is only around 1,000 years old.
While legal remedies exist should this system break down, impersonal trading cannot occur unless most people share the values of fair play and reciprocal cooperation.
Even in impersonal market exchange, we cannot help but personalize transactions, say, with the grocery store cashier who smiles and thanks us, or the store greeter whose only purpose is to make us feel cared for.
This personalization draws upon regions of the brain that evolved when our trading partners were members of small kin-based groups where moral violations were immediately identified and remedied.
Research by primatologists Sarah Brosnan and Frans de Waal at Emory University has shown that monkeys also have what look like moral values.
When two monkeys work for food, a fair split is expected.
If a fair division is not received, it elicits cries of outrage and hurled food by the wronged partner.
Moral values have powerful physiological representations in humans, too, and we feel them strongly when they are violated.
The philosopher Josh Greene and his colleagues at Princeton University have shown that personal moral dilemmas (for example, whether you would directly kill one person to save seven others) use our emotions rather than higher cognition – to the chagrin of many philosophers who claimed otherwise.
The personal aspect of such decisions makes our hearts speed up and our palms sweat.
In neuroeconomics experiments that my lab has conducted, we have found that when a stranger places trust in another by making a considered monetary investment that can either be returned or stolen, our brains release an ancient mammalian hormone called oxytocin.
Oxytocin is what bonds mammals to their offspring, and in humans makes spouses care about and love each other.
We have found that trust causes a spike in oxytocin and begets reciprocation – the sharing of money.
We are “wired” to cooperate, and we find it rewarding in the same way that our brains identify eating a good meal or sex as rewarding. 
Oxytocin is active in evolutionarily old areas of our brain, outside of our conscious awareness.
We simply have a sense that sharing with someone who has trusted us is the right thing to do.
We have also found that about 2% of undergraduates we studied are pure non-cooperators.
When they have an opportunity to share money with a stranger who has trusted him or her, non-cooperators keep all the money rather than share the largess.
The technical term in my lab for these people is “bastards.”
Our evidence suggests that bastards’ brains work differently.
Their character traits are similar to those of sociopaths.
They simply do not care about others the way most people do, and the dysfunctional processing of oxytocin in their brains appears to be one reason for this.
Because bastards are out there, we still need government and personal enforcement of economic exchange.
Nevertheless, too much government regulation may “crowd out” moral behavior.
When every offense has an associated penalty, transgressions cease to be moral violations, but are simply a way for wrongdoers to effectively “use the system” while facing some risk of getting caught and paying a fine.
These external penalties can displace the internal sanctions we feel when we do wrong.
At Enron, this was accomplished by breaking down tasks into small chunks so that no one person was ultimately responsible for a decision and could claim ignorance when caught.
Former Enron chief executive Jeffrey K. Skilling excused his behavior at his trial by saying, “I’m not an accountant.”
Many people have been convinced that market exchange diminishes our humanity.
Think of Charlie Chaplin’s film 
 Modern Times
 , in which the little tramp is literally a cog in the capitalist machine.
That view, a residue of Marxist thinking, is wrong.
On the contrary, working together, and trading with each other in markets, is morality in action.
MELBOURNE – Is the global financial crisis an opportunity to forge a new form of capitalism based on sound values?
So French President Nicholas Sarkozy and former British Prime Minister Tony Blair appear to think.
At a symposium in Paris last month entitled “New World, New Capitalism,” Sarkozy described capitalism based on financial speculation as “an immoral system” that has “perverted the logic of capitalism.”
He argued that capitalism needs to find new moral values and to accept a stronger role for governments.
Blair called for a new financial order based on “values other than the maximum short-term profit.”
It is surprising how readily politicians of all parties – even strong ideological defenders of the unregulated market – accepted the idea that the state should bail out banks and insurance companies when they got into trouble.
With the exception of a small number of ideologically committed defenders of free enterprise, few were willing to take the risks inherent in letting major banks collapse.
Who knows what the consequences would have been?
Many feared mass unemployment, a tidal wave of bankruptcies, millions of families evicted from their homes, the social safety net strained to the breaking point, and perhaps even riots and a resurgence of the political extremism that brought Hitler to power in Germany during the depression of the 1930’s.
The choice to save the banks from the financial consequences of their own errors indicates a shift in values away from belief in the wisdom of the market.
Evidently, the market got some things – like the value of certain financial securities – horrendously wrong.
But will the downturn also produce a deeper shift in the values of consumers?
It is no accident that the “New World, New Capitalism” symposium was held in France, where some critics have seen the global financial crisis as necessary and desirable precisely because it is producing this change in values.
In the newspaper Le Figaro, a section on how to scale back one’s expenses predicted a “revolution in values” and claimed that people will put family ahead of work.
(Americans think the French, with their shorter working hours and longer summer vacations, already put family ahead of work.)
The French have always been less likely to go into debt – when they pay with plastic, they tend to use debit cards, drawing on funds they already have, rather than credit cards.
Now they see the current crisis as a vindication of the value of not spending money that you don’t have.
That means, in many cases, less luxury spending – something that is hard to reconcile with the image of France as the country of fashion, perfume, and champagne.
But excess is out of style, and there are reports of cutbacks in luxury goods everywhere.
Richemont, the Swiss luxury goods company that owns the Cartier and Montblanc brands, has said that it is facing “the toughest market conditions since its formation 20 years ago.”
But does this mark an enduring change in values, or just a temporary reduction, forced upon consumers by investment losses and greater economic uncertainty?
In his inauguration speech, American President Barack Obama said, “The time has come to set aside childish things” and instead to choose the noble idea that “all are equal, all are free, and all deserve a chance to pursue their full measure of happiness.”
It would be an excellent thing if the global financial crisis restored a proper sense of what is important. 
Could the crisis remind us that we buy luxury items more because of the status they bring than because of their intrinsic value?
Could it help us to appreciate that many things are more central to our happiness than our ability to spend money on fashion, expensive watches, and fine dining?
Could it even, as Obama suggests, make us more aware of the needs of those who are living in real poverty and are far worse off than we will ever be, financial crisis or no financial crisis?
The danger is that the potential for a real change in values will be co-opted, as has happened so often before, by those who see it as just another opportunity to make money.
The designer Nathalie Rykiel is reportedly planning to show the new Sonia Rykiel collection in March not in the usual vast rented area, but in the smaller space of her own boutique. “It's a desire for intimacy, to go back to values,” she told the International Herald Tribune .
“We need to return to a smaller scale, one that touches people.
We will be saying, ‘Come to my house. Look at and feel the clothes.’”
Ah yes, in a world in which ten million children die every year from avoidable, poverty-related causes, and greenhouse-gas emissions threaten to create hundreds of millions of climate refugees, we should be visiting Paris boutiques and feeling the clothes.
If people were really concerned about defensible moral values, they wouldn’t be buying designer clothes at all.
But what are the chances of Nathalie Rykiel – or the affluent elites of France, or Italy, or the United States – adopting those values?
WARSAW: Around the world, democracy is on the march.
Totalitarian and authoritarian regimes have been swept away.
Popular resentment against the remaining ones is growing.
But it is too early to declare victory.
For although capitalism is triumphant, we cannot speak of the triumph of democracy.
The connection between capitalism and democracy is far from automatic.
Repressive regimes do not willingly abdicate power and are often abetted by business interests, both foreign and domestic, particularly in countries where resources such as oil and diamonds are at stake.
Perhaps today's greatest threat to freedom comes from an unholy alliance between government and business, such as in Fujimori's Peru, Mugabe's Zimbabwe, Mahatir's Malaysia, and the oligarchs' Russia, where the appearances of democratic process are often observed but state powers are diverted to benefit private interests.
Capitalism creates wealth but cannot be relied upon to assure freedom, democracy and the rule of law.
Business is motivated by profit; it is not designed to safeguard universal principles.
Even the preservation of the market itself requires more than self-interest: market participants compete to win, and if they could, would eliminate competition.
So freedom, democracy and the rule of law cannot be left to the care of market forces; we need institutional safeguards.
Traditionally, protecting the common interest was the task of the nation state.
But state powers shrank as global capital markets expanded.
Since capital can now avoid states that tax and regulate, governments cater to its demands.
In many ways, this is beneficial.
Free competition produces more wealth than state control; globalization prevents states from abusing their power and offers a degree of freedom that no state could provide.
But globalization has its downside: financial markets are unstable; free competition creates and reinforces inequalities nationally and internationally; collective interests, from preservation of peace to human rights and environmental protection, receive short shrift.
To enjoy globalization's benefits we must address these shortcomings on an international scale.
Unfortunately, existing international institutions, like the UN, are ill-suited to safeguard universal interests because they are associations of states, and states jealously guard their interests.
Moreover, the faults of state bureaucracies are multiplied within international bureaucracies.
In today's world, most conflicts occur not between states but within states.
For people living under repressive regimes, outside protection is the only lifeline.
Democratic countries cannot tolerate large scale violation of human rights, and are liable to be drawn into local conflicts.
Even if they refuse to be drawn in, they face an influx of refugees and other forms of contagion.
Once conflict erupts, as Yugoslavia shows, most forms of punitive intervention have unintended adverse consequences.
Trade sanctions foster smuggling and smugglers are usually in cahoots with authorities, so that sanctions strengthen the governments they are supposed to topple.
Military action tends to silence internal opposition to the regime against which it is directed.
Crisis prevention is much to be preferred to intervention; the best way to prevent crises is to foster the development of open societies.
That is what my network of foundations seeks to do.
Open societies allow people with different views, backgrounds, and interests to live together in peace.
Given our human nature, conflicts cannot be avoided, but the chances of crises requiring outside intervention are greatly reduced.
I advocate a concerted effort by developed democracies to foster the development of democracy in less developed parts of the world.
This should take the form of technical assistance and economic incentives.
Economics and politics cannot be separated.
Nobel laureate Amartya Sen makes a convincing case that development should be defined in terms of freedom, not in terms of gross national product.
The global capitalist system has produced a very uneven playing field.
The gap between rich and poor is getting wider.
We must find ways to counteract this because a system that does not offer hope and opportunity to its losers is liable to be disrupted by acts of desperation.
By contrast, economic aid can foster democratic development; it can also be used as leverage against recalcitrant governments.
Unfortunately, there is scant support for this idea.
Foreign aid failed in Africa and the post-communist states, and is in danger of failing in the Balkans.
But that does not mean we should abandon the idea.
Rather, we must examine the reasons for failure and devise better ways.
Foreign aid is all too often directed at satisfying the needs of the donor, not the recipient.
Based on the experience of my foundations in countries like Russia, I assert that outside assistance can be effective.
Recent changes to the global financial architecture in the wake of the international financial crises aim exclusively at imposing greater market discipline. The goal is to eliminate the moral hazard introduced by the IMF.
This will reduce the danger of excessive capital flows to emerging markets, but the next crisis is likely to arise from inadequate capital flows.
Today's market fundamentalist creed fails to recognize that financial markets are inherently unstable.
By imposing market discipline, it is, in fact, imposing instability.
Global financial markets require a global central bank or some other international financial institutions to keep financial markets on an even keel.
The same applies to the World Trade Organization.
There is a crying need for both labor standards and environmental protection.
But poor countries cannot afford them.
Instead of punitive measures to enforce such standards, poor countries ought to be given incentives, such as tariff relief, to comply.
The Meltzer Commission established by the US Congress recently recommended converting the World Bank from a lender to a World Development Agency.
Splendid, but the Meltzer Commission would shrink the World Bank, returning unused capital to shareholders – a major resource transfer to the rich.
I would put the unused capital to productive use and increase grant-giving activities of the Bank.
The World Bank should also stop insisting that recipient governments guarantee its loans, which gives governments control over which private sector company, local government, or non-governmental organization receives financing.
Such control is detrimental to the evolution of open societies.
Removing this constraint might endanger the Bank's triple A rating, but will make it more effective.
I propose that the world's open societies form an alliance with a dual purpose: fostering both development of open societies in individual countries and the evolution of a global open society.
The first involves development assistance; the second, strengthening international institutions, such as an international central bank and a World Development Agency.
Such an alliance requires the co-operation not only of governments, but also of civil society.
Governments represent the interests of the state, but democratic governments are responsive to the wishes of the electorate.
Only if people believe in an open society that transcends national borders can such a society be brought into existence.
So far, civil society has been mobilized for the destruction of international institutions as in the recent protests against the WTO and World Bank in Seattle and Washington.
We must reverse the trend and start a movement for the creation of a global open society.
The World Forum on Democracy, held in Warsaw June 25 – 27 made a start, but it must be followed up.
As a final act of his presidency - it will end at the Communist Party meeting beginning November 7 th - China's Jiang Zemin wants businessmen to join the Party leadership.
Marx and Mao are probably spinning in their graves.
Who are these businessmen President Jiang wants to court and how do they operate?
Kenichi Ohmae offers a portrait.
Officially, China remains Communist.
Yet companies in China face far fewer regulations than in Taiwan, Korea, Japan, Germany, France, and Sweden.
Even in comparison with the US, China is a capitalist paradise - so long as you steer clear of the central government.
For example, tariffs (which are set by the central government, but administered locally) are low or nonexistent for companies that take advantage of China's regional systems of tax-free zones and tax benefits.
None of this was conceivable as recently as 1992, when Beijing's proclamation of "one country, two systems" - and the decision to peg the mainland's currency, the Renminbi, to the Hong Kong dollar - unleashed the floodgates of foreign investment.
Money poured into the Shenzhen and Shanghai stock markets, as did direct investment to build factories and offices in tax-free zones.
The trappings of entrepreneurial culture are everywhere.
The face of General Electric's longtime boss Jack Welch is in bookstore windows across China, although his latest book is probably a pirated edition because China still has a way to go on copyright protection. Many managers attended China's elite foreign language schools (which trained spies during the Cold War era) and then headed to America for an MBA.
Back home, they practice just-in-time manufacturing, 360-degree performance evaluations (including bosses reviewed by subordinates), and re-engineering - all with unmatched resourcefulness and purposefulness.
In fact, more students than ever who left for universities in Japan, the US, and Europe are being lured back.
The Dalian local government constructed an elaborate software development park à la Silicon Valley, where students returning from abroad can rent low-cost office space for startup companies.
They benefit from broadband network environments, introductions to investors and financial angels, and exposure to each other.
Like rival businesses in a single large corporation, other cities are creating their own incubators and lures for talent as well.
As a result, China's reputation for lackluster innovation is changing.
Consider the story of Shenyang-based Neusoft Group, China's largest publicly traded software company, with sales of $134 million last year.
Neusoft began as a low-cost competitor to the Oracle Corporation.
After moving on to produce car audio equipment, Liu Jiren, Neusoft's CEO, began hearing complaints from local hospitals about the high cost of specialized X-ray, MRI, ultrasound, and CT-scanning machines (such as those made by GE, Philips, Siemens, and Toshiba).
Suddenly, a new business was born.
Liu realized that Neusoft could link standard Intel chips and its own imaging software to a range of digital sensors.
Neusoft's equipment looks like little personal computers with sensors attached.
But it is inexpensive and adaptable enough that every hospital room can now have its own multipurpose scanner.
In the US or Japan, facing entrenched industry opposition, such a startup might never have gotten off the ground.
But by selling to Chinese hospitals first, Neusoft built up a customer base that will allow it to challenge the existing medical electronics industry worldwide, just as Honda and Toyota challenged the worldwide auto industry in the 1970s.
Nor is Neusoft alone.
Little Swan sells washing machines in 40 countries, while Legend Group is now the world's largest manufacturer of personal computers (mostly sold under other brand names).
Hua Wei, based in Shenzhen with 14,000 employees (70% of whom are engineers), makes routers and telecommunications switches at half the price of most global companies.
Many leading American and European telephone equipment manufacturers fear Hua Wei more than Fujitsu or NEC.
The Chinese have grasped the hidden key to Japan's success in the 1970s and 1980s.
Companies like Toshiba and Sony depended on two regions - Otaku in Tokyo, and Higashi Osaka in Osaka Prefecture -where thousands of manufacturers of precision mechanical and electronic components were clustered.
Today, Otaku and Higashi Osaka are anachronisms.
With modern highways, port facilities, and communications links available, a cellular phone manufacturer in Shenzhen might receive just-in-time deliveries of parts several times a day from suppliers that are only hours away.
Similar manufacturing clusters are sprouting up everywhere in China.
Dalian is becoming a center for software development and Japanese-language back-office work, such as insurance processing and call centers.
Japanese companies also prefer Qingdao, on the Shandong Peninsula, which specializes in production of high-quality processed food.
More than 4,000 Taiwanese manufacturers have set up shop in Xiamen and Dongguan.
Zhongguancun, a former military research zone in Beijing that houses half a million scientists and engineers, is popular with American high-tech companies.
All this clustering resulted in state-of-the-art production and cutting-edge business.
Consider Japan's Fast Retailing Company, which retails high-quality clothing manufactured in China under the Uniqlo brand in its own Japanese outlets.
Fast Retailing charges one-third the price that competitors charge and earns nearly five times the margin.
The verb "to uniqlo-ize" (to cut costs dramatically through Chinese production and eliminating intermediaries) has entered Japan's business vernacular, as in: "Can we uniqlo-ize the housing industry?"
The US confronted something similar in the late 1980s.
It responded by internalizing foreign competitors like Sony, Toyota, Bayer, Nestlé, and DaimlerChrysler - in effect turning them into US companies with US investors, loyalties, and even corporate cultures.
The challenge for the US, Europe, and Japan will now be to internalize Chinese companies and methods in order to galvanize their own to higher levels of productivity and innovation.
PARIS – There is a strange foreboding in the world economy.
Newspapers report downward revisions in growth estimates for all the major developed countries: the United States, Germany, France, Japan.
No one, it seems, is being left out.
Indeed, these estimates are roughly half a percentage point lower than those issued only last autumn.
At the same time, newspapers report in bleak terms almost exclusively about banks and financial markets, with little attention to the real economy, as if today’s crisis were purely financial and bound to remain so.
Indeed, some experts, too, believe that the crisis can be resolved simply by refinancing banks, and that the impact on the real economy will be relatively limited.
This is clearly the belief of the European Central Bank, which is pumping hundreds of billions of euros into the banking system to ensure liquidity.
But, unlike the US Federal Reserve, it has not lowered key interest rates, which is what matters most to firms and households.
Other experts, of course, believe that the real economy is in jeopardy, and that the threat of a recession is genuine.
But, unfortunately, hardly any experts can speak with confidence about both finance and macroeconomics.
So what is a non-expert to think?
It is helpful to review where the world economy now stands.
The largest number of defaults on sub-prime mortgages will occur this spring.
So the full impact of the crisis remains ahead of us: 1.3 million American homeowners have already defaulted on their mortgages.
In 2008, another three million will join them.
Moreover, the size of the bad debt threatening banks remains unknown, and could amount to several hundred billion dollars.
The total sum of assets now under threat is even more important, because mortgages have been mixed up with other kinds of securities, and these “packages” have been sold throughout the world.
A US subsidiary of Deutsche Bank, for example, has been barred by an American court from foreclosing on a house because it could not demonstrate ownership.
The global economy is overrun with such poisoned packages.
As a result, banks distrust one another and have mostly stopped lending to each other, which jeopardizes economic activity by severely reducing the availability of credit to businesses.
As a result, recession seems certain.
The quantity of liquidity in the world economy is surprising, and monetary expansion by central banks does not explain it completely.
For more than two decades, shareholders in all the developed countries, unorganized and passive from 1945 until 1975-1980, have recast themselves in the form of pension funds, investment funds, and hedge funds.
Now they are significant and active players (as majorities or strong minorities) in all the big companies of the developed world.
To boost the value of their shares, these shareholders backed the drive to reduce the global volume of the payroll and the number of workers that companies employ.
Indeed, in the last 25 years, the share of direct and indirect wages as a percentage of GDP has fallen by 8% to 11% in all the countries involved.
As a result, precarious employment and job insecurity, which hardly existed between 1940 and 1970, now affect more than 15% of the developed world’s population.
The average real wage has been flat in the US for 20 years, with 1% of the population capturing all of the gains brought about by a 50% growth in GDP during this period.
This “liberated” a lot of liquidity for financial activities, gambling, and speculation.
In France alone over the past 20 years, roughly 2.5 trillion euros have poured into the financial world, which suggests a total of 30-60 trillion dollars for the world economy as a whole.
This has been accompanied by a growing immorality of the system.
Remuneration of company bosses now reaches 300 to 500 times the average salary of rank-and-file employees, up from 40 to one for the century and a half before 1980.
Throughout the world, the number of companies facing legal problems for various types of fraud is growing dramatically.
The worst, sadly, is yet to come.
Because most people’s incomes are stagnant and being eroded as their mortgage payments rise, consumption is bound to fall, yielding lower growth and employment.
A recession will only increase job precariousness and unemployment, creating social tensions that will not, of course, help to ease the financial crisis.
All the ingredients seem to be in place for a long and powerful perfect storm of economic decline and social unrest.
We in the developed world live in democracies.
Every four or five years, the legitimacy of the system needs to be confirmed by elections.
But is the system being so delegitimized by the economic and social turmoil that elections will no longer be viable?
Of course, capitalism remains more compatible with personal freedom than communism ever was.
But it is now blindingly obvious that capitalism is too unstable to survive without strong public regulation.
That is why, after years of being neglected as a viable option, it is time for the social-democratic project to return to the political fore.
NEW YORK – Recently, China’s government announced that it wants Shanghai to become a global financial capital equal to London and New York by 2020.
An ambitious goal, which may or may not be achieved.
But China’s aspirations also underscore a worrisome and increasingly pervasive new reality: political officials are making decisions normally left to markets on a scale not seen in decades.
Like the financial crisis itself, this trend is now global.
Political leaders in dozens of countries are making decisions that will drive the performance of local (and global) markets for the foreseeable future.
In China, exports fell by more than 25% in February.
Not to worry, said Premier Wen Jiabao: the Chinese government has “adequate ammunition” to add to its $586 billion stimulus package, a plan meant to create millions of jobs via enormous government investment in transportation, energy infrastructure, housing, and other large-scale projects.
In India, where government is more often considered a drag on commerce than a catalyst of growth, the decisions that move local markets are now more likely to come from bureaucrats in Delhi than from innovators in Mumbai.
In fact, the Congress Party-led government, anxious to appear responsive to public demand for help during an election-year economic slowdown, has pushed forward three stimulus packages since December.
The bottom line: to find out how, when, and where assets will be allocated and wealth generated in dozens of countries across the developed and developing worlds these days, we must now look toward political, not financial, capitals.  
This trend will spell trouble for longer-term global economic growth.
First, it’s tough enough for leaders within the Chinese Communist Party elite to agree on economic-policy priorities.
The challenges facing US President Barack Obama as he tries to win support for risky and expensive policy options from quarrelsome Democrats and obstinate Republicans will create some tortured legislative compromises.
That pattern is being repeated elsewhere.
In Russia, Ukraine, Hungary, Pakistan, Turkey, Malaysia, Mexico, Nigeria, and other states, battles among domestic political factions will yield often-incoherent responses to pressing economic problems.
Second, if it’s difficult to forge consensus within one country on how best to promote growth, imagine the same argument on a global scale.
Most politicians craft policy to serve their local constituents and to protect their personal political capital.
Reinvigorating global growth runs a distant second.
In Washington, many Democrats will use these policy debates to capitalize on popular fury at Wall Street, while many Republicans look for an opening to capitalize on hoped-for public anger at the Democrats.
Some within the Chinese Communist Party leadership will support plans to engineer a shift from export-led growth to a model based on domestic consumption.
Others will try to direct state funding toward their personal investment projects.
Factions within the Russian, Indian, Mexican, and South African governments have their own competing political priorities.
With so many political officials crafting crisis responses to solve local problems or to create local opportunities, how likely are they to agree on a unified international approach?
Our first glimpse of the trouble in coordinating an international response to the financial crisis came last November, during the emergency G-20 summit in Washington.
To get the G-8 to agree on priorities is a complicated enough; building consensus within the G-20 is exponentially more difficult, not simply because of the larger number of players involved, but because many of them don’t agree on the most basic rules of the global economic game.
While the April G-20 summit in London produced more economic-policy agreement than expected, this was largely because the most divisive issue – the US and British demand for more global stimulus spending – was removed from the table beforehand.
As a result, the smiling presidents and prime ministers could afford to be more diplomatic than Czech Prime Minister Mirek Topolanek, who, in his role as acting president of the European Union, had warned that Obama’s economic plan would lead others down a “road to hell.”
Topolanek wasn’t at the G-20; his country is not a member.
And, while British Prime Minister Gordon Brown agrees with Obama that the world’s leading industrialized countries must stimulate their domestic economies as much as they can, Bank of England Governor Mervyn King has warned that Britain may already have taken on too much debt for another round of stimulus.  
However frightening the global recession, a coordinated and coherent response to it by the world’s political leaders remains highly uncertain at best.
And the increasingly heavy influence of political factors on market performance will likely weigh on global growth for years to come.
NEW YORK – Nothing illustrates better the political crosscurrents, special interests, and shortsighted economics now at play in Europe than the debate over the restructuring of Greece’s sovereign debt.
Germany insists on a deep restructuring – at least a 50% “haircut” for bondholders – whereas the European Central Bank insists that any debt restructuring must be voluntary.
In the old days – think of the 1980’s Latin American debt crisis – one could get creditors, mostly large banks, in a small room, and hammer out a deal, aided by some cajoling, or even arm-twisting, by governments and regulators eager for things to go smoothly.
But, with the advent of debt securitization, creditors have become far more numerous, and include hedge funds and other investors over whom regulators and governments have little sway.
Moreover, “innovation” in financial markets has made it possible for securities owners to be insured, meaning that they have a seat at the table, but no “skin in the game.”
They do have interests: they want to collect on their insurance, and that means that the restructuring must be a “credit event” –&nbsp;tantamount to a default.
The ECB’s insistence on “voluntary” restructuring – that is, avoidance of a credit event –&nbsp;has placed the two sides at loggerheads.
The irony is that the regulators have allowed the creation of this dysfunctional system.&nbsp;
The ECB’s stance is peculiar.
One would have hoped that the banks might have managed the default risk on the bonds in their portfolios by buying insurance.
And, if they bought insurance, a regulator concerned with systemic stability would want to be sure that the insurer pays in the event of a loss.
But the ECB wants the banks to suffer a 50% loss on their bond holdings, without insurance “benefits” having to be paid.
There are three explanations for the ECB’s position, none of which speaks well for the institution and its regulatory and supervisory conduct.
The first explanation is that the banks have not, in fact, bought insurance, and some have taken speculative positions.
The second is that the ECB knows that the financial system lacks transparency – and knows that investors know that they cannot gauge the impact of an involuntary default, which could cause credit markets to freeze, reprising the aftermath of Lehman Brothers’ collapse in September 2008.
Finally, the ECB may be trying to protect the few banks that have written the insurance.
None of these explanations is an adequate excuse for the ECB’s opposition to deep involuntary restructuring of Greece’s debt.
The ECB should have insisted on more transparency – indeed, that should have been one of the main lessons of 2008.
Regulators should not have allowed the banks to speculate as they did; if anything, they should have required them to buy insurance – and then insisted on restructuring in a way that ensured that the insurance paid off.
There is, moreover, little evidence that a deep involuntary restructuring would be any more traumatic than a deep voluntary restructuring.
By insisting on its voluntariness, the ECB may be trying to ensure that the restructuring is not deep; but, in that case, it is putting the banks’ interests before that of Greece, for which a deep restructuring is essential if it is to emerge from the crisis.
In fact, the ECB may be putting the interests of the few banks that have written credit-default swaps before those of Greece, Europe’s taxpayers, and creditors who acted prudently and bought insurance.
The final oddity of the ECB’s stance concerns democratic governance.
Deciding whether a credit event has occurred is left to a secret committee of the International Swaps and Derivatives Association, an industry group that has a vested interest in the outcome.
If news reports are correct, some members of the committee have been using their position to promote more accommodative negotiating positions.
But it seems unconscionable that the ECB would delegate to a secret committee of self-interested market participants the right to determine what is an acceptable debt restructuring.
The one argument that seems – at least superficially – to put the public interest first is that an involuntary restructuring might lead to financial contagion, with large eurozone economies like Italy, Spain, and even France facing a sharp, and perhaps prohibitive, rise in borrowing costs.
But that begs the question: why should an involuntary restructuring lead to worse contagion than a voluntary restructuring of comparable depth?
If the banking system were well regulated, with banks holding sovereign debt having purchased insurance, an involuntary restructuring should perturb financial markets less.
Of course, it might be argued that if Greece gets away with an involuntary restructuring, others would be tempted to try it as well.
Financial markets, worried about this, would immediately raise interest rates on other at-risk eurozone countries, large and small.
But the riskiest countries already have been shut out of financial markets, so the possibility of a panic reaction is of limited consequence.
Of course, others might be tempted to imitate Greece if Greece were indeed better off restructuring than not doing so.
That is true, but everyone already knows it.
The ECB’s behavior should not be surprising: as we have seen elsewhere, institutions that are not democratically accountable tend to be captured by special interests.
That was true before 2008; unfortunately for Europe –&nbsp;and for the global economy – the problem has not been adequately addressed since then.
CAMBRIDGE – Care-giving is understood by economists as a “burden,” by clinical psychologists as a “coping process,” by health-services researchers in terms of health-care costs, and by physicians as a matter of clinical competency.
But, for many people, care-giving is a foundational component of moral experience.
It is a practice of acknowledgement, empathic imagination, witnessing, responsibility, solidarity, and the most concrete forms of assistance.
It is this moral aspect that makes care-givers, and at times even care-receivers, feel more “present” – and thus more fully human.
But, aside from skilled nursing, rehabilitation efforts by occupational and physical therapists, and the practical assistance of social workers and home health aides, care-giving, especially for victims of health catastrophes and end-stage conditions, has relatively little to do with the contemporary practice of medicine.
To illustrate this point, I draw on my personal experience as the care-giver for my wife, who suffers from a severe neurodegenerative disorder that has impaired her memory and motor functions, restricting her independence.
I wake her up in the morning, assist her in toileting, bathing, and dressing, make us breakfast, and help her feed herself.
I assist her in walking, placing her in a chair, and getting into our car.
I am with her nearly all the time to protect her from injuring herself, because she can neither see nor navigate safely on the street or in our own home.
It is disturbing to witness the deterioration of a once elegant, intellectually lively, and highly independent companion of more than four decades.
But our emotional reactions, from frustration and anger to sadness, have been cushioned and sublimated by our work, the long rhythm of our days together, and, above all, by the support of family and close friends.
That concern and responsibility for us is as much a part of care-giving as all the mundane practices I have listed, and amounts to moral solidarity with our struggle.
I give you this personal sketch because it is the best I can do to illustrate what care-giving entails, and why it is so crucial to everyone’s life – and to the human condition more generally.
Care-giving, as illustrated by our case, includes what happens when hope and consolation are abandoned, when theodicy ends, and when all there is to do is to be present with the sufferer, sharing his or her suffering by simply – and usually silently – being there.
In medical schools, however, the curriculum in both the basic science and clinical apprenticeship years places the greatest emphasis on understanding the biology of disease processes and high-technology treatments.
The illness experience gets less and less pedagogic attention as the student progresses from classroom to inpatient ward and clinic.
In the broader system of healthcare, students can readily discern that medicine largely leaves the practical and emotional tasks of care-giving to nurses, social workers, and the patient and his or her network of support.
The structure of service delivery and the funding of health services work to discourage professionals from the art of care-giving, and can, in fact, undermine the practitioner’s efforts.
The result is moral impoverishment of the practice of medicine.
For medical anthropologists, people everywhere live in the flow of interpersonal interactions in local worlds – social networks, families, institutions, and communities.
That is to say, experience, viewed as the flow of words, movements, and emotions between us, is not only local, but also inherently moral, because living our lives is about animating and enacting values.
For patients and families faced with health catastrophes and serious chronic medical conditions, the experience of suffering is not just a personal one, but is strongly influenced by cultural and historical changes in the processes that contribute to moral life being distinctive in different eras and societies.
Faced with a threat of pain, disfigurement, loss of function, and serious disability, individuals and families reframe the experience of suffering within their local moral world by remaking meanings, emotions, and values via ethical, religious, and aesthetic activities.
Doctors are no different from laypersons in drawing on personal and cultural resources –involving imagination, responsibility, sensibility, insight, and communication – to accomplish their care-giving.
And what they engage in is an amalgam of ethical, aesthetic, religious, and practical action.
The physician’s art – now so circumscribed by bureaucratic, political, and economic forces – turns on both the professionalization of these inherently human resources and the impact of their routine use on the doctor’s own moral life.
To prepare for a career of care-giving, medical students and young doctors clearly require something besides scientific and technological training.
Indeed, current professional education can even be seen as enabling the physician as a technical expert, while disabling him or her as a care-giver.
To overcome this trend, we must incorporate the humanities into medical training as a means of rekindling and deepening those human experiences of imagination and commitment that are essential for care-giving, and resisting the bureaucratization of values and emotional responses that causes failure in the physician’s art.
In essence, the practitioner must come to feel that the art of care-giving is as much at stake as the science and technology of diagnosis and treatment.
In my view, what is needed is reform of the very culture of contemporary biomedicine.
We must train students and practitioners in critical self-reflection on that which limits their care-giving; in strategies and techniques aimed at opening a space for the moral acts of care-giving; and in the most concrete and practical acts of assistance, so that they never forget what care-giving actually means.
On British television recently, a tearful farmer spoke of the fact that his sheep were being shot to prevent the spread of foot and mouth disease: "We’re so sorry to see our lambs die – they should be the symbol of spring, of new life.
But now they die due to this awful disease.” Total hypocrisy.
Before you start weeping in sympathy with the farmer, ask yourself one question: what would have been the fate of the lambs if there had been no outbreak of foot and mouth disease?
The farmer would have taken these little symbols of spring away from their mothers, packed them into trucks, and sent them to slaughter.
The symbol of new life would become dead meat.
Then the farmer would have happily banked the cheque he was paid for doing this.
(He'll still get a cheque, since farmers are compensated by government for animals shot to contain the outbreak.)
The lambs may have lost out on a few weeks of life, but they were also spared the distress of separation from their mothers, the misery of transportation, possibly for hundreds of kilometres, and the crowding and terror of the slaughterhouse.
When intensively reared pigs are shot as a disease control measure, they lose even less.
Kept indoors all their lives, on bare concrete without straw for bedding – pigs love straw, but it costs money and makes the floors harder to keep clean – with nothing to do all day except for the short time they are eating, it is hard to see that longer existence brings them any benefits at all.
It's a matter of judgment, and others might disagree, but in my view the lucky factory farmed pigs are those shot on the farm.
The unlucky ones have to live longer.
I've been reading newspaper columns in which writers say how dreadful it is, this mass slaughter of hundreds of thousands of animals.
They question its necessity, noting that the disease poses zero risk to humans, and even in animals, 95% will recover within a week or two – or would, if they were not shot first.
There is even a vaccine for it.
Columnists point out that the real reason for the slaughter is economic.
The disease causes a temporary loss of production, and once foot and mouth disease is established in a country, other countries will prohibit the importation of its meat and dairy products because they don't want the disease to spread it to their animals.
Vaccination, however, doesn't solve the export problem, because it produces false positives on blood tests of animals suspected of having the disease, so the importing countries don't know if they have found an animal with the disease, or an animal that has been vaccinated against it.
To do further tests distinguishing the infected animals from the vaccinated ones is expensive, and not yet proven to be reliable.
To be on the safe side, countries ban the import of vaccinated animals anyway.
So, having demonstrated that the slaughter is unnecessary, it is then said that the slaughter should stop, that it shows the wrong attitude to animals, that we must show them more respect, and not just treat them as a means to our ends.
While they are not vegetarian, some of these columnists say, they are so disgusted with what they have been seeing on television that they have been thinking of giving up meat.
Oh please!
Where have the people been all these years?
You must have known that all these animals were going to get slaughtered anyway?
If you can read, and didn't deliberately turn away from anything that might disturb your comfort, you should also know that the entire animal industry is unnecessary, that we would be healthier, and do less damage to our environment, without it?
These animals are just means to our ends, that is their sole reason for existing.
How can farmers treat them with respect when consumers want cheaper meat and supermarkets are using their immense bargaining power to force producers to use every possible means to cut costs?
Yes, do give up meat.
It's the right decision to make, and better late than never.
But don't give it up because you pity the animals being shot, and don't like the attitude to animals that is conveyed by the fact that all this killing is taking place for mere economic gain.
Give it up because all of this slaughter has at last brought home to you the real truth about the nature of the animal industry today.
COPENHAGEN – For the better part of a decade, I have upset many climate activists by pointing out that there are far better ways to stop global warming than trying to persuade governments to force or bribe their citizens into slashing their reliance on fuels that emit carbon dioxide.
What especially bugs my critics is the idea that cutting carbon is a cure that is worse than the disease – or, to put it in economic terms, that it would cost far more than the problem it is meant to solve. “How can that possibly be true?” they ask.
“After all, we are talking about the end of the world. What could be worse – or more costly – than that?”
They have a point.
If we actually face, as Al Gore recently put it, “an unimaginable calamity requiring large-scale, preventative measures to protect human civilization as we know it,” then no price would be too high to pay to stop global warming in its tracks.
But are the stakes really that high?
The answer is no.
Even the worst-case scenarios proposed by mainstream climate scientists – scenarios that go far beyond what the consensus climate models predict – are not as bad as Gore would have us believe.
For example, a sea-level rise of five meters – more than eight times what the United Nations’ Intergovernmental Panel on Climate Change expects, and more than twice what is probably physically possible – would not deluge all or even most of mankind.
Of course, such a rise would not be a trivial problem.
It would affect about 400 million people, force the relocation of 15 million, and imply costly protection of the rest.
But it would certainly not mean the end of the world.
Estimates show that the cost in terms of adaptation would be less than 1% of global GDP.
In other words, the price of unchecked global warming may be high, but it is not infinite.
According to the best global-warming economic models, every ton of carbon dioxide that we put into the atmosphere now will do about $7 worth of damage to the environment.
What this means is that we should be prepared to pay an awful lot to stop global warming, but anything more than $7 a ton would be economically indefensible.
This idea is hard for a lot of people to accept.
If we have a solution to a serious problem like global warming, they argue, how can we possibly say that it is too expensive to implement?
Well, we do exactly that all the time.
There are many potential solutions to serious problems that we do not implement, or that we implement only partially, because the costs associated with them are greater than the benefits.
For example, traffic accidents claim an estimated 1.2 million lives every year.
We have the ability to solve this problem completely, eliminating half a trillion dollars in damages, and sparing untold anguish.
All we have to do is lower the speed limit everywhere to five kilometers per hour.
Obviously, we will not do this.
The benefits of driving moderately fast vastly outweigh the costs.
For a wide variety of social and economic reasons, a world moving at only five kilometers per hour would be utterly unacceptable to most of us – so unacceptable that we are willing to tolerate millions of accidental deaths if that is what it takes to keep us speeding down the highway.
Consider, too, homeland security.
On the one hand, the more we spend on anti-terrorism measures (and the more inconvenience we are willing to tolerate), the safer we feel.
On the other, even though everyone agrees that a successful terrorist attack is unacceptable, there is clearly a limit to how much we are willing to spend (and how much inconvenience we are willing to put up with) to keep ourselves safe.
Why are we willing to calculate costs and benefits when it comes to traffic safety and terrorism, but not when devising policies to deal with global warming?
Perhaps it is because we experience the downside of excessive traffic regulation or security measures every day, while the downside of bad climate policy is more of an abstraction.
It shouldn’t be, for the risks posed by bad climate policy deserve just as much attention as the risks of worse-than-expected climate impacts – maybe more.
Remember how biofuel requirements were supposed to help reduce carbon emissions?
In fact, the artificially inflated demand for ethanol – and for the corn to manufacture it – wound up driving up food prices (which pushed roughly 30 million poor people into the ranks of the malnourished).
It also ate up more arable land, which led directly to the destruction of rain forests and generally created a situation that will result in more CO2 emissions over the next hundred years.
The biofuel lesson is salutary.
If we panic and make the wrong choices in response to global warming, we run the risk of leaving the world’s most vulnerable people – those who will overwhelmingly experience the worst effects of warming – even worse off.
If we are to have a constructive dialogue about the smartest policy responses to global warming, we need to replace our fixation on far-fetched, Armageddon scenarios with realism about the true costs of dealing with this challenge.
Princeton &#45;&#45; If anyone wanted evidence that we are not in the mental and political world of the interwar Great Depression, the German election result and its outcome – a stable government of the center-right - should be a clincher.  In interwar Germany, the Depression destroyed German democracy and led to the rise to power of Hitler and the National Socialists; in today’s Germany, the most severe economic crisis since the Second World War produced the reelection of Frau Merkel.
Conventional wisdom claims that incumbent parties and politicians are punished by voters in times of economic distress.  Throughout the campaign there was never any doubt about the position or tpopularity of Chancellor Angela Merkel. 
The interwar Depression led to the disintegration of liberal economic and political values.  In Germany in 2009 not only was there was no swing to political extremism of the right: there was no sign of any support for a radical right.  In the elections for regional parliaments, the small radical right parties (which have never been a feature of national politics) simply disappeared. 
The real victor of the campaign, with a vote that jumped up to 14.5% and a position in parliament that will determine the shape of the new coalition government, was the heir of classic German liberalism, the FDP.  It campaigned on a promise of tax reduction and of deregulation in order to stimulate the economic growth that Germany needs to get out of the economic crisis.
The real losers of the election were the Social Democrats, with a drop in support of 11% that is without precedent in the very stable history of German electoral behavior.  Some on the left claim that the SPD’s catastrophic result was the product of too close an engagement with liberalism and deregulation.  According to this view, the party is now paying the price for Chancellor Gerhard Schroeder’s successful attempts at economic reform in the early 2000’s.  It seems more likely that the party was punished for its lackluster electoral campaign, and for the negativity with which it tried to present the outcome of the election (the center-right coalition) as a threat to social peace in Germany.
In the interwar crisis of democracy, participation in elections surged as voters tried to protest against what the radical parties denounced as “the system”.  In Germany in 2009, electoral participation fell by 5%, to 72.5%.  Those voters who were disillusioned by politics simply thought that there was no point in voting.
The only point in common with the interwar results seems to be that economic crisis then as now strengthened the radical left.
But what a difference!  Then there was a powerful communist party, closely aligned with the interests and policies of the Soviet Union.  Now the party of protest is unambiguously the party of historical losers: in the East, of Germans who are nostalgic for the planned economy and society of state socialism; in the West, of critics of the SPD who lost a power struggle with Gerhard Schroeder. 
It is a party with no coherent program, but rather a compendium of popular and nationalist slogans.
It is a testimony of the responsibility and maturity of the German people that this miscellaneous alliance of the disaffected only attracted 12% of the vote.
If the election is clearly not a victory for political and economic radicalism, it would be equally misleading to interpret it as the triumph of the free market.  Throughout the campaign, there was an eerie degree of consensus about the desirability of central features of a distinctly European and more specifically German system of values.
What are those values?
A social market economy, rather than unbridled market capitalism; an export economy built on a large and technically innovative manufacturing base; a large network of small and medium sized enterprise, often family-owned, that is open to the global economy; a sense of environmental responsibility; and a suspicion of financially driven Anglo-Saxon style globalization and corporate capitalism.  Indeed the sense that Germany had the opportunity to show off the unique strengths of the “German model” was a key to Merkel’s appeal, and she repeatedly noted what a tough line she had taken against the position of banks.
In coming years, the German government is likely to be more vocal in European and global debates.  It is likely to present the German model as something that corresponds more closely to what the world needs in the aftermath of the financial crisis. 
Financial activity was concentrated largely in what the Europeans termed “Anglo-Saxon” economies: above all the United States and the United Kingdom, and a few small countries that tried, disastrously, to replicate a model of free-for-all finance such as Iceland and Ireland.  But the emerging markets that drive globalization in the early twenty-first century have a similar mix of export orientation and a prominent industrial base of small and medium-sized and frequently family-owned enterprises.  They have the problem today of trying to reconcile dynamic growth and social cohesion that was the problem of Germany in the past, and to which the German social model was and is held up as the answer.
Merkel’s new coalition will sit neatly alongside the new Japanese government of Yukio Hatoyama, which is also dedicated to finding a new and peculiarly Japanese model of economic growth.
These new national visions of economics in the twenty-first century are not simply turning in on themselves, or embarking on aggressive campaigns driven by xenophobic and racial nationalism – that was the world of the twentieth century.  In the world of the twenty-first century, models of social organization have to persuade rather than conquer.  The world looks for local or national solutions to global problems.  Frau Merkel won the election because she formulated a clear answer.
Three cheers for the new Nobel laureates in economics: Daniel Kahneman of Princeton University, and Vernon Smith of George Mason University in Virginia.
Like many Nobel prizes, these awards recognize not only the seminal work undertaken by Kahneman and Smith, but also the schools of thought they help to lead.
Kahneman, a psychologist, has demonstrated how individuals systematically behave in ways less rational than orthodox economists believe they do.
His research shows not only that individuals sometimes act differently than standard economic theories predict, but that they do so regularly, systematically, and in ways that can be understood and interpreted through alternative hypotheses, competing with those utilized by orthodox economists.
To most market participants - and indeed, ordinary observers -- this does not seem like big news.
Wall Street brokers who peddled stocks they knew to be garbage exploited the irrationality that Kahneman and Smith exposed.
Much of the mania that led to the bubble economy was based on exploiting investor psychology.
In fact, this irrationality is no news to the economics profession either.
John Maynard Keynes long ago described the stock market as based not on rational individuals struggling to uncover market fundamentals, but as a beauty contest in which the winner is the one who guesses best what the judges will say.
This year's Nobel prize celebrates a critique of simplistic market economics, just as last year's award (of which I was one of the three winners) did.
Last year's laureates emphasized that different market participants have different (and imperfect) information, and these asymmetries in information have profound impact on how an economy functions.
In particular, last year's laureates implied that markets were not, in general, efficient; that there was an important role for government to play.
Adam Smith's invisible hand -- the idea that free markets lead to efficiency as if by an invisible hand -- is invisible at least in part because it is not there.
This, too, is not news to those who work day after day in the market (and make their fortunes by taking advantage of and overcoming asymmetries in information).
For more than twenty years economists were enthralled to so called "rational expectations" models which assumed that all participants have the same (if not perfect) information and act perfectly rationally, that markets are perfectly efficient, that unemployment never exists (except when caused by greedy unions or government minimum wages), and where there is never any credit rationing.
That such models prevailed, especially in America's graduate schools, despite evidence to the contrary bears testimony to a triumph of ideology over science.
Unfortunately, students of these graduate programs now act as policymakers in many countries, and are trying to implement programs based on the ideas that have come to be called market fundamentalism.
Let me be clear: the rational expectations models made an important contribution to economics; the rigor which its supporters imposed on economic thinking helped expose the weaknesses many underlying hypotheses.
Good science recognizes its limitations, but the prophets of rational expectations have usually shown no such modesty.
Vernon Smith is a leader in the development of experimental economics, the idea that one could test many economic propositions in laboratory settings.
One reason that economics is such a difficult subject, and why there are so many disagreements among economists, is that economists cannot conduct controlled experiments.
Nature throws up natural experiments, but in most circumstances, so many things change so rapidly that it is often difficult to untangle what caused what.
In principle, in a laboratory, we can conduct controlled experiments, and therefore make more reliable inferences.
Critics of experimental economics worry that subjects bring to experimental situations modes of thought determined outside of the experiment, and thus that the experiments are not as clean and the inferences not as clear cut as in the physical sciences.
Nonetheless, economic experiments provide insights into a number of important issues, such as the improved design of auctions.
Most importantly, the irrationality of market participants, which was the focus of Kahneman's work, has been verified repeatedly in laboratory contexts.
Among the more amusing results that have come out of experimental economics are those concerning altruism and selfishness.
It appears (at least in experimental situations) that experimental subjects are not as selfish as economists have hypothesized--except for one group - the economists themselves.
Is it because economics as a discipline attracts individuals who are by nature more selfish or is it because economics helps shape individuals, making them more selfish?
The answer, almost certainly, is a little bit of both.
Presumably, future experimental research will help resolve the question of the relative importance of these two hypotheses.
The Nobel Prize signifies how important it is to study people and economies as they are, not as we want them to be.
Only by understanding better actual human behavior can we hope to design policies that will make our economies work better as well.
Is Eastern Europe's political pendulum about to run down?
Across Central Europe since 1989, elections have oscillated between right and left.
Is Hungary's slick young prime minister, Viktor Orban, poised to end all that?
A ruthless program to absorb his political rivals on the right has helped Orban's FIDESZ party become nearly equal in size to his Socialist rivals on the left.
Moreover, infighting among the Socialists has dented one of their biggest political advantages: the hard-headed discipline and political professionalism inherited from their Communist days.
Premier Orban's semi-successful efforts to unify the right under the banner of FIDESZ are unique among Eastern Europe's fractured and fractious rightist parties.
Since Communism's fall, center right parties in the Czech Republic, Hungary, Poland, and Slovakia have suffered from disunity and a lack of vision.
Despite the fact the region is still recovering from decades of communist mismanagement, the political right's fragmentation helped the political left, in some cases represented by former Communists, to win democratic elections regularly.
Some problems faced by Central Europe's right are similar to those the political right faces elsewhere in Europe, where social democratic parties expropriated many formerly liberal ideas to seize a monopoly of the political center.
In Central Europe this effect has been amplified by the fact that, regardless of ideological leanings, rulings parties have had to privatize the economy and, under pressure from the European Union, introduce reform measures that would, in a classical Western system, usually be undertaken by the political right.
Leftist parties in various Central European countries, indeed, have often turned out to be more successful in reforming because they, paradoxically, have greater legitimacy in this respect.
Many people believe that the Socialists would not privatize the economy or slash welfare systems if such measures were not absolutely necessary.
The most serious problem of Central Europe's political right is a lack of identity.
Although right-of-center politicians in Central European countries formally embrace traditional ideologies, for example, liberalism or conservatism, their electorates, unfamiliar with Western political philosophies, do not always understand the real meaning of those terms.
In various surveys, significant segments of Central European electorates describe themselves as ``rightist,'' but years of communist paternalism pushed the region's political center of gravity firmly to the left.
A person may describe him or herself as, for example, a liberal, yet at same time demand that the government continue subsidizing energy, education, or housing.
Under the communist regimes, ideologies became totally instrumental.
As during those years, many people now formally accept ideological labels but identify with them only as long as such an allegiance to a specific political current has tangible short-term benefits for them.
One consequence of this cynical treatment of political ideologies is the wild swings in voters' preferences seen in various Central European countries.
The problem of identity is made even worse by the fact that most Central European nations, where nation-building was retarded by Communism, easily succumb to nationalist sentiments that in turn are misused by some politicians.
Although such politicians often describe themselves as ``rightist,'' their real policies, such as, for, example, those of former Slovak Prime Minister Vladimir Meciar, are in fact demagogic populist or authoritarian.
The situation of the political right in each Central European country is also influenced by experiences that are rooted in history and tradition.
Political developments in Czechoslovakia during the last 20 years of communism set the Czech Republic and Slovakia apart from both Poland and Hungary.
While both the Polish and Hungarian communist parties experienced internal liberalization that allowed relatively large semi-official zones of activity outside communist control, Czechoslovakia after the Soviet-led invasion of 1968 became a rigid neo-Stalinist regime.
When the communist regimes collapsed in 1989, the communist parties of Poland and Hungary transformed themselves into credible democratic-left parties that became formidable opponents of the newly emerging political right.
No strong social democratic party in Czechoslovakia could emerge from the rigid Czechoslovak Communist Party.
In the absence of a credible democratic left party, Czech center-right politicians had the upper hand, and were relatively united, until 1997.
However, lack of a strong opposition corrupted the political right, which splintered into various groupings that cannot find a common language.
In Slovakia, where nationalist sentiments were an important political factor after 1989, the political spectrum has not yet coalesced along standard right-left political axis.
The main political battles occur between nationalist/populist forces, whose outlook have in essence been undemocratic, and forces that struggle for standard democracy.
The threat of return to power by Meciar forced all democrats, leftist or rightist, into one camp.
Even in this situation the political right has been quarrelsome, creating space for Meciar's possible return to power.
Hungary's political right has suffered mainly from differences between conservative and populist forces on the one hand, and traditional, mainly urban, liberals on the other.
Various rightist parties failed to decide whether the modus operandi on the political right should be traditional Western ideologies or a Hungarian brand of nationalist conservatism and populism.
Although the current governing coalition, consisting of conservatives and populists, has been successful, the real reckoning for Hungary's right may still be yet to come.
Poland's right poses the most difficult case.
Its problems originate in the communist era, when a trade union movement, which under normal circumstances should stand to the political left, became the main anti-communist opposition.
As a result, various political groups associated with the Solidarity trade union movement have, since Communism's fall, aspired to represent the political right, confusing the terms of political discourse.
Christian-democratic parties, associated with the Catholic Church, and the liberals have been to some extent marginalized.
The confusion has been made complete by the existence of relatively strong nationalist and populist parties that use the numerous Polish farmers as their electoral base.
As in other postcommunist countries, the main beneficiary of such a lack of unity has been the democratic left.
WARSAW – It was two decades ago this summer that communist rule began to implode from Tallinn in the Baltic to Tirana in the Adriatic, ushering in free elections, market reforms, and expanded civil liberties.
Since then, the countries of Central and Eastern Europe have come a long way.
Many are now members of the European Union.
My homeland, Poland, has a steady economy and a thriving media.
Yet Poland, like many of the other new democracies in our region, remains stuck in the past when it comes to the humane treatment of drug users.
Indeed, throughout the former Soviet bloc, there is a disturbing trend in using outdated, conservative, and heavy-handed policies to address drug abuse.
For example, Gdansk – the birthplace of the Solidarity movement – does not have a single methadone treatment center.
People must travel for three hours to get the medicine that is proven to control cravings and reduce the harms of drug use.
And they are the lucky ones.
Only 5% of opiate users in Poland have access to methadone at all, compared to 40% in Germany.
Instead of focusing on treatment that works, the Polish government chooses to give priority to long-term rehabilitation centers located in the depths of the countryside that have little, if anything, to do with evidence-based medicine.
Poland also chooses to treat possession of even the smallest quantities of drugs as criminal, as evidenced by the fact that 60% of people sentenced for drug possession in Poland are marijuana smokers.
Addressing drug use through criminalization and rehabilitation centers does nothing to curb demand, however, and usage rates have failed to decline.
By driving users underground, criminalization contributes to a deepening public-health crisis.
This pattern persists across Central and Eastern Europe, where governments have also opted to imprison drug users.
In Hungary, for example, the penal code calls for two years imprisonment for personal possession by a drug-dependent person.
In neighboring Slovakia, the penalty for personal possession is, as in Poland, up to three years.
This approach is not only inhumane, but also economically untenable: leaders in these countries should be encouraged to redirect scarce law enforcement, court, and prison resources towards more pressing causes.
Simply put, governments can no longer afford to drain precious time and money that could be better spent elsewhere by locking up people for drug-related offenses.
If Poland and its neighbors are to chart a new way forward, at least three things must happen.  First, these countries should look West for alternative, and more humane, drug policies.
A report released recently by the United Kingdom’s Drug Policy Commission correctly calls for a “smarter” drug policy that focuses on addressing associated violence rather than simply making arrests.
Officials in Central and Eastern Europe should pay heed to recent comments by the UK’s Home Office, which said that “harm reduction underpins every element of our approach to tackling this complex issue.”
Portugal recently went a step further in voting to decriminalize recreational drugs, including heroin and cocaine – a move that has led to a significant decline in drug-related deaths and a fall in new HIV infections.
Second, law-makers should listen to their constituents: a recent public awareness campaign by Gazeta Wyborcza , a leading Polish daily newspaper, collected more than 23,000 signatures in five days for a petition calling for changes to the current drug law.
The changes, modeled after Germany’s progressive policies, would stop punishing people for possessing small amounts of drugs for their own use, impose stricter penalties for dealers and provide more effective treatment for drug-dependent people.
In a step forward, a debate in the Polish parliament on the proposed drug law is set to start in September.
Young people should not start their working lives with criminal records because of personal possession.
Finally, at the European level, EU policymakers can help by encouraging member states to decriminalize possession of small amounts of drugs.
By freeing up resources devoted to enforcing policies against low-level users, countries can better tackle serious drug-supply issues and provide people with the effective treatment that they need and deserve.
BUDAPEST – This month marks the 20th anniversary of the reburial of Imre Nagy, the leader of Hungary’s failed anti-Soviet revolution of 1956.
The reinternment, organized by Hungary’s anti-communist opposition on the 31st anniversary of his execution, drew more than 100,000 attendees, heralding the beginning of the end of the country’s sclerotic regime.
We Hungarians, and Central Europe in general, have come far since those heady times, but the past 20 years have also given us much cause to question the path we took.
Hungary played a special role in the collapse of Communism, accelerating the process by opening its borders for East German refugees.
But democratic transformation in Hungary required an opposition strategy throughout the 1980’s: revolution wouldn’t work, as the Soviet invasion in 1956 showed.
Nor would internal reforms work, because the Soviets would intervene to save the system, as they did in 1968 in Czechoslovakia.
Instead, the new strategy was to sideline the issue of political power.
Rather than attacking Communist rule directly, we would create small islands of freedom, inter-connected social circles and associations, which, when the moment came, could all be connected in order to change the system.
In Hungary, several youth organizations existed and were aware of each other, so the political community that took part in the political changes in Hungary in 1989 was organized on this basis.
History also played a part in the success of the Hungarian transition.
The 1956 revolution was a real one, with barricades.
In no other Central European country did Communists experience the possibility of paying with their own lives for the suffering and oppression that they inflicted on others.
This historical experience was good for reform capability.
A new generation was also needed.
It appeared symbolically on June 16, 1989, when I had the opportunity to speak on behalf of the young generation.
A whole generation felt that the moment had come when Hungarians could at last determine their own future.
So, what kind of future did they determine?
The past 20 years can be divided into three phases.
First, a market economy was created, the rule of law established, and democratic institutions built.
Next, we applied for admission to NATO and prepared for European Union membership, with all of the institutional reforms that these goals implied.
The third phase was one of economic catch-up, which, unlike the first two phases, has not really been successful in Hungary, which today may even be falling back.
But, for Central Europe as a whole, the past 20 years have been the best since the Peace of Westphalia, with Slovakia and Slovenia even joining the euro zone.
Nevertheless, the 20th anniversary of the collapse of communism is overshadowed by the global financial and economic crisis.
And it is now clear that the biggest winners of globalization are no longer the Europeans or the Americans, but the Asians.
The world market is being re-divided – peacefully, because territories and markets are separated, so that no power occupies another power’s territory.
But Europe must nonetheless recognize the need to distinguish clearly between partners, competitors, and opponents, and to formulate a more sophisticated and articulated policy towards Russia, in particular.
For example, we Central Europeans are opponents when we do not accept Russia’s policy of renewing “spheres of interest” and “security zones.”
Moreover, after all that has happened in the past six months, Central Europeans can no longer look up to old countries representing the moral values of Western civilization.
This crisis was not caused by bad luck or some professional misunderstanding, but by character problems, especially in the United States and later Western Europe.
Money was stolen, not merely “mismanaged.”
Investments were not simply bad, but unacceptably risky.
The moral state of business leaders caused this crisis, and you cannot find Central Europeans among those leaders.
Central Europe has found itself in a completely new situation.
Crisis management measures undertaken in the Western world are practically cutting our countries off from the EU market.
In this situation, Central European countries must cooperate to defend their own interests, as well as their dream of a common Europe.
The question for the European elite is whether we believe in the work of the past 20 years, whether we believe in an integrated European market and an ever-widening European Community.
If not, then first the biggest and the strongest countries, and then the Central Europeans, will turn away from the European dream.
Those of us who believe that the past 20 years made sense, and that we are on the right track, are still the majority in Hungary.
Everyone in Europe and the world needs a unified, robust Europe.
If our faith is strong enough, we can survive this crisis without destroying what we have built together by opening our borders, destroying the Wall, unifying Germany, and completing our democratic transitions.
Any observer who reads the world's great international newspapers will probably think that Venezuela is in deep crisis.
With an oddball president who led a failed coup only to return to impose his brand of Cuban socialism cum Latin American tinhorn dictatorship cum political evangelism, poor Venezuela seems destined for a fall.
A paradox, indeed, haunts Venezuela: if people abroad have such a poor view of our country, then perhaps we are going to the dogs, regardless of what we see around us.
Of course, most foreign opinions about a country come from local sources.
A disproportionate share reflects the narrow group of people who speak English, travel abroad, and belong in the top income group - hardly an unbiased sample.
The power of the foreign press is worrisome for those with an interest in Venezuela's welfare, because perceptions affect realities, including foreign investment, risk premiums on debt, tourism and capital outflows.
Few argue that things are all wonderful with President Chávez.
Dogged by a small, disorganized, yet wily and persistent opposition that follows his every step and publicizes his frequent missteps, the President's popularity ratings have plummeted from above 80% in 1999 to half that today.
Any government expects its popularity to erode, especially in a society with as many intractable problems as Venezuela: unemployment, crime, high infant mortality and so on.
President Fox in Mexico, Cardoso in Brazil, De La Rúa in Argentina and Toledo in Peru aren't doing better in terms of popularity, but they seem better citizens of this globalized world and so are not taking the public beating that President Chávez is absorbing.
Chávez's popularity has fallen sharply since September 11 th , both because of his public comments and because of private sector shrieks following the publication of 49 laws issued under special executive powers and after limited consultation with parliament.
Business exasperation with the President's highhandedness led to the announcement of a one-day strike on December 10 th , as well as serious doubts over an international strategy that seemed to favor Osama Bin Laden over George Bush.
Venezuela's pro-American elites sprouted goose bumps when US Ambassador Hrinak was recalled to Washington for ``consultations'' about President Chávez's seeming Castro-style highjinks.
Who else would have shown Afghanistan's dead children on prime-time TV, while denouncing the use of terrorism to counter terrorism?
If the world is either with or against America, Chávez seems to be on the wrong side.
Intellectuals may be able to say the type of things he has said and get away with it, not chiefs of state.
Hard facts appear to support the international press depictions of Venezuela.
Poverty persists after three years of Chávez rule; there is a frightening crime rate and homeless children sniff glue on the streets despite a naive president's oath to house them.
But is Río any better?
The distinction lies in expectations and in Chávez's own silliness in thinking he could change things quickly with a big stick of good intentions and an army of inexperienced (and often opportunistic) followers invading an already pathetic state bureaucracy.
But other facts speak out.
Surveys show that only 25% of Venezuelans rate the government as poor or very poor, even though an overwhelming majority rejects the President's penchant for monopolizing the airwaves once a week, displacing their favorite soap operas.
They think he is overly aggressive, creating unwanted conflict, when what Venezuelans want is peace and calm.
Still, they give him credit - 68% of them - for having the power to resolve the country's principal problems.
It is rarely reported that, after 20 years of inflation averaging 30-40 % per year and with income-crunching peaks set at over 80%, prices have risen less under Chávez.
Indeed, inflation was 13% in 2001.
Venezuelans know that GDP has been growing modestly for two years, with private sector growth at over 5% in 2001.
Automobile sales rose 50%; employment levels improved slightly, especially in the formal sector.
After decades of exchange and price controls, the economy has enjoyed three years of open trade, free currency exchange and free prices.
Stores are full of goods.
Caracas is no Havana.
For the first time in history, the government has saved excess oil earnings for the next rainy day.
Foreign debt is among the lowest in Latin America compared to the size of the economy.
The National Assembly is negotiating a social security law that may turn out to be reasonable; a flap over the education law is giving way to agreements among warring parties.
So why do international financial markets rate Venezuela as riskier than all its neighbors, save for bankrupt Argentina?
It is a puzzle here.
Critics counter that the Chávez government's ``populism'' will cede to crisis when falling oil prices take their toll.
Unsustainable capital outflows bode poorly for future stability, fueled by doubts about Chávez, democracy and the future of capitalism.
Yet, with government spending at some 22% of GDP, charges of socialism fall flat.
These critics say that Chávez's insistence that the State hold the majority of shares in oil production will scare off investors, even though his Hydrocarbons Law is more liberal than the old one, especially where new gas projects and downstream activities are concerned.
The Land Law, although it is not very different from the forgotten one on the books for 40 years, is still portrayed as creating conditions that will starve investment in agriculture and cattle farming and marks a direct assault on private property.
What, then, is the truth about Venezuela?
The truth is that the country is facing difficult changes, zigzagging through complicated negotiations among competing and legitimate interests.
Without a strong opposition, the Chávez government would certainly veer too far left; without Chávez, it would have no keel at all.
Equilibrium requires that outsiders not tip the balance of a ship of state already enduring a rough ride.
The 10 warmest years on record have all occurred since 1990, and 2005 is likely to be the warmest ever.
This year, we’ve gotten a taste of the many kinds of dangers that lie ahead: more extreme hurricanes, massive droughts, forest fires, spreading infectious diseases, and floods.
The climate is changing, and more is yet to come.
The world’s governments will meet in Montreal at the end of November to plot the next steps, including specific measures that the world could adopt if the Bush administration abandoned its willful neglect of this critical issue.
Climate change is equated with “global warming,” but much more than warming is involved.
The rising concentration of carbon dioxide and other greenhouse gases is leading to more extreme storms, higher-intensity hurricanes, rising ocean levels, melting glaciers and ice sheets, droughts, floods and other climate changes.
Even the chemistry of the land and ocean is changing, with the ocean becoming more acidic – thus threatening coral reefs – as a result of higher carbon dioxide.
The specific patterns of change are not known precisely, but the risks of continuing on our current global course are widely appreciated.
Yet the United States has refused to sign the Kyoto Protocol, which does little to change the long-term course of events on the planet, since it calls for only small steps up to the year 2012.
Under the terms of the UN treaty on climate change, the signatories – virtually the whole world - are to gather each year to discuss the treaty’s implementation.
The conference in Montreal - the 11th such meeting - should look beyond 2012, so that the world gets onto a safe and sustainable long-term climate path.
The actions that are needed are difficult to introduce, because they go to the heart of the world’s use of energy, particularly its use of fossil fuels (coal, oil, and gas), which, when burned, release carbon dioxide – the key source of rising greenhouse gases – into the atmosphere.
Yet the world economy depends on fossil fuels, and developing countries will need to use more, not less, of them as their economies grow.
Even if the world runs out of oil and gas in the coming years, coal will prove to be plentiful, and solid coal can be converted at relatively low cost to liquid fuels for automobiles and other uses.
Unfortunately, clean, renewable energy sources that do not emit carbon dioxide, such as wind power and geothermal power, are not yet sufficient.
Solar power can be produced on the required scale but is too expensive under current technologies.
Nuclear power is relatively cheap, and could be plentiful, but poses huge dangers for increased proliferation of nuclear-weapons materials.
So: fossil fuels are plentiful, but harmful; renewable sources like wind are good for the climate but not plentiful.
Solar power is plentiful but not cheap.
Nuclear power is plentiful but not safe.
Improved technologies can offer a way out of this bind, but only if we think and act ahead.
There are two main kinds of technologies that look most promising.
The first is energy conservation through more fuel-efficient vehicles.
New hybrid automobiles, pioneered by Toyota, use both gasoline and electric power to boost gasoline efficiency by approximately two-fold.
A massive changeover to more fuel-efficient vehicles would make a big difference, especially as the numbers of vehicles on the road soars in China, India, and other developing countries.
The second big technology that could make a major difference is called “carbon capture and storage.”
The idea is to “capture” the carbon dioxide that is emitted in power plants and other big factories when fossil fuels are burned, thereby preventing it from entering the atmosphere.
The captured carbon is then pumped into underground storage sites such as empty oil fields and other suitable locations.
All of the key aspects of the technology – capturing the carbon dioxide, putting it into pipelines for shipment, and then depositing it underground – have already been demonstrated, but they have not yet been tried, and proven, on a large scale.
There is strong evidence, however, that it would not cost the world huge amounts to undertake large-scale carbon capture and storage.
The problem is timing.
The changeover of the world’s vehicles to hybrid and other efficient technologies will take decades, not years.
So will the changeover of power plants to carbon capture and storage.
If we procrastinate, the dangers posed by climate change will confront us as we talk, debate, and plan.
The world needs to start acting soon - very soon - if it is to head off the major threats.
All major regions of the world will need to be involved.
Today’s developing countries are not yet major emitters of carbon dioxide, but with economic growth they will become so.
Therefore, all countries, both developed and developing, need to do their part, with rich countries helping poor countries cover the financial costs of adjustment.
Plenty of carbon dioxide will be emitted into the atmosphere as the world’s climate negotiators fly to and from the Montreal meeting.
Let’s press our governments to make real progress when they meet; otherwise they will merely be adding to the problem.
Stanley Fischer’s looming departure as the IMF’s first deputy managing director marks the end of an era.
Indeed, all those who led that institution during the global crises of 1997-1998 (Fischer, Managing Director Michel Camdessus, director of research Michael Mussa, as well as the two men who directed events behind the scenes from the US Treasury, Robert Rubin and Larry Summers) are all gone or going.
Failures in Indonesia, Thailand, and Korea of 1997 were followed by failures in Russia and Brazil the next year: in those cases, attempts to maintain exchange rates at overvalued levels left taxpayers in those countries billions of dollars poorer.
Preserving exchange rates, however, provided vital time for people with money to get out at more favorable terms.
Only devaluation restored growth to these countries.
With each failure, the IMF’s credibility decreased.
Still, it thrashed about for solutions, each little more successful than before.
Sometimes the solution entailed precautionary lending, as in Brazil; another time it was a “bail-in” strategy that was eventually abandoned, as in Romania.
The last straws were this year’s crises in Turkey and Argentina.
Turkey’s panic came on the heels of Fischer saying that everything seemed on track.
Argentina, long an IMF poster child, was lauded for bringing down inflation and stabilizing its exchange rate.
In this fog of praise, the IMF ignored the fact that Argentina’s growth rate had stagnated and that double-digit unemployment persisted for half-a-decade.
Without growth, it would become increasingly difficult for Argentina to repay their huge loans.
As a result of these failures, a global consensus has emerged that the global financial crisis was mismanaged and that reforms are needed in the global economic architecture.
What is lacking now is consensus about what should be done.
The IMF seems to have learned much from its mistakes – at least rhetorically.
It now recognizes that the capital market liberalization which it pushed around the world incited huge instabilities and was a central factor in the global financial crisis.
It also recognizes that the way it restructured Indonesia’s banks led to a run on them , that it pursued excessively contractionary policies in East Asia, and that these policies deepened the downturns.
But the IMF has yet to ask itself why these mistakes occurred?
It has yet to translate its new rhetoric into policy.
The next IMF team should reflect on the following questions and lessons:
• Economics is not ideology but the practical employment of evidence and theory.
What evidence, for example, suggested that liberalizing capital markets in poor countries would deliver faster growth?
Before forcing changes on the international economic system, overwhelming evidence should support it.
What evidence suggested that high interest rates, in economies burdened by short term debt, would help stabilize exchange rates?
Before imposing policies with devastating consequences, strong evidence should show that the policies will work.
Saying that interest rates will eventually come down is not enough.
After all, you cannot “unbankrupt” a firm ruined by punishing interest rates.
• Greater intellectual coherence is needed.
Why shout that government should not intervene in markets, claiming that markets are efficient, yet intervene in currency markets?
• Economic reforms may entail pain, but the pain the poor must bear should not be minimized.
Why were billions of dollars available to bail-out banks, but a few million dollars for food and fuel subsidies for Indonesia’s poor could not be spared?
How was it that a few oligarchs could bleed Russia of billions of dollars through state-give aways of assets under privatization schemes encouraged by the IMF, but there was not enough money to pay miserly pensions to the aged?
The IMF, like it or not, is a public institution – despite its corporate speak.
In the IMF world, member countries are referred to as shareholders.
But IMF policies affect lives and economies in ways no corporation could ever do.
As a public institution, it should be guided by democratic principles.
When the World Bank sought private discussions with IMF on the policy implications of East Asia’s crisis, it was largely spurned.
When I sought public discussion – even after the crisis had settled – it was resisted.
Even debate about reforming the global financial architecture was stilted: only finance ministers and central bankers, it seems, are allowed a seat at the IMF table.
In behaving this way, the IMF rode roughshod over basic economic and ethical principles.
There are always trade-offs between policies.
Some are more advantageous to some groups; others represent greater risks.
Decisions about which policy to choose is a matter best left to a country’s political processes; they should not be usurped by international bureaucrats, no matter how competent.
For economists to misrepresent their policy decisions as mere technical matters violates basic ethical and professional precepts.
The irony of the IMF’s position over the past eight years is that, while the Clinton Administration advanced Third Way principles at home through an active government role in promoting growth, in the international arena America’s Treasury (directly and through the IMF) advanced views that reflected, with only slight variations, traditional market fundamentalism and trickle down economics, ideas which America itself had rejected.
Here, the new Bush administration shows greater intellectual coherence.
The Republicans criticized huge international bail-outs as “corporate welfare” before they took office, and in Turkey they basically stuck to their principles, though not enough to stop an IMF bail-out.
Whether the Bush team will continue to this line when American and not German banks are at risk is another matter.
The Bush administration and the new team at the IMF (when it arrives) have an opportunity to move away from the failed strategies for development, transition, and crises of the past.
The challenge is to craft policies based on economic science, not ideology, in an open and democratic manner, paying particular attention to the consequences for the poor.
Unfortunately, from what we have seen of domestic US policy of late, we cannot be sanguine.
CAMBRIDGE – A leadership transition is scheduled in two major autocracies in 2012.
Neither is likely to be a surprise.
Xi Jinping is set to replace Hu Jintao as President in China, and, in Russia, Vladimir Putin has announced that he will reclaim the presidency from Dmitri Medvedev.
Among the world’s democracies, political outcomes this year are less predictable.
Nicolas Sarkozy faces a difficult presidential re-election campaign in France, as does Barack Obama in the United States.
In the 2008 US presidential election, the press told us that Obama won because he had “charisma” – the special power to inspire fascination and loyalty.
If so, how can his re-election be uncertain just four years later?
Can a leader lose his or her charisma?
Does charisma originate in the individual, in that person’s followers, or in the situation?
Academic research points to all three.
Charisma proves surprisingly hard to identify in advance.
A recent survey concluded that “relatively little” is known about who charismatic leaders are.
Dick Morris, an American political consultant, reports that in his experience, “charisma is the most elusive of political traits, because it doesn’t exist in reality; only in our perception once a candidate has made it by hard work and good issues.”
Similarly, the business press has described many a CEO as “charismatic” when things are going well, only to withdraw the label when profits fall.
Political scientists have tried to create charisma scales that would predict votes or presidential ratings, but they have not proven fruitful.
Among US presidents, John F. Kennedy is often described as charismatic, but obviously not for everyone, given that he failed to capture a majority of the popular vote, and his ratings varied during his presidency.
Kennedy’s successor, Lyndon Johnson, lamented that he lacked charisma.
That was true of his relations with the public, but Johnson could be magnetic – even overwhelming – in personal contacts.
One careful study of presidential rhetoric found that even such famous orators as Franklin Roosevelt and Ronald Reagan could not count on charisma to enact their programs.
Charisma is more easily identified after the fact.
In that sense, the concept is circular.
It is like the old Chinese concept of the “mandate of heaven”: emperors were said to rule because they had it, and when they were overthrown, it was because they had lost it.
But no one could predict when that would happen.
Similarly, success is often used to prove – after the fact – that a modern political leader has charisma.
It is much harder to use charisma to predict who will be a successful leader.
Followers are more likely to attribute charisma to leaders when they feel a strong need for change, often in the context of a personal, organizational, or social crisis.
For example, the British public did not regard Winston Churchill as a charismatic leader in 1939, but, a year later, his vision, confidence, and communication skills gave him charisma, given Britons’ anxiety after the fall of France and the Dunkirk evacuation.
And then, in 1945, after the public’s focus had turned from winning the war to constructing a welfare state, Churchill was voted out of office.
His charisma did not predict defeat; the change in followers’ needs did.
In practice, charisma is a vague synonym for “personal magnetism.”
People vary in their ability to attract others, and their attraction depends partly on inherent traits, partly on learned skills, and partly on social context.
Some dimensions of personal attraction, such as appearance and non-verbal communication, can be tested.
Various studies show that people who are rated as attractive are treated more favorably than unattractive people.
One study finds that a handsome man enjoys an edge over an ugly rival that is worth 6-8% of the vote.
For women, the advantage is close to ten points.
Non-verbal signals account for a major part of human communications, and simple experiments have shown that some people communicate non-verbally better than others.
For example, a Princeton University study found that when people were shown images of two candidates in unfamiliar elections, they could predict the winners seven times out of ten.
A similar study at Harvard, in which people were shown 10-second silent video clips of 58 elections, found that viewers’ predictions explained 20% of the variation in the two-party vote – a more powerful variable than economic performance.
Ironically, the predictions became poorer when the sound was turned on.
In the 2008 election, Americans felt disillusioned by the Bush administration’s war in Iraq, and by the financial crisis that erupted two months before the vote.
Obama was an attractive young candidate who spoke well and projected a sense of hope for the future.
Clearly, this is one reason why Obama gained a reputation for charisma.
But part of his charisma was in the eyes of his followers.
People sometimes say of charisma that “we know it when we see it,” but we are also looking in a mirror.
As the economy worsened, unemployment rose, and Obama had to deal with the messy compromises of governing, the mirror became cloudier.
Charisma tells us something about a candidate, but it tells us even more about ourselves, the mood of our country, and the types of change we desire.
Hard economic times make it difficult to maintain charisma.
Obama faces the continuing challenges of unemployment and a recalcitrant Republican opposition, and Sarkozy must contend with similar problems.
When they are campaigning, however, their rhetoric will be freed from the need to compromise.
This year’s elections will be the true test of their charisma.
PRINCETON – As I tour the U.S. promoting my new book, The Life You Can Save: Acting Now to End World Poverty , I am often asked if this isn’t the wrong time to call on affluent people to increase their effort to end poverty in other countries.
I reply emphatically that it is not.
There is no doubt that the world economy is in trouble.
But if governments or individuals use this as an excuse to reduce assistance to the world’s poorest people, they would only multiply the seriousness of the problem for the world as a whole.
The financial crisis has been more damaging for the poor than it has been for the rich.
Without in any way minimizing the economic and psychological blow that people experience when they lose their jobs, the unemployed in affluent countries still have a safety net, in the form of social security payments, and usually free health care and free education for their children.
They also have sanitation and safe drinking water.
The poor in developing countries have none of these benefits, which proves fatal for an estimated 18 million of them each year.
That’s a higher annual death toll than during World War II, and it’s easier to prevent.
Of those who die from avoidable, poverty-related causes, nearly ten million, according to UNICEF, are children under five.
They die from diseases like measles, diarrhea, and malaria that are easy and inexpensive to treat or prevent.
We may feel the pain of falling back from a level of affluence to which we have grown accustomed, but most people in developed countries are still, by historical standards, extraordinarily well off.
Have you, in the past week, bought a bottle of water, a beer, or a coffee when tap water was available at no cost?
If you did, that’s a luxury that the world’s poorest billion people can’t afford, because they have to live for an entire day on what you spent on just one of those drinks.
One reason that we can afford to increase the amount of aid we give is that the amount we are giving now is insignificant in comparison to what we spend on other things.
The United States government, for example, spends about $22 billion on foreign aid, while Americans privately donate perhaps another $10 billion. 
Compared to the $787 billion stimulus package signed by President Barack Obama last month, that $32 billion is trivial.
It’s also less than $0.25 for every $100 that Americans earn.
Of course, some nations do better: Sweden, Norway, Denmark, The Netherlands, and Luxembourg all exceed the United Nations target of allocating the equivalent of 0.7% of gross national income in foreign aid.
But even $0.70 for every $100 is still not a lot with which to confront one of the great moral problems of our age.
If extreme poverty is allowed to increase, it will give rise to new problems, including new diseases that will spread from countries that cannot provide adequate health care to those that can.
Poverty will lead to more migrants seeking to move, whether legally or not, to rich nations.
When there is eventually an economic recovery, the global economy will be smaller than it would be if all the world’s people could take part in it.
Nor is the global financial crisis a justification for the world’s leaders failing to keep their word.
Nearly nine years ago, at the Millennium Development Summit in New York, the leaders of 180 countries, including all the major affluent nations, promised that by 2015 they would together achieve the Millennium Development Goals.
These goals include halving the proportion of the world’s people living in poverty and ensuring that children everywhere receive a full primary education.
Since that meeting in 2000, the commitments made by most nations have fallen short of what is required, and 2015 is now only six years away.
If we cut back on aid, we will fail to keep our promise, and poorer countries will learn, once again, that rich countries’ actions fall short of their inspiring rhetoric about reducing world poverty.
That is not a good basis for future cooperation between rich and poor countries on issues such as climate change.
Finally, if anything good comes out of this global financial crisis, it will be a reassessment of our basic values and priorities.
We need to recognize that what really matters isn’t buying more and more consumer goods, but family, friends, and knowing that we are doing something worthwhile with our lives.
Helping to reduce the appalling consequences of world poverty should be part of that reassessment.
After two years of off-and-on nuclear brinkmanship, India and Pakistan are once again talking about how to settle their differences rather than issuing threats and rattling nuclear sabers.
But do the talks now underway have any better chance of success than the countless failed negotiations that have marked the past fifty years?
On November 25, 2003, India and Pakistan agreed to a cease-fire along the Line of Control (LoC), the international border that divides Indian Kashmir from Pakistani Kashmir, as well as the actual ground control (AGPL) in strategic Siachen region.
The cease-fire thus covers a huge area: the 778-kilometer LoC, the 150-kilometer AGPL and the 198-kilometer international border.
This should pave the way for a meaningful dialogue at the South Asian Association for Regional Cooperation (SAARC) meeting to be held in Islamabad between January 4-5.
Moreover, Pakistan has partly conceded its demand--which dates to the creation of India and Pakistan a little more than half a century ago--for an internationally supervised referendum in Kashmir to determine the province's sovereignty.
A brave concession, no doubt, but India has a more rigorous criterion for believing that Pakistan is truly serious about reaching a peaceful agreement: it wants Pakistan to dismantle the infrastructure of cross-border terrorism--in particular, the training camps for Kashmiri separatists and their international jihadi brethren.
Reining in the violent militants who keep the Kashmiri pot boiling, however, is difficult on both sides.
In India and Pakistan, Kashmir is the national question.
Every Indian and Pakistani government embraces the Kashmiri cause, both as a useful device to divert attention from their failures and because they fear what their publics might do if they were seen as surrendering to the traditional enemy on so vital an issue.
With Pakistan's economy in a tailspin, and with the jihad culture of so many young Pakistanis undermining the country's international credibility, moderate voices are at long last breaking through.
The eminent columnist Amin M. Lakhani recently argued in the Dawn , Pakistan's largest-circulation newspaper, that "Pakistan's singular preoccupation with Kashmir...has been self-defeating.
Domestically, it has thwarted the country's economic, social and political development.
Internationally, [it] has diminished the country's stature and left its reputation smeared.
Even its spiritual development has been warped by the proliferation, popularization, and increase in relative power...of religious groups that represent an intolerant, militant, and gender-based interpretation of Islam."
Lakhani points to the bitter irony that Pakistan's 143 million people have sacrificed much in demanding democratic rights and self-determination for Kashmir's 13 million people, while enjoying precious few of those same rights at home for the past 55 years. Can Pakistan demand, with a straight face, rights for another people that it constantly denies to its own?
That is the sad and awful question Lakhani asks, but alas he offers no answer.
Undoubtedly, at the forthcoming summit between the leaders of the two countries, India's Prime Minister Atal Behari Vajpayee will not miss any opportunity to ask the same question of his Pakistani counterpart.
Obviously, Pakistani Prime Minister Mir Zafarulla Khan Jamali will be able to offer no satisfactory answer to this question--not when he has to go home and report to his boss, the General-turned-President Pervez Musharraf.
But Vajpayee should try to do more than score points off Musharraf.
That Pakistan may be willing to put aside its demand for an international referendum in Kashmir is the first real sign of compromise to be seen over the issue in decades.
Vajpayee should test Pakistan's seriousness on this point.
There is clearly room for doubt: on December 18, President Musharraf declared that, at the Islamabad SAARC summit, he would demand a UN-sponsored plebiscite in Kashmir.
The very next day, however, Pakistan's Foreign Office spokesman, Masood Khan, claimed that President Musharraf was prepared to drop this demand.
India needs to know if Musharraf is sincere.
If so, the foundation for a real dialogue to defuse the struggle over Kashmir may be possible.
But Musharraf has good reasons to talk out of both sides of his mouth at this stage.
He recently survived two assassination attempts, and Islamists accuse him of entering into a "bargain" with the infidel enemy, India.
Such rhetoric makes it hard to be optimistic about the outcome of the summit.
Musharraf's vulnerable domestic position makes him probably the last man who can resolve with India the core issue of Kashmir.
Seen as too pro-American because of his support of the recent war in Afghanistan, Musharraf needs to burnish his nationalist credentials.
Posturing over Kashmir remains the best way of doing that.
Vajpayee, for his part, has hinted that if Pakistan wants a decent deal, it ought to make one with him, as he might be the last Indian leader for a long time who is willing to compromise even a little on the issue.
The hard men of his nationalist Bharatiya Janata Party (BJP) look likely to do as they are told.
But the BJP has never shown any sign of solicitude towards Pakistan's interests.